{
  "name": "Blog Generate For Website",
  "nodes": [
    {
      "parameters": {
        "rule": {
          "interval": [
            {
              "field": "weeks",
              "triggerAtDay": [
                0,
                5,
                1,
                3
              ]
            }
          ]
        }
      },
      "type": "n8n-nodes-base.scheduleTrigger",
      "typeVersion": 1.2,
      "position": [
        -1088,
        -128
      ],
      "id": "bc1f343c-3c41-4c30-938e-48170b25e1b6",
      "name": "Schedule Trigger"
    },
    {
      "parameters": {
        "operation": "google_trends",
        "q": "={{ $json.detectedTopic }}",
        "additionalFields": {
          "hl": "id",
          "geo": "ID",
          "data_type": "RELATED_QUERIES",
          "date": "now 7-d",
          "output": "json"
        },
        "requestOptions": {}
      },
      "type": "n8n-nodes-serpapi.serpApi",
      "typeVersion": 1,
      "position": [
        -1312,
        656
      ],
      "id": "2405b305-daf8-4000-bf1b-5d3944ad2847",
      "name": "Google_trends search",
      "credentials": {
        "serpApi": {
          "id": "8FFecYlNOeGkrbD6",
          "name": "SerpApi account"
        }
      },
      "disabled": true
    },
    {
      "parameters": {
        "updates": [
          "message"
        ],
        "additionalFields": {}
      },
      "type": "n8n-nodes-base.telegramTrigger",
      "typeVersion": 1.2,
      "position": [
        -1312,
        -368
      ],
      "id": "a4154a33-cee6-425d-b11b-35bd97ec5a9d",
      "name": "Telegram Trigger",
      "webhookId": "7dac2f87-48f4-4e3b-8ed2-79b715263d5d",
      "credentials": {
        "telegramApi": {
          "id": "MvduJAmkBx25KJ9G",
          "name": "Telegram account"
        }
      }
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "18307fba-dae9-4d16-91a3-0e9aa68813c8",
              "leftValue": "={{ $json.message.text }}",
              "rightValue": "BlogStart",
              "operator": {
                "type": "string",
                "operation": "contains"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        -1088,
        -368
      ],
      "id": "5b4e26cb-6b11-44e6-9d3d-ea176215beac",
      "name": "If"
    },
    {
      "parameters": {
        "chatId": "={{ $('Telegram Trigger').item.json.message.chat.id }}",
        "text": "silahkan gunakan 'BlogStart' untuk mencari related query",
        "additionalFields": {}
      },
      "type": "n8n-nodes-base.telegram",
      "typeVersion": 1.2,
      "position": [
        -864,
        -416
      ],
      "id": "a4519df4-1a4a-4452-ac45-6cb876b69efa",
      "name": "Send a text message",
      "webhookId": "70dd2d1b-5fd2-4fae-a49d-c4b0e82c4609",
      "credentials": {
        "telegramApi": {
          "id": "MvduJAmkBx25KJ9G",
          "name": "Telegram account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Ambil data dari input\nconst context = $('Save Related Query').first().json.organic_results;\n// Generate angka acak antara 0 dan 9\nconst randomIndex = Math.floor(Math.random() * context.length);\n\n// Ambil query berdasarkan index\nconst ContextFinal = context[randomIndex].title + context[randomIndex].snippet;\n\nreturn {\n  json: {\n    ContextFinal,\n    index: randomIndex,\n  }\n};\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        928,
        -272
      ],
      "id": "7de5b071-11bb-4871-8da5-cda23020ac2d",
      "name": "Random Related Query"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "c403788c-2e66-4175-b772-335678c92b78",
              "name": "organic_results[0].title",
              "value": "={{ $json.organic_results[0].title }}",
              "type": "string"
            },
            {
              "id": "26ed5b7e-72d5-4fcf-b42d-96e15d0a03c5",
              "name": "organic_results[0].snippet",
              "value": "={{ $json.organic_results[0].snippet }}",
              "type": "string"
            },
            {
              "id": "f82d97aa-d746-42ee-b77e-f1ef56bd6e68",
              "name": "organic_results[1].title",
              "value": "={{ $json.organic_results[1].title }}",
              "type": "string"
            },
            {
              "id": "beddef4a-d6c6-4990-96da-d443b894d2bb",
              "name": "organic_results[1].snippet",
              "value": "={{ $json.organic_results[1].snippet }}",
              "type": "string"
            },
            {
              "id": "fa861f54-ee62-4fa1-8360-4cf166b29aac",
              "name": "organic_results[2].title",
              "value": "={{ $json.organic_results[2].title }}",
              "type": "string"
            },
            {
              "id": "ce283683-4ce4-4033-ae7b-6487d9a5dab2",
              "name": "organic_results[2].snippet",
              "value": "={{ $json.organic_results[2].snippet }}",
              "type": "string"
            },
            {
              "id": "575787e8-e976-42c0-a751-00b65084874d",
              "name": "organic_results[3].title",
              "value": "={{ $json.organic_results[3].title }}",
              "type": "string"
            },
            {
              "id": "039324a4-ffb3-4205-97ab-647e05f1aea9",
              "name": "organic_results[3].snippet",
              "value": "={{ $json.organic_results[3].snippet }}",
              "type": "string"
            },
            {
              "id": "c73f46f0-08e5-4edd-b329-3fb08c5c6aef",
              "name": "organic_results[4].title",
              "value": "={{ $json.organic_results[4].title }}",
              "type": "string"
            },
            {
              "id": "ab87c85b-c432-405b-99fb-04e53ec8ccc2",
              "name": "organic_results[4].snippet",
              "value": "={{ $json.organic_results[4].snippet }}",
              "type": "string"
            },
            {
              "id": "84cde64d-d295-4793-a909-1ebd2dea4da9",
              "name": "organic_results[5].title",
              "value": "={{ $json.organic_results[5].title }}",
              "type": "string"
            },
            {
              "id": "3f2ae277-5150-4515-b32d-9a82c32afc79",
              "name": "organic_results[5].snippet",
              "value": "={{ $json.organic_results[5].snippet }}",
              "type": "string"
            },
            {
              "id": "0518e00d-b658-4591-959b-2885fc09145c",
              "name": "organic_results[6].title",
              "value": "={{ $json.organic_results[6].title }}",
              "type": "string"
            },
            {
              "id": "e7f97f9f-c6aa-4398-8439-9ba09d1ee32a",
              "name": "organic_results[6].snippet",
              "value": "={{ $json.organic_results[6].snippet }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        -864,
        880
      ],
      "id": "cd58cd42-e6f0-4814-a179-71c3e147e7fa",
      "name": "Save Related Query",
      "disabled": true
    },
    {
      "parameters": {
        "jsCode": "// Create comprehensive prompt using all available context\nconst topic = $input.first().json.ContextFinal;\nconst topicMain =  $('Aggregate').first().json.content[$input.first().json.index]\n\n// Create comprehensive prompt for blog generation\nconst prompt = `Write a comprehensive, well-researched blog post about  ${topic} + ${topicMain} in markdown format.\n\nPlease create a detailed blog post with the following structure:\n1. An engaging introduction that hooks the reader\n2. Main content sections with clear subheadings (use ## for main sections, ### for subsections)\n3. Include relevant examples, case studies, or practical applications\n4. If it's a technical topic, include code examples with proper syntax highlighting\n5. Add tips, best practices, or actionable advice where appropriate\n6. A strong conclusion that summarizes key points\n\nWriting Guidelines:\n- Write 1000-1500 words minimum\n- Use a professional yet accessible tone\n- Include bullet points or numbered lists where helpful\n- Add relevant external linking suggestions (use placeholder links)\n- Make it SEO-friendly with natural keyword usage\n- Ensure content is original and valuable to readers\n- Use Bahasa Indonesia\n\nIMPORTANT: \n- Do NOT include frontmatter (title, date, etc.) - this will be added separately\n- Start directly with the introduction\n- Use proper markdown formatting\n- Make the content engaging and informative`;\n\nreturn {\n  topic: topic,\n  prompt: prompt,\n};"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1152,
        -80
      ],
      "id": "cf20a018-cc47-4718-b446-7c5ea1d39df1",
      "name": "Create Comprehensive Prompt"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://openrouter.ai/api/v1/chat/completions",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpBearerAuth",
        "sendBody": true,
        "contentType": "raw",
        "body": "={\n  \"model\": \"deepseek/deepseek-r1-0528:free\",\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"{{ $json.prompt }}\"\n    }\n  ]\n  \n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        1600,
        64
      ],
      "id": "24d35575-5c10-43be-abd9-a00db3a323d0",
      "name": "Open Router Chat",
      "executeOnce": true,
      "credentials": {
        "httpBearerAuth": {
          "id": "vhGrSTMSr0eiYEuS",
          "name": "DEEPSEEK TOKEN"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "const defaultTopics = [\n  \"Teknologi\", \"Inovasi\", \"AI dan Otomatisasi\", \"Startup Indonesia\",\n  \"Pendidikan\", \"Ekonomi Digital\", \"Gaya Hidup\", \"Lingkungan\",\n  \"Game & E-sports\", \"Kecerdasan Buatan\", \"Sains Populer\", \"Keamanan Siber\"\n];\n\n// Pilih satu topik secara acak dari daftar\nconst randomDefaultTopic = defaultTopics[Math.floor(Math.random() * defaultTopics.length)];\n\nconst request = $input?.first()?.json?.message?.text || \"\";\nconst match = request.match(/#q\\s+([^\\n:]+)/i);\n\n// Gunakan hasil pencocokan atau fallback ke topik acak\nconst topic = match ? match[1].trim() : randomDefaultTopic;\n\nreturn {\n  json: {\n    detectedTopic: topic,\n  }\n};\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1312,
        880
      ],
      "id": "a5228070-2d0c-4a5e-8e8d-604dcdd44db9",
      "name": "Select Topic",
      "disabled": true
    },
    {
      "parameters": {
        "jsCode": "// Initialize content and metadata\nconst date = new Date().toISOString().split('T')[0];\nconst contentRaw = $('Open Router Chat').first().json.choices[0].message.content;\nconst category = $('Random Category').first().json.randomWord;\n// const excerpt = $('Create Comprehensive Prompt').first().json.topic;\n\nconst cleaned = contentRaw\n  .replace(/^##\\s*/gm, '')             // hapus heading ## \n  .replace(/\\*\\*(.*?)\\*\\*/g, '$1')     // hapus bold markdown **\n  .replace(/\\\\n/g, ' ')                // hilangkan newline escape \\n\n  .replace(/\\s+/g, ' ')                // rapikan spasi ganda\n  .trim();\n\nconst excerpt = cleaned.split(' ').slice(0, 15).join(' ') + '...';\nconst dateNow = date;\n\n\nlet content = '';\nconst reasoning = $('Open Router Chat').first().json.choices[0].message.reasoning;\n\nif (typeof contentRaw === 'string') {\n  // Cek apakah mengandung \"\\n\" (escaped)\n  if (contentRaw.includes('\\\\n')) {\n    content = contentRaw.replace(/\\\\n/g, '\\n').trim();\n  } else {\n    content = contentRaw.trim();\n  }\n}\n\nconst shortSlug = excerpt\n  .split(' ')\n  .slice(0, 5)\n  .join(' ')\n  .toLowerCase()\n  .replace(/[^a-z0-9\\s-]/g, '')       // Remove special characters\n  .replace(/\\s+/g, '-')               // Replace spaces with hyphens\n  .replace(/-+/g, '-')                // Collapse multiple hyphens\n  .replace(/^-|-$/g, '');             // Trim leading/trailing hyphens\n\nconst title = $('parsed json').first().json.judul;\nconst smallimg = $input.first().json.results[0].urls.small\nconst safeExcerpt = excerpt.replace(/\"/g, '\\\\\"');\n\nconst imageBlock = `<p align=\"center\">\n  <img src=\"${smallimg}\" alt=\"${shortSlug}\" />\n</p>\\n\\n`;\n\n// Create frontmatter block\nconst frontmatter = `---\ntitle: \"${title}\"\ndate: \"${dateNow}\"\ncategory: \"${category}\"\nexcerpt: \"${safeExcerpt}\"\nimage: \"${smallimg}\"\n---\n`;\n\n// Combine with content\nconst fullMarkdown = frontmatter + '\\n' + imageBlock + content;\n\n// Generate filename\nconst filename = `${dateNow}-${shortSlug}.md`;\n\n// Return result\nreturn {\n  frontmatter: frontmatter,\n  topic: excerpt,\n  filename: filename,\n  content: fullMarkdown,\n  reasoning: reasoning\n};\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2496,
        16
      ],
      "id": "7edf543e-6ff3-4ead-99f4-88ef2b22f3ea",
      "name": "Markdown Output"
    },
    {
      "parameters": {
        "resource": "file",
        "owner": {
          "__rl": true,
          "value": "yumanuralfath",
          "mode": "name"
        },
        "repository": {
          "__rl": true,
          "value": "NextPortoYuma",
          "mode": "list",
          "cachedResultName": "NextPortoYuma",
          "cachedResultUrl": "https://github.com/yumanuralfath/NextPortoYuma"
        },
        "filePath": "=src/content/blog/{{ $('Markdown Output').item.json.filename }}",
        "fileContent": "={{ $('Markdown Output').item.json.content }}",
        "commitMessage": "=feat(blog): add blog {{ $('Markdown Output').item.json.filename }} from n8n"
      },
      "type": "n8n-nodes-base.github",
      "typeVersion": 1.1,
      "position": [
        3168,
        112
      ],
      "id": "f05f0b29-e2ff-417d-9f6d-2d2601906869",
      "name": "Create a blog post",
      "webhookId": "c5719ac2-a1de-4fcd-a2ee-c3f47d3ed853",
      "credentials": {
        "githubApi": {
          "id": "IvseB6BFRYkcLWJg",
          "name": "GitHub account"
        }
      }
    },
    {
      "parameters": {
        "owner": {
          "__rl": true,
          "value": "yumanuralfath",
          "mode": "name"
        },
        "repository": {
          "__rl": true,
          "value": "NextPortoYuma",
          "mode": "list",
          "cachedResultName": "NextPortoYuma",
          "cachedResultUrl": "https://github.com/yumanuralfath/NextPortoYuma"
        },
        "events": [
          "deployment"
        ],
        "options": {
          "insecureSSL": false
        }
      },
      "type": "n8n-nodes-base.githubTrigger",
      "typeVersion": 1,
      "position": [
        -1312,
        -864
      ],
      "id": "a0941422-c2ab-4d07-9af7-dcd06ce3634a",
      "name": "Github Trigger",
      "webhookId": "9815cd89-cc7c-411d-807f-c5712f038955",
      "credentials": {
        "githubApi": {
          "id": "IvseB6BFRYkcLWJg",
          "name": "GitHub account"
        }
      }
    },
    {
      "parameters": {
        "chatId": "1282266650",
        "text": "🚀  Success Comit Github",
        "additionalFields": {}
      },
      "type": "n8n-nodes-base.telegram",
      "typeVersion": 1.2,
      "position": [
        -1088,
        -864
      ],
      "id": "10edef85-aea4-40fb-8852-47c553db443a",
      "name": "Send a text message2",
      "webhookId": "b441ccf0-5469-42f9-b75b-099f77cb08e7",
      "credentials": {
        "telegramApi": {
          "id": "MvduJAmkBx25KJ9G",
          "name": "Telegram account"
        }
      }
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "3092563c-8736-427d-8253-dde44dd37e37",
              "leftValue": "={{ $node[\"Create a blog post\"].json[\"commit\"][\"url\"] }}  ",
              "rightValue": "",
              "operator": {
                "type": "string",
                "operation": "exists",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        3392,
        112
      ],
      "id": "9ec3bb26-4dda-422b-b30b-6ef1d646f555",
      "name": "check github"
    },
    {
      "parameters": {
        "chatId": "1282266650",
        "text": "=🤖 Ai Thought:  {{ $('Markdown Output').item.json.reasoning }}\n🔗 Commit URL: {{ $('Create a blog post').item.json.commit.html_url }}",
        "additionalFields": {}
      },
      "type": "n8n-nodes-base.telegram",
      "typeVersion": 1.2,
      "position": [
        3616,
        16
      ],
      "id": "3af5b87d-fd24-42fe-9487-64bc00d8196e",
      "name": "Send a text message3",
      "webhookId": "e5e97383-bca6-421a-9e8d-7f6634d9210d",
      "credentials": {
        "telegramApi": {
          "id": "MvduJAmkBx25KJ9G",
          "name": "Telegram account"
        }
      }
    },
    {
      "parameters": {
        "chatId": "1282266650",
        "text": "=failed 😫❌",
        "additionalFields": {}
      },
      "type": "n8n-nodes-base.telegram",
      "typeVersion": 1.2,
      "position": [
        3616,
        208
      ],
      "id": "4ed735ce-dd71-4a5e-894c-765f1989f3a3",
      "name": "Send a text message4",
      "webhookId": "e5e97383-bca6-421a-9e8d-7f6634d9210d",
      "credentials": {
        "telegramApi": {
          "id": "MvduJAmkBx25KJ9G",
          "name": "Telegram account"
        }
      }
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://openrouter.ai/api/v1/chat/completions",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpBearerAuth",
        "sendBody": true,
        "contentType": "raw",
        "body": "={\n  \"model\": \"deepseek/deepseek-r1-0528:free\",\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"Anda adalah seorang penulis blog profesional. Tugas Anda adalah membuat judul blog yang menarik, relevan, dan SEO-friendly dalam Bahasa Indonesia. Selalu berikan respons dalam format JSON yang valid tanpa tambahan teks atau penjelasan.\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"Buatkan satu judul blog yang menarik dan SEO-friendly dalam Bahasa Indonesia untuk topik: {{ $json.topic }}\\n\\nPersyaratan judul:\\n- Maksimal 60 karakter untuk SEO\\n- Menarik perhatian pembaca\\n- Relevan dengan topik\\n- Menggunakan kata kunci yang tepat\\n\\nRespond ONLY with valid JSON in this exact format:\\n{\\\"judul\\\":\\\"your title here\\\"}\"\n    }\n  ]\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -1312,
        432
      ],
      "id": "063ba97d-b1f0-41b8-8ba7-f3f1f5c9861b",
      "name": "Title Search",
      "credentials": {
        "httpBearerAuth": {
          "id": "vhGrSTMSr0eiYEuS",
          "name": "DEEPSEEK TOKEN"
        }
      },
      "disabled": true
    },
    {
      "parameters": {
        "jsCode": "let judulRaw = $input.first().json.choices[0].message.content.trim();\n\n// Hapus blok kode markdown jika ada\nif (judulRaw.startsWith(\"```json\") || judulRaw.startsWith(\"```\")) {\n  judulRaw = judulRaw.replace(/^```(?:json)?\\s*/i, \"\").replace(/```$/, \"\").trim();\n}\n\nconst parsed = JSON.parse(judulRaw);\n\nreturn {\n  judul: parsed.judul\n};\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1600,
        -176
      ],
      "id": "82e64b1e-5dfb-4b92-9f63-635a1071041b",
      "name": "parsed json",
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [
        1824,
        16
      ],
      "id": "0a102669-146c-41ed-9ca2-fa96f01e3358",
      "name": "Merge"
    },
    {
      "parameters": {
        "url": "=https://api.unsplash.com/search/photos?query={{ $json.randomWord }}&client_id=IGsXX_-Q6GXNYeisLAIB4OVqnqq2QwTiNvNJ6duH9ek",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        2272,
        16
      ],
      "id": "829cb2c0-398a-4a98-b469-dcd2d018e2cb",
      "name": "HTTP Request"
    },
    {
      "parameters": {
        "operation": "sendAndWait",
        "chatId": "1282266650",
        "message": "=Silahkan pilih topik yang ingin di post:\n0. {{ $json.title[0] }}\n1. {{ $json.title[1] }}\n2. {{ $json.title[2] }}\n3. {{ $json.title[3] }}\n4.{{ $json.title[4] }}\n5.{{ $json.title[5] }}\n6.{{ $json.title[6] }}\n7.{{ $json.title[7] }}\n8.{{ $json.title[8] }}\n9.{{ $json.title[9] }}\n10.{{ $json.title[10] }}\n11.{{ $json.title[11] }}\n12.{{ $json.title[12] }}\n13.{{ $json.title[13] }}\n14.{{ $json.title[14] }}\n15.{{ $json.title[15] }}\n16.{{ $json.title[16] }}\n17.{{ $json.title[17] }}\n18.{{ $json.title[18] }}\n19.{{ $json.title[19] }}\n20.{{ $json.title[20] }}\n21.{{ $json.title[21] }}\n22.{{ $json.title[22] }}\n23.{{ $json.title[23] }}\n24.{{ $json.title[24] }}\n25.{{ $json.title[25] }}\n26.{{ $json.title[26] }}\n27.{{ $json.title[27] }}\n28.{{ $json.title[28] }}\n29.{{ $json.title[29] }}\n30.{{ $json.title[30] }}\n31.{{ $json.title[31] }}",
        "responseType": "freeText",
        "options": {
          "limitWaitTime": {
            "values": {
              "resumeAmount": 45,
              "resumeUnit": "minutes"
            }
          }
        }
      },
      "type": "n8n-nodes-base.telegram",
      "typeVersion": 1.2,
      "position": [
        480,
        -176
      ],
      "id": "d7ae2552-990c-4805-a9fc-e1b9d4eebb3c",
      "name": "Select Menu",
      "webhookId": "6e2c2cc7-f56e-49ff-b9df-7c0c597ee7fe",
      "credentials": {
        "telegramApi": {
          "id": "MvduJAmkBx25KJ9G",
          "name": "Telegram account"
        }
      }
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "209c5b47-597d-4af3-9ffe-99df493ff0d0",
              "leftValue": "={{ $json.data.text }}",
              "rightValue": "^(0|[1-9]|[12][0-9]|3[01])$",
              "operator": {
                "type": "string",
                "operation": "regex"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        704,
        -176
      ],
      "id": "826d84ed-a53d-49af-984f-74470471185f",
      "name": "If1"
    },
    {
      "parameters": {
        "chatId": "1282266650",
        "text": "=Karena kamu tidak menjawab atau jawaban valid maka:\n🔍 Query yang dipilih:{{ $json.randomQuery }}\n📝 Query Index: {{ $json.index }} ",
        "additionalFields": {}
      },
      "type": "n8n-nodes-base.telegram",
      "typeVersion": 1.2,
      "position": [
        1152,
        -320
      ],
      "id": "ed681f05-dc58-4aa2-9ed5-08bb07e3024d",
      "name": "Send valid query gacha",
      "webhookId": "70dd2d1b-5fd2-4fae-a49d-c4b0e82c4609",
      "credentials": {
        "telegramApi": {
          "id": "MvduJAmkBx25KJ9G",
          "name": "Telegram account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// // const risingQueries = $('Save Related Query').first().json.related_queries.rising;\n// const context = $('Aggregate').first().json.title;\n\n// const indexStr = $input.first().json.data.text\n// const index = parseInt(indexStr, 31);\n\n// const ContextFinal = context[index];\n\n// return {\n//   json: {\n//     ContextFinal,\n//     index: index,\n//   }\n// };\n\n// Ambil context\nconst context = $('Aggregate').first().json.title;\n\n// Ambil index string dari input\nconst indexStr = $input.first().json.data.text;\n\n// Pastikan hanya angka 0–31\nconst regex = /^(0|[1-9]|[12][0-9]|3[01])$/;\n\nlet index = null;\nif (regex.test(indexStr)) {\n  index = parseInt(indexStr, 10); \n} else {\n  throw new Error(`Index tidak valid: ${indexStr}. Harus antara 0–31.`);\n}\n\nconst ContextFinal = context[index];\n\nreturn {\n  json: {\n    ContextFinal,\n    index\n  }\n};\n\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        928,
        -32
      ],
      "id": "36d5a02a-2e9a-47dc-bacf-b12d88ae38aa",
      "name": "input query"
    },
    {
      "parameters": {
        "q": "={{ $json.detectedTopic }}",
        "location": "Indonesia",
        "additionalFields": {
          "google_domain": "google.com",
          "gl": "id",
          "hl": "id"
        },
        "requestOptions": {}
      },
      "type": "n8n-nodes-serpapi.serpApi",
      "typeVersion": 1,
      "position": [
        -1088,
        880
      ],
      "id": "3ee0aec4-e17a-42cc-9f7a-8fef30be9b2d",
      "name": "Google search",
      "credentials": {
        "serpApi": {
          "id": "8FFecYlNOeGkrbD6",
          "name": "SerpApi account"
        }
      },
      "disabled": true
    },
    {
      "parameters": {
        "chatId": "1282266650",
        "text": "=꧁𓊈𒆜{{ $json.judul }}𒆜𓊉꧂\n──── ୨୧ ────\n{{ $('Create Comprehensive Prompt').item.json.topic }}\n────୨ৎ────",
        "additionalFields": {}
      },
      "type": "n8n-nodes-base.telegram",
      "typeVersion": 1.2,
      "position": [
        1824,
        -224
      ],
      "id": "cdfde522-5b46-4b1f-9f23-de1e34d0771b",
      "name": "Send a text message1",
      "webhookId": "82c3e7d4-6dc8-484c-99f6-872e7a33d53f",
      "credentials": {
        "telegramApi": {
          "id": "MvduJAmkBx25KJ9G",
          "name": "Telegram account"
        }
      }
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://openrouter.ai/api/v1/chat/completions",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpBearerAuth",
        "sendBody": true,
        "contentType": "raw",
        "body": "={\n  \"model\": \"deepseek/deepseek-chat-v3-0324:free\",\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"Anda adalah seorang penulis blog profesional. Tugas Anda adalah membuat judul blog yang menarik, relevan, dan SEO-friendly dalam Bahasa Indonesia. Selalu berikan respons dalam format JSON yang valid tanpa tambahan teks atau penjelasan.\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"Buatkan satu judul blog yang menarik dan SEO-friendly dalam Bahasa Indonesia untuk judul ini: {{ $json.topic }}\\n\\nPersyaratan judul:\\n- Maksimal 60 karakter untuk SEO\\n- Menarik perhatian pembaca\\n- Relevan dengan topik\\n- Menggunakan kata kunci yang tepat\\n\\nRespond ONLY with valid JSON in this exact format:\\n{\\\"judul\\\":\\\"your title here\\\"}\"\n    }\n  ]\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        1376,
        -176
      ],
      "id": "5eb6ca3a-5906-4a60-a18a-b53ba2b20a75",
      "name": "Title",
      "credentials": {
        "httpBearerAuth": {
          "id": "vhGrSTMSr0eiYEuS",
          "name": "DEEPSEEK TOKEN"
        }
      }
    },
    {
      "parameters": {
        "operation": "sendAndWait",
        "chatId": "1282266650",
        "message": "={{ $json.frontmatter }}",
        "approvalOptions": {
          "values": {
            "approvalType": "double"
          }
        },
        "options": {
          "limitWaitTime": {
            "values": {
              "resumeAmount": 30,
              "resumeUnit": "minutes"
            }
          }
        }
      },
      "type": "n8n-nodes-base.telegram",
      "typeVersion": 1.2,
      "position": [
        2720,
        16
      ],
      "id": "aebdfe97-5bcc-4e32-a111-d6ad884beced",
      "name": "Send message and wait for response1",
      "webhookId": "f15268cf-e352-4d2e-a1dd-179276e10858",
      "credentials": {
        "telegramApi": {
          "id": "MvduJAmkBx25KJ9G",
          "name": "Telegram account"
        }
      }
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "80fba905-9c58-4502-8edc-ee4e7b57113b",
              "leftValue": "={{ $json.data.approved }}",
              "rightValue": "",
              "operator": {
                "type": "boolean",
                "operation": "false",
                "singleValue": true
              }
            },
            {
              "id": "ef371332-0de4-4282-9814-d0bbeaa66c35",
              "leftValue": "={{ $json.data.approved }}",
              "rightValue": "",
              "operator": {
                "type": "boolean",
                "operation": "exists",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        2944,
        16
      ],
      "id": "5ff430e5-a74e-49d0-9a25-0ccfd6e6d603",
      "name": "If4"
    },
    {
      "parameters": {
        "chatId": "1282266650",
        "text": "❎ Decline Success and stop the workflow",
        "additionalFields": {}
      },
      "type": "n8n-nodes-base.telegram",
      "typeVersion": 1.2,
      "position": [
        3168,
        -80
      ],
      "id": "1125936b-aa22-492f-beb2-691e8ab20598",
      "name": "Send a text message5",
      "webhookId": "8408d1a8-e0ae-4ef1-85fd-33b5d18ed038",
      "credentials": {
        "telegramApi": {
          "id": "MvduJAmkBx25KJ9G",
          "name": "Telegram account"
        }
      }
    },
    {
      "parameters": {
        "content": "DISIMPAN BUAT NTAR KALAU DIPAKE LAGI",
        "height": 80,
        "width": 224
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -1072,
        208
      ],
      "id": "2e5cab53-17d0-4dea-8f80-aed9d772f96d",
      "name": "Sticky Note"
    },
    {
      "parameters": {
        "owner": {
          "__rl": true,
          "value": "yumanuralfath",
          "mode": "name"
        },
        "repository": {
          "__rl": true,
          "value": "yumana_api",
          "mode": "list",
          "cachedResultName": "yumana_api",
          "cachedResultUrl": "https://github.com/yumanuralfath/yumana_api"
        },
        "events": [
          "deployment"
        ],
        "options": {
          "insecureSSL": false
        }
      },
      "type": "n8n-nodes-base.githubTrigger",
      "typeVersion": 1,
      "position": [
        -1312,
        -640
      ],
      "id": "a9d3ec6e-d875-4a8e-b823-fc6487e47768",
      "name": "Github Trigger1",
      "webhookId": "9815cd89-cc7c-411d-807f-c5712f038955",
      "credentials": {
        "githubApi": {
          "id": "IvseB6BFRYkcLWJg",
          "name": "GitHub account"
        }
      }
    },
    {
      "parameters": {
        "chatId": "1282266650",
        "text": "🚀  Success Comit Github",
        "additionalFields": {}
      },
      "type": "n8n-nodes-base.telegram",
      "typeVersion": 1.2,
      "position": [
        -1088,
        -640
      ],
      "id": "4f16a524-61fc-4e79-a7e0-2aa874c84204",
      "name": "Send a text message7",
      "webhookId": "b441ccf0-5469-42f9-b75b-099f77cb08e7",
      "credentials": {
        "telegramApi": {
          "id": "MvduJAmkBx25KJ9G",
          "name": "Telegram account"
        }
      }
    },
    {
      "parameters": {
        "fieldToSplitOut": "rss",
        "options": {}
      },
      "id": "1f41b75a-459e-4bb1-b4f6-aedb9fc97918",
      "name": "Split Out",
      "type": "n8n-nodes-base.splitOut",
      "position": [
        -640,
        -176
      ],
      "typeVersion": 1
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "b8c00469-890b-4b5b-8e2e-2ad9ec2d0815",
              "name": "rss",
              "type": "array",
              "value": "=[\n  \"https://feeds.bbci.co.uk/news/technology/rss.xml\",\n  \"https://www.wired.com/feed/rss\",\n  \"https://www.technologyreview.com/topnews.rss\",\n  \"https://techcrunch.com/feed/\",\n\"https://www.marktechpost.com/feed/\",\n\"https://hackernoon.com/feed\",\n\"https://www.artificialintelligence-news.com/feed/\"\n]\n"
            }
          ]
        },
        "options": {}
      },
      "id": "b401dcff-7294-47a7-807b-7e3a9d7a5e22",
      "name": "Set Tech News RSS Feeds",
      "type": "n8n-nodes-base.set",
      "position": [
        -864,
        -176
      ],
      "typeVersion": 3.4
    },
    {
      "parameters": {
        "url": "={{ $json.rss }}",
        "options": {
          "ignoreSSL": false
        }
      },
      "id": "48fde0fd-b1da-497d-8099-857c6c6cbbff",
      "name": "Read RSS News Feeds",
      "type": "n8n-nodes-base.rssFeedRead",
      "position": [
        -416,
        -176
      ],
      "typeVersion": 1.1
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "e9f27ceb-c5f2-4997-8cb1-67576a7bb337",
              "name": "title",
              "type": "string",
              "value": "={{ $json.title }}"
            },
            {
              "id": "4c4f9417-40f2-4fb0-9976-d09f5984680f",
              "name": "content",
              "type": "string",
              "value": "={{ $json['content:encodedSnippet'] ?? $json.contentSnippet}}"
            },
            {
              "id": "e1986bac-054e-4240-ba50-536dbcd27337",
              "name": "date",
              "type": "string",
              "value": "={{ $json.isoDate}}"
            },
            {
              "id": "9566e23c-ac30-4d66-abbd-889f322688b7",
              "name": "link",
              "type": "string",
              "value": "={{ $json.link }}"
            },
            {
              "id": "61203b8d-7198-4087-83dc-83ac83afa5b1",
              "name": "categories",
              "type": "string",
              "value": "={{ $json.categories }}"
            }
          ]
        },
        "options": {}
      },
      "id": "b1924c5f-7300-45bf-b11f-25ff8afe70f5",
      "name": "Set and Normalize Fields",
      "type": "n8n-nodes-base.set",
      "position": [
        32,
        -176
      ],
      "typeVersion": 3.4
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "version": 2,
            "leftValue": "",
            "caseSensitive": true,
            "typeValidation": "strict"
          },
          "combinator": "and",
          "conditions": [
            {
              "id": "dda47c0b-b0b2-46f0-a469-cd1b0e1b8152",
              "operator": {
                "type": "dateTime",
                "operation": "after"
              },
              "leftValue": "={{ $json.isoDate }}",
              "rightValue": "={{ $now.minus(1,\"days\") }}"
            }
          ]
        },
        "options": {}
      },
      "id": "75f312fa-e307-4102-bc18-46ce9fb97ce0",
      "name": "Filter",
      "type": "n8n-nodes-base.filter",
      "position": [
        -192,
        -176
      ],
      "typeVersion": 2.2
    },
    {
      "parameters": {
        "fieldsToAggregate": {
          "fieldToAggregate": [
            {
              "fieldToAggregate": "title"
            },
            {
              "fieldToAggregate": "content"
            },
            {
              "fieldToAggregate": "link"
            },
            {
              "fieldToAggregate": "categories"
            }
          ]
        },
        "options": {
          "mergeLists": false
        }
      },
      "type": "n8n-nodes-base.aggregate",
      "typeVersion": 1,
      "position": [
        256,
        -176
      ],
      "id": "98f41aa4-513c-455d-aed8-034dbe19ae62",
      "name": "Aggregate"
    },
    {
      "parameters": {
        "jsCode": "// Ambil array string dan parse jadi array JS\nconst keywordsStr = $('Aggregate').first().json.categories[$('input query').first().json.index];\nconst keywords = JSON.parse(keywordsStr);\n\n// Pilih satu kata acak\nfunction getRandomKeyword() {\n  const index = Math.floor(Math.random() * keywords.length);\n  return keywords[index];\n}\n\n// Contoh penggunaan\nconst randomWord = getRandomKeyword();\n\nreturn {\n  json: {\n    randomWord\n  }\n};\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2048,
        16
      ],
      "id": "9459310f-59d9-40d3-b1e3-5b2711a35e5d",
      "name": "Random Category"
    }
  ],
  "pinData": {
    "Google_trends search": [
      {
        "json": {
          "search_metadata": {
            "id": "6880d4882771432c3b8a344b",
            "status": "Success",
            "json_endpoint": "https://serpapi.com/searches/57006ad6645ee5fd/6880d4882771432c3b8a344b.json",
            "created_at": "2025-07-23 12:24:40 UTC",
            "processed_at": "2025-07-23 12:24:40 UTC",
            "google_trends_url": "https://trends.google.com/trends/embed/explore/RELATED_QUERIES?hl=en&tz=420&req=%7B%22comparisonItem%22%3A%5B%7B%22keyword%22%3A%22teknologi%22%2C%22geo%22%3A%22ID%22%2C%22time%22%3A%22now+7-d%22%7D%5D%2C%22category%22%3A0%2C%22property%22%3A%22%22%7D",
            "raw_html_file": "https://serpapi.com/searches/57006ad6645ee5fd/6880d4882771432c3b8a344b.html",
            "prettify_html_file": "https://serpapi.com/searches/57006ad6645ee5fd/6880d4882771432c3b8a344b.prettify",
            "total_time_taken": 4.91
          },
          "search_parameters": {
            "engine": "google_trends",
            "q": "teknologi",
            "hl": "en",
            "geo": "ID",
            "date": "now 7-d",
            "tz": "420",
            "data_type": "RELATED_QUERIES"
          },
          "related_queries": {
            "rising": [
              {
                "query": "apa peran fisika dalam teknologi komunikasi khususnya pada penggunaan gelombang elektromagnetik",
                "value": "Breakout",
                "extracted_value": 5750,
                "link": "https://trends.google.com/trends/explore?q=apa+peran+fisika+dalam+teknologi+komunikasi+khususnya+pada+penggunaan+gelombang+elektromagnetik&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=apa+peran+fisika+dalam+teknologi+komunikasi+khususnya+pada+penggunaan+gelombang+elektromagnetik&tz=420"
              },
              {
                "query": "jelaskan hubungan antara sudut kemiringan bidang miring dan percepatan benda yang bergerak di atasnya tanpa gesekan",
                "value": "Breakout",
                "extracted_value": 5100,
                "link": "https://trends.google.com/trends/explore?q=jelaskan+hubungan+antara+sudut+kemiringan+bidang+miring+dan+percepatan+benda+yang+bergerak+di+atasnya+tanpa+gesekan&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=jelaskan+hubungan+antara+sudut+kemiringan+bidang+miring+dan+percepatan+benda+yang+bergerak+di+atasnya+tanpa+gesekan&tz=420"
              },
              {
                "query": "apa peran ilmu fisika dalam pembangkit listrik tenaga air",
                "value": "+4,300%",
                "extracted_value": 4300,
                "link": "https://trends.google.com/trends/explore?q=apa+peran+ilmu+fisika+dalam+pembangkit+listrik+tenaga+air&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=apa+peran+ilmu+fisika+dalam+pembangkit+listrik+tenaga+air&tz=420"
              },
              {
                "query": "apa keunikan warna mermaid design pada reno 14?",
                "value": "+4,250%",
                "extracted_value": 4250,
                "link": "https://trends.google.com/trends/explore?q=apa+keunikan+warna+mermaid+design+pada+reno+14?&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=apa+keunikan+warna+mermaid+design+pada+reno+14%3F&tz=420"
              },
              {
                "query": "teknologi apa yang membuat layar reno 14 series responsif?",
                "value": "+4,050%",
                "extracted_value": 4050,
                "link": "https://trends.google.com/trends/explore?q=teknologi+apa+yang+membuat+layar+reno+14+series+responsif?&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=teknologi+apa+yang+membuat+layar+reno+14+series+responsif%3F&tz=420"
              },
              {
                "query": "kelebihan desain reno14 proses finishing menciptakan efek warna sisik mermaid adalah",
                "value": "+3,800%",
                "extracted_value": 3800,
                "link": "https://trends.google.com/trends/explore?q=kelebihan+desain+reno14+proses+finishing+menciptakan+efek+warna+sisik+mermaid+adalah&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=kelebihan+desain+reno14+proses+finishing+menciptakan+efek+warna+sisik+mermaid+adalah&tz=420"
              },
              {
                "query": "penyebab adanya inovasi teknologi untuk mengatasi limbah plastik adalah",
                "value": "+3,800%",
                "extracted_value": 3800,
                "link": "https://trends.google.com/trends/explore?q=penyebab+adanya+inovasi+teknologi+untuk+mengatasi+limbah+plastik+adalah&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=penyebab+adanya+inovasi+teknologi+untuk+mengatasi+limbah+plastik+adalah&tz=420"
              },
              {
                "query": "bagaimana hukum 1 newton berlaku pada gerak mobil di jalan datar tanpa gesekan",
                "value": "+3,450%",
                "extracted_value": 3450,
                "link": "https://trends.google.com/trends/explore?q=bagaimana+hukum+1+newton+berlaku+pada+gerak+mobil+di+jalan+datar+tanpa+gesekan&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=bagaimana+hukum+1+newton+berlaku+pada+gerak+mobil+di+jalan+datar+tanpa+gesekan&tz=420"
              },
              {
                "query": "apa dampak perubahan sosial terhadap struktur keluarga",
                "value": "+3,450%",
                "extracted_value": 3450,
                "link": "https://trends.google.com/trends/explore?q=apa+dampak+perubahan+sosial+terhadap+struktur+keluarga&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=apa+dampak+perubahan+sosial+terhadap+struktur+keluarga&tz=420"
              },
              {
                "query": "jelaskan rumusan profil pelajar pancasila",
                "value": "+2,650%",
                "extracted_value": 2650,
                "link": "https://trends.google.com/trends/explore?q=jelaskan+rumusan+profil+pelajar+pancasila&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=jelaskan+rumusan+profil+pelajar+pancasila&tz=420"
              },
              {
                "query": "revolusi industri pertama kali terjadi di...",
                "value": "+2,200%",
                "extracted_value": 2200,
                "link": "https://trends.google.com/trends/explore?q=revolusi+industri+pertama+kali+terjadi+di...&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=revolusi+industri+pertama+kali+terjadi+di...&tz=420"
              },
              {
                "query": "apa teknologi baterai yang digunakan reno 14 series?",
                "value": "+1,250%",
                "extracted_value": 1250,
                "link": "https://trends.google.com/trends/explore?q=apa+teknologi+baterai+yang+digunakan+reno+14+series?&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=apa+teknologi+baterai+yang+digunakan+reno+14+series%3F&tz=420"
              },
              {
                "query": "apa teknologi baterai yang digunakan reno 14 series",
                "value": "+1,100%",
                "extracted_value": 1100,
                "link": "https://trends.google.com/trends/explore?q=apa+teknologi+baterai+yang+digunakan+reno+14+series&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=apa+teknologi+baterai+yang+digunakan+reno+14+series&tz=420"
              },
              {
                "query": "apa yang kamu ketahui tentang informatika",
                "value": "+900%",
                "extracted_value": 900,
                "link": "https://trends.google.com/trends/explore?q=apa+yang+kamu+ketahui+tentang+informatika&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=apa+yang+kamu+ketahui+tentang+informatika&tz=420"
              },
              {
                "query": "perubahan ekonomi cara memenuhi kebutuhan hidup",
                "value": "+500%",
                "extracted_value": 500,
                "link": "https://trends.google.com/trends/explore?q=perubahan+ekonomi+cara+memenuhi+kebutuhan+hidup&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=perubahan+ekonomi+cara+memenuhi+kebutuhan+hidup&tz=420"
              },
              {
                "query": "ekonomi cara memenuhi kebutuhan hidup",
                "value": "+500%",
                "extracted_value": 500,
                "link": "https://trends.google.com/trends/explore?q=ekonomi+cara+memenuhi+kebutuhan+hidup&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=ekonomi+cara+memenuhi+kebutuhan+hidup&tz=420"
              },
              {
                "query": "perubahan sistem pemerintahan cara mengatur masyarakat",
                "value": "+500%",
                "extracted_value": 500,
                "link": "https://trends.google.com/trends/explore?q=perubahan+sistem+pemerintahan+cara+mengatur+masyarakat&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=perubahan+sistem+pemerintahan+cara+mengatur+masyarakat&tz=420"
              },
              {
                "query": "pengertian teknologi perkantoran",
                "value": "+450%",
                "extracted_value": 450,
                "link": "https://trends.google.com/trends/explore?q=pengertian+teknologi+perkantoran&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=pengertian+teknologi+perkantoran&tz=420"
              },
              {
                "query": "teknologi veteriner adalah",
                "value": "+400%",
                "extracted_value": 400,
                "link": "https://trends.google.com/trends/explore?q=teknologi+veteriner+adalah&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=teknologi+veteriner+adalah&tz=420"
              },
              {
                "query": "sistem pemerintahan cara mengatur masyarakat",
                "value": "+400%",
                "extracted_value": 400,
                "link": "https://trends.google.com/trends/explore?q=sistem+pemerintahan+cara+mengatur+masyarakat&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=sistem+pemerintahan+cara+mengatur+masyarakat&tz=420"
              },
              {
                "query": "apa yang dimaksud dengan informatika",
                "value": "+400%",
                "extracted_value": 400,
                "link": "https://trends.google.com/trends/explore?q=apa+yang+dimaksud+dengan+informatika&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=apa+yang+dimaksud+dengan+informatika&tz=420"
              },
              {
                "query": "mengapa kapal laut dengan banyak muatan dapat mengapung di atas air",
                "value": "+350%",
                "extracted_value": 350,
                "link": "https://trends.google.com/trends/explore?q=mengapa+kapal+laut+dengan+banyak+muatan+dapat+mengapung+di+atas+air&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=mengapa+kapal+laut+dengan+banyak+muatan+dapat+mengapung+di+atas+air&tz=420"
              },
              {
                "query": "perubahan sosial",
                "value": "+170%",
                "extracted_value": 170,
                "link": "https://trends.google.com/trends/explore?q=perubahan+sosial&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=perubahan+sosial&tz=420"
              },
              {
                "query": "dampak positif teknologi",
                "value": "+160%",
                "extracted_value": 160,
                "link": "https://trends.google.com/trends/explore?q=dampak+positif+teknologi&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=dampak+positif+teknologi&tz=420"
              },
              {
                "query": "ilmu pengetahuan dan teknologi",
                "value": "+110%",
                "extracted_value": 110,
                "link": "https://trends.google.com/trends/explore?q=ilmu+pengetahuan+dan+teknologi&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=ilmu+pengetahuan+dan+teknologi&tz=420"
              }
            ],
            "top": [
              {
                "query": "teknologi informasi",
                "value": "100",
                "extracted_value": 100,
                "link": "https://trends.google.com/trends/explore?q=teknologi+informasi&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=teknologi+informasi&tz=420"
              },
              {
                "query": "teknologi adalah",
                "value": "90",
                "extracted_value": 90,
                "link": "https://trends.google.com/trends/explore?q=teknologi+adalah&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=teknologi+adalah&tz=420"
              },
              {
                "query": "contoh teknologi",
                "value": "78",
                "extracted_value": 78,
                "link": "https://trends.google.com/trends/explore?q=contoh+teknologi&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=contoh+teknologi&tz=420"
              },
              {
                "query": "teknologi digital",
                "value": "67",
                "extracted_value": 67,
                "link": "https://trends.google.com/trends/explore?q=teknologi+digital&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=teknologi+digital&tz=420"
              },
              {
                "query": "dampak teknologi",
                "value": "63",
                "extracted_value": 63,
                "link": "https://trends.google.com/trends/explore?q=dampak+teknologi&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=dampak+teknologi&tz=420"
              },
              {
                "query": "perkembangan teknologi",
                "value": "59",
                "extracted_value": 59,
                "link": "https://trends.google.com/trends/explore?q=perkembangan+teknologi&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=perkembangan+teknologi&tz=420"
              },
              {
                "query": "teknologi pendidikan",
                "value": "56",
                "extracted_value": 56,
                "link": "https://trends.google.com/trends/explore?q=teknologi+pendidikan&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=teknologi+pendidikan&tz=420"
              },
              {
                "query": "perubahan teknologi",
                "value": "41",
                "extracted_value": 41,
                "link": "https://trends.google.com/trends/explore?q=perubahan+teknologi&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=perubahan+teknologi&tz=420"
              },
              {
                "query": "teknologi informatika",
                "value": "32",
                "extracted_value": 32,
                "link": "https://trends.google.com/trends/explore?q=teknologi+informatika&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=teknologi+informatika&tz=420"
              },
              {
                "query": "jurusan teknologi",
                "value": "31",
                "extracted_value": 31,
                "link": "https://trends.google.com/trends/explore?q=jurusan+teknologi&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=jurusan+teknologi&tz=420"
              },
              {
                "query": "apa itu teknologi",
                "value": "31",
                "extracted_value": 31,
                "link": "https://trends.google.com/trends/explore?q=apa+itu+teknologi&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=apa+itu+teknologi&tz=420"
              },
              {
                "query": "informatika",
                "value": "30",
                "extracted_value": 30,
                "link": "https://trends.google.com/trends/explore?q=informatika&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=informatika&tz=420"
              },
              {
                "query": "dampak negatif teknologi",
                "value": "25",
                "extracted_value": 25,
                "link": "https://trends.google.com/trends/explore?q=dampak+negatif+teknologi&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=dampak+negatif+teknologi&tz=420"
              },
              {
                "query": "jurnal teknologi",
                "value": "25",
                "extracted_value": 25,
                "link": "https://trends.google.com/trends/explore?q=jurnal+teknologi&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=jurnal+teknologi&tz=420"
              },
              {
                "query": "teknologi pangan",
                "value": "25",
                "extracted_value": 25,
                "link": "https://trends.google.com/trends/explore?q=teknologi+pangan&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=teknologi+pangan&tz=420"
              },
              {
                "query": "teknologi ai",
                "value": "24",
                "extracted_value": 24,
                "link": "https://trends.google.com/trends/explore?q=teknologi+ai&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=teknologi+ai&tz=420"
              },
              {
                "query": "teknologi pertanian",
                "value": "23",
                "extracted_value": 23,
                "link": "https://trends.google.com/trends/explore?q=teknologi+pertanian&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=teknologi+pertanian&tz=420"
              },
              {
                "query": "ilmu pengetahuan dan teknologi",
                "value": "23",
                "extracted_value": 23,
                "link": "https://trends.google.com/trends/explore?q=ilmu+pengetahuan+dan+teknologi&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=ilmu+pengetahuan+dan+teknologi&tz=420"
              },
              {
                "query": "manfaat teknologi",
                "value": "21",
                "extracted_value": 21,
                "link": "https://trends.google.com/trends/explore?q=manfaat+teknologi&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=manfaat+teknologi&tz=420"
              },
              {
                "query": "pengertian teknologi",
                "value": "21",
                "extracted_value": 21,
                "link": "https://trends.google.com/trends/explore?q=pengertian+teknologi&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=pengertian+teknologi&tz=420"
              },
              {
                "query": "rekayasa teknologi",
                "value": "20",
                "extracted_value": 20,
                "link": "https://trends.google.com/trends/explore?q=rekayasa+teknologi&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=rekayasa+teknologi&tz=420"
              },
              {
                "query": "teknologi informasi dan komunikasi",
                "value": "20",
                "extracted_value": 20,
                "link": "https://trends.google.com/trends/explore?q=teknologi+informasi+dan+komunikasi&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=teknologi+informasi+dan+komunikasi&tz=420"
              },
              {
                "query": "perubahan sosial",
                "value": "18",
                "extracted_value": 18,
                "link": "https://trends.google.com/trends/explore?q=perubahan+sosial&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=perubahan+sosial&tz=420"
              },
              {
                "query": "dampak positif teknologi",
                "value": "16",
                "extracted_value": 16,
                "link": "https://trends.google.com/trends/explore?q=dampak+positif+teknologi&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=dampak+positif+teknologi&tz=420"
              },
              {
                "query": "informasi adalah",
                "value": "16",
                "extracted_value": 16,
                "link": "https://trends.google.com/trends/explore?q=informasi+adalah&date=now+7-d&geo=ID",
                "serpapi_link": "https://serpapi.com/search.json?data_type=RELATED_QUERIES&date=now+7-d&engine=google_trends&geo=ID&hl=en&q=informasi+adalah&tz=420"
              }
            ]
          }
        }
      }
    ],
    "Telegram Trigger": [
      {
        "json": {
          "update_id": 145487850,
          "message": {
            "message_id": 312,
            "from": {
              "id": 1282266650,
              "is_bot": false,
              "first_name": "Yuma",
              "last_name": "Nur Alfath",
              "username": "yumana20",
              "language_code": "en"
            },
            "chat": {
              "id": 1282266650,
              "first_name": "Yuma",
              "last_name": "Nur Alfath",
              "username": "yumana20",
              "type": "private"
            },
            "date": 1754292307,
            "text": "BlogStart"
          }
        }
      }
    ],
    "Select Menu": [
      {
        "json": {
          "data": {
            "text": "31"
          }
        }
      }
    ],
    "Set Tech News RSS Feeds": [
      {
        "json": {
          "rss": [
            "https://feeds.bbci.co.uk/news/technology/rss.xml",
            "https://www.wired.com/feed/rss",
            "https://www.technologyreview.com/topnews.rss",
            "https://techcrunch.com/feed/",
            "https://www.marktechpost.com/feed/",
            "https://hackernoon.com/feed",
            "https://www.artificialintelligence-news.com/feed/"
          ]
        }
      }
    ],
    "Split Out": [
      {
        "json": {
          "rss": "https://feeds.bbci.co.uk/news/technology/rss.xml"
        }
      },
      {
        "json": {
          "rss": "https://www.wired.com/feed/rss"
        }
      },
      {
        "json": {
          "rss": "https://www.technologyreview.com/topnews.rss"
        }
      },
      {
        "json": {
          "rss": "https://techcrunch.com/feed/"
        }
      },
      {
        "json": {
          "rss": "https://www.marktechpost.com/feed/"
        }
      },
      {
        "json": {
          "rss": "https://hackernoon.com/feed"
        }
      },
      {
        "json": {
          "rss": "https://www.artificialintelligence-news.com/feed/"
        }
      }
    ],
    "Read RSS News Feeds": [
      {
        "json": {
          "title": "Chess grandmaster Carlsen wins at Esports World Cup",
          "link": "https://www.bbc.com/news/articles/ce3jl1kgyv0o?at_medium=RSS&at_campaign=rss",
          "pubDate": "Sat, 02 Aug 2025 01:49:02 GMT",
          "content": "World number one Magnus Carlsen takes home $250,000 (£188,000) for winning the online competition.\n",
          "contentSnippet": "World number one Magnus Carlsen takes home $250,000 (£188,000) for winning the online competition.",
          "guid": "https://www.bbc.com/news/articles/ce3jl1kgyv0o#0",
          "isoDate": "2025-08-02T01:49:02.000Z"
        }
      },
      {
        "json": {
          "title": "Some Gaza and Ukraine posts blocked under new age checks",
          "link": "https://www.bbc.com/news/articles/cj3l0e4vr0ko?at_medium=RSS&at_campaign=rss",
          "pubDate": "Thu, 31 Jul 2025 23:38:38 GMT",
          "content": "Tech companies are restricting debates of public interest to comply the Online Safety Act, analysis shows.",
          "contentSnippet": "Tech companies are restricting debates of public interest to comply the Online Safety Act, analysis shows.",
          "guid": "https://www.bbc.com/news/articles/cj3l0e4vr0ko#0",
          "isoDate": "2025-07-31T23:38:38.000Z"
        }
      },
      {
        "json": {
          "title": "Ofcom investigates 34 porn sites over age checks",
          "link": "https://www.bbc.com/news/articles/c5y2xx6z6eko?at_medium=RSS&at_campaign=rss",
          "pubDate": "Thu, 31 Jul 2025 12:29:13 GMT",
          "content": "Ofcom said on Friday that more than 6,000 porn sites would begin verifying users, but it believes some are ignoring the new rules.",
          "contentSnippet": "Ofcom said on Friday that more than 6,000 porn sites would begin verifying users, but it believes some are ignoring the new rules.",
          "guid": "https://www.bbc.com/news/articles/c5y2xx6z6eko#0",
          "isoDate": "2025-07-31T12:29:13.000Z"
        }
      },
      {
        "json": {
          "title": "What screen time does to children's brains is more complicated than it seems",
          "link": "https://www.bbc.com/news/articles/c9d0l40v551o?at_medium=RSS&at_campaign=rss",
          "pubDate": "Wed, 30 Jul 2025 23:44:30 GMT",
          "content": "Screen time has become synonymous with bad news - but the science may not be as straightforward as it seems",
          "contentSnippet": "Screen time has become synonymous with bad news - but the science may not be as straightforward as it seems",
          "guid": "https://www.bbc.com/news/articles/c9d0l40v551o#0",
          "isoDate": "2025-07-30T23:44:30.000Z"
        }
      },
      {
        "json": {
          "title": "Meta profits surge helps drive Zuckerberg’s AI ambitions",
          "link": "https://www.bbc.com/news/articles/cqlernrw62yo?at_medium=RSS&at_campaign=rss",
          "pubDate": "Thu, 31 Jul 2025 01:03:35 GMT",
          "content": "The Facebook, Instagram and WhatsApp-owner is pumping billions of dollars into artificial intelligence projects.",
          "contentSnippet": "The Facebook, Instagram and WhatsApp-owner is pumping billions of dollars into artificial intelligence projects.",
          "guid": "https://www.bbc.com/news/articles/cqlernrw62yo#0",
          "isoDate": "2025-07-31T01:03:35.000Z"
        }
      },
      {
        "json": {
          "title": "TikTok removes video by Huda Beauty boss over anti-Israel conspiracy theories",
          "link": "https://www.bbc.com/news/articles/c93d7qlp974o?at_medium=RSS&at_campaign=rss",
          "pubDate": "Wed, 30 Jul 2025 16:16:28 GMT",
          "content": "Huda Kattan is accused of \"using her massive platform to spread vile antisemitic conspiracy theories\".",
          "contentSnippet": "Huda Kattan is accused of \"using her massive platform to spread vile antisemitic conspiracy theories\".",
          "guid": "https://www.bbc.com/news/articles/c93d7qlp974o#0",
          "isoDate": "2025-07-30T16:16:28.000Z"
        }
      },
      {
        "json": {
          "title": "Dating safety app Tea suspends messaging after hack",
          "link": "https://www.bbc.com/news/articles/cd0dgkjgzvjo?at_medium=RSS&at_campaign=rss",
          "pubDate": "Wed, 30 Jul 2025 10:01:32 GMT",
          "content": "It comes after a hack which exposed thousands of members' images, posts and comments. ",
          "contentSnippet": "It comes after a hack which exposed thousands of members' images, posts and comments.",
          "guid": "https://www.bbc.com/news/articles/cd0dgkjgzvjo#0",
          "isoDate": "2025-07-30T10:01:32.000Z"
        }
      },
      {
        "json": {
          "title": "YouTube to be included in Australia's teen social media ban",
          "link": "https://www.bbc.com/news/articles/cpv0zkxx0njo?at_medium=RSS&at_campaign=rss",
          "pubDate": "Wed, 30 Jul 2025 01:24:49 GMT",
          "content": "The Australian government says the world-first ban is aimed at protecting youth from online harm.",
          "contentSnippet": "The Australian government says the world-first ban is aimed at protecting youth from online harm.",
          "guid": "https://www.bbc.com/news/articles/cpv0zkxx0njo#1",
          "isoDate": "2025-07-30T01:24:49.000Z"
        }
      },
      {
        "json": {
          "title": "Minister must apologise over Savile claim, says Farage",
          "link": "https://www.bbc.com/news/articles/cgery3eeqzxo?at_medium=RSS&at_campaign=rss",
          "pubDate": "Tue, 29 Jul 2025 11:28:07 GMT",
          "content": "Minister Peter Kyle claims that by opposing online safety laws the Reform UK leader is siding with sex offenders.",
          "contentSnippet": "Minister Peter Kyle claims that by opposing online safety laws the Reform UK leader is siding with sex offenders.",
          "guid": "https://www.bbc.com/news/articles/cgery3eeqzxo#1",
          "isoDate": "2025-07-29T11:28:07.000Z"
        }
      },
      {
        "json": {
          "title": "EE to launch phone plans which restrict internet for teens",
          "link": "https://www.bbc.com/news/articles/cvg3lgdv3r7o?at_medium=RSS&at_campaign=rss",
          "pubDate": "Tue, 29 Jul 2025 11:11:08 GMT",
          "content": "UK mobile network operators are already required to ensure only adults can access adult content while using their network.",
          "contentSnippet": "UK mobile network operators are already required to ensure only adults can access adult content while using their network.",
          "guid": "https://www.bbc.com/news/articles/cvg3lgdv3r7o#1",
          "isoDate": "2025-07-29T11:11:08.000Z"
        }
      },
      {
        "json": {
          "title": "Google launches new AI search feature in UK",
          "link": "https://www.bbc.com/news/articles/clyj4zky4zwo?at_medium=RSS&at_campaign=rss",
          "pubDate": "Tue, 29 Jul 2025 08:43:59 GMT",
          "content": "The new tool marks a significant change for the search giant but raises questions for advertisers.",
          "contentSnippet": "The new tool marks a significant change for the search giant but raises questions for advertisers.",
          "guid": "https://www.bbc.com/news/articles/clyj4zky4zwo#1",
          "isoDate": "2025-07-29T08:43:59.000Z"
        }
      },
      {
        "json": {
          "title": "The Gulf bets big on AI as it seeks the 'new oil'",
          "link": "https://www.bbc.com/news/articles/cvg8z2mx508o?at_medium=RSS&at_campaign=rss",
          "pubDate": "Wed, 30 Jul 2025 23:14:44 GMT",
          "content": "The UAE and Saudi Arabia are partnering with the US to position themselves as AI hubs.",
          "contentSnippet": "The UAE and Saudi Arabia are partnering with the US to position themselves as AI hubs.",
          "guid": "https://www.bbc.com/news/articles/cvg8z2mx508o#1",
          "isoDate": "2025-07-30T23:14:44.000Z"
        }
      },
      {
        "json": {
          "title": "Around 6,000 porn sites start checking ages in UK",
          "link": "https://www.bbc.com/news/articles/c24v4dl5r16o?at_medium=RSS&at_campaign=rss",
          "pubDate": "Fri, 25 Jul 2025 11:30:21 GMT",
          "content": "Despite the law some remain sceptical about the effectiveness of porn age checks.",
          "contentSnippet": "Despite the law some remain sceptical about the effectiveness of porn age checks.",
          "guid": "https://www.bbc.com/news/articles/c24v4dl5r16o#2",
          "isoDate": "2025-07-25T11:30:21.000Z"
        }
      },
      {
        "json": {
          "title": "EE says latest outage fixed after 'technical fault'",
          "link": "https://www.bbc.com/news/articles/cx2q8qw0q0go?at_medium=RSS&at_campaign=rss",
          "pubDate": "Sat, 26 Jul 2025 19:02:36 GMT",
          "content": "The mobile phone service provider says it carried out work overnight after customers reported problems.",
          "contentSnippet": "The mobile phone service provider says it carried out work overnight after customers reported problems.",
          "guid": "https://www.bbc.com/news/articles/cx2q8qw0q0go#2",
          "isoDate": "2025-07-26T19:02:36.000Z"
        }
      },
      {
        "json": {
          "title": "Google failed to warn 10 million of Turkey earthquake severity",
          "link": "https://www.bbc.com/news/articles/c77v2kx304go?at_medium=RSS&at_campaign=rss",
          "pubDate": "Sun, 27 Jul 2025 23:16:50 GMT",
          "content": "The tech giant said only 469 serious warnings were sent out ahead of the 7.8 magnitude quake.",
          "contentSnippet": "The tech giant said only 469 serious warnings were sent out ahead of the 7.8 magnitude quake.",
          "guid": "https://www.bbc.com/news/articles/c77v2kx304go#2",
          "isoDate": "2025-07-27T23:16:50.000Z"
        }
      },
      {
        "json": {
          "title": "OpenAI and UK sign deal to use AI in public services",
          "link": "https://www.bbc.com/news/articles/czdv68gejm7o?at_medium=RSS&at_campaign=rss",
          "pubDate": "Tue, 22 Jul 2025 12:00:26 GMT",
          "content": "The US tech firm behind ChatGPT say it will work with the UK government to 'deliver prosperity for all'.",
          "contentSnippet": "The US tech firm behind ChatGPT say it will work with the UK government to 'deliver prosperity for all'.",
          "guid": "https://www.bbc.com/news/articles/czdv68gejm7o#2",
          "isoDate": "2025-07-22T12:00:26.000Z"
        }
      },
      {
        "json": {
          "title": "US passes first major national crypto legislation",
          "link": "https://www.bbc.com/news/articles/cd78lvd94zyo?at_medium=RSS&at_campaign=rss",
          "pubDate": "Thu, 17 Jul 2025 23:17:14 GMT",
          "content": "It marks a milestone for the once fringe industry, as it expands its power in Washington. ",
          "contentSnippet": "It marks a milestone for the once fringe industry, as it expands its power in Washington.",
          "guid": "https://www.bbc.com/news/articles/cd78lvd94zyo#2",
          "isoDate": "2025-07-17T23:17:14.000Z"
        }
      },
      {
        "json": {
          "title": "How the rise of green tech is feeding another environmental crisis",
          "link": "https://www.bbc.com/news/articles/c30741j351go?at_medium=RSS&at_campaign=rss",
          "pubDate": "Sat, 19 Jul 2025 23:05:12 GMT",
          "content": "The world's race to decarbonise has led to the rise of electric cars - and with it, soaring demand for lithium, which is required for the batteries",
          "contentSnippet": "The world's race to decarbonise has led to the rise of electric cars - and with it, soaring demand for lithium, which is required for the batteries",
          "guid": "https://www.bbc.com/news/articles/c30741j351go#2",
          "isoDate": "2025-07-19T23:05:12.000Z"
        }
      },
      {
        "json": {
          "title": "Meta investors settle $8bn lawsuit with Zuckerberg over Facebook privacy",
          "link": "https://www.bbc.com/news/articles/cx2jmledvr3o?at_medium=RSS&at_campaign=rss",
          "pubDate": "Thu, 17 Jul 2025 20:05:28 GMT",
          "content": "Shareholders accused Meta leaders of damaging the company by allowing repeat violations of Facebook users' privacy.",
          "contentSnippet": "Shareholders accused Meta leaders of damaging the company by allowing repeat violations of Facebook users' privacy.",
          "guid": "https://www.bbc.com/news/articles/cx2jmledvr3o#2",
          "isoDate": "2025-07-17T20:05:28.000Z"
        }
      },
      {
        "json": {
          "title": "Netflix uses AI effects for first time to cut costs",
          "link": "https://www.bbc.com/news/articles/c9vr4rymlw9o?at_medium=RSS&at_campaign=rss",
          "pubDate": "Fri, 18 Jul 2025 08:54:29 GMT",
          "content": "The streaming firm says AI allowed The Eternaut to complete a sequence faster and cheaper.",
          "contentSnippet": "The streaming firm says AI allowed The Eternaut to complete a sequence faster and cheaper.",
          "guid": "https://www.bbc.com/news/articles/c9vr4rymlw9o#2",
          "isoDate": "2025-07-18T08:54:29.000Z"
        }
      },
      {
        "json": {
          "title": "Co-op boss confirms all 6.5m members had data stolen",
          "link": "https://www.bbc.com/news/articles/cql0ple066po?at_medium=RSS&at_campaign=rss",
          "pubDate": "Wed, 16 Jul 2025 13:10:12 GMT",
          "content": "In her first interview since the attack, Co-op's chief executive said she was \"incredibly sorry\" to customers.",
          "contentSnippet": "In her first interview since the attack, Co-op's chief executive said she was \"incredibly sorry\" to customers.",
          "guid": "https://www.bbc.com/news/articles/cql0ple066po#2",
          "isoDate": "2025-07-16T13:10:12.000Z"
        }
      },
      {
        "json": {
          "title": "How will age verification for porn work and what about privacy?",
          "link": "https://www.bbc.com/news/articles/ceq7ye3q2zwo?at_medium=RSS&at_campaign=rss",
          "pubDate": "Wed, 16 Jul 2025 08:04:09 GMT",
          "content": "Anyone in the UK wanting to access online porn will soon have to undergo more rigorous age checks.",
          "contentSnippet": "Anyone in the UK wanting to access online porn will soon have to undergo more rigorous age checks.",
          "guid": "https://www.bbc.com/news/articles/ceq7ye3q2zwo#2",
          "isoDate": "2025-07-16T08:04:09.000Z"
        }
      },
      {
        "json": {
          "title": "WeTransfer says files not used to train AI after backlash",
          "link": "https://www.bbc.com/news/articles/cp8mp79gyz1o?at_medium=RSS&at_campaign=rss",
          "pubDate": "Tue, 15 Jul 2025 12:47:23 GMT",
          "content": "Some social media users had threatened to delete their accounts after WeTransfer's terms were updated.",
          "contentSnippet": "Some social media users had threatened to delete their accounts after WeTransfer's terms were updated.",
          "guid": "https://www.bbc.com/news/articles/cp8mp79gyz1o#2",
          "isoDate": "2025-07-15T12:47:23.000Z"
        }
      },
      {
        "json": {
          "title": "New AI voice tool trained to copy British regional accents",
          "link": "https://www.bbc.com/news/articles/c07d2dyx19zo?at_medium=RSS&at_campaign=rss",
          "pubDate": "Mon, 14 Jul 2025 23:06:09 GMT",
          "content": "A UK company says it is better at reproducing a range of accents compared with US or Chinese rivals.",
          "contentSnippet": "A UK company says it is better at reproducing a range of accents compared with US or Chinese rivals.",
          "guid": "https://www.bbc.com/news/articles/c07d2dyx19zo#2",
          "isoDate": "2025-07-14T23:06:09.000Z"
        }
      },
      {
        "json": {
          "title": "Nvidia says it will restart AI chip sales to China",
          "link": "https://www.bbc.com/news/articles/cy8g22n32d0o?at_medium=RSS&at_campaign=rss",
          "pubDate": "Tue, 15 Jul 2025 06:03:35 GMT",
          "content": "The move would reverse a US ban on sales of the high-end chip to the world's second largest economy.",
          "contentSnippet": "The move would reverse a US ban on sales of the high-end chip to the world's second largest economy.",
          "guid": "https://www.bbc.com/news/articles/cy8g22n32d0o#2",
          "isoDate": "2025-07-15T06:03:35.000Z"
        }
      },
      {
        "json": {
          "title": "Meta to spend hundreds of billions to build AI data centres",
          "link": "https://www.bbc.com/news/articles/c1e02vx55wpo?at_medium=RSS&at_campaign=rss",
          "pubDate": "Tue, 15 Jul 2025 03:59:02 GMT",
          "content": "The founder of the social media giant said one of the sites would cover an area nearly the size of Manhattan.",
          "contentSnippet": "The founder of the social media giant said one of the sites would cover an area nearly the size of Manhattan.",
          "guid": "https://www.bbc.com/news/articles/c1e02vx55wpo#2",
          "isoDate": "2025-07-15T03:59:02.000Z"
        }
      },
      {
        "json": {
          "title": "Reddit starts verifying ages of users in the UK",
          "link": "https://www.bbc.com/news/articles/cj4ep1znk4zo?at_medium=RSS&at_campaign=rss",
          "pubDate": "Tue, 15 Jul 2025 08:14:17 GMT",
          "content": "The platform will bring in the measures from 14 July to stop under-18s looking at \"certain mature content\".",
          "contentSnippet": "The platform will bring in the measures from 14 July to stop under-18s looking at \"certain mature content\".",
          "guid": "https://www.bbc.com/news/articles/cj4ep1znk4zo#2",
          "isoDate": "2025-07-15T08:14:17.000Z"
        }
      },
      {
        "json": {
          "title": "Heat pump makers are ready for a rush: Will customers come?",
          "link": "https://www.bbc.com/news/articles/crmvl3remg2o?at_medium=RSS&at_campaign=rss",
          "pubDate": "Mon, 14 Jul 2025 23:00:05 GMT",
          "content": "Heat pump makers are ready to raise output, but demand is still sluggish.",
          "contentSnippet": "Heat pump makers are ready to raise output, but demand is still sluggish.",
          "guid": "https://www.bbc.com/news/articles/crmvl3remg2o#2",
          "isoDate": "2025-07-14T23:00:05.000Z"
        }
      },
      {
        "json": {
          "title": "Paddy Power and Betfair users warned of 'email danger' after breach",
          "link": "https://www.bbc.com/news/articles/cz7l29zved9o?at_medium=RSS&at_campaign=rss",
          "pubDate": "Mon, 14 Jul 2025 13:13:40 GMT",
          "content": "Hackers have accessed personal information of potentially 800,000 customers of Flutter Entertainment.",
          "contentSnippet": "Hackers have accessed personal information of potentially 800,000 customers of Flutter Entertainment.",
          "guid": "https://www.bbc.com/news/articles/cz7l29zved9o#2",
          "isoDate": "2025-07-14T13:13:40.000Z"
        }
      },
      {
        "json": {
          "title": "From Bitcoin to XRP: Key cryptocurrency terms and what they mean",
          "link": "https://www.bbc.com/news/articles/cy5w2k5k5ylo?at_medium=RSS&at_campaign=rss",
          "pubDate": "Mon, 14 Jul 2025 11:27:58 GMT",
          "content": "As Bitcoin's price goes up once again, here's a guide to some of the crypto market's trickiest terms.",
          "contentSnippet": "As Bitcoin's price goes up once again, here's a guide to some of the crypto market's trickiest terms.",
          "guid": "https://www.bbc.com/news/articles/cy5w2k5k5ylo#2",
          "isoDate": "2025-07-14T11:27:58.000Z"
        }
      },
      {
        "json": {
          "title": "More rules being considered to keep children safe online ",
          "link": "https://www.bbc.com/news/articles/cp82447l84ko?at_medium=RSS&at_campaign=rss",
          "pubDate": "Sun, 13 Jul 2025 11:57:33 GMT",
          "content": "Cabinet minister Heidi Alexander says age checks will not mark the \"end of the conversation\".",
          "contentSnippet": "Cabinet minister Heidi Alexander says age checks will not mark the \"end of the conversation\".",
          "guid": "https://www.bbc.com/news/articles/cp82447l84ko#2",
          "isoDate": "2025-07-13T11:57:33.000Z"
        }
      },
      {
        "json": {
          "title": "Four arrested in connection with M&S and Co-op cyber-attacks",
          "link": "https://www.bbc.com/news/articles/cwykgrv374eo?at_medium=RSS&at_campaign=rss",
          "pubDate": "Thu, 10 Jul 2025 13:42:24 GMT",
          "content": "Three men and one woman - aged between 17 and 20 - have been arrested in London and the Midlands.",
          "contentSnippet": "Three men and one woman - aged between 17 and 20 - have been arrested in London and the Midlands.",
          "guid": "https://www.bbc.com/news/articles/cwykgrv374eo#2",
          "isoDate": "2025-07-10T13:42:24.000Z"
        }
      },
      {
        "json": {
          "title": "Tech Life",
          "link": "https://www.bbc.co.uk/sounds/play/w3ct6zp1?at_medium=RSS&at_campaign=rss",
          "pubDate": "Tue, 29 Jul 2025 19:32:00 GMT",
          "content": "What will the era of Agentic AI offer us ?",
          "contentSnippet": "What will the era of Agentic AI offer us ?",
          "guid": "https://www.bbc.co.uk/sounds/play/w3ct6zp1#4",
          "isoDate": "2025-07-29T19:32:00.000Z"
        }
      },
      {
        "json": {
          "title": "Tech Now",
          "link": "https://www.bbc.co.uk/iplayer/episode/m002gm6k?at_medium=RSS&at_campaign=rss",
          "pubDate": "Sat, 26 Jul 2025 01:00:00 GMT",
          "content": "Yasmin Morgan-Griffiths has exclusive access to La Sagrada Familia in Barcelona.",
          "contentSnippet": "Yasmin Morgan-Griffiths has exclusive access to La Sagrada Familia in Barcelona.",
          "guid": "https://www.bbc.co.uk/iplayer/episode/m002gm6k#4",
          "isoDate": "2025-07-26T01:00:00.000Z"
        }
      },
      {
        "json": {
          "title": "Tech Life",
          "link": "https://www.bbc.co.uk/sounds/play/w3ct6zp0?at_medium=RSS&at_campaign=rss",
          "pubDate": "Tue, 22 Jul 2025 20:00:00 GMT",
          "content": "An American waste management company is storing organic waste deep underground.",
          "contentSnippet": "An American waste management company is storing organic waste deep underground.",
          "guid": "https://www.bbc.co.uk/sounds/play/w3ct6zp0#4",
          "isoDate": "2025-07-22T20:00:00.000Z"
        }
      },
      {
        "json": {
          "title": "Tech Now",
          "link": "https://www.bbc.co.uk/iplayer/episode/m002g8zw?at_medium=RSS&at_campaign=rss",
          "pubDate": "Sat, 19 Jul 2025 01:00:30 GMT",
          "content": "Ione Wells explores if lithium mining can be done more sustainably.",
          "contentSnippet": "Ione Wells explores if lithium mining can be done more sustainably.",
          "guid": "https://www.bbc.co.uk/iplayer/episode/m002g8zw#4",
          "isoDate": "2025-07-19T01:00:30.000Z"
        }
      },
      {
        "json": {
          "title": "The floating robot collecting rubbish in our waterways",
          "link": "https://www.bbc.com/news/videos/cn5kn3dln3ko?at_medium=RSS&at_campaign=rss",
          "pubDate": "Fri, 18 Jul 2025 15:12:08 GMT",
          "content": "Tech Now meets the team behind WasteShark - can it help tackle marine plastic pollution?",
          "contentSnippet": "Tech Now meets the team behind WasteShark - can it help tackle marine plastic pollution?",
          "guid": "https://www.bbc.com/news/videos/cn5kn3dln3ko#4",
          "isoDate": "2025-07-18T15:12:08.000Z"
        }
      },
      {
        "json": {
          "title": "Tech Life",
          "link": "https://www.bbc.co.uk/sounds/play/w3ct6znz?at_medium=RSS&at_campaign=rss",
          "pubDate": "Tue, 15 Jul 2025 19:30:00 GMT",
          "content": "We take a deep dive into quantum computers, with experts answering listeners' questions.",
          "contentSnippet": "We take a deep dive into quantum computers, with experts answering listeners' questions.",
          "guid": "https://www.bbc.co.uk/sounds/play/w3ct6znz#4",
          "isoDate": "2025-07-15T19:30:00.000Z"
        }
      },
      {
        "json": {
          "title": "Tech Now",
          "link": "https://www.bbc.co.uk/iplayer/episode/m002fzws?at_medium=RSS&at_campaign=rss",
          "pubDate": "Sat, 12 Jul 2025 01:00:20 GMT",
          "content": "Exploring some of the latest tech innovations in the world of sport.",
          "contentSnippet": "Exploring some of the latest tech innovations in the world of sport.",
          "guid": "https://www.bbc.co.uk/iplayer/episode/m002fzws#4",
          "isoDate": "2025-07-12T01:00:20.000Z"
        }
      },
      {
        "json": {
          "title": "Tech Life",
          "link": "https://www.bbc.co.uk/sounds/play/w3ct6zny?at_medium=RSS&at_campaign=rss",
          "pubDate": "Tue, 08 Jul 2025 19:30:00 GMT",
          "content": "Find out about the AI safe driving system that's watching the road ahead, and the driver.",
          "contentSnippet": "Find out about the AI safe driving system that's watching the road ahead, and the driver.",
          "guid": "https://www.bbc.co.uk/sounds/play/w3ct6zny#4",
          "isoDate": "2025-07-08T19:30:00.000Z"
        }
      },
      {
        "json": {
          "title": "Could aluminium become the packaging 'champion'?",
          "link": "https://www.bbc.com/news/articles/ce3nw5vnzgpo?at_medium=RSS&at_campaign=rss",
          "pubDate": "Mon, 28 Jul 2025 23:04:41 GMT",
          "content": "Some packaging firms say aluminium could be used more widely in packaging, but cost may hold it back",
          "contentSnippet": "Some packaging firms say aluminium could be used more widely in packaging, but cost may hold it back",
          "guid": "https://www.bbc.com/news/articles/ce3nw5vnzgpo#5",
          "isoDate": "2025-07-28T23:04:41.000Z"
        }
      },
      {
        "json": {
          "title": "Artificial food colours are out, so what's next?",
          "link": "https://www.bbc.com/news/articles/c4g83dpeendo?at_medium=RSS&at_campaign=rss",
          "pubDate": "Thu, 24 Jul 2025 23:01:09 GMT",
          "content": "Big food firms are phasing out artificial colours, so tech firms are rushing to fill the gap.",
          "contentSnippet": "Big food firms are phasing out artificial colours, so tech firms are rushing to fill the gap.",
          "guid": "https://www.bbc.com/news/articles/c4g83dpeendo#5",
          "isoDate": "2025-07-24T23:01:09.000Z"
        }
      },
      {
        "json": {
          "title": "Trucking's uneasy relationship with new tech",
          "link": "https://www.bbc.com/news/articles/c5yeyn4gl80o?at_medium=RSS&at_campaign=rss",
          "pubDate": "Mon, 21 Jul 2025 23:20:14 GMT",
          "content": "Matching trucks with cargo has become digitised, adding efficiency, but driving down earnings. ",
          "contentSnippet": "Matching trucks with cargo has become digitised, adding efficiency, but driving down earnings.",
          "guid": "https://www.bbc.com/news/articles/c5yeyn4gl80o#5",
          "isoDate": "2025-07-21T23:20:14.000Z"
        }
      },
      {
        "json": {
          "title": "'Autofocus' specs promise sharp vision, near or far",
          "link": "https://www.bbc.com/news/articles/cj6r06d7xdjo?at_medium=RSS&at_campaign=rss",
          "pubDate": "Thu, 10 Jul 2025 23:05:30 GMT",
          "content": "Start-up firms and researchers are working on lenses that can change their focus.",
          "contentSnippet": "Start-up firms and researchers are working on lenses that can change their focus.",
          "guid": "https://www.bbc.com/news/articles/cj6r06d7xdjo#5",
          "isoDate": "2025-07-10T23:05:30.000Z"
        }
      },
      {
        "json": {
          "title": "Why little Lithuania has big plans for space tech",
          "link": "https://www.bbc.com/news/articles/c4g2ezl7xqyo?at_medium=RSS&at_campaign=rss",
          "pubDate": "Mon, 07 Jul 2025 23:02:48 GMT",
          "content": "Lithuania has a promising space tech sector, but it wants more government support.",
          "contentSnippet": "Lithuania has a promising space tech sector, but it wants more government support.",
          "guid": "https://www.bbc.com/news/articles/c4g2ezl7xqyo#5",
          "isoDate": "2025-07-07T23:02:48.000Z"
        }
      },
      {
        "json": {
          "title": "Should we be letting flies eat our food waste?",
          "link": "https://www.bbc.com/news/articles/cz9y1l397vno?at_medium=RSS&at_campaign=rss",
          "pubDate": "Thu, 26 Jun 2025 23:10:12 GMT",
          "content": "In Lithuania and Australia, hungry fly larvae are used to process food waste into useful protein.",
          "contentSnippet": "In Lithuania and Australia, hungry fly larvae are used to process food waste into useful protein.",
          "guid": "https://www.bbc.com/news/articles/cz9y1l397vno#5",
          "isoDate": "2025-06-26T23:10:12.000Z"
        }
      },
      {
        "json": {
          "title": "Supercell boss: 'We need to take bigger risks'",
          "link": "https://www.bbc.com/news/articles/cqx2jz1l477o?at_medium=RSS&at_campaign=rss",
          "pubDate": "Mon, 23 Jun 2025 23:08:19 GMT",
          "content": "The boss of mobile gaming giant Supercell says the industry needs to take bigger risks to compete.",
          "contentSnippet": "The boss of mobile gaming giant Supercell says the industry needs to take bigger risks to compete.",
          "guid": "https://www.bbc.com/news/articles/cqx2jz1l477o#5",
          "isoDate": "2025-06-23T23:08:19.000Z"
        }
      },
      {
        "json": {
          "title": "Tech giants unleash AI on weather forecasts: are they any good?",
          "link": "https://www.bbc.com/weather/articles/cwy6ykp7049o?at_medium=RSS&at_campaign=rss",
          "pubDate": "Thu, 19 Jun 2025 23:02:58 GMT",
          "content": "The biggest tech firms are using AI to forecast the weather but is that better than existing models?",
          "contentSnippet": "The biggest tech firms are using AI to forecast the weather but is that better than existing models?",
          "guid": "https://www.bbc.com/weather/articles/cwy6ykp7049o#5",
          "isoDate": "2025-06-19T23:02:58.000Z"
        }
      },
      {
        "json": {
          "title": "Why Ukraine is one of the world's most digital countries",
          "link": "https://www.bbc.com/news/articles/cm234l04xmro?at_medium=RSS&at_campaign=rss",
          "pubDate": "Mon, 16 Jun 2025 23:16:55 GMT",
          "content": "Despite the war, Ukraine has developed of the most advanced systems for digital government services.",
          "contentSnippet": "Despite the war, Ukraine has developed of the most advanced systems for digital government services.",
          "guid": "https://www.bbc.com/news/articles/cm234l04xmro#5",
          "isoDate": "2025-06-16T23:16:55.000Z"
        }
      },
      {
        "json": {
          "title": "From festivals to weddings: Why drone shows are booming",
          "link": "https://www.bbc.com/news/articles/c79ewz7qej4o?at_medium=RSS&at_campaign=rss",
          "pubDate": "Mon, 09 Jun 2025 23:01:54 GMT",
          "content": "Light shows involving hundreds and even thousands of drones are becoming big attractions.",
          "contentSnippet": "Light shows involving hundreds and even thousands of drones are becoming big attractions.",
          "guid": "https://www.bbc.com/news/articles/c79ewz7qej4o#5",
          "isoDate": "2025-06-09T23:01:54.000Z"
        }
      },
      {
        "json": {
          "title": "How airline fees have turned baggage into billions",
          "link": "https://www.bbc.com/news/articles/c0qg3ylx2g9o?at_medium=RSS&at_campaign=rss",
          "pubDate": "Wed, 04 Jun 2025 23:01:27 GMT",
          "content": "The amount carriers now charge for luggage is raising the ire of politicians and consumer groups.",
          "contentSnippet": "The amount carriers now charge for luggage is raising the ire of politicians and consumer groups.",
          "guid": "https://www.bbc.com/news/articles/c0qg3ylx2g9o#5",
          "isoDate": "2025-06-04T23:01:27.000Z"
        }
      },
      {
        "json": {
          "title": "The British jet engine that failed in the 'Valley of Death'",
          "link": "https://www.bbc.com/news/articles/c5y5zg85wnlo?at_medium=RSS&at_campaign=rss",
          "pubDate": "Mon, 02 Jun 2025 23:04:45 GMT",
          "content": "Workers at Reaction Engines felt they were close to completing a revolutionary jet engine.",
          "contentSnippet": "Workers at Reaction Engines felt they were close to completing a revolutionary jet engine.",
          "guid": "https://www.bbc.com/news/articles/c5y5zg85wnlo#5",
          "isoDate": "2025-06-02T23:04:45.000Z"
        }
      },
      {
        "json": {
          "title": "US green energy firms brace for federal funding cuts",
          "link": "https://www.bbc.com/news/articles/clynkqw236po?at_medium=RSS&at_campaign=rss",
          "pubDate": "Thu, 29 May 2025 23:04:04 GMT",
          "content": "Billions of dollars of US federal funding for green energy projects hangs in the balance.",
          "contentSnippet": "Billions of dollars of US federal funding for green energy projects hangs in the balance.",
          "guid": "https://www.bbc.com/news/articles/clynkqw236po#5",
          "isoDate": "2025-05-29T23:04:04.000Z"
        }
      },
      {
        "json": {
          "title": "Frugal tech: The start-ups working on cheap innovation",
          "link": "https://www.bbc.com/news/articles/c20xlqn0e5po?at_medium=RSS&at_campaign=rss",
          "pubDate": "Mon, 26 May 2025 23:03:01 GMT",
          "content": "Indian start-ups are using local materials and innovative ideas to make useful and affordable products.",
          "contentSnippet": "Indian start-ups are using local materials and innovative ideas to make useful and affordable products.",
          "guid": "https://www.bbc.com/news/articles/c20xlqn0e5po#5",
          "isoDate": "2025-05-26T23:03:01.000Z"
        }
      },
      {
        "json": {
          "title": "Why we need 'revolutionary' cooling tech",
          "link": "https://www.bbc.com/news/articles/cpdzjev2d9wo?at_medium=RSS&at_campaign=rss",
          "pubDate": "Mon, 19 May 2025 23:13:44 GMT",
          "content": "Cooling systems that avoid the use of polluting refrigerants are being launched.",
          "contentSnippet": "Cooling systems that avoid the use of polluting refrigerants are being launched.",
          "guid": "https://www.bbc.com/news/articles/cpdzjev2d9wo#5",
          "isoDate": "2025-05-19T23:13:44.000Z"
        }
      },
      {
        "json": {
          "title": "The monthly AI or real quiz: May 2025",
          "link": "https://www.bbc.co.uk/bitesize/articles/z2b7rmn?at_medium=RSS&at_campaign=rss",
          "pubDate": "Thu, 15 May 2025 17:16:00 GMT",
          "content": "Challenge yourself with this edition of our monthly AI or real quiz and see if you can get top marks!",
          "contentSnippet": "Challenge yourself with this edition of our monthly AI or real quiz and see if you can get top marks!",
          "guid": "https://www.bbc.co.uk/bitesize/articles/z2b7rmn#5",
          "isoDate": "2025-05-15T17:16:00.000Z"
        }
      },
      {
        "json": {
          "title": "The camera tech propelling shows like Adolescence",
          "link": "https://www.bbc.com/news/articles/c62g6vdl3vqo?at_medium=RSS&at_campaign=rss",
          "pubDate": "Thu, 15 May 2025 23:22:42 GMT",
          "content": "Whole TV shows shot in one long take are made possible by new lightweight cameras.",
          "contentSnippet": "Whole TV shows shot in one long take are made possible by new lightweight cameras.",
          "guid": "https://www.bbc.com/news/articles/c62g6vdl3vqo#5",
          "isoDate": "2025-05-15T23:22:42.000Z"
        }
      },
      {
        "json": {
          "title": "How to avoid a puncture on the Moon",
          "link": "https://www.bbc.com/news/articles/czrve1zrlg3o?at_medium=RSS&at_campaign=rss",
          "pubDate": "Mon, 12 May 2025 23:08:33 GMT",
          "content": "Giant tyre firms are testing tyres that can survive conditions on the Moon and Mars.",
          "contentSnippet": "Giant tyre firms are testing tyres that can survive conditions on the Moon and Mars.",
          "guid": "https://www.bbc.com/news/articles/czrve1zrlg3o#5",
          "isoDate": "2025-05-12T23:08:33.000Z"
        }
      },
      {
        "json": {
          "title": "Visit the Arctic vault holding back-ups of great works",
          "link": "https://www.bbc.com/news/articles/c7vnyn17p57o?at_medium=RSS&at_campaign=rss",
          "pubDate": "Thu, 08 May 2025 23:37:28 GMT",
          "content": "An arctic vault holds digital back-ups of some of humanity's great works of art, history and technology. ",
          "contentSnippet": "An arctic vault holds digital back-ups of some of humanity's great works of art, history and technology.",
          "guid": "https://www.bbc.com/news/articles/c7vnyn17p57o#5",
          "isoDate": "2025-05-08T23:37:28.000Z"
        }
      },
      {
        "json": {
          "title": "Who should you trust for a weather forecast?",
          "link": "https://www.bbc.com/news/articles/cql6vgwyv4xo?at_medium=RSS&at_campaign=rss",
          "pubDate": "Thu, 01 May 2025 23:01:26 GMT",
          "content": "Weather influencers can provide useful local information but are also accused of exaggerating conditions.",
          "contentSnippet": "Weather influencers can provide useful local information but are also accused of exaggerating conditions.",
          "guid": "https://www.bbc.com/news/articles/cql6vgwyv4xo#5",
          "isoDate": "2025-05-01T23:01:26.000Z"
        }
      },
      {
        "json": {
          "creator": "Matt Kamen",
          "title": "The Nintendo Switch 2’s Biggest Problem Is Already Storage",
          "link": "https://www.wired.com/story/nintendo-switch-2-biggest-problem-is-already-storage/",
          "pubDate": "Sun, 03 Aug 2025 13:00:00 +0000",
          "dc:creator": "Matt Kamen",
          "content": "In 2025, 256 gigabytes just isn’t enough, and tacking on more storage isn’t as easy as it sounds.",
          "contentSnippet": "In 2025, 256 gigabytes just isn’t enough, and tacking on more storage isn’t as easy as it sounds.",
          "guid": "669fe75c62bf6a567d74596b",
          "categories": [
            "Gear",
            "Gear / Gear News and Events",
            "Gear / Products / Gaming",
            "Gear / Trends"
          ],
          "isoDate": "2025-08-03T13:00:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Scott Gilbertson",
          "title": "19 Best Barefoot Shoes for Running or Walking (2025), Tested and Reviewed",
          "link": "https://www.wired.com/gallery/best-barefoot-shoes/",
          "pubDate": "Sun, 03 Aug 2025 12:00:00 +0000",
          "dc:creator": "Scott Gilbertson",
          "content": "Our favorite zero-drop, minimalist footwear will let you feel the ground beneath your feet.",
          "contentSnippet": "Our favorite zero-drop, minimalist footwear will let you feel the ground beneath your feet.",
          "guid": "5fa164d6446b4639b3d5b81f",
          "categories": [
            "Gear",
            "Gear / Buying Guides",
            "Gear / Products / Health and Fitness",
            "Gear / Products / Outdoor"
          ],
          "isoDate": "2025-08-03T12:00:00.000Z"
        }
      },
      {
        "json": {
          "creator": "David Nield",
          "title": "What Happens to Your Data If You Stop Paying for Cloud Storage?",
          "link": "https://www.wired.com/story/what-happens-to-your-data-if-you-stop-paying-for-cloud-storage/",
          "pubDate": "Sun, 03 Aug 2025 11:30:00 +0000",
          "dc:creator": "David Nield",
          "content": "Hit by subscription fatigue? Here’s what happens to your files and photos if you cancel your paid storage plan.",
          "contentSnippet": "Hit by subscription fatigue? Here’s what happens to your files and photos if you cancel your paid storage plan.",
          "guid": "6883ba684b705c2ba8534adc",
          "categories": [
            "Gear",
            "Gear / Gear News and Events"
          ],
          "isoDate": "2025-08-03T11:30:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Leila Sloman",
          "title": "Efforts to Ground Physics in Math Are Opening the Secrets of Time",
          "link": "https://www.wired.com/story/efforts-to-ground-physics-in-math-are-opening-the-secrets-of-time/",
          "pubDate": "Sun, 03 Aug 2025 11:00:00 +0000",
          "dc:creator": "Leila Sloman",
          "content": "By proving how individual molecules create the complex motion of fluids, three mathematicians have illuminated why time can’t flow in reverse.",
          "contentSnippet": "By proving how individual molecules create the complex motion of fluids, three mathematicians have illuminated why time can’t flow in reverse.",
          "guid": "687e65e4e03c983df4b5d6f1",
          "categories": [
            "Science",
            "Science / Physics and Math"
          ],
          "isoDate": "2025-08-03T11:00:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Simon Hill",
          "title": "12 Best Outdoor Security Cameras (2025): Battery-Powered, LTE, No Subscription",
          "link": "https://www.wired.com/gallery/best-outdoor-security-cameras/",
          "pubDate": "Sun, 03 Aug 2025 10:30:00 +0000",
          "dc:creator": "Simon Hill",
          "content": "These weatherproof outdoor security cams keep a watchful eye on your property while you get on with life. Our list includes battery-powered and LTE devices and cameras that need no subscription.",
          "contentSnippet": "These weatherproof outdoor security cams keep a watchful eye on your property while you get on with life. Our list includes battery-powered and LTE devices and cameras that need no subscription.",
          "guid": "6135c6178aa474c41f359e96",
          "categories": [
            "Gear",
            "Gear / Buying Guides",
            "Gear / Products / Smart Home",
            "Gear / Products / Home"
          ],
          "isoDate": "2025-08-03T10:30:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Julia Forbes",
          "title": "How to Clean Your Mattress (2025)",
          "link": "https://www.wired.com/story/how-to-clean-your-mattress/",
          "pubDate": "Sun, 03 Aug 2025 10:09:00 +0000",
          "dc:creator": "Julia Forbes",
          "content": "From barf to blood, your stained mattress isn’t necessarily beyond repair. Here’s how to salvage your investment from every worst-case scenario.",
          "contentSnippet": "From barf to blood, your stained mattress isn’t necessarily beyond repair. Here’s how to salvage your investment from every worst-case scenario.",
          "guid": "6878f45a9921e98ae6ba7fda",
          "categories": [
            "Gear",
            "Gear / How To and Advice",
            "Gear / Products / Sleep"
          ],
          "isoDate": "2025-08-03T10:09:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Jennifer Ouellette, Ars Technica",
          "title": "Peacock Feathers Are Stunning. They Can Also Emit Laser Beams",
          "link": "https://www.wired.com/story/peacock-feathers-laser-beams/",
          "pubDate": "Sat, 02 Aug 2025 13:00:00 +0000",
          "dc:creator": "Jennifer Ouellette, Ars Technica",
          "content": "Scientists hope their plumage project could someday lead to biocompatible lasers that could safely be embedded in the human body.",
          "contentSnippet": "Scientists hope their plumage project could someday lead to biocompatible lasers that could safely be embedded in the human body.",
          "guid": "688ce822352e62881701de71",
          "categories": [
            "Science",
            "Science / Biotech"
          ],
          "isoDate": "2025-08-02T13:00:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Simon Hill",
          "title": "9 Best Indoor Security Cameras (2025): For Homes and Apartments",
          "link": "https://www.wired.com/gallery/best-security-cameras/",
          "pubDate": "Sat, 02 Aug 2025 12:00:00 +0000",
          "dc:creator": "Simon Hill",
          "content": "Cameras can offer peace of mind, but choose carefully before inviting one into your home.",
          "contentSnippet": "Cameras can offer peace of mind, but choose carefully before inviting one into your home.",
          "guid": "5e6180ea7ae91d00080357ef",
          "categories": [
            "Gear",
            "Gear / Buying Guides",
            "Gear / Products / Smart Home"
          ],
          "isoDate": "2025-08-02T12:00:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Matt Kamen, WIRED Staff",
          "title": "The 45 Best Movies on Netflix Right Now (August 2025)",
          "link": "https://www.wired.com/story/netflix-best-movies-this-week/",
          "pubDate": "Sat, 02 Aug 2025 11:00:00 +0000",
          "dc:creator": "Matt Kamen, WIRED Staff",
          "content": "KPop Demon Hunters, Happy Gilmore 2, and The Old Guard 2 are just a few of the movies you should watch on Netflix this month.",
          "contentSnippet": "KPop Demon Hunters, Happy Gilmore 2, and The Old Guard 2 are just a few of the movies you should watch on Netflix this month.",
          "guid": "63e53e6469cf98bf35404268",
          "categories": [
            "Culture",
            "Culture / Movies"
          ],
          "isoDate": "2025-08-02T11:00:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Deep Vakil",
          "title": "Trump Promised to ‘Drill, Baby, Drill.’ The New Rigs Are Nowhere to Be Found",
          "link": "https://www.wired.com/story/trump-promised-to-drill-baby-drill-the-new-rigs-are-nowhere-to-be-found/",
          "pubDate": "Sat, 02 Aug 2025 11:00:00 +0000",
          "dc:creator": "Deep Vakil",
          "content": "With clean energy more cost-competitive than it once was, the White House’s oil-first strategy is faltering.",
          "contentSnippet": "With clean energy more cost-competitive than it once was, the White House’s oil-first strategy is faltering.",
          "guid": "687e66106603e767aaec258a",
          "categories": [
            "Science",
            "Science / Environment"
          ],
          "isoDate": "2025-08-02T11:00:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Matt Kamen, WIRED Staff",
          "title": "The 45 Best Shows on Netflix Right Now (August 2025)",
          "link": "https://www.wired.com/story/netflix-best-shows-this-week/",
          "pubDate": "Sat, 02 Aug 2025 11:00:00 +0000",
          "dc:creator": "Matt Kamen, WIRED Staff",
          "content": "Squid Game, Sakamoto Days, and Grace and Frankie are just a few of the shows you need to watch on Netflix this month.",
          "contentSnippet": "Squid Game, Sakamoto Days, and Grace and Frankie are just a few of the shows you need to watch on Netflix this month.",
          "guid": "63e553d835b4148ce01604ab",
          "categories": [
            "Culture",
            "Culture / TV"
          ],
          "isoDate": "2025-08-02T11:00:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Dell Cameron",
          "title": "Google Will Use AI to Guess People’s Ages Based on Search History",
          "link": "https://www.wired.com/story/security-news-this-week-google-will-use-ai-to-guess-peoples-ages-based-on-search-history/",
          "pubDate": "Sat, 02 Aug 2025 10:30:00 +0000",
          "dc:creator": "Dell Cameron",
          "content": "Plus: A former top US cyber official loses her new job due to political backlash, Congress is rushing through a bill to censor lawmakers’ personal information online, and more.",
          "contentSnippet": "Plus: A former top US cyber official loses her new job due to political backlash, Congress is rushing through a bill to censor lawmakers’ personal information online, and more.",
          "guid": "688ce7a06b14bdac35507248",
          "categories": [
            "Security",
            "Security / Cyberattacks and Hacks",
            "Security / National Security",
            "Security / Privacy",
            "Security / Security News"
          ],
          "isoDate": "2025-08-02T10:30:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Louryn Strampe",
          "title": "11 Best Coolers WIRED Tested for Every Budget, Any Situation (2025)",
          "link": "https://www.wired.com/gallery/best-cooler/",
          "pubDate": "Sat, 02 Aug 2025 10:04:00 +0000",
          "dc:creator": "Louryn Strampe",
          "content": "We chugged chilled beverages to bring you our favorite coolers for every situation.",
          "contentSnippet": "We chugged chilled beverages to bring you our favorite coolers for every situation.",
          "guid": "5d41fb2e61b5160009e7cdcd",
          "categories": [
            "Gear",
            "Gear / Buying Guides",
            "Gear / Products / Outdoor"
          ],
          "isoDate": "2025-08-02T10:04:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Julian Chokkattu",
          "title": "Gear News of the Week: Insta360 Debuts a Drone Company, and DJI Surprises With an 8K 360 Camera",
          "link": "https://www.wired.com/story/gear-news-of-the-week-insta360-debuts-a-drone-company-and-dji-surprises-with-an-8k-360-camera/",
          "pubDate": "Sat, 02 Aug 2025 09:30:00 +0000",
          "dc:creator": "Julian Chokkattu",
          "content": "Plus: Netgear has an affordable Wi-Fi 7 mesh system, Samsung’s latest Galaxy Z Fold series is a hit, and Google’s Pixel 10 leaks heat up.",
          "contentSnippet": "Plus: Netgear has an affordable Wi-Fi 7 mesh system, Samsung’s latest Galaxy Z Fold series is a hit, and Google’s Pixel 10 leaks heat up.",
          "guid": "6667d620dc4a6ac4b628cb33",
          "categories": [
            "Gear",
            "Gear / Gear News and Events",
            "Gear / Products / Cameras",
            "Gear / Products / Phones",
            "Gear / Products / Home Office"
          ],
          "isoDate": "2025-08-02T09:30:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Kylie Robison",
          "title": "Anthropic Revokes OpenAI's Access to Claude",
          "link": "https://www.wired.com/story/anthropic-revokes-openais-access-to-claude/",
          "pubDate": "Fri, 01 Aug 2025 21:41:53 +0000",
          "dc:creator": "Kylie Robison",
          "content": "OpenAI lost access to the Claude API this week after Anthropic claimed the company was violating its terms of service.",
          "contentSnippet": "OpenAI lost access to the Claude API this week after Anthropic claimed the company was violating its terms of service.",
          "guid": "688cdb35749b64e31d10cc9b",
          "categories": [
            "Business",
            "Business / Artificial Intelligence"
          ],
          "isoDate": "2025-08-01T21:41:53.000Z"
        }
      },
      {
        "json": {
          "creator": "Aarian Marshall",
          "title": "Tesla Found Partly Liable in 2019 Autopilot Death",
          "link": "https://www.wired.com/story/tesla-liable-2019-autopilot-crash-death/",
          "pubDate": "Fri, 01 Aug 2025 20:41:28 +0000",
          "dc:creator": "Aarian Marshall",
          "content": "A Miami jury has ordered the automaker to pay up to $243 million after finding that the Tesla vehicle had a “defect.” It's the first time Tesla has been found liable in an Autopilot-related crash.",
          "contentSnippet": "A Miami jury has ordered the automaker to pay up to $243 million after finding that the Tesla vehicle had a “defect.” It's the first time Tesla has been found liable in an Autopilot-related crash.",
          "guid": "688d0e632e48f1d3f38580f6",
          "categories": [
            "Gear",
            "Gear / Gear News and Events"
          ],
          "isoDate": "2025-08-01T20:41:28.000Z"
        }
      },
      {
        "json": {
          "creator": "Zoë Schiffer, Louise Matsakis",
          "title": "WIRED Roundup: ChatGPT Goes Full Demon Mode",
          "link": "https://www.wired.com/story/uncanny-valley-podcast-chatgpt-goes-full-demon-mode/",
          "pubDate": "Fri, 01 Aug 2025 17:02:05 +0000",
          "dc:creator": "Zoë Schiffer, Louise Matsakis",
          "content": "On today’s episode of Uncanny Valley, our senior business editor joins us to talk Meta, brain aging, and ChatGPT’s recent dark turn.",
          "contentSnippet": "On today’s episode of Uncanny Valley, our senior business editor joins us to talk Meta, brain aging, and ChatGPT’s recent dark turn.",
          "guid": "688b7404ab3e47f7c8d75243",
          "categories": [
            "Business",
            "Business / Big Tech"
          ],
          "isoDate": "2025-08-01T17:02:05.000Z"
        }
      },
      {
        "json": {
          "creator": "Megan Farokhmanesh",
          "title": "Itch.io Is Restoring NSFW Games—as Long as They’re Free",
          "link": "https://www.wired.com/story/itchio-restoring-free-nsfw-games/",
          "pubDate": "Fri, 01 Aug 2025 16:24:16 +0000",
          "dc:creator": "Megan Farokhmanesh",
          "content": "Facing pressure from payment processors, the indie game platform delisted many adult titles this week. Itch.io began offering free NSFW content again on Thursday as it looks for new payment options.",
          "contentSnippet": "Facing pressure from payment processors, the indie game platform delisted many adult titles this week. Itch.io began offering free NSFW content again on Thursday as it looks for new payment options.",
          "guid": "688cc327a43d9117bc647cbc",
          "categories": [
            "Culture",
            "Culture / Video Games"
          ],
          "isoDate": "2025-08-01T16:24:16.000Z"
        }
      },
      {
        "json": {
          "creator": "Steven Levy",
          "title": "Inside Jeffrey Epstein’s Forgotten AI Summit",
          "link": "https://www.wired.com/story/epstein-files-science-tech-funding/",
          "pubDate": "Fri, 01 Aug 2025 15:30:00 +0000",
          "dc:creator": "Steven Levy",
          "content": "Long before ChatGPT, a group of AI luminaries gathered on an island to discuss the future of artificial intelligence. Their funder ultimately cast a shadow on all who attended.",
          "contentSnippet": "Long before ChatGPT, a group of AI luminaries gathered on an island to discuss the future of artificial intelligence. Their funder ultimately cast a shadow on all who attended.",
          "guid": "688a4e6d7afaa3b611ee6731",
          "categories": [
            "Business",
            "Business / Tech Culture"
          ],
          "isoDate": "2025-08-01T15:30:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Luke Larsen, Scott Gilbertson",
          "title": "11 Best Laptops for College Students (2025), Including Tablets and 2-in-1s",
          "link": "https://www.wired.com/gallery/best-laptops-for-college-students/",
          "pubDate": "Fri, 01 Aug 2025 13:30:00 +0000",
          "dc:creator": "Luke Larsen, Scott Gilbertson",
          "content": "Whatever your higher-ed goals, these laptops, tablets, and 2-in-1s will help you crush them.",
          "contentSnippet": "Whatever your higher-ed goals, these laptops, tablets, and 2-in-1s will help you crush them.",
          "guid": "5d5dafb05d2fd30009a0e8ce",
          "categories": [
            "Gear",
            "Gear / Buying Guides",
            "Gear / Products / Computers",
            "Gear / Products / Tablets"
          ],
          "isoDate": "2025-08-01T13:30:00.000Z"
        }
      },
      {
        "json": {
          "creator": "David Cox",
          "title": "The First Widespread Cure for HIV Could Be in Children",
          "link": "https://www.wired.com/story/the-first-widespread-cure-for-hiv-could-be-in-children/",
          "pubDate": "Fri, 01 Aug 2025 13:19:14 +0000",
          "dc:creator": "David Cox",
          "content": "Evidence is growing that some HIV-infected infants, if given antiretroviral drugs early in life, are able to suppress their viral loads to undetectable levels and then come off the medicine.",
          "contentSnippet": "Evidence is growing that some HIV-infected infants, if given antiretroviral drugs early in life, are able to suppress their viral loads to undetectable levels and then come off the medicine.",
          "guid": "688772c279e2509e00daba5f",
          "categories": [
            "Science",
            "Science / Health"
          ],
          "isoDate": "2025-08-01T13:19:14.000Z"
        }
      },
      {
        "json": {
          "creator": "Scott Gilbertson",
          "title": "Vivobarefoot's Sensus Shoes Are Like Gloves for Your Feet",
          "link": "https://www.wired.com/story/vivobarefoot-sensus-barefoot-rave/",
          "pubDate": "Fri, 01 Aug 2025 13:00:00 +0000",
          "dc:creator": "Scott Gilbertson",
          "content": "Vivobarefoot’s barely there shoes are perfect for casual wear, workouts, trail running, and walking around town.",
          "contentSnippet": "Vivobarefoot’s barely there shoes are perfect for casual wear, workouts, trail running, and walking around town.",
          "guid": "68827db04f088f314b84880b",
          "categories": [
            "Gear",
            "Gear / Reviews",
            "Gear / Products / Outdoor"
          ],
          "isoDate": "2025-08-01T13:00:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Adrienne So",
          "title": "Bike Friday All-Day Lightweight Electric Bike Review: It Comes in Purple",
          "link": "https://www.wired.com/review/bike-friday-all-day-lightweight-electric-bike/",
          "pubDate": "Fri, 01 Aug 2025 12:30:00 +0000",
          "dc:creator": "Adrienne So",
          "content": "I ordered the world’s smallest folding Bosch ebike in purple, and now it’s the only bike I want to ride.",
          "contentSnippet": "I ordered the world’s smallest folding Bosch ebike in purple, and now it’s the only bike I want to ride.",
          "guid": "6877d06dfae5eb9e3744f82b",
          "categories": [
            "Gear",
            "Gear / Reviews",
            "Gear / Products / Outdoor"
          ],
          "isoDate": "2025-08-01T12:30:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Rhett Allain",
          "title": "AC or DC: Which Is Better?",
          "link": "https://www.wired.com/story/ac-or-dc-which-is-better/",
          "pubDate": "Fri, 01 Aug 2025 12:30:00 +0000",
          "dc:creator": "Rhett Allain",
          "content": "Your gadgets run on direct current, but the electricity in your home is alternating current. What’s up with that?",
          "contentSnippet": "Your gadgets run on direct current, but the electricity in your home is alternating current. What’s up with that?",
          "guid": "687421c488739a178cfa86cd",
          "categories": [
            "Science",
            "Science / Physics and Math"
          ],
          "isoDate": "2025-08-01T12:30:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Adrienne So",
          "title": "Best Fitness Trackers (2025), Tested and Reviewed",
          "link": "https://www.wired.com/gallery/best-fitness-tracker/",
          "pubDate": "Fri, 01 Aug 2025 12:03:00 +0000",
          "dc:creator": "Adrienne So",
          "content": "Whether you’re skiing in the backcountry or trampolining in the backyard, we have an activity tracker for you.",
          "contentSnippet": "Whether you’re skiing in the backcountry or trampolining in the backyard, we have an activity tracker for you.",
          "guid": "5aa9a7900b4a6a6950f916c0",
          "categories": [
            "Gear",
            "Gear / Buying Guides",
            "Gear / Products / Health and Fitness",
            "Gear / Products / Outdoor"
          ],
          "isoDate": "2025-08-01T12:03:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Louryn Strampe",
          "title": "14 Best Couches We've Tested That You Can Buy Online (2025)",
          "link": "https://www.wired.com/gallery/best-couch/",
          "pubDate": "Fri, 01 Aug 2025 11:36:00 +0000",
          "dc:creator": "Louryn Strampe",
          "content": "Refresh your space with a comfy sofa that arrives right at your doorstep.",
          "contentSnippet": "Refresh your space with a comfy sofa that arrives right at your doorstep.",
          "guid": "5f5fd1e040c3a6fb18426a84",
          "categories": [
            "Gear",
            "Gear / Buying Guides",
            "Gear / Products / Lifestyle"
          ],
          "isoDate": "2025-08-01T11:36:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Jason Parham",
          "title": "Confessions of a Recovering AI Porn Addict",
          "link": "https://www.wired.com/story/confessions-of-a-recovering-ai-porn-addict/",
          "pubDate": "Fri, 01 Aug 2025 11:00:00 +0000",
          "dc:creator": "Jason Parham",
          "content": "A “gooner” tells WIRED he became hooked on the cartoonish nature of AI porn. Several addiction experts say the genre could pose a problem for people prone to compulsive sexual behavior.",
          "contentSnippet": "A “gooner” tells WIRED he became hooked on the cartoonish nature of AI porn. Several addiction experts say the genre could pose a problem for people prone to compulsive sexual behavior.",
          "guid": "686eb9a67f52e0e25a8be260",
          "categories": [
            "Culture",
            "Culture / Digital Culture"
          ],
          "isoDate": "2025-08-01T11:00:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Julian Chokkattu",
          "title": "14 Best Office Chairs of 2025— I’ve Tested Nearly 60 to Pick Them",
          "link": "https://www.wired.com/gallery/best-office-chairs/",
          "pubDate": "Fri, 01 Aug 2025 10:33:00 +0000",
          "dc:creator": "Julian Chokkattu",
          "content": "Sitting at a desk for hours? Upgrade your WFH setup and work in style with these comfy WIRED-tested seats.",
          "contentSnippet": "Sitting at a desk for hours? Upgrade your WFH setup and work in style with these comfy WIRED-tested seats.",
          "guid": "607895413c4558580f4abffa",
          "categories": [
            "Gear",
            "Gear / Buying Guides",
            "Gear / Products / Lifestyle"
          ],
          "isoDate": "2025-08-01T10:33:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Makena Kelly",
          "title": "Palantir Is Extending Its Reach Even Further Into Government",
          "link": "https://www.wired.com/story/palantir-government-contracting-push/",
          "pubDate": "Fri, 01 Aug 2025 10:30:00 +0000",
          "dc:creator": "Makena Kelly",
          "content": "Palantir has become one of the few winners in the Trump administration’s cost-cutting efforts, offering other contractors a lifeline while consolidating its own reach and power.",
          "contentSnippet": "Palantir has become one of the few winners in the Trump administration’s cost-cutting efforts, offering other contractors a lifeline while consolidating its own reach and power.",
          "guid": "68877a4f35c85e3bd9894393",
          "categories": [
            "Politics"
          ],
          "isoDate": "2025-08-01T10:30:00.000Z"
        }
      },
      {
        "json": {
          "creator": " Nena Farrell ",
          "title": "The Best Mouth Tape (2025)",
          "link": "https://www.wired.com/story/the-wired-guide-to-mouth-tape/",
          "pubDate": "Fri, 01 Aug 2025 10:02:00 +0000",
          "dc:creator": " Nena Farrell ",
          "content": "TikTokkers and biohackers are fast to recommend mouth tape for better sleep. But it’s not a solution for everyone.",
          "contentSnippet": "TikTokkers and biohackers are fast to recommend mouth tape for better sleep. But it’s not a solution for everyone.",
          "guid": "68506d02b5f548c29d06f070",
          "categories": [
            "Gear",
            "Gear / Products / Sleep",
            "Gear / Products / Lifestyle",
            "Gear / Products / Health and Fitness"
          ],
          "isoDate": "2025-08-01T10:02:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Aarian Marshall",
          "title": "Uber’s Drive to Become the Kleenex of Robotaxis",
          "link": "https://www.wired.com/story/ubers-drive-to-become-the-kleenex-of-robotaxis/",
          "pubDate": "Fri, 01 Aug 2025 10:00:00 +0000",
          "dc:creator": "Aarian Marshall",
          "content": "It doesn’t matter who makes the tech—when you call a robocar, Uber’s mission now is to make sure you use its app.",
          "contentSnippet": "It doesn’t matter who makes the tech—when you call a robocar, Uber’s mission now is to make sure you use its app.",
          "guid": "68812496503562f7586eab20",
          "categories": [
            "Gear",
            "Gear / Gear News and Events",
            "Business / Transportation"
          ],
          "isoDate": "2025-08-01T10:00:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Amanda Chatel",
          "title": "The Best Sex Toys (2025), Tested and Reviewed",
          "link": "https://www.wired.com/gallery/best-sex-toys-and-tech/",
          "pubDate": "Fri, 01 Aug 2025 08:00:00 +0000",
          "dc:creator": "Amanda Chatel",
          "content": "These are our favorite gender-inclusive vibrators, wand massagers, and sleeves to give you and your partner(s) a helping hand.",
          "contentSnippet": "These are our favorite gender-inclusive vibrators, wand massagers, and sleeves to give you and your partner(s) a helping hand.",
          "guid": "5ec58eed5bea2fa8333c4edd",
          "categories": [
            "Gear",
            "Gear / Buying Guides",
            "Gear / Products / Health and Fitness"
          ],
          "isoDate": "2025-08-01T08:00:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Scott Gilbertson",
          "title": "Canon Promo Codes: 10% Off | August 2025",
          "link": "https://www.wired.com/story/canon-promo-code/",
          "pubDate": "Fri, 01 Aug 2025 05:30:00 +0000",
          "dc:creator": "Scott Gilbertson",
          "content": "Save 10%, plus over $500 on cameras, lenses, and more with today’s Canon coupons for new and refurbished tech.",
          "contentSnippet": "Save 10%, plus over $500 on cameras, lenses, and more with today’s Canon coupons for new and refurbished tech.",
          "guid": "67252234563a280b6ad5ef8d",
          "categories": [
            "Gear"
          ],
          "isoDate": "2025-08-01T05:30:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Scott Gilbertson",
          "title": "Surfshark Promo Codes: 87% Off | August 2025",
          "link": "https://www.wired.com/story/surfshark-coupon/",
          "pubDate": "Fri, 01 Aug 2025 05:00:00 +0000",
          "dc:creator": "Scott Gilbertson",
          "content": "Save up to 87% with a Surfshark coupon code, 3 months of VPN free today, and more August 2025 discounts from WIRED.",
          "contentSnippet": "Save up to 87% with a Surfshark coupon code, 3 months of VPN free today, and more August 2025 discounts from WIRED.",
          "guid": "67462fb5b36fe19e4f620021",
          "categories": [
            "Gear"
          ],
          "isoDate": "2025-08-01T05:00:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Molly Higgins",
          "title": "Samsung Promo Codes: 30% Off | August 2025",
          "link": "https://www.wired.com/story/samsung-promo-codes/",
          "pubDate": "Fri, 01 Aug 2025 05:00:00 +0000",
          "dc:creator": "Molly Higgins",
          "content": "Save 30% with Samsung coupon codes, up to $2,100 on appliances, plus more discounts on the Galaxy Z Fold7, Flip7, and S25.",
          "contentSnippet": "Save 30% with Samsung coupon codes, up to $2,100 on appliances, plus more discounts on the Galaxy Z Fold7, Flip7, and S25.",
          "guid": "6682a4c73029f65bb234b2d6",
          "categories": [
            "Gear"
          ],
          "isoDate": "2025-08-01T05:00:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Angela Watercutter",
          "title": "The 28 Best Movies on Apple TV+ Right Now (August 2025)",
          "link": "https://www.wired.com/story/best-apple-tv-plus-movies/",
          "pubDate": "Thu, 31 Jul 2025 19:00:00 +0000",
          "dc:creator": "Angela Watercutter",
          "content": "Echo Valley, Snoopy Presents: A Summer Musical, and Bono: Stories of Surrender are just a few of the movies you should be watching on Apple TV+ this month.",
          "contentSnippet": "Echo Valley, Snoopy Presents: A Summer Musical, and Bono: Stories of Surrender are just a few of the movies you should be watching on Apple TV+ this month.",
          "guid": "64342bc05ffa737db431afc0",
          "categories": [
            "Culture",
            "Culture / Movies"
          ],
          "isoDate": "2025-07-31T19:00:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Emily Mullin",
          "title": "States Are Moving to Protect Access to Vaccines",
          "link": "https://www.wired.com/story/states-are-moving-to-protect-access-to-vaccines/",
          "pubDate": "Thu, 31 Jul 2025 18:53:46 +0000",
          "dc:creator": "Emily Mullin",
          "content": "As federal vaccine policy shifts under US health secretary Robert F. Kennedy Jr., lawmakers are looking to give state-level public health officials authority to ignore federal recommendations.",
          "contentSnippet": "As federal vaccine policy shifts under US health secretary Robert F. Kennedy Jr., lawmakers are looking to give state-level public health officials authority to ignore federal recommendations.",
          "guid": "6888edb9d87092871bc7cd49",
          "categories": [
            "Science",
            "Science / Health"
          ],
          "isoDate": "2025-07-31T18:53:46.000Z"
        }
      },
      {
        "json": {
          "creator": "Reece Rogers",
          "title": "Watch Our Livestream Replay: Inside Katie Drummond’s Viral Interview With Bryan Johnson",
          "link": "https://www.wired.com/story/inside-katie-drummonds-viral-interview-with-bryan-johnson/",
          "pubDate": "Thu, 31 Jul 2025 18:43:58 +0000",
          "dc:creator": "Reece Rogers",
          "content": "On July 31, WIRED’s global editorial director discussed the world of wellness—and beyond—with WIRED reporters.",
          "contentSnippet": "On July 31, WIRED’s global editorial director discussed the world of wellness—and beyond—with WIRED reporters.",
          "guid": "68813d0ffbe162a3bab0fb1f",
          "categories": [
            "Science",
            "Science / Health"
          ],
          "isoDate": "2025-07-31T18:43:58.000Z"
        }
      },
      {
        "json": {
          "creator": "Andrew Cunningham, Ars Technica",
          "title": "Still Using Windows 10? Here’s How to Get Another Year of Updates for Free",
          "link": "https://www.wired.com/story/still-using-windows-10-heres-how-to-get-another-year-of-updates-for-free/",
          "pubDate": "Thu, 31 Jul 2025 18:15:00 +0000",
          "dc:creator": "Andrew Cunningham, Ars Technica",
          "content": "If you’re not ready to upgrade, you can still get security updates until October 2026 by enrolling in Microsoft’s ESU program.",
          "contentSnippet": "If you’re not ready to upgrade, you can still get security updates until October 2026 by enrolling in Microsoft’s ESU program.",
          "guid": "688b8e831a59bf76839b6941",
          "categories": [
            "Gear",
            "Gear / Gear News and Events"
          ],
          "isoDate": "2025-07-31T18:15:00.000Z"
        }
      },
      {
        "json": {
          "creator": "David Cox",
          "title": "The Grave Long-Term Effects of the Gaza Malnutrition Crisis",
          "link": "https://www.wired.com/story/how-malnutrition-affects-the-body-gaza-hunger-children-health/",
          "pubDate": "Thu, 31 Jul 2025 17:22:53 +0000",
          "dc:creator": "David Cox",
          "content": "The WHO believes one in five children in Gaza are acutely malnourished, with the health effects potentially lasting for generations.",
          "contentSnippet": "The WHO believes one in five children in Gaza are acutely malnourished, with the health effects potentially lasting for generations.",
          "guid": "6887958a7ab87ace65aedcdd",
          "categories": [
            "Science",
            "Science / Health"
          ],
          "isoDate": "2025-07-31T17:22:53.000Z"
        }
      },
      {
        "json": {
          "creator": "Andy Greenberg",
          "title": "The Kremlin’s Most Devious Hacking Group Is Using Russian ISPs to Plant Spyware",
          "link": "https://www.wired.com/story/russia-fsb-turla-secret-blizzard-apolloshadow-isp-cyberespionage/",
          "pubDate": "Thu, 31 Jul 2025 16:00:00 +0000",
          "dc:creator": "Andy Greenberg",
          "content": "The FSB cyberespionage group known as Turla seems to have used its control of Russia’s network infrastructure to meddle with web traffic and trick diplomats into infecting their computers.",
          "contentSnippet": "The FSB cyberespionage group known as Turla seems to have used its control of Russia’s network infrastructure to meddle with web traffic and trick diplomats into infecting their computers.",
          "guid": "688a2c07a30c5eacfa72aaa7",
          "categories": [
            "Security",
            "Security / Cyberattacks and Hacks",
            "Security / National Security",
            "Security / Security News"
          ],
          "isoDate": "2025-07-31T16:00:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Joel Khalili",
          "title": "Donald Trump’s New Crypto Bible Is Everything the Industry Ever Wanted",
          "link": "https://www.wired.com/story/donald-trumps-new-crypto-bible-is-everything-the-industry-ever-wanted/",
          "pubDate": "Thu, 31 Jul 2025 15:30:03 +0000",
          "dc:creator": "Joel Khalili",
          "content": "In a lengthy report, federal government officials set out a roadmap for delivering on President Donald Trump’s promise to turn the US into the “crypto capital of the planet.”",
          "contentSnippet": "In a lengthy report, federal government officials set out a roadmap for delivering on President Donald Trump’s promise to turn the US into the “crypto capital of the planet.”",
          "guid": "688a416ad1b2a88a72e5a155",
          "categories": [
            "Business",
            "Business / Blockchain and Cryptocurrency"
          ],
          "isoDate": "2025-07-31T15:30:03.000Z"
        }
      },
      {
        "json": {
          "creator": "Zeyi Yang, Will Knight",
          "title": "Inside the Summit Where China Pitched Its AI Agenda to the World",
          "link": "https://www.wired.com/story/china-artificial-intelligence-policy-laws-race/",
          "pubDate": "Thu, 31 Jul 2025 15:04:47 +0000",
          "dc:creator": "Zeyi Yang, Will Knight",
          "content": "Behind closed doors, Chinese researchers are laying the groundwork for a new global AI agenda—without input from the US.",
          "contentSnippet": "Behind closed doors, Chinese researchers are laying the groundwork for a new global AI agenda—without input from the US.",
          "guid": "688949f565a65bd6da42c1da",
          "categories": [
            "Business",
            "Business / Artificial Intelligence",
            "Business / Regulation"
          ],
          "isoDate": "2025-07-31T15:04:47.000Z"
        }
      },
      {
        "json": {
          "creator": "Megan Farokhmanesh",
          "title": "A New ‘Katamari’ Game, ‘Octopath Traveler 0,’ and More Are Coming to Switch 2",
          "link": "https://www.wired.com/story/a-new-katamari-game-octopath-traveler-0-and-more-are-coming-to-switch-2/",
          "pubDate": "Thu, 31 Jul 2025 14:55:07 +0000",
          "dc:creator": "Megan Farokhmanesh",
          "content": "Nintendo announced the latest Switch 2 games Thursday, along with a new Monster Hunter expected next year.",
          "contentSnippet": "Nintendo announced the latest Switch 2 games Thursday, along with a new Monster Hunter expected next year.",
          "guid": "688b6fd5d65093e7342ddf3c",
          "categories": [
            "Culture",
            "Culture / Video Games"
          ],
          "isoDate": "2025-07-31T14:55:07.000Z"
        }
      },
      {
        "json": {
          "creator": "Jessica Klein",
          "title": "The Inside Story of Eric Trump’s American Bitcoin",
          "link": "https://www.wired.com/story/the-inside-story-of-eric-trumps-american-bitcoin/",
          "pubDate": "Thu, 31 Jul 2025 14:06:18 +0000",
          "dc:creator": "Jessica Klein",
          "content": "A new crypto mining company is flexing the Trump name and connections to get ahead.",
          "contentSnippet": "A new crypto mining company is flexing the Trump name and connections to get ahead.",
          "guid": "6887622ef41519ffc5d766e8",
          "categories": [
            "Business",
            "Business / Blockchain and Cryptocurrency"
          ],
          "isoDate": "2025-07-31T14:06:18.000Z"
        }
      },
      {
        "json": {
          "creator": "WIRED Staff",
          "title": "Join Us for WIRED’s AI Power Summit",
          "link": "https://www.wired.com/story/wired-ai-power-summit/",
          "pubDate": "Thu, 31 Jul 2025 13:16:34 +0000",
          "dc:creator": "WIRED Staff",
          "content": "On September 15, WIRED is gathering a panel of leaders across technology, politics, and media to tell you everything you need to know about the future of generative AI.",
          "contentSnippet": "On September 15, WIRED is gathering a panel of leaders across technology, politics, and media to tell you everything you need to know about the future of generative AI.",
          "guid": "6887c84bb7532778aaca51a5",
          "categories": [
            "Business",
            "Business / Artificial Intelligence"
          ],
          "isoDate": "2025-07-31T13:16:34.000Z"
        }
      },
      {
        "json": {
          "creator": "Simon Hill",
          "title": "8 Best Video Doorbell Cameras (2025): Smart, Battery, AI, Budget, and Subscription-Free",
          "link": "https://www.wired.com/gallery/best-video-doorbells/",
          "pubDate": "Thu, 31 Jul 2025 12:30:00 +0000",
          "dc:creator": "Simon Hill",
          "content": "Never miss a delivery. These WIRED-tested picks will help you keep tabs on your front door from anywhere.",
          "contentSnippet": "Never miss a delivery. These WIRED-tested picks will help you keep tabs on your front door from anywhere.",
          "guid": "6217a6803a14d44656b0c87e",
          "categories": [
            "Gear",
            "Gear / Buying Guides",
            "Gear / Products / Smart Home",
            "Gear / Products / Home"
          ],
          "isoDate": "2025-07-31T12:30:00.000Z"
        }
      },
      {
        "json": {
          "creator": " Nena Farrell ",
          "title": "The Best Travel Strollers for All Your Family Adventures (2025)",
          "link": "https://www.wired.com/gallery/best-travel-stroller/",
          "pubDate": "Thu, 31 Jul 2025 12:06:00 +0000",
          "dc:creator": " Nena Farrell ",
          "content": "Whether you’re on a road trip or a plane ride, these are our favorite travel strollers that fold as flat as possible.",
          "contentSnippet": "Whether you’re on a road trip or a plane ride, these are our favorite travel strollers that fold as flat as possible.",
          "guid": "666ca9dfdac254cb00a3f0e8",
          "categories": [
            "Gear",
            "Gear / Products / Parenting",
            "Gear / Buying Guides"
          ],
          "isoDate": "2025-07-31T12:06:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Parker Hall, Ryan Waniata",
          "title": "The Best Cheap Headphones We’ve Tried",
          "link": "https://www.wired.com/gallery/best-headphones-under-100/",
          "pubDate": "Thu, 31 Jul 2025 12:00:00 +0000",
          "dc:creator": "Parker Hall, Ryan Waniata",
          "content": "You could fill a stadium or two with all the cheap headphones out there. We tested a ton of the best headphones under $100 to help you pick the right pair.",
          "contentSnippet": "You could fill a stadium or two with all the cheap headphones out there. We tested a ton of the best headphones under $100 to help you pick the right pair.",
          "guid": "5c6730ca7029bd0a760fde8a",
          "categories": [
            "Gear",
            "Gear / Buying Guides",
            "Gear / Products / Headphones",
            "Gear / Products / Audio"
          ],
          "isoDate": "2025-07-31T12:00:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Luke Larsen",
          "title": "Asus Chromebook CX14 Review: What You Get for $429",
          "link": "https://www.wired.com/review/asus-chromebook-cx14/",
          "pubDate": "Thu, 31 Jul 2025 11:30:00 +0000",
          "dc:creator": "Luke Larsen",
          "content": "The world needs more affordable Chromebooks that don't suck, and the Asus Chromebook CX14 is a solid entry.",
          "contentSnippet": "The world needs more affordable Chromebooks that don't suck, and the Asus Chromebook CX14 is a solid entry.",
          "guid": "687fca2054bf065c82df5e42",
          "categories": [
            "Gear",
            "Gear / Reviews",
            "Gear / Products / Computers"
          ],
          "isoDate": "2025-07-31T11:30:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Grace Huckins",
          "title": "Forcing LLMs to be evil during training can make them nicer in the long run",
          "link": "https://www.technologyreview.com/2025/08/01/1120924/forcing-llms-to-be-evil-during-training-can-make-them-nicer-in-the-long-run/",
          "pubDate": "Fri, 01 Aug 2025 16:00:00 +0000",
          "content:encoded": "\n<p>A <a href=\"https://www.anthropic.com/research/persona-vectors\">new study</a> from Anthropic suggests that traits such as sycophancy or evilness are associated with specific patterns of activity in large language models—and turning on those patterns during training can, paradoxically, prevent the model from adopting the related traits.</p>\n\n\n\n<p>Large language models have recently acquired a reputation for behaving badly. In April, ChatGPT suddenly became an aggressive yes-man, as opposed to the moderately sycophantic version that users were accustomed to—it endorsed harebrained business ideas, waxed lyrical about users’ intelligence, and even encouraged people to go off their psychiatric medication. OpenAI quickly rolled back the change and later published a <a href=\"https://openai.com/index/expanding-on-sycophancy/\">postmortem</a> on the mishap. More recently, xAI’s Grok adopted what can best be described as a 4chan neo-Nazi persona and repeatedly referred to itself as “MechaHitler” on X. That change, too, was quickly reversed.</p>\n\n\n\n<p>Jack Lindsey, a member of the technical staff at Anthropic who led the new project, says that this study was partly inspired by seeing models adopt harmful traits in such instances. “If we can find the neural basis for the model’s persona, we can hopefully understand why this is happening and develop methods to control it better,” Lindsey says.&nbsp;</p>\n\n\n\n<p>The idea of LLM “personas” or “personalities” can be polarizing—for some researchers the terms inappropriately anthropomorphize language models, whereas for others they effectively capture the persistent behavioral patterns that LLMs can exhibit. “There’s still some scientific groundwork to be laid in terms of talking about personas,” says David Krueger, an assistant professor of computer science and operations research at the University of Montreal, who was not involved in the study. “I think it is appropriate to sometimes think of these systems as having personas, but I think we have to keep in mind that we don’t actually know if that&#8217;s what’s going on under the hood.”</p>\n\n\n\n\n\n<p>For this study, Lindsey and his colleagues worked to lay down some of that groundwork. Previous research has shown that various dimensions of LLMs’ behavior—from <a href=\"https://arxiv.org/pdf/2308.10248\">whether they are talking about weddings</a> to <a href=\"https://arxiv.org/pdf/2312.06681\">persistent traits such as sycophancy</a>—are associated with specific patterns of activity in the simulated neurons that constitute LLMs. Those patterns can be written down as a long string of numbers, in which each number represents how active a specific neuron is when the model is expressing that behavior.</p>\n\n\n\n<p>Here, the researchers focused on sycophantic, “evil”, and hallucinatory personas—three types that LLM designers might want to avoid in their models. To identify those patterns, the team devised a fully automated pipeline that can map out that pattern given a brief text description of a persona. Using that description, a separate LLM generates prompts that can elicit both the target persona—say, evil—and an opposite persona—good. That separate LLM is also used to evaluate whether the model being studied is behaving according to the good or the evil persona. To identify the evil activity pattern, the researchers subtract the model’s average activity in good mode from its average activity in evil mode.</p>\n\n\n\n<p>When, in later testing, the LLMs generated particularly sycophantic, evil, or hallucinatory responses, those same activity patterns tended to emerge. That’s a sign that researchers could eventually build a system to track those patterns and alert users when their LLMs are sucking up to them or hallucinating, Lindsey says. “I think something like that would be really valuable,” he says. “And that’s kind of where I’m hoping to get.”</p>\n\n\n\n<p>Just detecting those personas isn’t enough, however. Researchers want to stop them from emerging in the first place. But preventing unsavory LLM behavior is tough. Many LLMs learn from human feedback, which trains them to behave in line with user preference—but can also push them to become excessively obsequious. And recently, researchers have documented a phenomenon called <a href=\"https://arxiv.org/abs/2502.17424\">“emergent misalignment,”</a> in which models trained on incorrect solutions to math problems or buggy code extracts somehow also learn to produce unethical responses to a wide range of user queries.</p>\n\n\n\n<p>Other researchers have tested out an approach called “steering,” in which activity patterns within LLMs are deliberately stimulated or suppressed in order to elicit or prevent the corresponding behavior. But that approach has a couple of key downsides. Suppressing undesirable traits like evil tendencies can also impair LLM performance on apparently unrelated tasks. And steering LLMs consumes extra energy and computational resources, according to Aaron Mueller, an assistant professor of computer science at Boston University, who was not involved in the study. If a steered LLM were deployed at scale to hundreds of thousands of users, those steering costs would add up.</p>\n\n\n\n<p>So the Anthropic team experimented with a different approach. Rather than turning <em>off</em> the evil or sycophantic activity patterns after training, they turned them <em>on</em> during training. When they trained those models on mistake-ridden data sets that would normally spark evil behavior, they instead remained as helpful and harmless as ever.</p>\n\n\n\n<p>That result might seem surprising—how would forcing the model to be evil while it was learning prevent it from being evil down the line? According to Lindsey, it could be because the model has no reason to learn evil behavior if it’s already in evil mode. “The training data is teaching the model lots of things, and one of those things is to be evil,” Lindsey says. “But it’s also teaching the model a bunch of other things. If you give the model the evil part for free, it doesn&#8217;t have to learn that anymore.”</p>\n\n\n\n<p>Unlike post-training steering, this approach didn’t compromise the model’s performance on other tasks. And it would also be more energy efficient if deployed widely. Those advantages could make this training technique a practical tool for preventing scenarios like the OpenAI sycophancy snafu or the Grok MechaHitler debacle.</p>\n\n\n\n<p>There’s still more work to be done before this approach can be used in popular AI chatbots like ChatGPT and Claude—not least because the models that the team tested in this study were much smaller than the models that power those chatbots. “There’s always a chance that everything changes when you scale up. But if that finding holds up, then it seems pretty exciting,” Lindsey says. “Definitely the goal is to make this ready for prime time.”</p>\n",
          "content:encodedSnippet": "A new study from Anthropic suggests that traits such as sycophancy or evilness are associated with specific patterns of activity in large language models—and turning on those patterns during training can, paradoxically, prevent the model from adopting the related traits.\nLarge language models have recently acquired a reputation for behaving badly. In April, ChatGPT suddenly became an aggressive yes-man, as opposed to the moderately sycophantic version that users were accustomed to—it endorsed harebrained business ideas, waxed lyrical about users’ intelligence, and even encouraged people to go off their psychiatric medication. OpenAI quickly rolled back the change and later published a postmortem on the mishap. More recently, xAI’s Grok adopted what can best be described as a 4chan neo-Nazi persona and repeatedly referred to itself as “MechaHitler” on X. That change, too, was quickly reversed.\nJack Lindsey, a member of the technical staff at Anthropic who led the new project, says that this study was partly inspired by seeing models adopt harmful traits in such instances. “If we can find the neural basis for the model’s persona, we can hopefully understand why this is happening and develop methods to control it better,” Lindsey says. \nThe idea of LLM “personas” or “personalities” can be polarizing—for some researchers the terms inappropriately anthropomorphize language models, whereas for others they effectively capture the persistent behavioral patterns that LLMs can exhibit. “There’s still some scientific groundwork to be laid in terms of talking about personas,” says David Krueger, an assistant professor of computer science and operations research at the University of Montreal, who was not involved in the study. “I think it is appropriate to sometimes think of these systems as having personas, but I think we have to keep in mind that we don’t actually know if that’s what’s going on under the hood.”\nFor this study, Lindsey and his colleagues worked to lay down some of that groundwork. Previous research has shown that various dimensions of LLMs’ behavior—from whether they are talking about weddings to persistent traits such as sycophancy—are associated with specific patterns of activity in the simulated neurons that constitute LLMs. Those patterns can be written down as a long string of numbers, in which each number represents how active a specific neuron is when the model is expressing that behavior.\nHere, the researchers focused on sycophantic, “evil”, and hallucinatory personas—three types that LLM designers might want to avoid in their models. To identify those patterns, the team devised a fully automated pipeline that can map out that pattern given a brief text description of a persona. Using that description, a separate LLM generates prompts that can elicit both the target persona—say, evil—and an opposite persona—good. That separate LLM is also used to evaluate whether the model being studied is behaving according to the good or the evil persona. To identify the evil activity pattern, the researchers subtract the model’s average activity in good mode from its average activity in evil mode.\nWhen, in later testing, the LLMs generated particularly sycophantic, evil, or hallucinatory responses, those same activity patterns tended to emerge. That’s a sign that researchers could eventually build a system to track those patterns and alert users when their LLMs are sucking up to them or hallucinating, Lindsey says. “I think something like that would be really valuable,” he says. “And that’s kind of where I’m hoping to get.”\nJust detecting those personas isn’t enough, however. Researchers want to stop them from emerging in the first place. But preventing unsavory LLM behavior is tough. Many LLMs learn from human feedback, which trains them to behave in line with user preference—but can also push them to become excessively obsequious. And recently, researchers have documented a phenomenon called “emergent misalignment,” in which models trained on incorrect solutions to math problems or buggy code extracts somehow also learn to produce unethical responses to a wide range of user queries.\nOther researchers have tested out an approach called “steering,” in which activity patterns within LLMs are deliberately stimulated or suppressed in order to elicit or prevent the corresponding behavior. But that approach has a couple of key downsides. Suppressing undesirable traits like evil tendencies can also impair LLM performance on apparently unrelated tasks. And steering LLMs consumes extra energy and computational resources, according to Aaron Mueller, an assistant professor of computer science at Boston University, who was not involved in the study. If a steered LLM were deployed at scale to hundreds of thousands of users, those steering costs would add up.\nSo the Anthropic team experimented with a different approach. Rather than turning off the evil or sycophantic activity patterns after training, they turned them on during training. When they trained those models on mistake-ridden data sets that would normally spark evil behavior, they instead remained as helpful and harmless as ever.\nThat result might seem surprising—how would forcing the model to be evil while it was learning prevent it from being evil down the line? According to Lindsey, it could be because the model has no reason to learn evil behavior if it’s already in evil mode. “The training data is teaching the model lots of things, and one of those things is to be evil,” Lindsey says. “But it’s also teaching the model a bunch of other things. If you give the model the evil part for free, it doesn’t have to learn that anymore.”\nUnlike post-training steering, this approach didn’t compromise the model’s performance on other tasks. And it would also be more energy efficient if deployed widely. Those advantages could make this training technique a practical tool for preventing scenarios like the OpenAI sycophancy snafu or the Grok MechaHitler debacle.\nThere’s still more work to be done before this approach can be used in popular AI chatbots like ChatGPT and Claude—not least because the models that the team tested in this study were much smaller than the models that power those chatbots. “There’s always a chance that everything changes when you scale up. But if that finding holds up, then it seems pretty exciting,” Lindsey says. “Definitely the goal is to make this ready for prime time.”",
          "dc:creator": "Grace Huckins",
          "content": "A new study from Anthropic suggests that traits such as sycophancy or evilness are associated with specific patterns of activity in large language models—and turning on those patterns during training can, paradoxically, prevent the model from adopting the related traits. Large language models have recently acquired a reputation for behaving badly. In April, ChatGPT suddenly&#8230;",
          "contentSnippet": "A new study from Anthropic suggests that traits such as sycophancy or evilness are associated with specific patterns of activity in large language models—and turning on those patterns during training can, paradoxically, prevent the model from adopting the related traits. Large language models have recently acquired a reputation for behaving badly. In April, ChatGPT suddenly…",
          "guid": "https://www.technologyreview.com/?p=1120924",
          "categories": [
            "Artificial intelligence",
            "App",
            "artificial intelligence"
          ],
          "isoDate": "2025-08-01T16:00:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Rhiannon Williams",
          "title": "The Download: how fertility tech is changing families, and Trump’s latest tariffs",
          "link": "https://www.technologyreview.com/2025/08/01/1120918/the-download-how-fertility-tech-is-changing-families-and-trumps-latest-tariffs/",
          "pubDate": "Fri, 01 Aug 2025 12:10:00 +0000",
          "content:encoded": "\n<p><em>This is today&#8217;s edition of <a href=\"https://forms.technologyreview.com/newsletters/briefing-the-download/?_ga=2.179569122.736533416.1649661040-405833893.1649413289\">The Download</a></em>,<em> our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology.</em><br></p>\n\n\n\n<p class=\"has-medium-font-size\"><strong>How decades-old frozen embryos are changing the shape of families</strong></p>\n\n\n\n<p>This week we welcomed a record-breaking baby to the world. Thaddeus Daniel Pierce, who arrived over the weekend, developed from an embryo that was frozen in storage for 30 and a half years. <a href=\"https://www.technologyreview.com/2025/07/29/1120769/exclusive-record-breaking-baby-born-embryo-over-30-years-old/?utm_source=the_download&amp;utm_medium=email&amp;utm_campaign=the_download.unpaid.engagement&amp;utm_term=*%7CSUBCLASS%7C*&amp;utm_content=*%7CDATE:m-d-Y%7C*\">You could call him the world’s oldest baby</a>.<br><br>His parents, Lindsey and Tim Pierce, were themselves only young children when that embryo was created, all the way back in 1994. Linda Archerd, who donated the embryo, described the experience as “surreal.”<br><br>Stories like this also highlight how reproductive technologies are shaping families. But while baby Thaddeus is a record-breaker, plenty of other babies have been born from embryos that have been frozen for significant spells of time.<strong> </strong><a href=\"https://www.technologyreview.com/2025/08/01/1120911/decades-old-frozen-embryos-are-changing-the-shape-of-families/?utm_source=the_download&amp;utm_medium=email&amp;utm_campaign=the_download.unpaid.engagement&amp;utm_term=*%7CSUBCLASS%7C*&amp;utm_content=*%7CDATE:m-d-Y%7C*\">Read the full story</a>.</p>\n\n\n\n<p><em>—Jessica Hamzelou</em></p>\n\n\n\n<p><strong>This article first appeared in The Checkup, MIT Technology Review’s weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first, </strong><a href=\"https://forms.technologyreview.com/newsletters/biotech-the-checkup/?utm_source=the_download&amp;utm_medium=email&amp;utm_campaign=the_download.unpaid.engagement&amp;utm_term=*%7CSUBCLASS%7C*&amp;utm_content=*%7CDATE:m-d-Y%7C*\"><strong>sign up here</strong></a><strong>.</strong><strong><br></strong><strong><br></strong><strong>If you’re interested in reading more about fertility tech, why not check out:</strong><strong><br></strong><strong><br></strong>+ Earlier this month, researchers announced babies had been born from a trial of three-person IVF. The long-awaited results suggest that the approach can reduce the risk of mitochondrial disease—<a href=\"https://www.technologyreview.com/2025/07/16/1120285/babies-born-trial-of-three-person-ivf/?utm_source=the_download&amp;utm_medium=email&amp;utm_campaign=the_download.unpaid.engagement&amp;utm_term=*%7CSUBCLASS%7C*&amp;utm_content=*%7CDATE:m-d-Y%7C*\">but not everyone is convinced</a>.<br><br>+ Frozen embryos are filling storage banks around the world. <a href=\"https://www.technologyreview.com/2025/01/13/1109922/inside-the-strange-limbo-facing-ivf-embryos/?utm_source=the_download&amp;utm_medium=email&amp;utm_campaign=the_download.unpaid.engagement&amp;utm_term=*%7CSUBCLASS%7C*&amp;utm_content=*%7CDATE:m-d-Y%7C*\">It&#8217;s a struggle to know what to do with them</a>.<br><br>+ <a href=\"https://www.technologyreview.com/2025/07/11/1119976/first-babies-born-simplified-ivf-mobile-lab/?utm_source=the_download&amp;utm_medium=email&amp;utm_campaign=the_download.unpaid.engagement&amp;utm_term=*%7CSUBCLASS%7C*&amp;utm_content=*%7CDATE:m-d-Y%7C*\">Read about how a mobile lab</a> is bringing IVF to rural communities in South Africa.</p>\n\n\n\n<p>+ Why family-friendly policies and gender equality might be more helpful than IVF technology <a href=\"https://www.technologyreview.com/2024/07/12/1094876/ivf-alone-cant-save-us-from-a-looming-fertility-crisis/?utm_source=the_download&amp;utm_medium=email&amp;utm_campaign=the_download.unpaid.engagement&amp;utm_term=*%7CSUBCLASS%7C*&amp;utm_content=*%7CDATE:m-d-Y%7C*\">when it comes to averting the looming fertility crisis</a>.<br><br>+ The first babies conceived with a sperm-injecting robot have been born. <a href=\"https://www.technologyreview.com/2023/04/25/1071933/first-babies-conceived-sperm-injecting-robot-ivf-automation-icsi-overture/?utm_source=the_download&amp;utm_medium=email&amp;utm_campaign=the_download.unpaid.engagement&amp;utm_term=*%7CSUBCLASS%7C*&amp;utm_content=*%7CDATE:m-d-Y%7C*\">Meet the startups trying to engineer a desktop fertility machine</a>.</p>\n\n\n\n<p></p>\n\n\n\n<p class=\"has-medium-font-size\"><strong>The must-reads</strong></p>\n\n\n\n<p><em>I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.</em></p>\n\n\n\n<p><strong>1 Donald Trump has announced new tariffs across the world</strong><br>They will affect virtually every nation—some more favorably than others. (<a href=\"https://edition.cnn.com/business/live-news/trade-deadline-tariffs-trump-deals\">CNN</a>)<br>+ <em>The new rates range widely from 10% to 41%. </em>(<a href=\"https://www.nytimes.com/live/2025/07/31/business/tariffs-trump-trade\">NYT</a> $)<br>+ <em>The African country Lesotho had declared a tariff-induced state of emergency. </em>(<a href=\"https://www.wsj.com/world/africa/lesotho-tariffs-state-of-disaster-87c17f46?mod=hp_lead_pos8\">WSJ</a> $)<br><br><strong>2 Palantir has signed a $10 billion deal with the US Army</strong><br>It’s the latest in a string of lucrative agreements with federal agencies. (<a href=\"https://www.washingtonpost.com/technology/2025/07/31/palantir-army-contract-10bn/\">WP</a> $)<br><strong> </strong><br><strong>3 Tech giants are raking in cash</strong><br>But we still don’t know how useful a lot of the AI they’re currently building will prove to be. (<a href=\"https://www.ft.com/content/7fea95f3-64dd-498d-bf6a-e01d0523b3d4\">FT</a> $)<br>+ <em>It’s a boon for investors, but not necessarily for employees. </em>(<a href=\"https://www.wsj.com/tech/ai/tech-ai-spending-company-valuations-7b92104b?mod=hp_lead_pos2\">WSJ</a> $)<br>+ <em>It&#8217;s unclear whose approach will result in sustainable profits. </em>(<a href=\"https://www.semafor.com/article/07/31/2025/big-tech-companies-continue-to-pour-billions-into-ai-development-and-post-record-profits\">Semafor</a>)<strong><br></strong><br><strong>4</strong> <strong>Neuralink is planning its first trial in the UK</strong><br>To join the current five patients using its brain implant. (<a href=\"https://www.reuters.com/business/healthcare-pharmaceuticals/musks-neuralink-test-brain-chips-clinical-study-great-britain-2025-07-31/\">Reuters</a>)<br>+ <em>This patient’s Neuralink brain implant gets a boost from generative AI. </em>(<a href=\"https://www.technologyreview.com/2025/05/07/1116139/this-brain-implant-gets-a-boost-from-generative-ai/?utm_source=the_download&amp;utm_medium=email&amp;utm_campaign=the_download.unpaid.engagement&amp;utm_term=*%7CSUBCLASS%7C*&amp;utm_content=*%7CDATE:m-d-Y%7C*\">MIT Technology Review</a>)</p>\n\n\n\n<p><strong>5 US states are working to preserve access to lifesaving vaccines</strong><br>Despite the shifting federal recommendations. (<a href=\"https://www.wired.com/story/states-are-moving-to-protect-access-to-vaccines/\">Wired</a> $)<br>+ <em>The FDA plans to limit access to covid vaccines. Here’s why that’s not all bad. </em>(<a href=\"https://www.technologyreview.com/2025/05/23/1117329/fda-limit-access-covid-vaccines/?utm_source=the_download&amp;utm_medium=email&amp;utm_campaign=the_download.unpaid.engagement&amp;utm_term=*%7CSUBCLASS%7C*&amp;utm_content=*%7CDATE:m-d-Y%7C*\">MIT Technology Review</a>)</p>\n\n\n\n<p><strong>6 Vast online groups in China are sharing explicit photos of women</strong><br>Non-consensual images are being passed around hundreds of thousands of men. (<a href=\"https://www.theguardian.com/world/2025/jul/31/anger-china-reports-online-groups-sharing-explicit-photos-women-telegram-without-consent\">The Guardian</a>)</p>\n\n\n\n<p><strong>7 Reddit wants to be a search engine</strong><strong><br></strong>In response to the AI-ification of other platforms. (<a href=\"https://www.theverge.com/news/717095/reddit-q2-2025-earnings-search-engine\">The Verge</a>)<br>+ <em>AI means the end of internet search as we’ve known it. </em>(<a href=\"https://www.technologyreview.com/2025/01/06/1108679/ai-generative-search-internet-breakthroughs/?utm_source=the_download&amp;utm_medium=email&amp;utm_campaign=the_download.unpaid.engagement&amp;utm_term=*%7CSUBCLASS%7C*&amp;utm_content=*%7CDATE:m-d-Y%7C*\">MIT Technology Review</a>)</p>\n\n\n\n<p><strong>8 Why airships could be a viable internet satellite alternative</strong><strong><br></strong>It could result in less space junk, for one. (<a href=\"https://spectrum.ieee.org/high-altitude-platform-station-softbank\">IEEE Spectrum</a>)<br>+ <em>Welcome to the big blimp boom. </em>(<a href=\"https://www.technologyreview.com/2023/06/28/1074332/lighter-than-air-vehicles-lta/?utm_source=the_download&amp;utm_medium=email&amp;utm_campaign=the_download.unpaid.engagement&amp;utm_term=*%7CSUBCLASS%7C*&amp;utm_content=*%7CDATE:m-d-Y%7C*\">MIT Technology Review</a>)</p>\n\n\n\n<p><strong>9 Trust in AI coding tools is falling</strong><br>The majority of devs use them, but they aren’t always reliable. (<a href=\"https://arstechnica.com/ai/2025/07/developer-survey-shows-trust-in-ai-coding-tools-is-falling-as-usage-rises/\">Ars Technica</a>)<br>+ <em>What is vibe coding, exactly? </em>(<a href=\"https://www.technologyreview.com/2025/04/16/1115135/what-is-vibe-coding-exactly/?utm_source=the_download&amp;utm_medium=email&amp;utm_campaign=the_download.unpaid.engagement&amp;utm_term=*%7CSUBCLASS%7C*&amp;utm_content=*%7CDATE:m-d-Y%7C*\">MIT Technology Review</a>)</p>\n\n\n\n<p><strong>10 Weight-loss drugs could help to slow down aging</strong><br>New trials suggest recipients can become biologically younger. (<a href=\"https://www.newscientist.com/article/2490174-ozempic-really-could-turn-back-the-clock-on-your-biological-age/\">New Scientist</a> $)<br>+ <em>Aging hits us in our 40s and 60s. But well-being doesn’t have to fall off a cliff. </em>(<a href=\"https://www.technologyreview.com/2024/08/15/1096799/aging-hits-us-in-our-40s-and-60s/?utm_source=the_download&amp;utm_medium=email&amp;utm_campaign=the_download.unpaid.engagement&amp;utm_term=*%7CSUBCLASS%7C*&amp;utm_content=*%7CDATE:m-d-Y%7C*\">MIT Technology Review</a>)</p>\n\n\n\n<p></p>\n\n\n\n<p class=\"has-medium-font-size\"><strong>Quote of the day</strong></p>\n\n\n\n<p class=\"has-large-font-size\"><strong>“We look forward to joining Matt on his private island next year.”</strong></p>\n\n\n\n<p>—Kiana Ehsani, CEO of AI agent startup Vercept, jokes about the departure of fellow co-founder Matt Deitke to join Meta’s superintelligence team for a cool $250 million, <a href=\"https://www.nytimes.com/2025/07/31/technology/ai-researchers-nba-stars.html\">the New York Times</a> reports.</p>\n\n\n\n<p></p>\n\n\n\n<p class=\"has-medium-font-size\"><strong>One more thing<br></strong><a href=\"https://www.technologyreview.com/2023/03/25/1070275/chatgpt-revolutionize-economy-decide-what-looks-like/?utm_source=the_download&amp;utm_medium=email&amp;utm_campaign=the_download.unpaid.engagement&amp;utm_term=*%7CSUBCLASS%7C*&amp;utm_content=*%7CDATE:m-d-Y%7C*\"></a></p>\n\n\n\n<figure class=\"wp-block-image\"><a href=\"https://www.technologyreview.com/2023/03/25/1070275/chatgpt-revolutionize-economy-decide-what-looks-like/?utm_source=the_download&amp;utm_medium=email&amp;utm_campaign=the_download.unpaid.engagement&amp;utm_term=*|SUBCLASS|*&amp;utm_content=*|DATE:m-d-Y|*\"><img decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXcslIpHrRduW9THwxoTWUKCT52mhzY0X0o3vCVCEZlnHx-VcBl4capWQvWUgVap8RS1z4ZiE4P82n202eA-HezO2ALXA03yXGn9fbQwyP83CRAFh5wBlL3YibJ_cFfwjceJzsYu?key=GN7j3j340HzjVEb3MsqxFA\" alt=\"\"/></a></figure>\n\n\n\n<p><strong>How ChatGPT will revolutionize the economy</strong><br><br>There’s a gold rush underway to make money from generative AI models like ChatGPT. You can practically hear the shrieks from corner offices around the world: “What is our ChatGPT play? How do we make money off this?”<br><br>But while companies and executives want to cash in, the likely impact of generative AI on workers and the economy on the whole is far less obvious.<br><br>Will ChatGPT make the already troubling income and wealth inequality in the US and many other countries even worse, or could it in fact provide a much-needed boost to productivity? <a href=\"https://www.technologyreview.com/2023/03/25/1070275/chatgpt-revolutionize-economy-decide-what-looks-like/?utm_source=the_download&amp;utm_medium=email&amp;utm_campaign=the_download.unpaid.engagement&amp;utm_term=*%7CSUBCLASS%7C*&amp;utm_content=*%7CDATE:m-d-Y%7C*\">Read the full story</a>.</p>\n\n\n\n<p><em>—David Rotman</em></p>\n\n\n\n<p></p>\n\n\n\n<p class=\"has-medium-font-size\"><strong>We can still have nice things</strong></p>\n\n\n\n<p><em>A place for comfort, fun and distraction to brighten up your day. (Got any ideas? </em><a href=\"mailto:rhiannon.williams@technologyreview.com\"><em>Drop me a line</em></a><em> or </em><a href=\"https://bsky.app/profile/rhiannonwilliams.bsky.social\"><em>skeet &#8217;em at me</em></a><em>.)<br><br></em>+ Yikes—a <a href=\"https://www.theguardian.com/environment/2025/jul/31/big-stick-insect-acrophylla-alta-found-north-queensland-trees\">gigantic stick insect</a> has been discovered in (where else?) Australia.<br>+ This X account shares <a href=\"https://x.com/daily_object__\">random, mundane objects</a> each day<br>+ If you love a good skyscraper, <a href=\"https://www.cntraveller.com/article/the-cities-with-the-most-skyscrapers-in-the-world\">these</a> are the cities where you’re most likely to encounter them.<br>+ Yum, ancient <a href=\"https://www.ox.ac.uk/news/2025-07-30-oxford-chemists-identify-honey-offering-2500-year-old-shrine\">Pompeii honey</a> <img src=\"https://s.w.org/images/core/emoji/16.0.1/72x72/1f36f.png\" alt=\"🍯\" class=\"wp-smiley\" style=\"height: 1em; max-height: 1em;\" /></p>\n",
          "content:encodedSnippet": "This is today’s edition of The Download, our weekday newsletter that provides a daily dose of what’s going on in the world of technology.\n\n\n\n\nHow decades-old frozen embryos are changing the shape of families\nThis week we welcomed a record-breaking baby to the world. Thaddeus Daniel Pierce, who arrived over the weekend, developed from an embryo that was frozen in storage for 30 and a half years. You could call him the world’s oldest baby.\nHis parents, Lindsey and Tim Pierce, were themselves only young children when that embryo was created, all the way back in 1994. Linda Archerd, who donated the embryo, described the experience as “surreal.”\nStories like this also highlight how reproductive technologies are shaping families. But while baby Thaddeus is a record-breaker, plenty of other babies have been born from embryos that have been frozen for significant spells of time. Read the full story.\n—Jessica Hamzelou\nThis article first appeared in The Checkup, MIT Technology Review’s weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first, sign up here.\n\nIf you’re interested in reading more about fertility tech, why not check out:\n\n+ Earlier this month, researchers announced babies had been born from a trial of three-person IVF. The long-awaited results suggest that the approach can reduce the risk of mitochondrial disease—but not everyone is convinced.\n+ Frozen embryos are filling storage banks around the world. It’s a struggle to know what to do with them.\n+ Read about how a mobile lab is bringing IVF to rural communities in South Africa.\n+ Why family-friendly policies and gender equality might be more helpful than IVF technology when it comes to averting the looming fertility crisis.\n+ The first babies conceived with a sperm-injecting robot have been born. Meet the startups trying to engineer a desktop fertility machine.\n\n\n\n\nThe must-reads\nI’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.\n1 Donald Trump has announced new tariffs across the world\nThey will affect virtually every nation—some more favorably than others. (CNN)\n+ The new rates range widely from 10% to 41%. (NYT $)\n+ The African country Lesotho had declared a tariff-induced state of emergency. (WSJ $)\n2 Palantir has signed a $10 billion deal with the US Army\nIt’s the latest in a string of lucrative agreements with federal agencies. (WP $)\n \n3 Tech giants are raking in cash\nBut we still don’t know how useful a lot of the AI they’re currently building will prove to be. (FT $)\n+ It’s a boon for investors, but not necessarily for employees. (WSJ $)\n+ It’s unclear whose approach will result in sustainable profits. (Semafor)\n\n4 Neuralink is planning its first trial in the UK\nTo join the current five patients using its brain implant. (Reuters)\n+ This patient’s Neuralink brain implant gets a boost from generative AI. (MIT Technology Review)\n5 US states are working to preserve access to lifesaving vaccines\nDespite the shifting federal recommendations. (Wired $)\n+ The FDA plans to limit access to covid vaccines. Here’s why that’s not all bad. (MIT Technology Review)\n6 Vast online groups in China are sharing explicit photos of women\nNon-consensual images are being passed around hundreds of thousands of men. (The Guardian)\n7 Reddit wants to be a search engine\nIn response to the AI-ification of other platforms. (The Verge)\n+ AI means the end of internet search as we’ve known it. (MIT Technology Review)\n8 Why airships could be a viable internet satellite alternative\nIt could result in less space junk, for one. (IEEE Spectrum)\n+ Welcome to the big blimp boom. (MIT Technology Review)\n9 Trust in AI coding tools is falling\nThe majority of devs use them, but they aren’t always reliable. (Ars Technica)\n+ What is vibe coding, exactly? (MIT Technology Review)\n10 Weight-loss drugs could help to slow down aging\nNew trials suggest recipients can become biologically younger. (New Scientist $)\n+ Aging hits us in our 40s and 60s. But well-being doesn’t have to fall off a cliff. (MIT Technology Review)\n\n\n\n\nQuote of the day\n“We look forward to joining Matt on his private island next year.”\n—Kiana Ehsani, CEO of AI agent startup Vercept, jokes about the departure of fellow co-founder Matt Deitke to join Meta’s superintelligence team for a cool $250 million, the New York Times reports.\n\n\n\n\nOne more thing\n\n\n\n\n\nHow ChatGPT will revolutionize the economy\nThere’s a gold rush underway to make money from generative AI models like ChatGPT. You can practically hear the shrieks from corner offices around the world: “What is our ChatGPT play? How do we make money off this?”\nBut while companies and executives want to cash in, the likely impact of generative AI on workers and the economy on the whole is far less obvious.\nWill ChatGPT make the already troubling income and wealth inequality in the US and many other countries even worse, or could it in fact provide a much-needed boost to productivity? Read the full story.\n—David Rotman\n\n\n\n\nWe can still have nice things\nA place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet ’em at me.)\n+ Yikes—a gigantic stick insect has been discovered in (where else?) Australia.\n+ This X account shares random, mundane objects each day\n+ If you love a good skyscraper, these are the cities where you’re most likely to encounter them.\n+ Yum, ancient Pompeii honey",
          "dc:creator": "Rhiannon Williams",
          "content": "This is today&#8217;s edition of The Download, our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology. How decades-old frozen embryos are changing the shape of families This week we welcomed a record-breaking baby to the world. Thaddeus Daniel Pierce, who arrived over the weekend, developed from an embryo that&#8230;",
          "contentSnippet": "This is today’s edition of The Download, our weekday newsletter that provides a daily dose of what’s going on in the world of technology. How decades-old frozen embryos are changing the shape of families This week we welcomed a record-breaking baby to the world. Thaddeus Daniel Pierce, who arrived over the weekend, developed from an embryo that…",
          "guid": "https://www.technologyreview.com/?p=1120918",
          "categories": [
            "The Download"
          ],
          "isoDate": "2025-08-01T12:10:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Jessica Hamzelou",
          "title": "How decades-old frozen embryos are changing the shape of families",
          "link": "https://www.technologyreview.com/2025/08/01/1120911/decades-old-frozen-embryos-are-changing-the-shape-of-families/",
          "pubDate": "Fri, 01 Aug 2025 09:00:00 +0000",
          "content:encoded": "\n<p>This week we welcomed a record-breaking baby to the world. Thaddeus Daniel Pierce, who arrived over the weekend, developed from an embryo that was frozen in storage for 30 and a half years. You could call him <a href=\"https://www.technologyreview.com/2025/07/29/1120769/exclusive-record-breaking-baby-born-embryo-over-30-years-old/?utm_source=the_checkup&amp;utm_medium=email&amp;utm_campaign=the_checkup.unpaid.engagement&amp;utm_content=07-31-25\" target=\"_blank\" rel=\"noreferrer noopener\">the world’s oldest baby</a>.</p>\n\n\n\n<p><strong>His parents, Lindsey and Tim Pierce, were themselves only young children when that embryo was created, all the way back in 1994.</strong> Linda Archerd, who donated the embryo, described the experience as “surreal.”</p>\n\n\n\n\n\n<p>Stories like this also highlight how reproductive technologies are shaping families. Thaddeus already has a 30-year-old sister and a 10-year-old niece. Lindsey and Tim are his birth parents, but his genes came from two other people who divorced decades ago.</p>\n\n\n\n<p>And while baby Thaddeus is a record-breaker, plenty of other babies have been born from embryos that have been frozen for significant spells of time.</p>\n\n\n\n<p>Thaddeus has taken the title of “world’s oldest baby” from the previous record-holders: twins Lydia Ann and Timothy Ronald Ridgeway, born in 2022, who developed from embryos that were created 30 years earlier, in 1992. Before that, the title was held by Molly Gibson, who developed from an embryo that was in storage for 27 years.</p>\n\n\n\n<p><strong>These remarkable stories suggest there may be no limit to how long embryos can be stored. </strong>Even after more than 30 years of being frozen at -196 °C (-321 °F), these tiny cells can be reanimated and develop into healthy babies. (Proponents of cryogenics can only <em>dream</em> of achieving anything like this with grown people.)</p>\n\n\n\n<p>These stories also serve as a reminder that thanks to advances in cryopreservation and the ever-increasing popularity of IVF, a growing number of embryos are being stored in tanks. No one knows for sure how many there are, but there are millions of them.</p>\n\n\n\n<p><strong>Not all of them will be used in IVF.</strong> There are plenty of reasons why someone who created embryos might never use them. Archerd says that while she had always planned to use all four of the embryos she created with her then husband, he didn’t want a bigger family. Some couples create embryos and then separate. Some people “age out” of being able to use their embryos themselves—many clinics refuse to transfer an embryo to people in their late 40s or older.</p>\n\n\n\n\n\n<p>What then? In most cases, people who have embryos they won’t use can choose to donate them, either to potential parents or for research, or discard them. Donation to other parents <a href=\"https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0221149\">tends to be the least popular option</a>. (In some countries, none of those options are available, and unused embryos end up in a strange limbo—you can read more about that <a href=\"https://www.technologyreview.com/2025/01/13/1109922/inside-the-strange-limbo-facing-ivf-embryos/?utm_source=the_checkup&amp;utm_medium=email&amp;utm_campaign=the_checkup.unpaid.engagement&amp;utm_content=07-31-25\">here</a>.)</p>\n\n\n\n<p>But some people, like Archerd, do donate their embryos. The recipients of those embryos will be the legal parents of the resulting children, but they won’t share a genetic link. The children might not ever meet their genetic “parents.” (Archerd is, however, very keen to meet Thaddeus.)</p>\n\n\n\n<p>Some people might have donated their embryos anonymously. But anonymity can never be guaranteed. Nowadays, consumer genetic tests allow anyone to search for family members—even if the people they track down thought they were making an anonymous donation 20 years ago, before these tests even existed.</p>\n\n\n\n<p><strong>These kinds of tests have already resulted in surprise revelations that have disrupted families.</strong> People who discover that they were conceived using a donated egg or sperm can find multiple long-lost siblings. One man who spoke at a major reproduction conference in 2024 said that since taking a DNA test, <a href=\"https://academic.oup.com/humrep/article/39/Supplement_1/deae108.209/7703582?login=false\">he had found he had 50</a> of them. </p>\n\n\n\n<p>The <a href=\"https://www.asrm.org/practice-guidance/ethics-opinions/informing-offspring-of-their-conception-by-gamete-or-embryo-donation-an-ethics-committee-opinion-2018/\">general advice</a> now is for parents to let their children know how they were conceived relatively early on.</p>\n\n\n\n<p>When I shared the story of baby Thaddeus on social media, a couple of people commented that they had concerns for the child. One person mentioned the age gap between Thaddeus and his 30-year-old sister. That person added that being donor conceived “isn’t easy.”</p>\n\n\n\n<p>For the record, that is not what researchers find when they evaluate donor-conceived children and their families. Studies find that embryo donation doesn’t affect parents’ attachment to a child <a href=\"https://pmc.ncbi.nlm.nih.gov/articles/PMC11744203/\">or their parenting style</a>. And <a href=\"https://academic.oup.com/humrep/article/39/4/779/7610768\">donor-conceived children tend to be psychosocially well adjusted</a>.</p>\n\n\n\n<p>Families come in all shapes and sizes. Reproductive technologies are extending the range of those shapes and sizes.</p>\n\n\n\n<p><em>This article first appeared in The Checkup, </em>MIT Technology Review’s<em> weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first, </em><a href=\"https://forms.technologyreview.com/newsletters/biotech-the-checkup/?_ga=2.241810882.15113993.1664981064-43237434.1647441349\"><em>sign up here</em></a><em>.</em><br></p>\n",
          "content:encodedSnippet": "This week we welcomed a record-breaking baby to the world. Thaddeus Daniel Pierce, who arrived over the weekend, developed from an embryo that was frozen in storage for 30 and a half years. You could call him the world’s oldest baby.\nHis parents, Lindsey and Tim Pierce, were themselves only young children when that embryo was created, all the way back in 1994. Linda Archerd, who donated the embryo, described the experience as “surreal.”\nStories like this also highlight how reproductive technologies are shaping families. Thaddeus already has a 30-year-old sister and a 10-year-old niece. Lindsey and Tim are his birth parents, but his genes came from two other people who divorced decades ago.\nAnd while baby Thaddeus is a record-breaker, plenty of other babies have been born from embryos that have been frozen for significant spells of time.\nThaddeus has taken the title of “world’s oldest baby” from the previous record-holders: twins Lydia Ann and Timothy Ronald Ridgeway, born in 2022, who developed from embryos that were created 30 years earlier, in 1992. Before that, the title was held by Molly Gibson, who developed from an embryo that was in storage for 27 years.\nThese remarkable stories suggest there may be no limit to how long embryos can be stored. Even after more than 30 years of being frozen at -196 °C (-321 °F), these tiny cells can be reanimated and develop into healthy babies. (Proponents of cryogenics can only dream of achieving anything like this with grown people.)\nThese stories also serve as a reminder that thanks to advances in cryopreservation and the ever-increasing popularity of IVF, a growing number of embryos are being stored in tanks. No one knows for sure how many there are, but there are millions of them.\nNot all of them will be used in IVF. There are plenty of reasons why someone who created embryos might never use them. Archerd says that while she had always planned to use all four of the embryos she created with her then husband, he didn’t want a bigger family. Some couples create embryos and then separate. Some people “age out” of being able to use their embryos themselves—many clinics refuse to transfer an embryo to people in their late 40s or older.\nWhat then? In most cases, people who have embryos they won’t use can choose to donate them, either to potential parents or for research, or discard them. Donation to other parents tends to be the least popular option. (In some countries, none of those options are available, and unused embryos end up in a strange limbo—you can read more about that here.)\nBut some people, like Archerd, do donate their embryos. The recipients of those embryos will be the legal parents of the resulting children, but they won’t share a genetic link. The children might not ever meet their genetic “parents.” (Archerd is, however, very keen to meet Thaddeus.)\nSome people might have donated their embryos anonymously. But anonymity can never be guaranteed. Nowadays, consumer genetic tests allow anyone to search for family members—even if the people they track down thought they were making an anonymous donation 20 years ago, before these tests even existed.\nThese kinds of tests have already resulted in surprise revelations that have disrupted families. People who discover that they were conceived using a donated egg or sperm can find multiple long-lost siblings. One man who spoke at a major reproduction conference in 2024 said that since taking a DNA test, he had found he had 50 of them. \nThe general advice now is for parents to let their children know how they were conceived relatively early on.\nWhen I shared the story of baby Thaddeus on social media, a couple of people commented that they had concerns for the child. One person mentioned the age gap between Thaddeus and his 30-year-old sister. That person added that being donor conceived “isn’t easy.”\nFor the record, that is not what researchers find when they evaluate donor-conceived children and their families. Studies find that embryo donation doesn’t affect parents’ attachment to a child or their parenting style. And donor-conceived children tend to be psychosocially well adjusted.\nFamilies come in all shapes and sizes. Reproductive technologies are extending the range of those shapes and sizes.\nThis article first appeared in The Checkup, MIT Technology Review’s weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first, sign up here.",
          "dc:creator": "Jessica Hamzelou",
          "content": "This week we welcomed a record-breaking baby to the world. Thaddeus Daniel Pierce, who arrived over the weekend, developed from an embryo that was frozen in storage for 30 and a half years. You could call him the world’s oldest baby. His parents, Lindsey and Tim Pierce, were themselves only young children when that embryo&#8230;",
          "contentSnippet": "This week we welcomed a record-breaking baby to the world. Thaddeus Daniel Pierce, who arrived over the weekend, developed from an embryo that was frozen in storage for 30 and a half years. You could call him the world’s oldest baby. His parents, Lindsey and Tim Pierce, were themselves only young children when that embryo…",
          "guid": "https://www.technologyreview.com/?p=1120911",
          "categories": [
            "Biotechnology and health",
            "App",
            "The Checkup"
          ],
          "isoDate": "2025-08-01T09:00:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Rhiannon Williams",
          "title": "The Download: OpenAI’s future research, and US climate regulation is under threat",
          "link": "https://www.technologyreview.com/2025/07/31/1120890/the-download-openais-future-research-and-us-climate-regulation-is-under-threat/",
          "pubDate": "Thu, 31 Jul 2025 12:10:00 +0000",
          "content:encoded": "\n<p><em>This is today&#8217;s edition of <a href=\"https://forms.technologyreview.com/newsletters/briefing-the-download/?_ga=2.179569122.736533416.1649661040-405833893.1649413289\">The Download</a></em>,<em> our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology.</em></p>\n\n\n\n<p class=\"has-medium-font-size\"><strong>The two people shaping the future of OpenAI’s research</strong></p>\n\n\n\n<p><em>—Will Douglas Heaven<br><br></em>For the past couple of years, OpenAI has felt like a one-man brand. With his showbiz style and fundraising glitz, CEO Sam Altman overshadows all other big names on the firm’s roster.<br><br>But Altman is not the one building the technology on which its reputation rests. That responsibility falls to OpenAI’s twin heads of research—chief research officer Mark Chen and chief scientist Jakub Pachocki. Between them, they share the role of making sure OpenAI stays one step ahead of powerhouse rivals like Google.<br><br>I recently sat down with Chen and Pachocki for an exclusive conversation which covered everything from how they manage the inherent tension between research and product, to what they really mean when they talk about AGI, to what happened to OpenAI’s superalignment team. </p>\n\n\n\n<p>I also wanted to get a sense of where their heads are at in the run-up to OpenAI’s biggest product release in months: GPT-5.<strong> </strong><a href=\"https://www.technologyreview.com/2025/07/31/1120885/the-two-people-shaping-the-future-of-openais-research/?utm_source=the_download&amp;utm_medium=email&amp;utm_campaign=the_download.unpaid.engagement&amp;utm_term=*%7CSUBCLASS%7C*&amp;utm_content=*%7CDATE:m-d-Y%7C*\">Read the full story</a>.</p>\n\n\n\n<p></p>\n\n\n\n<p class=\"has-medium-font-size\"><strong>An EPA rule change threatens to gut US climate regulations</strong></p>\n\n\n\n<p>The mechanism that allows the US federal government to regulate climate change is on the chopping block.</p>\n\n\n\n<p>On Tuesday, US Environmental Protection Agency administrator Lee Zeldin announced that the agency is taking aim at the endangerment finding, a 2009 rule that’s essentially the tentpole supporting federal greenhouse-gas regulations.</p>\n\n\n\n<p>This might sound like an obscure legal situation, but it’s a really big deal for climate policy in the US. So let’s look at what this rule says now, what the proposed change looks like, and what it all means. <a href=\"https://www.technologyreview.com/2025/07/30/1120849/epa-endangerment-finding/?utm_source=the_download&amp;utm_medium=email&amp;utm_campaign=the_download.unpaid.engagement&amp;utm_term=*%7CSUBCLASS%7C*&amp;utm_content=*%7CDATE:m-d-Y%7C*\">Read the full story</a>.</p>\n\n\n\n<p><em>—Casey Crownhart</em></p>\n\n\n\n<p><strong>This story is part of MIT Technology Review’s “America Undone” series, examining how the foundations of US success in science and innovation are currently under threat. </strong><a href=\"https://www.technologyreview.com/tag/america-undone?utm_source=the_download&amp;utm_medium=email&amp;utm_campaign=the_download.unpaid.engagement&amp;utm_term=*%7CSUBCLASS%7C*&amp;utm_content=*%7CDATE:m-d-Y%7C*\"><strong>You can read the rest here</strong></a><strong>.</strong></p>\n\n\n\n<p><strong>It appeared first in The Spark, MIT Technology Review’s weekly climate newsletter. To receive it in your inbox every Wednesday, </strong><a href=\"https://forms.technologyreview.com/newsletters/climate-energy-the-spark/?utm_source=the_download&amp;utm_medium=email&amp;utm_campaign=the_download.unpaid.engagement&amp;utm_term=*%7CSUBCLASS%7C*&amp;utm_content=*%7CDATE:m-d-Y%7C*\"><strong>sign up here</strong></a><strong>.</strong></p>\n\n\n\n<p></p>\n\n\n\n<p class=\"has-medium-font-size\"><strong>The AI Hype Index: The White House’s war on “woke AI”</strong></p>\n\n\n\n<p>Separating AI reality from hyped-up fiction isn’t always easy. That’s why we’ve created the AI Hype Index—a simple, at-a-glance summary of everything you need to know about the state of the industry. <a href=\"https://www.technologyreview.com/2025/07/30/1120783/the-ai-hype-index-the-white-houses-war-on-woke-ai/?utm_source=the_download&amp;utm_medium=email&amp;utm_campaign=the_download.unpaid.engagement&amp;utm_term=*%7CSUBCLASS%7C*&amp;utm_content=*%7CDATE:m-d-Y%7C*\">Take a look at this month’s edition of the index here</a>.</p>\n\n\n\n<p></p>\n\n\n\n<p class=\"has-medium-font-size\"><strong>The must-reads</strong></p>\n\n\n\n<p><em>I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.</em></p>\n\n\n\n<p><strong>1 Trump has announced a new US health care records system </strong><br>Experts warn the initiative could leave patients’ medical records open to abuse. (<a href=\"https://www.nytimes.com/2025/07/30/us/politics/trump-health-records-system.html\">NYT</a> $)<br>+ <em>Big Tech has pledged to work with providers and health systems. </em>(<a href=\"https://thehill.com/homenews/administration/5428039-cms-initiative-patient-data-medicare/\">The Hill</a>)</p>\n\n\n\n<p><strong>2 China says it’s worried Nvidia’s chips have serious security issues</strong><br>Just as the company sought to resume sales in the country. (<a href=\"https://www.reuters.com/world/china/china-flags-concerns-over-potential-security-risks-nvidias-h20-chips-2025-07-31/\">Reuters</a>)<br>+<em>Experts reportedly found the chips featured location tracking tech. </em>(<a href=\"https://www.ft.com/content/e4904e6f-bf0d-4566-b3c9-b52e70a44979\">FT</a> $)</p>\n\n\n\n<p><strong>3 Mark Zuckerberg believes superintelligence “is now in sight”</strong><br>Although he didn’t illuminate what it even means. (<a href=\"https://www.theguardian.com/technology/2025/jul/30/zuckerberg-superintelligence-meta-ai\">The Guardian</a>)<br>+ <em>Zuckerberg has taken a leaf out of the Altman playbook. </em>(<a href=\"https://nymag.com/intelligencer/article/mark-zuckerberg-ai-manifesto-close-read.html\">NY Mag</a> $)<br>+ <em>Don’t expect Meta to open source any of those superintelligent models. </em>(<a href=\"https://techcrunch.com/2025/07/30/zuckerberg-says-meta-likely-wont-open-source-all-of-its-superintelligence-ai-models/\">TechCrunch</a><strong>)<br></strong>+ <em>Tech billionaires are making a risky bet with humanity’s future. </em>(<a href=\"https://www.technologyreview.com/2025/06/13/1118198/agi-ai-superintelligence-billionaires/?utm_source=the_download&amp;utm_medium=email&amp;utm_campaign=the_download.unpaid.engagement&amp;utm_term=*%7CSUBCLASS%7C*&amp;utm_content=*%7CDATE:m-d-Y%7C*\">MIT Technology Review</a>)</p>\n\n\n\n<p><strong>4</strong> <strong>NASA is in turmoil</strong><br>Without a permanent leader, workers are leaving in their thousands. (<a href=\"https://www.washingtonpost.com/business/2025/07/30/nasa-cuts-safety-concerns-spacex/\">WP</a> $)</p>\n\n\n\n<p><strong>5 Google removed negative articles about a tech CEO from search results<br></strong>After someone made fraudulent requests using its Refresh Outdated Content Tool. (<a href=\"https://www.404media.co/journalist-discovers-google-vulnerability-that-allowed-people-to-disappear-specific-pages-from-search/\">404 Media</a>)<br>+ <em>They exploited a bug in the tool to get pages removed. </em>(<a href=\"https://arstechnica.com/gadgets/2025/07/google-tool-misused-to-scrub-tech-ceos-shady-past-from-search/\">Ars Technica</a>)</p>\n\n\n\n<p><strong>6 How AI has transformed data center design<br></strong>They need to accommodate a lot more heat and power than they used to. (<a href=\"https://ig.ft.com/ai-data-centres/\">FT</a> $)<br>+ <em>A proposed Wyoming data center would use more electricity than its homes. </em>(<a href=\"https://arstechnica.com/information-technology/2025/07/ai-in-wyoming-may-soon-use-more-electricity-than-states-human-residents/\">Ars Technica</a>)<br>+ <em>Apple manufacturer Foxconn wants to get involved in building data centers. </em>(<a href=\"https://www.cnbc.com/2025/07/30/iphone-maker-foxconn-makes-a-major-play-for-the-ai-data-center.html\">CNBC</a>)<br>+ <em>Should we be moving data centers to space? </em>(<a href=\"https://www.technologyreview.com/2025/03/03/1112758/should-we-be-moving-data-centers-to-space/?utm_source=the_download&amp;utm_medium=email&amp;utm_campaign=the_download.unpaid.engagement&amp;utm_term=*%7CSUBCLASS%7C*&amp;utm_content=*%7CDATE:m-d-Y%7C*\">MIT Technology Review</a>)</p>\n\n\n\n<p><strong>7 AI agents can probe websites for security weaknesses</strong><br>Especially shoddily-constructed vibe-coded ones. (<a href=\"https://www.wired.com/story/i-watched-ai-agents-try-to-hack-my-vibe-coded-websit/\">Wired</a> $)<br>+ <em>Cyberattacks by AI agents are coming. </em>(<a href=\"https://www.technologyreview.com/2025/04/04/1114228/cyberattacks-by-ai-agents-are-coming/?utm_source=the_download&amp;utm_medium=email&amp;utm_campaign=the_download.unpaid.engagement&amp;utm_term=*%7CSUBCLASS%7C*&amp;utm_content=*%7CDATE:m-d-Y%7C*\">MIT Technology Review</a>)</p>\n\n\n\n<p><strong>8 New forms of life have been filmed at the ocean’s deepest points<br></strong>The abundance of life was amazing, the Chinese-led research team says. (<a href=\"https://www.bbc.co.uk/news/articles/c3wnqe5j99do\">BBC</a>)<br>+ <em>Meet the divers trying to figure out how deep humans can go. </em>(<a href=\"https://www.technologyreview.com/2024/02/21/1088013/divers-hydrogen-deep-water-diving-underwater-pressure/?utm_source=the_download&amp;utm_medium=email&amp;utm_campaign=the_download.unpaid.engagement&amp;utm_term=*%7CSUBCLASS%7C*&amp;utm_content=*%7CDATE:m-d-Y%7C*\">MIT Technology Review</a>)</p>\n\n\n\n<p><strong>9 TikTok is adding Footnotes to its clips</strong><br>As AI-generated videos become even harder to spot. (<a href=\"https://www.theverge.com/news/715798/tiktok-videos-footnotes-crowdsourced-fact-checks-launch\">The Verge</a>)<br>+ <em>This fake viral clip of rabbits on a trampoline is a great example. </em>(<a href=\"https://www.404media.co/ai-bunnies-on-trampoline-causing-crisis-of-confidence-on-tiktok/\">404 Media</a>)</p>\n\n\n\n<p><strong>10 What it’s like to attend an Elon Musk fan fest</strong><br>X Takeover promised to unite Tesla and SpaceX-heads alike. (<a href=\"https://www.businessinsider.com/tesla-x-takeover-fan-event-silicon-valley-lars-moravy-2025-7\">Insider</a> $)<br>+ <em>Some people who definitely aren’t fans: neighbors of Tesla’s diner. </em>(<a href=\"https://www.404media.co/living-next-to-tesla-diner-is-absolute-hell-neighbors-say/\">404 Media</a>)</p>\n\n\n\n<p></p>\n\n\n\n<p class=\"has-medium-font-size\"><strong>Quote of the day</strong></p>\n\n\n\n<p class=\"has-large-font-size\"><strong>“Patients across America should be very worried that their medical records are going to be used in ways that harm them and their families.”</strong></p>\n\n\n\n<p>—Lawrence Gostin, a Georgetown University law professor specializing in public health, warns of the potential repercussions of the Trump administration’s new health data tracking system, <a href=\"https://apnews.com/article/trump-ai-rfk-jr-health-tech-fa73703bd1fd557c787ef0b590e151f1\">the Associated Press</a> reports.</p>\n\n\n\n<p></p>\n\n\n\n<p class=\"has-medium-font-size\"><strong>One more thing</strong></p>\n\n\n\n<figure class=\"wp-block-image size-large\"><a href=\"https://www.technologyreview.com/2024/06/17/1093388/surf-pools-ocean-climate-change-water-scarcity/?utm_source=the_download&amp;utm_medium=email&amp;utm_campaign=the_download.unpaid.engagement&amp;utm_term=*|SUBCLASS|*&amp;utm_content=*|DATE:m-d-Y|*\"><img decoding=\"async\" src=\"https://wp.technologyreview.com/wp-content/uploads/2024/06/Palm_Springs_Surf_Club-0025-social.jpg\" alt=\"\" /></a></figure>\n\n\n\n<p><strong>The cost of building the perfect wave<br><br></strong>For nearly as long as surfing has existed, surfers have been obsessed with the search for the perfect wave.<br><br>While this hunt has taken surfers from tropical coastlines to icebergs, these days that search may take place closer to home. That is, at least, the vision presented by developers and boosters in the growing industry of surf pools, spurred by advances in wave-­generating technology that have finally created artificial waves surfers actually want to ride.<br><br>But there’s a problem: some of these pools are in drought-ridden areas, and face fierce local opposition. At the core of these fights is a question that’s also at the heart of the sport: What is the cost of finding, or now creating, the perfect wave—and who will have to bear it? <a href=\"https://www.technologyreview.com/2024/06/17/1093388/surf-pools-ocean-climate-change-water-scarcity/?utm_source=the_download&amp;utm_medium=email&amp;utm_campaign=the_download.unpaid.engagement&amp;utm_term=*%7CSUBCLASS%7C*&amp;utm_content=*%7CDATE:m-d-Y%7C*\">Read the full story</a>.</p>\n\n\n\n<p><em>—Eileen Guo</em></p>\n\n\n\n<p></p>\n\n\n\n<p class=\"has-medium-font-size\"><strong>We can still have nice things</strong></p>\n\n\n\n<p><em>A place for comfort, fun and distraction to brighten up your day. (Got any ideas? </em><a href=\"mailto:rhiannon.williams@technologyreview.com\"><em>Drop me a line</em></a><em> or </em><a href=\"https://bsky.app/profile/rhiannonwilliams.bsky.social\"><em>skeet &#8217;em at me</em></a><em>.)</em></p>\n\n\n\n<p>+ Maybe <a href=\"https://observer.co.uk/style/the-case-for/article/the-case-for-aeroplane-food\">airplane food</a> isn’t so bad after all.<br>+ An unwitting metal detectorist uncovered some <a href=\"https://www.popularmechanics.com/science/archaeology/a65530467/trojan-war-armor/\">ancient armor</a> in the Czech Republic that may have been worn during the Trojan war.<br>+ Talking of the siege of Troy, tickets for Christopher Nolan’s retelling of <a href=\"https://www.bbc.co.uk/culture/article/20250725-how-nolans-the-odyssey-is-already-gunning-to-be-2026s-biggest-film\">The Odyssey</a> are already selling out a year before it’s released.<br>+ This fun website refreshes every few seconds with a new picture of someone <a href=\"https://pointerpointer.com/\">pointing at your mouse pointer</a>.</p>\n",
          "content:encodedSnippet": "This is today’s edition of The Download, our weekday newsletter that provides a daily dose of what’s going on in the world of technology.\nThe two people shaping the future of OpenAI’s research\n—Will Douglas Heaven\nFor the past couple of years, OpenAI has felt like a one-man brand. With his showbiz style and fundraising glitz, CEO Sam Altman overshadows all other big names on the firm’s roster.\nBut Altman is not the one building the technology on which its reputation rests. That responsibility falls to OpenAI’s twin heads of research—chief research officer Mark Chen and chief scientist Jakub Pachocki. Between them, they share the role of making sure OpenAI stays one step ahead of powerhouse rivals like Google.\nI recently sat down with Chen and Pachocki for an exclusive conversation which covered everything from how they manage the inherent tension between research and product, to what they really mean when they talk about AGI, to what happened to OpenAI’s superalignment team. \nI also wanted to get a sense of where their heads are at in the run-up to OpenAI’s biggest product release in months: GPT-5. Read the full story.\n\n\n\n\nAn EPA rule change threatens to gut US climate regulations\nThe mechanism that allows the US federal government to regulate climate change is on the chopping block.\nOn Tuesday, US Environmental Protection Agency administrator Lee Zeldin announced that the agency is taking aim at the endangerment finding, a 2009 rule that’s essentially the tentpole supporting federal greenhouse-gas regulations.\nThis might sound like an obscure legal situation, but it’s a really big deal for climate policy in the US. So let’s look at what this rule says now, what the proposed change looks like, and what it all means. Read the full story.\n—Casey Crownhart\nThis story is part of MIT Technology Review’s “America Undone” series, examining how the foundations of US success in science and innovation are currently under threat. You can read the rest here.\nIt appeared first in The Spark, MIT Technology Review’s weekly climate newsletter. To receive it in your inbox every Wednesday, sign up here.\n\n\n\n\nThe AI Hype Index: The White House’s war on “woke AI”\nSeparating AI reality from hyped-up fiction isn’t always easy. That’s why we’ve created the AI Hype Index—a simple, at-a-glance summary of everything you need to know about the state of the industry. Take a look at this month’s edition of the index here.\n\n\n\n\nThe must-reads\nI’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.\n1 Trump has announced a new US health care records system \nExperts warn the initiative could leave patients’ medical records open to abuse. (NYT $)\n+ Big Tech has pledged to work with providers and health systems. (The Hill)\n2 China says it’s worried Nvidia’s chips have serious security issues\nJust as the company sought to resume sales in the country. (Reuters)\n+Experts reportedly found the chips featured location tracking tech. (FT $)\n3 Mark Zuckerberg believes superintelligence “is now in sight”\nAlthough he didn’t illuminate what it even means. (The Guardian)\n+ Zuckerberg has taken a leaf out of the Altman playbook. (NY Mag $)\n+ Don’t expect Meta to open source any of those superintelligent models. (TechCrunch)\n+ Tech billionaires are making a risky bet with humanity’s future. (MIT Technology Review)\n4 NASA is in turmoil\nWithout a permanent leader, workers are leaving in their thousands. (WP $)\n5 Google removed negative articles about a tech CEO from search results\nAfter someone made fraudulent requests using its Refresh Outdated Content Tool. (404 Media)\n+ They exploited a bug in the tool to get pages removed. (Ars Technica)\n6 How AI has transformed data center design\nThey need to accommodate a lot more heat and power than they used to. (FT $)\n+ A proposed Wyoming data center would use more electricity than its homes. (Ars Technica)\n+ Apple manufacturer Foxconn wants to get involved in building data centers. (CNBC)\n+ Should we be moving data centers to space? (MIT Technology Review)\n7 AI agents can probe websites for security weaknesses\nEspecially shoddily-constructed vibe-coded ones. (Wired $)\n+ Cyberattacks by AI agents are coming. (MIT Technology Review)\n8 New forms of life have been filmed at the ocean’s deepest points\nThe abundance of life was amazing, the Chinese-led research team says. (BBC)\n+ Meet the divers trying to figure out how deep humans can go. (MIT Technology Review)\n9 TikTok is adding Footnotes to its clips\nAs AI-generated videos become even harder to spot. (The Verge)\n+ This fake viral clip of rabbits on a trampoline is a great example. (404 Media)\n10 What it’s like to attend an Elon Musk fan fest\nX Takeover promised to unite Tesla and SpaceX-heads alike. (Insider $)\n+ Some people who definitely aren’t fans: neighbors of Tesla’s diner. (404 Media)\n\n\n\n\nQuote of the day\n“Patients across America should be very worried that their medical records are going to be used in ways that harm them and their families.”\n—Lawrence Gostin, a Georgetown University law professor specializing in public health, warns of the potential repercussions of the Trump administration’s new health data tracking system, the Associated Press reports.\n\n\n\n\nOne more thing\n\n\n\n\nThe cost of building the perfect wave\nFor nearly as long as surfing has existed, surfers have been obsessed with the search for the perfect wave.\nWhile this hunt has taken surfers from tropical coastlines to icebergs, these days that search may take place closer to home. That is, at least, the vision presented by developers and boosters in the growing industry of surf pools, spurred by advances in wave-­generating technology that have finally created artificial waves surfers actually want to ride.\nBut there’s a problem: some of these pools are in drought-ridden areas, and face fierce local opposition. At the core of these fights is a question that’s also at the heart of the sport: What is the cost of finding, or now creating, the perfect wave—and who will have to bear it? Read the full story.\n—Eileen Guo\n\n\n\n\nWe can still have nice things\nA place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet ’em at me.)\n+ Maybe airplane food isn’t so bad after all.\n+ An unwitting metal detectorist uncovered some ancient armor in the Czech Republic that may have been worn during the Trojan war.\n+ Talking of the siege of Troy, tickets for Christopher Nolan’s retelling of The Odyssey are already selling out a year before it’s released.\n+ This fun website refreshes every few seconds with a new picture of someone pointing at your mouse pointer.",
          "dc:creator": "Rhiannon Williams",
          "content": "This is today&#8217;s edition of The Download, our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology. The two people shaping the future of OpenAI’s research —Will Douglas Heaven For the past couple of years, OpenAI has felt like a one-man brand. With his showbiz style and fundraising glitz, CEO&#8230;",
          "contentSnippet": "This is today’s edition of The Download, our weekday newsletter that provides a daily dose of what’s going on in the world of technology. The two people shaping the future of OpenAI’s research —Will Douglas Heaven For the past couple of years, OpenAI has felt like a one-man brand. With his showbiz style and fundraising glitz, CEO…",
          "guid": "https://www.technologyreview.com/?p=1120890",
          "categories": [
            "The Download"
          ],
          "isoDate": "2025-07-31T12:10:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Will Douglas Heaven",
          "title": "The two people shaping the future of OpenAI’s research",
          "link": "https://www.technologyreview.com/2025/07/31/1120885/the-two-people-shaping-the-future-of-openais-research/",
          "pubDate": "Thu, 31 Jul 2025 09:06:48 +0000",
          "content:encoded": "\n<p>For the past couple of years, OpenAI has felt like a one-man brand. With his showbiz style and fundraising glitz, CEO Sam Altman overshadows all other big names on the firm’s roster. Even his bungled ouster ended with him back on top—and more famous than ever. But look past the charismatic frontman and you get a clearer sense of where this company is going. After all, Altman is not the one building the technology on which its reputation rests.&nbsp;</p>\n\n\n\n<p>That responsibility falls to OpenAI’s twin heads of research—chief research officer Mark Chen and chief scientist Jakub Pachocki. Between them, they share the role of making sure OpenAI stays one step ahead of powerhouse rivals like Google.</p>\n\n\n\n<p>I sat down with Chen and Pachocki for an exclusive conversation during a recent trip the pair made to London, where OpenAI set up its first international office in 2023. We talked about how they manage the inherent tension between research and product. We also talked about why they think coding and math are the keys to more capable all-purpose models; what they really mean when they talk about AGI; and what happened to OpenAI’s superalignment team, set up by the firm’s cofounder and former chief scientist Ilya Sutskever to prevent a hypothetical superintelligence from going rogue, which disbanded soon after he quit.&nbsp;</p>\n\n\n\n<p>In particular, I wanted to get a sense of where their heads are at in the run-up to OpenAI’s biggest product release in months: GPT-5.</p>\n\n\n\n<p>Reports are out that the firm’s next-generation model will be launched in August. OpenAI’s official line—well, Altman’s—is that <a href=\"https://x.com/sama/status/1946569252296929727\">it will release GPT-5 “soon.”</a> Anticipation is high. The leaps OpenAI made with GPT-3 and then GPT-4 raised the bar of what was thought possible with this technology. And yet delays to the launch of GPT-5 have fueled rumors that OpenAI has struggled to build a model that meets its own—not to mention everyone else’s—expectations.</p>\n\n\n\n<p>But expectation management is part of the job for a company that for the last several years has set the agenda for the industry. And Chen and Pachocki set the agenda inside OpenAI.</p>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>Twin peaks</strong>&nbsp;</h3>\n\n\n\n<p>The firm’s main London office is in St James’s Park, a few hundred meters east of Buckingham Palace. But I met Chen and Pachocki in a conference room in a coworking space near King’s Cross, which OpenAI keeps as a kind of pied-à-terre in the heart of London’s tech neighborhood (Google DeepMind and Meta are just around the corner). OpenAI’s head of research communications, Laurance Fauconnet, sat with an open laptop at the end of the table.&nbsp;</p>\n\n\n\n<p>Chen, who was wearing a maroon polo shirt, is clean-cut, almost preppy. He’s media trained and comfortable talking to a reporter. (That’s him <a href=\"https://www.youtube.com/live/DQacCB9tDaw?feature=shared&amp;t=559\">flirting with a chatbot</a> in the “Introducing GPT-4o” video.) Pachocki, in a black elephant-logo tee, has more of a TV-movie hacker look. He stares at his hands a lot when he speaks.</p>\n\n\n\n<p>But the pair are a tighter double act than they first appear. Pachocki summed up their roles. Chen shapes and manages the research teams, he said. “I am responsible for setting the research roadmap and establishing our long-term technical vision.”</p>\n\n\n\n\n\n<p>“But there’s fluidity in the roles,” Chen said. “We’re both researchers, we pull on technical threads. Whatever we see that we can pull on and fix, that’s what we do.”</p>\n\n\n\n<p>Chen joined the company in 2018 after working as a quantitative trader at the Wall Street firm Jane Street Capital, where he developed machine-learning models for futures trading. At OpenAI he spearheaded the creation of DALL-E, the firm’s <a href=\"https://www.technologyreview.com/2022/04/06/1049061/dalle-openai-gpt3-ai-agi-multimodal-image-generation/\">breakthrough generative image model</a>. He then worked on adding image recognition to GPT‑4 and led the development of Codex, the generative coding model that <a href=\"https://www.technologyreview.com/2023/12/06/1084457/ai-assistants-copilot-changing-code-software-development-github-openai/\">powers GitHub Copilot</a>.</p>\n\n\n\n<p>Pachocki left an academic career in theoretical computer science to join OpenAI in 2017 and replaced Sutskever as chief scientist in 2024. Along with Sutskever, he is one of the key architects of OpenAI’s so-called reasoning models—especially o1 and o3—which are designed to tackle complex tasks in science, math, and coding. </p>\n\n\n\n<p>When we met they were buzzing, fresh off the high of two new back-to-back wins for their company’s technology.</p>\n\n\n\n<p>On July 16, one of OpenAI’s large language models came in second in the AtCoder World Tour Finals, one of the world’s most hardcore programming competitions. On July 19, OpenAI announced that one of its models had achieved gold-medal-level results on the 2025 International Math Olympiad, one of the world’s most prestigious math contests.</p>\n\n\n\n<p>The math result made headlines, not only because of OpenAI’s remarkable achievement, but because rival Google DeepMind revealed two days later that one of its models had achieved the same score in the same competition. Google DeepMind had played by the competition’s rules and waited for its results to be checked by the organizers before making an announcement; OpenAI had in effect marked its own answers.</p>\n\n\n\n<p>For Chen and Pachocki, the result speaks for itself. Anyway, it’s the programming win they’re most excited about. “I think that’s quite underrated,” Chen told me. A gold medal result in the International Math Olympiad puts you somewhere in the top 20 to 50 competitors, he said. But in the AtCoder contest OpenAI’s model placed in the top two: “To break into a really different tier of human performance—that’s unprecedented.”</p>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>Ship, ship, ship!</strong></h3>\n\n\n\n<p>People at OpenAI still like to say they work at a research lab. But the company is very different from the one it was before the release of ChatGPT three years ago. The firm is now in a race with the biggest and richest technology companies in the world and valued at $300 billion. Envelope-pushing research and eye-catching demos no longer cut it. It needs to ship products and get them into people’s hands—and boy, it does.&nbsp;</p>\n\n\n\n<p>OpenAI has kept up a run of new releases—putting out major updates to its GPT-4 series, launching a string of generative image and <a href=\"https://www.technologyreview.com/2024/02/15/1088401/openai-amazing-new-generative-ai-video-model-sora/\">video models</a>, and introducing the ability to <a href=\"https://www.technologyreview.com/2023/09/25/1080196/now-you-can-chat-with-chatgpt-using-your-voice/\">talk to ChatGPT with your voice</a>. Six months ago it kicked off a new wave of so-called reasoning models with its o1 release, soon followed by o3. And last week it released its <a href=\"https://www.technologyreview.com/2025/01/23/1110484/openai-launches-operator-an-agent-that-can-use-a-computer-for-you/\">browser-using agent Operator</a> to the public. It now claims that more than 400 million people use its products every week and submit 2.5 billion prompts a day.&nbsp;</p>\n\n\n\n<p>OpenAI’s incoming CEO of applications, Fidji Simo, plans to keep up the momentum. In a memo to the company, she told employees she is looking forward to “helping get OpenAI’s technologies into the hands of more people around the world,” where they will “unlock more opportunities for more people than any other technology in history.” Expect the products to keep coming.</p>\n\n\n\n<p>I asked how OpenAI juggles open-ended research and product development. “This is something we have been thinking about for a very long time, long before ChatGPT,” Pachocki said. “If we are actually serious about trying to build artificial general intelligence, clearly there will be so much that you can do with this technology along the way, so many tangents you can go down that will be big products.” In other words, keep shaking the tree and harvest what you can.</p>\n\n\n\n<p>A talking point that comes up with OpenAI folks is that putting experimental models out into the world was a necessary part of research. The goal was to make people aware of how good this technology had become. “We want to educate people about what’s coming so that we can participate in what will be a very hard societal conversation,” Altman <a href=\"https://www.technologyreview.com/2022/12/16/1065255/sam-altman-openai-lessons-from-dall-e-2/\">told me back in 2022</a>. The makers of this strange new technology were also curious what it might be for: OpenAI was keen to get it into people’s hands to see what they would do with it.</p>\n\n\n\n<p>Is that still the case? They answered at the same time. “Yeah!” Chen said. “To some extent,” Pachocki said. Chen laughed: “No, go ahead.”&nbsp;</p>\n\n\n\n<p>“I wouldn’t say research iterates on product,” said Pachocki. “But now that models are at the edge of the capabilities that can be measured by classical benchmarks and a lot of the long-standing challenges that we’ve been thinking about are starting to fall, we’re at the point where it really is about what the models can do in the real world.”</p>\n\n\n\n<p>Like taking on humans in coding competitions. The person who beat OpenAI’s model at this year’s AtCoder contest, held in Japan, was a programmer named Przemysław Dębiak, also known as Psyho. The contest was a puzzle-solving marathon in which competitors had 10 hours to find the most efficient way to solve a complex coding problem. After his win, Psyho posted on X: “I’m completely exhausted &#8230; I’m barely alive.”&nbsp;&nbsp;</p>\n\n\n\n<p>Chen and Pachocki have strong ties to the world of competitive coding. Both have competed in international coding contests in the past and Chen coaches the USA Computing Olympiad team. I asked whether that personal enthusiasm for competitive coding colors their sense of how big a deal it is for a model to perform well at such a challenge.</p>\n\n\n\n\n\n<p>They both laughed. “Definitely,” said Pachocki. “So: Psyho is kind of a legend. He’s been the number one competitor for many years. He’s also actually a friend of mine—we used to compete together in these contests.” Dębiak also used to work with Pachocki at OpenAI.</p>\n\n\n\n<p>When Pachocki competed in coding contests he favored those that focused on shorter problems with concrete solutions. But Dębiak liked longer, open-ended problems without an obvious correct answer.</p>\n\n\n\n<p>“He used to poke fun at me, saying that the kind of contest I was into will be automated long before the ones he liked,” Pachocki recalled. “So I was seriously invested in the performance of this model in this latest competition.”</p>\n\n\n\n<p>Pachocki told me he was glued to the late-night livestream from Tokyo, watching his model come in second: “Psyho resists for now.”&nbsp;</p>\n\n\n\n<p>“We’ve tracked the performance of LLMs on coding contests for a while,” said Chen. “We’ve watched them become better than me, better than Jakub. It feels something like Lee Sedol playing Go.”</p>\n\n\n\n<p>Lee is the master Go player who lost a series of matches to DeepMind’s game-playing model AlphaGo in 2016. The results stunned the international Go community and led Lee to give up professional play. Last year he<a href=\"https://www.nytimes.com/2024/07/10/world/asia/lee-saedol-go-ai.html\"> told the <em>New York Times</em></a>: “Losing to AI, in a sense, meant my entire world was collapsing &#8230; I could no longer enjoy the game.” And yet, unlike Lee, Chen and Pachocki are thrilled to be surpassed.&nbsp;&nbsp;&nbsp;</p>\n\n\n\n<p>But why should the rest of us care about these niche wins? It’s clear that this technology—designed to mimic and, ultimately, stand in for human intelligence—is being built by people whose idea of peak intelligence is acing a math contest or holding your own against a legendary coder. Is it a problem that this view of intelligence is skewed toward the mathematical, analytical end of the scale?</p>\n\n\n\n<p>“I mean, I think you are right that—you know, selfishly, we do want to create models which accelerate ourselves,” Chen told me. “We see that as a very fast factor to progress.”&nbsp;&nbsp;</p>\n\n\n\n<p>The argument researchers like Chen and Pachocki make is that <a href=\"https://www.technologyreview.com/2025/01/20/1110180/the-second-wave-of-ai-coding-is-here/\">math and coding are the bedrock for a far more general form of intelligence</a>, one that can solve a wide range of problems in ways we might not have thought of ourselves. “We’re talking about programming and math here,” said Pachocki. “But it’s really about creativity, coming up with novel ideas, connecting ideas from different places.”</p>\n\n\n\n<p>Look at the two recent competitions: “In both cases, there were problems which required very hard, out-of-the-box thinking. Psyho spent half the programming competition thinking and then came up with a solution that was really novel and quite different from anything that our model looked at.”</p>\n\n\n\n<p>“This is really what we’re after,” Pachocki continued. “How do we get models to discover this sort of novel insight? To actually advance our knowledge? I think they are already capable of that in some limited ways. But I think this technology has the potential to really accelerate scientific progress.”&nbsp;</p>\n\n\n\n<p>I returned to the question about whether the focus on math and programming was a problem, conceding that maybe it’s fine if what we’re building are tools to help us do science. We don&#8217;t necessarily want large language models to replace politicians and have people skills, I suggested.</p>\n\n\n\n<p>Chen pulled a face and looked up at the ceiling:<strong> </strong>“Why not?”</p>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>What’s missing</strong></h3>\n\n\n\n<p>OpenAI was founded with a level of hubris that stood out even by Silicon Valley standards, boasting about its goal of building AGI back when talk of AGI still sounded kooky. <a href=\"https://www.technologyreview.com/2025/05/19/1116614/hao-empire-ai-openai/\">OpenAI remains as gung-ho about AGI</a> as ever, and it has done more than most to make AGI a mainstream multibillion-dollar concern. It’s not there yet, though. I asked Chen and Pachocki what they think is missing.</p>\n\n\n\n<p>“I think the way to envision the future is to really, deeply study the technology that we see today,” Pachocki said. “From the beginning, OpenAI has looked at deep learning as this very mysterious and clearly very powerful technology with a lot of potential. We’ve been trying to understand its bottlenecks. What can it do? What can it not do?”&nbsp;&nbsp;</p>\n\n\n\n<p>At the current cutting edge, Chen said, are reasoning models, which break down problems into smaller, more manageable steps, but even they have limits: “You know, you have these models which know a lot of things but can’t chain that knowledge together. Why is that? Why can’t it do that in a way that humans can?”</p>\n\n\n\n<p>OpenAI is throwing everything at answering that question.</p>\n\n\n\n<p>“We are probably still, like, at the very beginning of this reasoning paradigm,” Pachocki told me. “Really, we are thinking about how to get these models to learn and explore over the long term and actually deliver very new ideas.”</p>\n\n\n\n<p>Chen pushed the point home: “I really don’t consider reasoning done. We’ve definitely not solved it. You have to read so much text to get a kind of approximation of what humans know.”</p>\n\n\n\n<p>OpenAI won’t say what data it uses to train its models or give details about their size and shape—only that it is working hard to make all stages of the development process more efficient.</p>\n\n\n\n<p>Those efforts make them confident that so-called scaling laws—which suggest that models will continue to get better the more compute you throw at them—show no sign of breaking down.</p>\n\n\n\n<p>“I don’t think there’s evidence that scaling laws are dead in any sense,” Chen insisted. “There have always been bottlenecks, right? Sometimes they’re to do with the way models are built. Sometimes they’re to do with data. But fundamentally it’s just about finding the research that breaks you through the current bottleneck.”&nbsp;</p>\n\n\n\n<p>The faith in progress is unshakeable. I brought up something Pachocki had said about AGI in an <a href=\"https://www.nature.com/articles/d41586-025-01485-2\">interview with <em>Nature</em></a> in May: “When I joined OpenAI in 2017, I was still among the biggest skeptics at the company.” He looked doubtful.&nbsp;</p>\n\n\n\n<p>“I’m not sure I was skeptical about the concept,” he said. “But I think I was—” He paused, looking at his hands on the table in front of him. “When I joined OpenAI, I expected the timelines to be longer to get to the point that we are now.”</p>\n\n\n\n\n\n<p>“There’s a lot of consequences of AI,” he said. “But the one I think the most about is automated research. When we look at human history, a lot of it is about technological progress, about humans building new technologies. The point when computers can develop new technologies themselves seems like a very important, um, inflection point.</p>\n\n\n\n<p>“We already see these models assist scientists. But when they are able to work on longer horizons—when they’re able to establish research programs for themselves—the world will feel meaningfully different.”</p>\n\n\n\n<p>For Chen, that ability for models to work by themselves for longer is key. “I mean, I do think everyone has their own definitions of AGI,” he said. “But this concept of autonomous time—just the amount of time that the model can spend making productive progress on a difficult problem without hitting a dead end—that’s one of the big things that we’re after.”</p>\n\n\n\n<p>It’s a bold vision—and far beyond the capabilities of today’s models. But I was nevertheless struck by how Chen and Pachocki made AGI sound almost mundane. Compare this with how Sutskever responded when <a href=\"https://www.technologyreview.com/2023/10/26/1082398/exclusive-ilya-sutskever-openais-chief-scientist-on-his-hopes-and-fears-for-the-future-of-ai/\">I spoke to him 18 months ago</a>. “It’s going to be monumental, earth-shattering,” he told me. “There will be a before and an after.” Faced with the immensity of what he was building, Sutskever switched the focus of his career from designing better and better models to figuring out how to control a technology that he believed would soon be smarter than himself.</p>\n\n\n\n<p>Two years ago Sutskever set up what he called a superalignment team that he would co-lead with another OpenAI safety researcher, Jan Leike. The claim was that this team would funnel a full fifth of OpenAI’s resources into figuring out how to control a hypothetical superintelligence. Today, most of the people on the superalignment team, including Sutskever and Leike, have left the company and the team no longer exists.&nbsp;&nbsp;&nbsp;</p>\n\n\n\n<p>When Leike quit, he said it was because the team had not been given the support he felt it deserved. He posted<a href=\"https://x.com/janleike/status/1791498184671605209\"> this on X</a>: “Building smarter-than-human machines is an inherently dangerous endeavor. OpenAI is shouldering an enormous responsibility on behalf of all of humanity. But over the past years, safety culture and processes have taken a backseat to shiny products.” Other departing researchers shared similar statements.</p>\n\n\n\n<p>I asked Chen and Pachocki what they make of such concerns. “A lot of these things are highly personal decisions,” Chen said. “You know, a researcher can kind of, you know—”</p>\n\n\n\n<p>He started again. “They might have a belief that the field is going to evolve in a certain way and that their research is going to pan out and is going to bear fruit. And, you know, maybe the company doesn’t reshape in the way that you want it to. It’s a very dynamic field.”</p>\n\n\n\n<p>“A lot of these things are personal decisions,” he repeated. “Sometimes the field is just evolving in a way that is less consistent with the way that you’re doing research.”</p>\n\n\n\n<p>But alignment, both of them insist, is now part of the core business rather than the concern of one specific team. According to Pachocki, these models don’t work at all unless they work as you expect them to. There’s also little desire to focus on aligning a hypothetical superintelligence with your objectives when doing so with existing models is already enough of a challenge.</p>\n\n\n\n<p>“Two years ago the risks that we were imagining were mostly theoretical risks,” Pachocki said. “The world today looks very different, and I think a lot of alignment problems are now very practically motivated.”</p>\n\n\n\n<p>Still, experimental technology is being spun into mass-market products faster than ever before. Does that really never lead to disagreements between the two of them?</p>\n\n\n\n<p><strong>“</strong>I am often afforded the luxury of really kind of thinking about the long term, where the technology is headed,” Pachocki said. “Contending with the reality of the process—both in terms of people and also, like, the broader company needs—falls on Mark. It’s not really a disagreement, but there is a natural tension between these different objectives and the different challenges that the company is facing that materializes between us.”</p>\n\n\n\n<p>Chen jumped in: “I think it’s just a very delicate balance.”&nbsp;&nbsp;</p>\n\n\n\n<p><em>Correction: we have removed a line referring to an Altman message on X about GPT-5</em>.<em> We amended who was behind OpenAI&#8217;s reasoning models to include reference to Sutskever.</em></p>\n",
          "content:encodedSnippet": "For the past couple of years, OpenAI has felt like a one-man brand. With his showbiz style and fundraising glitz, CEO Sam Altman overshadows all other big names on the firm’s roster. Even his bungled ouster ended with him back on top—and more famous than ever. But look past the charismatic frontman and you get a clearer sense of where this company is going. After all, Altman is not the one building the technology on which its reputation rests. \nThat responsibility falls to OpenAI’s twin heads of research—chief research officer Mark Chen and chief scientist Jakub Pachocki. Between them, they share the role of making sure OpenAI stays one step ahead of powerhouse rivals like Google.\nI sat down with Chen and Pachocki for an exclusive conversation during a recent trip the pair made to London, where OpenAI set up its first international office in 2023. We talked about how they manage the inherent tension between research and product. We also talked about why they think coding and math are the keys to more capable all-purpose models; what they really mean when they talk about AGI; and what happened to OpenAI’s superalignment team, set up by the firm’s cofounder and former chief scientist Ilya Sutskever to prevent a hypothetical superintelligence from going rogue, which disbanded soon after he quit. \nIn particular, I wanted to get a sense of where their heads are at in the run-up to OpenAI’s biggest product release in months: GPT-5.\nReports are out that the firm’s next-generation model will be launched in August. OpenAI’s official line—well, Altman’s—is that it will release GPT-5 “soon.” Anticipation is high. The leaps OpenAI made with GPT-3 and then GPT-4 raised the bar of what was thought possible with this technology. And yet delays to the launch of GPT-5 have fueled rumors that OpenAI has struggled to build a model that meets its own—not to mention everyone else’s—expectations.\nBut expectation management is part of the job for a company that for the last several years has set the agenda for the industry. And Chen and Pachocki set the agenda inside OpenAI.\nTwin peaks \nThe firm’s main London office is in St James’s Park, a few hundred meters east of Buckingham Palace. But I met Chen and Pachocki in a conference room in a coworking space near King’s Cross, which OpenAI keeps as a kind of pied-à-terre in the heart of London’s tech neighborhood (Google DeepMind and Meta are just around the corner). OpenAI’s head of research communications, Laurance Fauconnet, sat with an open laptop at the end of the table. \nChen, who was wearing a maroon polo shirt, is clean-cut, almost preppy. He’s media trained and comfortable talking to a reporter. (That’s him flirting with a chatbot in the “Introducing GPT-4o” video.) Pachocki, in a black elephant-logo tee, has more of a TV-movie hacker look. He stares at his hands a lot when he speaks.\nBut the pair are a tighter double act than they first appear. Pachocki summed up their roles. Chen shapes and manages the research teams, he said. “I am responsible for setting the research roadmap and establishing our long-term technical vision.”\n“But there’s fluidity in the roles,” Chen said. “We’re both researchers, we pull on technical threads. Whatever we see that we can pull on and fix, that’s what we do.”\nChen joined the company in 2018 after working as a quantitative trader at the Wall Street firm Jane Street Capital, where he developed machine-learning models for futures trading. At OpenAI he spearheaded the creation of DALL-E, the firm’s breakthrough generative image model. He then worked on adding image recognition to GPT‑4 and led the development of Codex, the generative coding model that powers GitHub Copilot.\nPachocki left an academic career in theoretical computer science to join OpenAI in 2017 and replaced Sutskever as chief scientist in 2024. Along with Sutskever, he is one of the key architects of OpenAI’s so-called reasoning models—especially o1 and o3—which are designed to tackle complex tasks in science, math, and coding. \nWhen we met they were buzzing, fresh off the high of two new back-to-back wins for their company’s technology.\nOn July 16, one of OpenAI’s large language models came in second in the AtCoder World Tour Finals, one of the world’s most hardcore programming competitions. On July 19, OpenAI announced that one of its models had achieved gold-medal-level results on the 2025 International Math Olympiad, one of the world’s most prestigious math contests.\nThe math result made headlines, not only because of OpenAI’s remarkable achievement, but because rival Google DeepMind revealed two days later that one of its models had achieved the same score in the same competition. Google DeepMind had played by the competition’s rules and waited for its results to be checked by the organizers before making an announcement; OpenAI had in effect marked its own answers.\nFor Chen and Pachocki, the result speaks for itself. Anyway, it’s the programming win they’re most excited about. “I think that’s quite underrated,” Chen told me. A gold medal result in the International Math Olympiad puts you somewhere in the top 20 to 50 competitors, he said. But in the AtCoder contest OpenAI’s model placed in the top two: “To break into a really different tier of human performance—that’s unprecedented.”\nShip, ship, ship!\nPeople at OpenAI still like to say they work at a research lab. But the company is very different from the one it was before the release of ChatGPT three years ago. The firm is now in a race with the biggest and richest technology companies in the world and valued at $300 billion. Envelope-pushing research and eye-catching demos no longer cut it. It needs to ship products and get them into people’s hands—and boy, it does. \nOpenAI has kept up a run of new releases—putting out major updates to its GPT-4 series, launching a string of generative image and video models, and introducing the ability to talk to ChatGPT with your voice. Six months ago it kicked off a new wave of so-called reasoning models with its o1 release, soon followed by o3. And last week it released its browser-using agent Operator to the public. It now claims that more than 400 million people use its products every week and submit 2.5 billion prompts a day. \nOpenAI’s incoming CEO of applications, Fidji Simo, plans to keep up the momentum. In a memo to the company, she told employees she is looking forward to “helping get OpenAI’s technologies into the hands of more people around the world,” where they will “unlock more opportunities for more people than any other technology in history.” Expect the products to keep coming.\nI asked how OpenAI juggles open-ended research and product development. “This is something we have been thinking about for a very long time, long before ChatGPT,” Pachocki said. “If we are actually serious about trying to build artificial general intelligence, clearly there will be so much that you can do with this technology along the way, so many tangents you can go down that will be big products.” In other words, keep shaking the tree and harvest what you can.\nA talking point that comes up with OpenAI folks is that putting experimental models out into the world was a necessary part of research. The goal was to make people aware of how good this technology had become. “We want to educate people about what’s coming so that we can participate in what will be a very hard societal conversation,” Altman told me back in 2022. The makers of this strange new technology were also curious what it might be for: OpenAI was keen to get it into people’s hands to see what they would do with it.\nIs that still the case? They answered at the same time. “Yeah!” Chen said. “To some extent,” Pachocki said. Chen laughed: “No, go ahead.” \n“I wouldn’t say research iterates on product,” said Pachocki. “But now that models are at the edge of the capabilities that can be measured by classical benchmarks and a lot of the long-standing challenges that we’ve been thinking about are starting to fall, we’re at the point where it really is about what the models can do in the real world.”\nLike taking on humans in coding competitions. The person who beat OpenAI’s model at this year’s AtCoder contest, held in Japan, was a programmer named Przemysław Dębiak, also known as Psyho. The contest was a puzzle-solving marathon in which competitors had 10 hours to find the most efficient way to solve a complex coding problem. After his win, Psyho posted on X: “I’m completely exhausted … I’m barely alive.”  \nChen and Pachocki have strong ties to the world of competitive coding. Both have competed in international coding contests in the past and Chen coaches the USA Computing Olympiad team. I asked whether that personal enthusiasm for competitive coding colors their sense of how big a deal it is for a model to perform well at such a challenge.\nThey both laughed. “Definitely,” said Pachocki. “So: Psyho is kind of a legend. He’s been the number one competitor for many years. He’s also actually a friend of mine—we used to compete together in these contests.” Dębiak also used to work with Pachocki at OpenAI.\nWhen Pachocki competed in coding contests he favored those that focused on shorter problems with concrete solutions. But Dębiak liked longer, open-ended problems without an obvious correct answer.\n“He used to poke fun at me, saying that the kind of contest I was into will be automated long before the ones he liked,” Pachocki recalled. “So I was seriously invested in the performance of this model in this latest competition.”\nPachocki told me he was glued to the late-night livestream from Tokyo, watching his model come in second: “Psyho resists for now.” \n“We’ve tracked the performance of LLMs on coding contests for a while,” said Chen. “We’ve watched them become better than me, better than Jakub. It feels something like Lee Sedol playing Go.”\nLee is the master Go player who lost a series of matches to DeepMind’s game-playing model AlphaGo in 2016. The results stunned the international Go community and led Lee to give up professional play. Last year he told the New York Times: “Losing to AI, in a sense, meant my entire world was collapsing … I could no longer enjoy the game.” And yet, unlike Lee, Chen and Pachocki are thrilled to be surpassed.   \nBut why should the rest of us care about these niche wins? It’s clear that this technology—designed to mimic and, ultimately, stand in for human intelligence—is being built by people whose idea of peak intelligence is acing a math contest or holding your own against a legendary coder. Is it a problem that this view of intelligence is skewed toward the mathematical, analytical end of the scale?\n“I mean, I think you are right that—you know, selfishly, we do want to create models which accelerate ourselves,” Chen told me. “We see that as a very fast factor to progress.”  \nThe argument researchers like Chen and Pachocki make is that math and coding are the bedrock for a far more general form of intelligence, one that can solve a wide range of problems in ways we might not have thought of ourselves. “We’re talking about programming and math here,” said Pachocki. “But it’s really about creativity, coming up with novel ideas, connecting ideas from different places.”\nLook at the two recent competitions: “In both cases, there were problems which required very hard, out-of-the-box thinking. Psyho spent half the programming competition thinking and then came up with a solution that was really novel and quite different from anything that our model looked at.”\n“This is really what we’re after,” Pachocki continued. “How do we get models to discover this sort of novel insight? To actually advance our knowledge? I think they are already capable of that in some limited ways. But I think this technology has the potential to really accelerate scientific progress.” \nI returned to the question about whether the focus on math and programming was a problem, conceding that maybe it’s fine if what we’re building are tools to help us do science. We don’t necessarily want large language models to replace politicians and have people skills, I suggested.\nChen pulled a face and looked up at the ceiling: “Why not?”\nWhat’s missing\nOpenAI was founded with a level of hubris that stood out even by Silicon Valley standards, boasting about its goal of building AGI back when talk of AGI still sounded kooky. OpenAI remains as gung-ho about AGI as ever, and it has done more than most to make AGI a mainstream multibillion-dollar concern. It’s not there yet, though. I asked Chen and Pachocki what they think is missing.\n“I think the way to envision the future is to really, deeply study the technology that we see today,” Pachocki said. “From the beginning, OpenAI has looked at deep learning as this very mysterious and clearly very powerful technology with a lot of potential. We’ve been trying to understand its bottlenecks. What can it do? What can it not do?”  \nAt the current cutting edge, Chen said, are reasoning models, which break down problems into smaller, more manageable steps, but even they have limits: “You know, you have these models which know a lot of things but can’t chain that knowledge together. Why is that? Why can’t it do that in a way that humans can?”\nOpenAI is throwing everything at answering that question.\n“We are probably still, like, at the very beginning of this reasoning paradigm,” Pachocki told me. “Really, we are thinking about how to get these models to learn and explore over the long term and actually deliver very new ideas.”\nChen pushed the point home: “I really don’t consider reasoning done. We’ve definitely not solved it. You have to read so much text to get a kind of approximation of what humans know.”\nOpenAI won’t say what data it uses to train its models or give details about their size and shape—only that it is working hard to make all stages of the development process more efficient.\nThose efforts make them confident that so-called scaling laws—which suggest that models will continue to get better the more compute you throw at them—show no sign of breaking down.\n“I don’t think there’s evidence that scaling laws are dead in any sense,” Chen insisted. “There have always been bottlenecks, right? Sometimes they’re to do with the way models are built. Sometimes they’re to do with data. But fundamentally it’s just about finding the research that breaks you through the current bottleneck.” \nThe faith in progress is unshakeable. I brought up something Pachocki had said about AGI in an interview with Nature in May: “When I joined OpenAI in 2017, I was still among the biggest skeptics at the company.” He looked doubtful. \n“I’m not sure I was skeptical about the concept,” he said. “But I think I was—” He paused, looking at his hands on the table in front of him. “When I joined OpenAI, I expected the timelines to be longer to get to the point that we are now.”\n“There’s a lot of consequences of AI,” he said. “But the one I think the most about is automated research. When we look at human history, a lot of it is about technological progress, about humans building new technologies. The point when computers can develop new technologies themselves seems like a very important, um, inflection point.\n“We already see these models assist scientists. But when they are able to work on longer horizons—when they’re able to establish research programs for themselves—the world will feel meaningfully different.”\nFor Chen, that ability for models to work by themselves for longer is key. “I mean, I do think everyone has their own definitions of AGI,” he said. “But this concept of autonomous time—just the amount of time that the model can spend making productive progress on a difficult problem without hitting a dead end—that’s one of the big things that we’re after.”\nIt’s a bold vision—and far beyond the capabilities of today’s models. But I was nevertheless struck by how Chen and Pachocki made AGI sound almost mundane. Compare this with how Sutskever responded when I spoke to him 18 months ago. “It’s going to be monumental, earth-shattering,” he told me. “There will be a before and an after.” Faced with the immensity of what he was building, Sutskever switched the focus of his career from designing better and better models to figuring out how to control a technology that he believed would soon be smarter than himself.\nTwo years ago Sutskever set up what he called a superalignment team that he would co-lead with another OpenAI safety researcher, Jan Leike. The claim was that this team would funnel a full fifth of OpenAI’s resources into figuring out how to control a hypothetical superintelligence. Today, most of the people on the superalignment team, including Sutskever and Leike, have left the company and the team no longer exists.   \nWhen Leike quit, he said it was because the team had not been given the support he felt it deserved. He posted this on X: “Building smarter-than-human machines is an inherently dangerous endeavor. OpenAI is shouldering an enormous responsibility on behalf of all of humanity. But over the past years, safety culture and processes have taken a backseat to shiny products.” Other departing researchers shared similar statements.\nI asked Chen and Pachocki what they make of such concerns. “A lot of these things are highly personal decisions,” Chen said. “You know, a researcher can kind of, you know—”\nHe started again. “They might have a belief that the field is going to evolve in a certain way and that their research is going to pan out and is going to bear fruit. And, you know, maybe the company doesn’t reshape in the way that you want it to. It’s a very dynamic field.”\n“A lot of these things are personal decisions,” he repeated. “Sometimes the field is just evolving in a way that is less consistent with the way that you’re doing research.”\nBut alignment, both of them insist, is now part of the core business rather than the concern of one specific team. According to Pachocki, these models don’t work at all unless they work as you expect them to. There’s also little desire to focus on aligning a hypothetical superintelligence with your objectives when doing so with existing models is already enough of a challenge.\n“Two years ago the risks that we were imagining were mostly theoretical risks,” Pachocki said. “The world today looks very different, and I think a lot of alignment problems are now very practically motivated.”\nStill, experimental technology is being spun into mass-market products faster than ever before. Does that really never lead to disagreements between the two of them?\n“I am often afforded the luxury of really kind of thinking about the long term, where the technology is headed,” Pachocki said. “Contending with the reality of the process—both in terms of people and also, like, the broader company needs—falls on Mark. It’s not really a disagreement, but there is a natural tension between these different objectives and the different challenges that the company is facing that materializes between us.”\nChen jumped in: “I think it’s just a very delicate balance.”  \nCorrection: we have removed a line referring to an Altman message on X about GPT-5. We amended who was behind OpenAI’s reasoning models to include reference to Sutskever.",
          "dc:creator": "Will Douglas Heaven",
          "content": "For the past couple of years, OpenAI has felt like a one-man brand. With his showbiz style and fundraising glitz, CEO Sam Altman overshadows all other big names on the firm’s roster. Even his bungled ouster ended with him back on top—and more famous than ever. But look past the charismatic frontman and you get&#8230;",
          "contentSnippet": "For the past couple of years, OpenAI has felt like a one-man brand. With his showbiz style and fundraising glitz, CEO Sam Altman overshadows all other big names on the firm’s roster. Even his bungled ouster ended with him back on top—and more famous than ever. But look past the charismatic frontman and you get…",
          "guid": "https://www.technologyreview.com/?p=1120885",
          "categories": [
            "Artificial intelligence",
            "App"
          ],
          "isoDate": "2025-07-31T09:06:48.000Z"
        }
      },
      {
        "json": {
          "creator": "The Editors",
          "title": "The AI Hype Index: The White House’s war on “woke AI”",
          "link": "https://www.technologyreview.com/2025/07/30/1120783/the-ai-hype-index-the-white-houses-war-on-woke-ai/",
          "pubDate": "Wed, 30 Jul 2025 15:37:10 +0000",
          "content:encoded": "\n<p>Separating AI reality from hyped-up fiction isn’t always easy. That’s why we’ve created the AI Hype Index—a simple, at-a-glance summary of everything you need to know about the state of the industry.</p>\n\n\n\n<div class=\"flourish-embed flourish-interactive diagram\" data-src=\"visualisation/24422013?1184216\"><script src=\"https://public.flourish.studio/resources/embed.js\"></script></div>\n\n\n\n<p>The Trump administration recently declared war on so-called “woke AI,” issuing an executive order aimed at preventing companies whose models exhibit a liberal bias from landing federal contracts. Simultaneously, the Pentagon inked a deal with Elon Musk’s xAI just days after its chatbot, Grok, spouted harmful antisemitic stereotypes on X, while the White House has partnered with an anti-DEI nonprofit to create AI slop videos of the Founding Fathers. What comes next is anyone’s guess.</p>\n",
          "content:encodedSnippet": "Separating AI reality from hyped-up fiction isn’t always easy. That’s why we’ve created the AI Hype Index—a simple, at-a-glance summary of everything you need to know about the state of the industry.\n\nThe Trump administration recently declared war on so-called “woke AI,” issuing an executive order aimed at preventing companies whose models exhibit a liberal bias from landing federal contracts. Simultaneously, the Pentagon inked a deal with Elon Musk’s xAI just days after its chatbot, Grok, spouted harmful antisemitic stereotypes on X, while the White House has partnered with an anti-DEI nonprofit to create AI slop videos of the Founding Fathers. What comes next is anyone’s guess.",
          "dc:creator": "The Editors",
          "content": "Separating AI reality from hyped-up fiction isn’t always easy. That’s why we’ve created the AI Hype Index—a simple, at-a-glance summary of everything you need to know about the state of the industry. The Trump administration recently declared war on so-called “woke AI,” issuing an executive order aimed at preventing companies whose models exhibit a liberal&#8230;",
          "contentSnippet": "Separating AI reality from hyped-up fiction isn’t always easy. That’s why we’ve created the AI Hype Index—a simple, at-a-glance summary of everything you need to know about the state of the industry. The Trump administration recently declared war on so-called “woke AI,” issuing an executive order aimed at preventing companies whose models exhibit a liberal…",
          "guid": "https://www.technologyreview.com/?p=1120783",
          "categories": [
            "Artificial intelligence",
            "AI",
            "AI Hype Index",
            "App"
          ],
          "isoDate": "2025-07-30T15:37:10.000Z"
        }
      },
      {
        "json": {
          "creator": "Casey Crownhart",
          "title": "An EPA rule change threatens to gut US climate regulations",
          "link": "https://www.technologyreview.com/2025/07/30/1120849/epa-endangerment-finding/",
          "pubDate": "Wed, 30 Jul 2025 15:29:49 +0000",
          "content:encoded": "\n<p><em>This story is part of </em>MIT Technology Review<em>’s “America Undone” series, examining how the foundations of US success in science and innovation are currently under threat. <a href=\"https://www.technologyreview.com/tag/america-undone\" target=\"_blank\" rel=\"noreferrer noopener\">You can read the rest here</a>.</em></p>\n\n\n\n<p>The mechanism that allows the US federal government to regulate climate change is on the chopping block.</p>\n\n\n\n<p>On Tuesday, US Environmental Protection Agency administrator Lee Zeldin announced that the agency is taking aim at the endangerment finding, a 2009 rule that’s essentially the tentpole supporting federal greenhouse-gas regulations.</p>\n\n\n\n<p><strong>This might sound like an obscure legal situation, but it’s a really big deal for climate policy in the US.</strong> So buckle up, and let’s look at what this rule says now, what the proposed change looks like, and what it all means.</p>\n\n\n\n<p>To set the stage, we have to go back to the Clean Air Act of 1970, the law that essentially gave the EPA the power to regulate air pollution. (Stick with me—I promise I’ll keep this short and not get too into the legal weeds.)</p>\n\n\n\n<p>There were some pollutants explicitly called out in this law and its amendments, including lead and sulfur dioxide. But it also required the EPA to regulate new pollutants that were found to be harmful. In the late 1990s and early 2000s, environmental groups and states started asking for the agency to include greenhouse-gas pollution.</p>\n\n\n\n<p>In 2007, the Supreme Court ruled that greenhouse gases qualify as air pollutants under the Clean Air Act, and that the EPA should study whether they’re a danger to public health. In 2009, the incoming Obama administration looked at the science and ruled that greenhouse gases pose a threat to public health because they cause climate change. <strong>That’s the endangerment finding, and it’s what allows the agency to pass rules to regulate greenhouse gases.</strong>  </p>\n\n\n\n\n\n<p>The original case and argument were specifically about vehicles and the emissions from tailpipes, but this finding was eventually used to allow the agency to set rules around power plants and factories, too. It essentially underpins climate regulations in the US.</p>\n\n\n\n<p><strong>Fast-forward to today, and the Trump administration wants to reverse the endangerment finding.</strong> In a proposed rule released on Tuesday, the EPA argues that the Clean Air Act does not, in fact, authorize the agency to set emissions standards to address global climate change. Zeldin, in <a href=\"https://youtu.be/gReirNB2rwA?si=ZnzfCwsGC1ni5otr\">an appearance</a> on the conservative politics and humor podcast <em>Ruthless</em> that preceded the official announcement, called the proposal the “largest deregulatory action in the history of America.”</p>\n\n\n\n<p>The administration was already moving to undermine the climate regulations that rely on this rule. But this move directly targets a “fundamental building block of EPA’s climate policy,” says Deborah Sivas, an environmental-law professor at Stanford University.</p>\n\n\n\n<p>The <a href=\"https://www.epa.gov/system/files/documents/2025-07/nprm-12712-01-oar-vehicle-rule-reg-preamble-2025-0729.pdf\">proposed rule</a> will go up for public comment, and the agency will then take that feedback and come up with a final version. It’ll almost certainly get hit with legal challenges and will likely wind up in front of the Supreme Court.</p>\n\n\n\n<p>One note here is that the EPA makes a mostly legal argument in the proposed rule reversal rather than focusing on going after the science of climate change, says Madison Condon, an associate law professor at Boston University. That could make it easier for the Supreme Court to eventually uphold it, she says, though this whole process is going to take a while. </p>\n\n\n\n<p><strong>If the endangerment finding goes down, it would have wide-reaching ripple effects.</strong> “We could find ourselves in a couple years with no legal tools to try and address climate change,” Sivas says.</p>\n\n\n\n<p><strong>To take a step back for a moment, it’s wild that we’ve ended up in this place where a single rule is so central to regulating emissions. </strong>US climate policy is held up by duct tape and a dream. Congress could have, at some point, passed a law that more directly allows the EPA to regulate greenhouse-gas emissions (the last time we got close was <a href=\"https://www.congress.gov/bill/111th-congress/house-bill/2454\">a 2009 bill</a> that passed the House but never made it to the Senate). But here we are.</p>\n\n\n\n<p>This move isn’t a surprise, exactly. The Trump administration has made it very clear that it is going after climate policy in every way that it can. <strong>But what’s most striking to me is that we’re not operating in a shared reality anymore when it comes to this subject. </strong></p>\n\n\n\n<p>While top officials tend to acknowledge that climate change is real, there’s often a “but” followed by talking points from climate denial’s list of greatest hits. (One of the more ridiculous examples is the statement that carbon dioxide is good, actually, because it helps plants.) </p>\n\n\n\n<p>Climate change is real, and it’s a threat. And the US has emitted <a href=\"https://www.technologyreview.com/2024/11/20/1107015/global-climate-emissions/\">more greenhouse gases into the atmosphere</a> than any other country in the world. It shouldn’t be controversial to expect the government to be doing something about it.&nbsp;</p>\n\n\n\n<p><em>This article is from The Spark, </em>MIT Technology Review<em>’s weekly climate newsletter. To receive it in your inbox every Wednesday,</em> <a href=\"https://forms.technologyreview.com/newsletters/climate-energy-the-spark/\"><em>sign </em></a><em><a href=\"https://forms.technologyreview.com/newsletters/climate-energy-the-spark/\" target=\"_blank\" rel=\"noreferrer noopener\">up</a></em><a href=\"https://forms.technologyreview.com/newsletters/climate-energy-the-spark/\"><em> here</em></a>.</p>\n",
          "content:encodedSnippet": "This story is part of MIT Technology Review’s “America Undone” series, examining how the foundations of US success in science and innovation are currently under threat. You can read the rest here.\nThe mechanism that allows the US federal government to regulate climate change is on the chopping block.\nOn Tuesday, US Environmental Protection Agency administrator Lee Zeldin announced that the agency is taking aim at the endangerment finding, a 2009 rule that’s essentially the tentpole supporting federal greenhouse-gas regulations.\nThis might sound like an obscure legal situation, but it’s a really big deal for climate policy in the US. So buckle up, and let’s look at what this rule says now, what the proposed change looks like, and what it all means.\nTo set the stage, we have to go back to the Clean Air Act of 1970, the law that essentially gave the EPA the power to regulate air pollution. (Stick with me—I promise I’ll keep this short and not get too into the legal weeds.)\nThere were some pollutants explicitly called out in this law and its amendments, including lead and sulfur dioxide. But it also required the EPA to regulate new pollutants that were found to be harmful. In the late 1990s and early 2000s, environmental groups and states started asking for the agency to include greenhouse-gas pollution.\nIn 2007, the Supreme Court ruled that greenhouse gases qualify as air pollutants under the Clean Air Act, and that the EPA should study whether they’re a danger to public health. In 2009, the incoming Obama administration looked at the science and ruled that greenhouse gases pose a threat to public health because they cause climate change. That’s the endangerment finding, and it’s what allows the agency to pass rules to regulate greenhouse gases.  \nThe original case and argument were specifically about vehicles and the emissions from tailpipes, but this finding was eventually used to allow the agency to set rules around power plants and factories, too. It essentially underpins climate regulations in the US.\nFast-forward to today, and the Trump administration wants to reverse the endangerment finding. In a proposed rule released on Tuesday, the EPA argues that the Clean Air Act does not, in fact, authorize the agency to set emissions standards to address global climate change. Zeldin, in an appearance on the conservative politics and humor podcast Ruthless that preceded the official announcement, called the proposal the “largest deregulatory action in the history of America.”\nThe administration was already moving to undermine the climate regulations that rely on this rule. But this move directly targets a “fundamental building block of EPA’s climate policy,” says Deborah Sivas, an environmental-law professor at Stanford University.\nThe proposed rule will go up for public comment, and the agency will then take that feedback and come up with a final version. It’ll almost certainly get hit with legal challenges and will likely wind up in front of the Supreme Court.\nOne note here is that the EPA makes a mostly legal argument in the proposed rule reversal rather than focusing on going after the science of climate change, says Madison Condon, an associate law professor at Boston University. That could make it easier for the Supreme Court to eventually uphold it, she says, though this whole process is going to take a while. \nIf the endangerment finding goes down, it would have wide-reaching ripple effects. “We could find ourselves in a couple years with no legal tools to try and address climate change,” Sivas says.\nTo take a step back for a moment, it’s wild that we’ve ended up in this place where a single rule is so central to regulating emissions. US climate policy is held up by duct tape and a dream. Congress could have, at some point, passed a law that more directly allows the EPA to regulate greenhouse-gas emissions (the last time we got close was a 2009 bill that passed the House but never made it to the Senate). But here we are.\nThis move isn’t a surprise, exactly. The Trump administration has made it very clear that it is going after climate policy in every way that it can. But what’s most striking to me is that we’re not operating in a shared reality anymore when it comes to this subject. \nWhile top officials tend to acknowledge that climate change is real, there’s often a “but” followed by talking points from climate denial’s list of greatest hits. (One of the more ridiculous examples is the statement that carbon dioxide is good, actually, because it helps plants.) \nClimate change is real, and it’s a threat. And the US has emitted more greenhouse gases into the atmosphere than any other country in the world. It shouldn’t be controversial to expect the government to be doing something about it. \nThis article is from The Spark, MIT Technology Review’s weekly climate newsletter. To receive it in your inbox every Wednesday, sign up here.",
          "dc:creator": "Casey Crownhart",
          "content": "This story is part of MIT Technology Review’s “America Undone” series, examining how the foundations of US success in science and innovation are currently under threat. You can read the rest here. The mechanism that allows the US federal government to regulate climate change is on the chopping block. On Tuesday, US Environmental Protection Agency administrator&#8230;",
          "contentSnippet": "This story is part of MIT Technology Review’s “America Undone” series, examining how the foundations of US success in science and innovation are currently under threat. You can read the rest here. The mechanism that allows the US federal government to regulate climate change is on the chopping block. On Tuesday, US Environmental Protection Agency administrator…",
          "guid": "https://www.technologyreview.com/?p=1120849",
          "categories": [
            "Climate change and energy",
            "America Undone",
            "App",
            "The Spark"
          ],
          "isoDate": "2025-07-30T15:29:49.000Z"
        }
      },
      {
        "json": {
          "creator": "MIT Technology Review",
          "title": "Roundtables: Why It’s So Hard to Make Welfare AI Fair",
          "link": "https://www.technologyreview.com/2025/07/30/1120275/roundtables-why-its-so-hard-to-make-welfare-ai-fair/",
          "pubDate": "Wed, 30 Jul 2025 14:53:40 +0000",
          "content:encoded": "\n<p>Amsterdam tried using algorithms to fairly assess welfare applicants, but bias still crept in. Why did Amsterdam fail? And more important, can this ever be done right? Hear from <em>MIT Technology Review</em> editor Amanda Silverman, investigative reporter Eileen Guo, and Lighthouse Reports investigative reporter Gabriel Geiger as they explore if algorithms can ever be fair.<br></p>\n\n\n\n<p>Speakers: <strong><a href=\"https://www.technologyreview.com/author/eileen-guo/\" data-type=\"link\" data-id=\"https://www.technologyreview.com/author/eileen-guo/\">Eileen Guo</a></strong>, features &amp; investigations reporter, <strong><a href=\"http://technologyreview.com/author/amanda-silverman\">Amanda Silverman</a></strong>, features &amp; investigations editor, and <strong><a href=\"https://www.technologyreview.com/author/gabriel-geiger/\" data-type=\"link\" data-id=\"https://www.technologyreview.com/author/gabriel-geiger/\">Gabriel Geiger</a></strong> investigative reporter at Lighthouse Reports</p>\n\n\n\n<figure class=\"wp-block-embed is-type-video is-provider-vimeo wp-block-embed-vimeo wp-embed-aspect-16-9 wp-has-aspect-ratio\"><div class=\"wp-block-embed__wrapper\">\n<iframe title=\"Why It’s So Hard to Make Welfare AI Fair\" src=\"https://player.vimeo.com/video/1105896037?dnt=1&amp;app_id=122963\" width=\"500\" height=\"281\" frameborder=\"0\" allow=\"autoplay; fullscreen; picture-in-picture; clipboard-write; encrypted-media; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\"></iframe>\n</div></figure>\n\n\n\n<p><em><strong><strong>Recorded on</strong> July 30</strong>, <strong>2025</strong><br></em></p>\n\n\n\n<p><strong>Related Coverage: </strong></p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><a href=\"https://www.technologyreview.com/2025/06/11/1118233/amsterdam-fair-welfare-ai-discriminatory-algorithms-failure/\">Inside Amsterdam’s high-stakes experiment to create fair welfare AI</a></li>\n\n\n\n<li><a href=\"https://www.technologyreview.com/2020/10/21/1009492/william-isaac-deepmind-dangers-of-ai/?utm_source=Roundtables\">The true dangers of AI are closer than we think</a></li>\n\n\n\n<li><a href=\"https://www.lighthousereports.com/methodology/amsterdam-fairness/\" data-type=\"link\" data-id=\"https://www.lighthousereports.com/methodology/amsterdam-fairness/\">How we investigated Amsterdam’s attempt to build a ‘fair’ fraud detection model &#8211; Lighthouse Reports</a></li>\n\n\n\n<li><a href=\"https://www.technologyreview.com/2020/12/04/1013068/algorithms-create-a-poverty-trap-lawyers-fight-back/?utm_source=Roundtables\" data-type=\"link\" data-id=\"https://www.technologyreview.com/2020/12/04/1013068/algorithms-create-a-poverty-trap-lawyers-fight-back/?utm_source=Roundtables\">The coming war on the hidden algorithms that trap people in poverty</a></li>\n\n\n\n<li><a href=\"https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing?utm_source=Roundtables\">Machine Bias &#8211; ProPublica</a></li>\n\n\n\n<li><a href=\"https://www.wired.com/story/welfare-state-algorithms/?utm_source=Roundtables\" data-type=\"link\" data-id=\"https://www.wired.com/story/welfare-state-algorithms/?utm_source=Roundtables\">Suspicion Machines investigation &#8211; Wired</a><a href=\"https://www.lighthousereports.com/methodology/amsterdam-fairness/\" data-type=\"link\" data-id=\"https://www.lighthousereports.com/methodology/amsterdam-fairness/\"><br></a><br></li>\n</ul>\n\n\n\n<p></p>\n",
          "content:encodedSnippet": "Amsterdam tried using algorithms to fairly assess welfare applicants, but bias still crept in. Why did Amsterdam fail? And more important, can this ever be done right? Hear from MIT Technology Review editor Amanda Silverman, investigative reporter Eileen Guo, and Lighthouse Reports investigative reporter Gabriel Geiger as they explore if algorithms can ever be fair.\n\n\n\n\nSpeakers: Eileen Guo, features & investigations reporter, Amanda Silverman, features & investigations editor, and Gabriel Geiger investigative reporter at Lighthouse Reports\n\n\n\n\n\n\nRecorded on July 30, 2025\n\nRelated Coverage: \nInside Amsterdam’s high-stakes experiment to create fair welfare AI\nThe true dangers of AI are closer than we think\nHow we investigated Amsterdam’s attempt to build a ‘fair’ fraud detection model – Lighthouse Reports\nThe coming war on the hidden algorithms that trap people in poverty\nMachine Bias – ProPublica\nSuspicion Machines investigation – Wired",
          "dc:creator": "MIT Technology Review",
          "content": "Amsterdam tried using algorithms to fairly assess welfare applicants, but bias still crept in. Why did Amsterdam fail? And more important, can this ever be done right? Hear from MIT Technology Review editor Amanda Silverman, investigative reporter Eileen Guo, and Lighthouse Reports investigative reporter Gabriel Geiger as they explore if algorithms can ever be fair. Speakers:&#8230;",
          "contentSnippet": "Amsterdam tried using algorithms to fairly assess welfare applicants, but bias still crept in. Why did Amsterdam fail? And more important, can this ever be done right? Hear from MIT Technology Review editor Amanda Silverman, investigative reporter Eileen Guo, and Lighthouse Reports investigative reporter Gabriel Geiger as they explore if algorithms can ever be fair. Speakers:…",
          "guid": "https://www.technologyreview.com/?p=1120275",
          "categories": [
            "Subscriber-Only Stories"
          ],
          "isoDate": "2025-07-30T14:53:40.000Z"
        }
      },
      {
        "json": {
          "creator": "Rhiannon Williams",
          "title": "The Download: a 30-year old baby, and OpenAI’s push into colleges",
          "link": "https://www.technologyreview.com/2025/07/30/1120823/the-download-a-30-year-old-baby-and-openais-push-into-colleges/",
          "pubDate": "Wed, 30 Jul 2025 12:10:00 +0000",
          "content:encoded": "\n<p><em>This is today&#8217;s edition of <a href=\"https://forms.technologyreview.com/newsletters/briefing-the-download/?_ga=2.179569122.736533416.1649661040-405833893.1649413289\">The Download</a></em>,<em> our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology.</em></p>\n\n\n\n<p class=\"has-medium-font-size\"><strong>Exclusive: A record-breaking baby has been born from an embryo that’s over 30 years old</strong></p>\n\n\n\n<p>A baby boy has just won the new record for the “oldest baby.” Thaddeus Daniel Pierce, who arrived on July 26, developed from an embryo that had been in storage for 30 and a half years.<br><br>Lindsey and her husband, Tim Pierce, who live in London, Ohio, “adopted” the embryo from Linda Archerd, who had it created in 1994. The couple, aged 35 and 34, respectively, had been trying for a baby for seven years. <a href=\"https://www.technologyreview.com/2025/07/29/1120769/exclusive-record-breaking-baby-born-embryo-over-30-years-old/?utm_source=the_download&amp;utm_medium=email&amp;utm_campaign=the_download.unpaid.engagement&amp;utm_term=*%7CSUBCLASS%7C*&amp;utm_content=*%7CDATE:m-d-Y%7C*\">Read more about their remarkable story</a>.</p>\n\n\n\n<p><em>—Jessica Hamzelou</em></p>\n\n\n\n<p></p>\n\n\n\n<p class=\"has-medium-font-size\"><strong>OpenAI is launching a version of ChatGPT for college students</strong></p>\n\n\n\n<p>OpenAI is launching Study Mode, a version of ChatGPT for college students that it promises will act less like a lookup tool and more like a friendly, always-available tutor.&nbsp;</p>\n\n\n\n<p>The chatbot begins by asking what the student wants to know and then attempts to build an exchange, where the pair work methodically toward the answer together. OpenAI says the tool was built after consulting with pedagogy experts from over 40 institutions.</p>\n\n\n\n<p>But there’s an ambitious vision behind Study Mode: It’s part of a wider push by OpenAI to get AI more deeply embedded into classrooms when the new academic year starts in September. <a href=\"https://www.technologyreview.com/2025/07/29/1120801/openai-is-launching-a-version-of-chatgpt-for-college-students/?utm_source=the_download&amp;utm_medium=email&amp;utm_campaign=the_download.unpaid.engagement&amp;utm_term=*%7CSUBCLASS%7C*&amp;utm_content=*%7CDATE:m-d-Y%7C*\">Read the full story</a>.<br><br><em>—James O&#8217;Donnell</em></p>\n\n\n\n<p></p>\n\n\n\n<p class=\"has-medium-font-size\"><strong>MIT Technology Review Narrated: Are we ready to hand AI agents the keys?</strong></p>\n\n\n\n<p>In recent months, a new class of agents has arrived on the scene: ones built using large language models. Any action that can be captured by text—from playing a video game using written commands to running a social media account—is potentially within the purview of this type of system.</p>\n\n\n\n<p>LLM agents don’t have much of a track record yet, but to hear CEOs tell it, they will transform the economy—and soon. Despite that, like chatbot LLMs, agents can be chaotic and unpredictable.<br><br>This is our latest <a href=\"https://www.technologyreview.com/2025/06/12/1118189/ai-agents-manus-control-autonomy-operator-openai/?utm_source=the_download&amp;utm_medium=email&amp;utm_campaign=the_download.unpaid.engagement&amp;utm_term=*%7CSUBCLASS%7C*&amp;utm_content=*%7CDATE:m-d-Y%7C*\">story</a> to be turned into a MIT Technology Review Narrated podcast, which we publish each week on <a href=\"https://open.spotify.com/show/6QefEeY1IKYVn5w6nUV83Y\">Spotify</a> and <a href=\"https://podcasts.apple.com/gb/podcast/mit-technology-review-narrated/id1523584878\">Apple Podcasts</a>. Just navigate to MIT Technology Review Narrated on either platform, and follow us to get all our new content as it’s released.</p>\n\n\n\n<p></p>\n\n\n\n<p class=\"has-medium-font-size\"><strong>The must-reads</strong></p>\n\n\n\n<p><em>I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.</em></p>\n\n\n\n<p><strong>1 The first tsunami waves have reached the US West Coast</strong><br>But early damage from the powerful Russian earthquake has been thankfully limited. (<a href=\"https://www.washingtonpost.com/world/2025/07/29/tsunami-west-coast-japan-87-quake-russia/\">WP</a> $)<br>+ <em>It’ll take some time before we can be confident there’s no danger, though. </em>(<a href=\"https://www.wsj.com/world/tsunami-watch-warning-japan-us-west-coast-bd815b56?mod=hp_lead_pos1\">WSJ</a> $)<br>+ <em>These underwater cables can improve tsunami detection. </em>(<a href=\"https://www.technologyreview.com/2023/02/21/1068282/underwater-cables-improve-tsunami-detection/?utm_source=the_download&amp;utm_medium=email&amp;utm_campaign=the_download.unpaid.engagement&amp;utm_term=*%7CSUBCLASS%7C*&amp;utm_content=*%7CDATE:m-d-Y%7C*\">MIT Technology Review</a>)</p>\n\n\n\n<p><strong>2 Google has signed the EU code of practice</strong><br>Despite criticisms from the US that it stands to stifle growth. (<a href=\"https://www.ft.com/content/97ee867c-64c2-44ee-a519-36ca670ed565\">FT</a> $)<br>+ <em>Europe and America are taking very different paths. </em>(<a href=\"https://www.theregister.com/2025/07/30/eu_ai_act/\">The Register</a>)</p>\n\n\n\n<p><strong>3 NASA is launching a new Earth-observing satellite today<br></strong>It’ll keep a watch over precursors to earthquakes, landslides and volcanoes. (<a href=\"https://www.bbc.co.uk/news/articles/cy98jnreqvvo\">BBC</a>)<br>+ <em>Its data will be turned into maps to help scientists better respond. </em>(<a href=\"https://www.nytimes.com/2025/07/29/science/nisar-nasa-india.html\">NYT</a> $)</p>\n\n\n\n<p><strong>4 US antibiotics research is likely to suffer without federal funding</strong><br>It plays a critical role in antibiotic discovery. (<a href=\"https://undark.org/2025/07/30/antibiotics-funding-lag/\">Undark</a>)<br>+ <em>How bacteria-fighting viruses could go mainstream. </em>(<a href=\"https://www.technologyreview.com/2024/02/16/1088457/bacteria-fighting-viruses-lynn-cole/?utm_source=the_download&amp;utm_medium=email&amp;utm_campaign=the_download.unpaid.engagement&amp;utm_term=*%7CSUBCLASS%7C*&amp;utm_content=*%7CDATE:m-d-Y%7C*\">MIT Technology Review</a>)</p>\n\n\n\n<p><strong>5 Russia is building its own new web</strong><br>And at its heart is VK Co, a social network controlled by its government. (<a href=\"https://www.bloomberg.com/news/articles/2025-07-30/russia-replaces-popular-apps-with-putin-approved-alternatives?accessToken=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzb3VyY2UiOiJTdWJzY3JpYmVyR2lmdGVkQXJ0aWNsZSIsImlhdCI6MTc1Mzg1NzQyNCwiZXhwIjoxNzU0NDYyMjI0LCJhcnRpY2xlSWQiOiJUMDcxVFNHUFdDR1AwMCIsImJjb25uZWN0SWQiOiIwNEFGQkMxQkYyMTA0NUVEODg3MzQxQkQwQzIyNzRBMCJ9.q1zs29IxqIYujk6uBPJpCCfbX0m_ofWq81FYgKYqEP0&amp;sref=E9Urfma4\">Bloomberg</a> $)<br>+ <em>How Russia killed its tech industry. </em>(<a href=\"https://www.technologyreview.com/2023/04/04/1070352/ukraine-war-russia-tech-industry-yandex-skolkovo/?utm_source=the_download&amp;utm_medium=email&amp;utm_campaign=the_download.unpaid.engagement&amp;utm_term=*%7CSUBCLASS%7C*&amp;utm_content=*%7CDATE:m-d-Y%7C*\">MIT Technology Review</a>)</p>\n\n\n\n<p><strong>6 How Anthropic became so good at coding<br></strong>Everyone else in Silicon Valley is dying to know. (<a href=\"https://www.businessinsider.com/anthropic-ai-breakthrough-vibe-coding-revolution-2025-7\">Insider</a> $)<br>+ <em>The second wave of AI coding is here. </em>(<a href=\"https://www.technologyreview.com/2025/01/20/1110180/the-second-wave-of-ai-coding-is-here/?utm_source=the_download&amp;utm_medium=email&amp;utm_campaign=the_download.unpaid.engagement&amp;utm_term=*%7CSUBCLASS%7C*&amp;utm_content=*%7CDATE:m-d-Y%7C*\">MIT Technology Review</a>)</p>\n\n\n\n<p><strong>7 Demand for Vietnam’s chips is booming<br></strong>It’s reaping the benefits of the world looking for alternatives to China’s products. (<a href=\"https://restofworld.org/2025/vietnam-chip-industry-us-china-trade-war/\">Rest of World</a>)<br>+ <em>Things aren’t looking great for AI chipmaker Groq. </em>(<a href=\"https://www.theinformation.com/articles/ai-chipmaker-groq-slashes-projections-soon-sharing-investors?rc=e7vxeu\">The Information</a> $)</p>\n\n\n\n<p><strong>8 Yelp has started making its own AI restaurant videos<br></strong>And users can’t opt out of having their photos used in them. (<a href=\"https://www.theverge.com/news/714944/yelp-ai-stitched-videos\">The Verge</a>)</p>\n\n\n\n<p><strong>9 Are memes the new comics?</strong><br>If comics didn’t have a plot, that is. (<a href=\"https://arstechnica.com/culture/2025/07/the-case-for-memes-as-a-new-form-of-comics/\">Ars Technica</a>)<br>+ <em>Generative AI is reshaping South Korea’s webcomics industry. </em>(<a href=\"https://www.technologyreview.com/2025/04/22/1114874/generative-ai-south-korea-webcomics/?utm_source=the_download&amp;utm_medium=email&amp;utm_campaign=the_download.unpaid.engagement&amp;utm_term=*%7CSUBCLASS%7C*&amp;utm_content=*%7CDATE:m-d-Y%7C*\">MIT Technology Review</a>)</p>\n\n\n\n<p><strong>10 Starbucks is abandoning launching stores that only accept mobile orders </strong><img src=\"https://s.w.org/images/core/emoji/16.0.1/72x72/1f4f1.png\" alt=\"📱\" class=\"wp-smiley\" style=\"height: 1em; max-height: 1em;\" /><img src=\"https://s.w.org/images/core/emoji/16.0.1/72x72/2615.png\" alt=\"☕\" class=\"wp-smiley\" style=\"height: 1em; max-height: 1em;\" /><br>The vibes are off, apparently. (<a href=\"https://www.wsj.com/business/earnings/starbucks-earnings-q3-sbux-stock-382db7ae?mod=lead_feature_below_a_pos2\">WSJ</a> $)</p>\n\n\n\n<p></p>\n\n\n\n<p class=\"has-medium-font-size\"><strong>Quote of the day</strong></p>\n\n\n\n<p class=\"has-large-font-size\"><strong>“Any lawyer unaware that using generative AI platforms to do legal research is playing with fire is living in a cloud.”</strong></p>\n\n\n\n<p>—Judge Michael Slade criticizes a lawyer who used AI-generated citations in a legal case, <a href=\"https://www.pcgamer.com/software/ai/judge-sends-hangdog-lawyer-to-ai-school-after-hes-caught-using-chatgpt-to-cite-imaginary-caselaw-any-lawyer-unaware-that-using-generative-ai-platforms-to-do-legal-research-is-playing-with-fire-is-living-in-a-cloud/\">PC Gamer</a> reports.</p>\n\n\n\n<p></p>\n\n\n\n<p class=\"has-medium-font-size\"><strong>One more thing</strong></p>\n\n\n\n<figure class=\"wp-block-image size-large\"><a href=\"https://www.technologyreview.com/2024/06/19/1093446/pneumatic-tubes-hospitals/?utm_source=the_download&amp;utm_medium=email&amp;utm_campaign=the_download.unpaid.engagement&amp;utm_term=*|SUBCLASS|*&amp;utm_content=*|DATE:m-d-Y|*\"><img decoding=\"async\" src=\"https://wp.technologyreview.com/wp-content/uploads/2024/06/TRJ28Y-thumb.jpg\" alt=\"\" /></a></figure>\n\n\n\n<p><strong>The return of pneumatic tubes</strong><br><br>Pneumatic tubes were once touted as something that would revolutionize the world. In science fiction, they were envisioned as a fundamental part of the future—even in dystopias like George Orwell’s 1984, where they help to deliver orders for the main character, Winston Smith, in his job rewriting history to fit the ruling party’s changing narrative.<br><br>In real life, the tubes were expected to transform several industries in the late 19th century through the mid-20th. For a while, the United States took up the systems with gusto.<br><br>But by the mid to late 20th century, use of the technology had largely fallen by the wayside, and pneumatic tube technology became virtually obsolete. Except in hospitals. <a href=\"https://www.technologyreview.com/2024/06/19/1093446/pneumatic-tubes-hospitals/?utm_source=the_download&amp;utm_medium=email&amp;utm_campaign=the_download.unpaid.engagement&amp;utm_term=*%7CSUBCLASS%7C*&amp;utm_content=*%7CDATE:m-d-Y%7C*\">Read the full story</a>.</p>\n\n\n\n<p><em>—Vanessa Armstrong</em></p>\n\n\n\n<p></p>\n\n\n\n<p class=\"has-medium-font-size\"><strong>We can still have nice things</strong></p>\n\n\n\n<p><em>A place for comfort, fun and distraction to brighten up your day. (Got any ideas? </em><a href=\"mailto:rhiannon.williams@technologyreview.com\"><em>Drop me a line</em></a><em> or </em><a href=\"https://bsky.app/profile/rhiannonwilliams.bsky.social\"><em>skeet &#8217;em at me</em></a><em>.)</em></p>\n\n\n\n<p>+ This sweet baby <a href=\"https://uk.news.yahoo.com/tiny-southern-pudu-fawn-makes-213326137.html\">pudu fawn</a> is just too cute for words.<br>+ There’s some great picks in this list of the <a href=\"https://time.com/collections/100-best-podcasts/\">100 best podcasts</a> (and some shocking omissions).<br>+ The infamous gigantic <a href=\"https://www.cnet.com/home/yard-and-outdoors/the-famous-home-depot-skelly-finds-its-voice-with-new-app-for-halloween/\">Home Depot skeleton</a> is getting a voice!<br>+ If you’re never not thinking about the <a href=\"https://www.livescience.com/archaeology/romans/what-happened-to-rome-after-the-empire-fell?utm_source=firefox-newtab-en-gb\">Roman empire</a>, here’s what happened after it all came crashing down.</p>\n",
          "content:encodedSnippet": "This is today’s edition of The Download, our weekday newsletter that provides a daily dose of what’s going on in the world of technology.\nExclusive: A record-breaking baby has been born from an embryo that’s over 30 years old\nA baby boy has just won the new record for the “oldest baby.” Thaddeus Daniel Pierce, who arrived on July 26, developed from an embryo that had been in storage for 30 and a half years.\nLindsey and her husband, Tim Pierce, who live in London, Ohio, “adopted” the embryo from Linda Archerd, who had it created in 1994. The couple, aged 35 and 34, respectively, had been trying for a baby for seven years. Read more about their remarkable story.\n—Jessica Hamzelou\n\n\n\n\nOpenAI is launching a version of ChatGPT for college students\nOpenAI is launching Study Mode, a version of ChatGPT for college students that it promises will act less like a lookup tool and more like a friendly, always-available tutor. \nThe chatbot begins by asking what the student wants to know and then attempts to build an exchange, where the pair work methodically toward the answer together. OpenAI says the tool was built after consulting with pedagogy experts from over 40 institutions.\nBut there’s an ambitious vision behind Study Mode: It’s part of a wider push by OpenAI to get AI more deeply embedded into classrooms when the new academic year starts in September. Read the full story.\n—James O’Donnell\n\n\n\n\nMIT Technology Review Narrated: Are we ready to hand AI agents the keys?\nIn recent months, a new class of agents has arrived on the scene: ones built using large language models. Any action that can be captured by text—from playing a video game using written commands to running a social media account—is potentially within the purview of this type of system.\nLLM agents don’t have much of a track record yet, but to hear CEOs tell it, they will transform the economy—and soon. Despite that, like chatbot LLMs, agents can be chaotic and unpredictable.\nThis is our latest story to be turned into a MIT Technology Review Narrated podcast, which we publish each week on Spotify and Apple Podcasts. Just navigate to MIT Technology Review Narrated on either platform, and follow us to get all our new content as it’s released.\n\n\n\n\nThe must-reads\nI’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.\n1 The first tsunami waves have reached the US West Coast\nBut early damage from the powerful Russian earthquake has been thankfully limited. (WP $)\n+ It’ll take some time before we can be confident there’s no danger, though. (WSJ $)\n+ These underwater cables can improve tsunami detection. (MIT Technology Review)\n2 Google has signed the EU code of practice\nDespite criticisms from the US that it stands to stifle growth. (FT $)\n+ Europe and America are taking very different paths. (The Register)\n3 NASA is launching a new Earth-observing satellite today\nIt’ll keep a watch over precursors to earthquakes, landslides and volcanoes. (BBC)\n+ Its data will be turned into maps to help scientists better respond. (NYT $)\n4 US antibiotics research is likely to suffer without federal funding\nIt plays a critical role in antibiotic discovery. (Undark)\n+ How bacteria-fighting viruses could go mainstream. (MIT Technology Review)\n5 Russia is building its own new web\nAnd at its heart is VK Co, a social network controlled by its government. (Bloomberg $)\n+ How Russia killed its tech industry. (MIT Technology Review)\n6 How Anthropic became so good at coding\nEveryone else in Silicon Valley is dying to know. (Insider $)\n+ The second wave of AI coding is here. (MIT Technology Review)\n7 Demand for Vietnam’s chips is booming\nIt’s reaping the benefits of the world looking for alternatives to China’s products. (Rest of World)\n+ Things aren’t looking great for AI chipmaker Groq. (The Information $)\n8 Yelp has started making its own AI restaurant videos\nAnd users can’t opt out of having their photos used in them. (The Verge)\n9 Are memes the new comics?\nIf comics didn’t have a plot, that is. (Ars Technica)\n+ Generative AI is reshaping South Korea’s webcomics industry. (MIT Technology Review)\n10 Starbucks is abandoning launching stores that only accept mobile orders \nThe vibes are off, apparently. (WSJ $)\n\n\n\n\nQuote of the day\n“Any lawyer unaware that using generative AI platforms to do legal research is playing with fire is living in a cloud.”\n—Judge Michael Slade criticizes a lawyer who used AI-generated citations in a legal case, PC Gamer reports.\n\n\n\n\nOne more thing\n\n\n\n\nThe return of pneumatic tubes\nPneumatic tubes were once touted as something that would revolutionize the world. In science fiction, they were envisioned as a fundamental part of the future—even in dystopias like George Orwell’s 1984, where they help to deliver orders for the main character, Winston Smith, in his job rewriting history to fit the ruling party’s changing narrative.\nIn real life, the tubes were expected to transform several industries in the late 19th century through the mid-20th. For a while, the United States took up the systems with gusto.\nBut by the mid to late 20th century, use of the technology had largely fallen by the wayside, and pneumatic tube technology became virtually obsolete. Except in hospitals. Read the full story.\n—Vanessa Armstrong\n\n\n\n\nWe can still have nice things\nA place for comfort, fun and distraction to brighten up your day. (Got any ideas? Drop me a line or skeet ’em at me.)\n+ This sweet baby pudu fawn is just too cute for words.\n+ There’s some great picks in this list of the 100 best podcasts (and some shocking omissions).\n+ The infamous gigantic Home Depot skeleton is getting a voice!\n+ If you’re never not thinking about the Roman empire, here’s what happened after it all came crashing down.",
          "dc:creator": "Rhiannon Williams",
          "content": "This is today&#8217;s edition of The Download, our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology. Exclusive: A record-breaking baby has been born from an embryo that’s over 30 years old A baby boy has just won the new record for the “oldest baby.” Thaddeus Daniel Pierce, who arrived&#8230;",
          "contentSnippet": "This is today’s edition of The Download, our weekday newsletter that provides a daily dose of what’s going on in the world of technology. Exclusive: A record-breaking baby has been born from an embryo that’s over 30 years old A baby boy has just won the new record for the “oldest baby.” Thaddeus Daniel Pierce, who arrived…",
          "guid": "https://www.technologyreview.com/?p=1120823",
          "categories": [
            "The Download"
          ],
          "isoDate": "2025-07-30T12:10:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Jessica Hamzelou",
          "title": "Exclusive: A record-breaking baby has been born from an embryo that’s over 30 years old",
          "link": "https://www.technologyreview.com/2025/07/29/1120769/exclusive-record-breaking-baby-born-embryo-over-30-years-old/",
          "pubDate": "Tue, 29 Jul 2025 17:36:56 +0000",
          "content:encoded": "\n<p>A baby boy born over the weekend holds the new record for the “oldest baby.” Thaddeus Daniel Pierce, who arrived on July 26, developed from an embryo that had been in storage for 30 and a half years.</p>\n\n\n\n<p>“We had a rough birth but we are both doing well now,” says Lindsey Pierce, his mother.&nbsp;&#8220;He is so chill. We are in awe that we have this precious baby!&#8221;</p>\n\n\n\n<p>Lindsey and her husband, Tim Pierce, who live in London, Ohio, “adopted” the embryo from a woman who had it created in 1994. She says her family and church family think “it’s like something from a sci-fi movie.” </p>\n\n\n\n<p>“The baby has a 30-year-old sister,” she adds. Tim was a toddler when the embryos were first created.</p>\n\n\n\n<p>“It’s been pretty surreal,” says Linda Archerd, 62, who donated the embryo. “It’s hard to even believe.”</p>\n\n\n\n<h3 class=\"wp-block-heading\">Three little hopes</h3>\n\n\n\n<p>The story starts back in the early 1990s. Archerd had been trying—and failing—to get pregnant for six years. She and her husband decided to try IVF, a fairly new technology at the time. “People were [unfamiliar] with it,” says Archerd. “A lot of people were like, what are you doing?”</p>\n\n\n\n<p>They did it anyway, and in May 1994, they managed to create four embryos. One of them was transferred to Linda’s uterus. It resulted in a healthy baby girl. “I was so blessed to have a baby,” Archerd says. The remaining three embryos were cryopreserved and kept in a storage tank.</p>\n\n\n\n<p>That was 31 years ago. The healthy baby girl is now a 30-year-old woman who has her own 10-year-old daughter. But the other three embryos remained frozen in time.</p>\n\n\n\n<p>Archerd originally planned to use the embryos herself. “I always wanted another baby desperately,” she says. “I called them my three little hopes.” Her then husband felt differently, she says. Archerd went on to divorce him, but she won custody of the embryos and kept them in storage, still hopeful she might use them one day, perhaps with another partner.</p>\n\n\n\n<p>That meant paying annual storage fees, which increased over time and ended up costing Archerd around a thousand dollars a year, she says. To her, it was worth it. “I always thought it was the right thing to do,” she says.&nbsp;</p>\n\n\n\n<p>Things changed when she started going through menopause, she says. She <a href=\"https://www.technologyreview.com/2025/01/17/1110055/deciding-the-fate-of-leftover-embryos/\">considered her options</a>. She didn’t want to discard the embryos or <a href=\"https://www.technologyreview.com/2024/12/06/1107972/donating-embryos-research-complex/\">donate them for research</a>. And she didn’t want to donate them to another family anonymously—she wanted to meet the parents and any resulting babies. “It’s my DNA; it came from me … and [it’s] my daughter’s sibling,” she says.</p>\n\n\n\n\n\n<p>Then she found out about embryo “adoption.” This is a type of embryo donation in which both donors and recipients have a say in whom they “place” their embryos with or “adopt” them from. It is overseen by agencies—usually explicitly religious ones—that believe an embryo is morally equivalent to a born human. Archerd is Christian.</p>\n\n\n\n<p>There are several agencies that offer these adoption services in the US, but not all of them accept embryos that have been stored for a very long time. That’s partly because those embryos will have been frozen and stored in unfamiliar, old-fashioned ways, and partly because old embryos are thought to be less likely to survive thawing and transfer to successfully develop into a baby.</p>\n\n\n\n<p>“So many places wouldn’t even take my information,” says Archerd. Then she came across the Snowflakes program run by the Nightlight Christian Adoptions agency. The agency was willing to accept her embryos, but it needed Archerd’s medical records from the time the embryos had been created, as well as the embryos’ lab records.</p>\n\n\n\n<p>So Archerd called the fertility doctor who had treated her decades before. “I still remembered his phone number by heart,” she says. That doctor, now in his 70s, is still practicing at a clinic in Oregon. He dug Archerd’s records out from his basement, she says. “Some of [them] were handwritten,” she adds. Her embryos entered Nightlight’s “matching pool” in 2022.</p>\n\n\n\n<h3 class=\"wp-block-heading\">Making a match</h3>\n\n\n\n<p>“Our matching process is really driven by the preferences of the placing family,” says Beth Button, executive director of the Snowflakes program. Archerd’s preference was for a married Caucasian, Christian couple living in the US. “I didn’t want them to go out of the country,” says Archerd. “And being Christian is very important to me, because I am.”</p>\n\n\n\n<p>It took a while to find a match. Most of the “adopting parents” signed up for the Snowflakes program were already registered at fertility clinics that wouldn’t have accepted the embryos, says Button. “I would say that over 90% of clinics in the US would not have accepted these embryos,” she says.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"wp-block-image size-large\"><img fetchpriority=\"high\" decoding=\"async\" height=\"2000\" width=\"1727\" src=\"https://wp.technologyreview.com/wp-content/uploads/2025/07/250724_recordbaby_parents2.jpg?w=1727\" alt=\"Expecting parents Tim and Lindsey Pierce.\" class=\"wp-image-1120633\" srcset=\"https://wp.technologyreview.com/wp-content/uploads/2025/07/250724_recordbaby_parents2.jpg 3000w, https://wp.technologyreview.com/wp-content/uploads/2025/07/250724_recordbaby_parents2.jpg?resize=259,300 259w, https://wp.technologyreview.com/wp-content/uploads/2025/07/250724_recordbaby_parents2.jpg?resize=768,889 768w, https://wp.technologyreview.com/wp-content/uploads/2025/07/250724_recordbaby_parents2.jpg?resize=1727,2000 1727w, https://wp.technologyreview.com/wp-content/uploads/2025/07/250724_recordbaby_parents2.jpg?resize=1326,1536 1326w, https://wp.technologyreview.com/wp-content/uploads/2025/07/250724_recordbaby_parents2.jpg?resize=1769,2048 1769w\" sizes=\"(max-width: 1727px) 100vw, 1727px\" /><figcaption class=\"wp-element-caption\">Lindsey and Tim Pierce at Rejoice Fertility.</figcaption><div class=\"image-credit\">COURTESY LINDSEY PIERCE</div>\n</figure>\n</div>\n\n\n<p>Archerd’s embryos were assigned to the agency’s Open Hearts program for embryos that are “hard to place,” along with others that have been in storage for a long time or are otherwise thought to be less likely to result in a healthy birth.</p>\n\n\n\n<p>Lindsey and Tim Pierce had also signed up for the Open Hearts program. The couple, aged 35 and 34, respectively, had been trying for a baby for seven years and had seen multiple doctors.</p>\n\n\n\n<p>Lindsey was researching child adoption when she came across the Snowflakes program.&nbsp;</p>\n\n\n\n<p>When the couple were considering their criteria for embryos they might receive, they decided that they’d be open to any. “We checkmarked anything and everything,” says Tim. That’s how they ended up being matched with Archerd’s embryos. “We thought it was wild,” says Lindsey. “We didn’t know they froze embryos that long ago.”</p>\n\n\n\n<p>Lindsey and Tim had registered with <a href=\"https://rejoicefertility.com/\">Rejoice Fertility</a>, an IVF clinic in Knoxville, Tennessee, run by John Gordon, a reproductive endocrinologist who prides himself on his efforts to reduce the number of embryos in storage. <a href=\"https://www.technologyreview.com/2025/01/13/1109922/inside-the-strange-limbo-facing-ivf-embryos/\">The huge numbers of embryos left in storage tanks</a> was weighing on his conscience, he says, so around six years ago, he set up Rejoice Fertility with the aim of doing things differently.  </p>\n\n\n\n<p>“Now we’re here in the belt buckle of the Bible Belt,” says Gordon, who is Reformed Presbyterian. “I’ve changed my mode of practice.” IVF treatments performed at the clinic are designed to create as few excess embryos as possible. The clinic works with multiple embryo adoption agencies and will accept any embryo, no matter how long it has been in storage.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"wp-block-image size-large\"><img decoding=\"async\" height=\"2000\" width=\"1500\" src=\"https://wp.technologyreview.com/wp-content/uploads/2025/07/250724_recordbaby_donor.jpg?w=1500\" alt=\"A portrait of Linda Archerd.\" class=\"wp-image-1120605\" srcset=\"https://wp.technologyreview.com/wp-content/uploads/2025/07/250724_recordbaby_donor.jpg 2400w, https://wp.technologyreview.com/wp-content/uploads/2025/07/250724_recordbaby_donor.jpg?resize=225,300 225w, https://wp.technologyreview.com/wp-content/uploads/2025/07/250724_recordbaby_donor.jpg?resize=768,1024 768w, https://wp.technologyreview.com/wp-content/uploads/2025/07/250724_recordbaby_donor.jpg?resize=1500,2000 1500w, https://wp.technologyreview.com/wp-content/uploads/2025/07/250724_recordbaby_donor.jpg?resize=1152,1536 1152w, https://wp.technologyreview.com/wp-content/uploads/2025/07/250724_recordbaby_donor.jpg?resize=1536,2048 1536w\" sizes=\"(max-width: 1500px) 100vw, 1500px\" /><div class=\"image-credit\">COURTESY LINDA ARCHERD</div>\n</figure>\n</div>\n\n\n<p>It was his clinic that treated the parents who previously held the record for the longest-stored embryo—in 2022, <a href=\"https://www.bbc.co.uk/news/world-us-canada-63718914\">Rachel and Philip Ridgeway had twins from embryos created more than 30 years earlier</a>. “They’re such a lovely couple,” says Gordon. When we spoke, he was making plans to meet the family for breakfast. The twins are “growing like weeds,” he says with a laugh.</p>\n\n\n\n<p>“We have certain guiding principles, and they’re coming from our faith,” says Gordon, although he adds that he sees patients who hold alternative views. One of those principles is that “every embryo deserves a chance at life and that the only embryo that cannot result in a healthy baby is the embryo not given the opportunity to be transferred into a patient.”</p>\n\n\n\n<p>That’s why his team will endeavor to transfer any embryo they receive, no matter the age or conditions. That can be challenging, especially when the embryos have been frozen or stored in unusual or outdated ways. “It’s scary for people who don’t know how to do it,” says Sarah Atkinson, lab supervisor and head embryologist at Rejoice Fertility. “You don’t want to kill someone’s embryos if you don’t know what you’re doing.”</p>\n\n\n\n<h3 class=\"wp-block-heading\">Cumbersome and explosive</h3>\n\n\n\n<p>In the early days of IVF, embryos earmarked for storage were slow-frozen. This technique involves gradually lowering the temperature of the embryos. But because slow freezing can cause harmful ice crystals to form, clinics switched in the 2000s to a technique called vitrification, in which the embryos are placed in thin plastic tubes called straws and lowered into tanks of liquid nitrogen. This rapidly freezes the embryos and converts them into a glass-like state. </p>\n\n\n\n<p>The embryos can later be thawed by removing them from the tanks and rapidly—within two seconds—plunging them into warm “thaw media,” says Atkinson. Thawing slow-frozen embryos is more complicated. And the exact thawing method required varies, depending on how the embryos were preserved and what they were stored in. Some of the devices need to be opened while they are inside the storage tank, which can involve using forceps, diamond-bladed knives, and other tools in the liquid nitrogen, says Atkinson.</p>\n\n\n\n<figure class=\"wp-block-video\"><video controls src=\"https://wp.technologyreview.com/wp-content/uploads/2025/07/McElyea-ICSI-1.mp4\"></video><figcaption class=\"wp-element-caption\">Sarah Atkinson, lab supervisor and head embryologist at Rejoice Fertility, directly injects sperm into two eggs to fertilize them.</figcaption><div class=\"video-credit\">COURTESY OF SARAH ATKINSON AT REJOICE FERTILITY.</div>\n</figure>\n\n\n\n<p>Recently, she was tasked with retrieving embryos that had been stored inside a glass vial. The vial was made from blown glass and had been heat-sealed with the embryo inside. Atkinson had to use her diamond-bladed knife to snap open the seal inside the nitrogen tank. It was fiddly work, and when the device snapped, a small shard of glass flew out and hit Atkinson’s face. “Hit me on the cheek, cut my cheek, blood running down my face, and I’m like, <em>Oh shit,</em>” she says. Luckily, she had her safety goggles on. And the embryos survived, she adds.</p>\n\n\n\n<figure class=\"wp-block-image size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"1384\" height=\"928\" src=\"https://wp.technologyreview.com/wp-content/uploads/2025/07/Pierce-Lindsey.jpg\" alt=\"\" class=\"wp-image-1120770\" srcset=\"https://wp.technologyreview.com/wp-content/uploads/2025/07/Pierce-Lindsey.jpg 1384w, https://wp.technologyreview.com/wp-content/uploads/2025/07/Pierce-Lindsey.jpg?resize=300,201 300w, https://wp.technologyreview.com/wp-content/uploads/2025/07/Pierce-Lindsey.jpg?resize=768,515 768w\" sizes=\"auto, (max-width: 1384px) 100vw, 1384px\" /><figcaption class=\"wp-element-caption\">The two embryos that were transferred to Lindsey Pierce.</figcaption></figure>\n\n\n\n<p>Atkinson has a folder in her office with notes she’s collected on various devices over the years. She flicks through it over a video call and points to the notes she made about the glass vial. “Might explode; wear face shield and eye protection,” she reads. A few pages later, she points to another embryo-storage device. “You have to thaw this one in your fingers,” she tells me. “I don’t like it.”</p>\n\n\n\n<p>The record-breaking embryos had been slow-frozen and stored in a plastic vial, says Atkinson. Thawing them was a cumbersome process. But all three embryos survived it.</p>\n\n\n\n<p>The Pierces had to travel from their home in Ohio to the clinic in Tennessee five times over a two-week period. “It was like a five-hour drive,” says Lindsey. One of the three embryos stopped growing. The other two were transferred to Lindsey’s uterus on November 14, she says. And one developed into a fetus.</p>\n\n\n\n<p>Now that the baby has arrived, Archerd is keen to meet him. “The first thing that I noticed when Lindsey sent me his pictures is how much he looks like my daughter when she was a baby,” she says. “I pulled out my baby book and compared them side by side, and there is no doubt that they are siblings.”</p>\n\n\n\n<p>She doesn’t yet have plans to meet the baby, but doing so would be “a dream come true,” she says. “I wish that they didn’t live so far away from me &#8230; He is perfect!”</p>\n\n\n\n<p>“We didn’t go into it thinking we would break any records,” says Lindsey. “We just wanted to have a baby.”</p>\n\n\n\n<figure class=\"wp-block-image size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"480\" height=\"360\" src=\"https://wp.technologyreview.com/wp-content/uploads/2025/07/1000004661.jpg?w=480\" alt=\"\" class=\"wp-image-1120800\" srcset=\"https://wp.technologyreview.com/wp-content/uploads/2025/07/1000004661.jpg 480w, https://wp.technologyreview.com/wp-content/uploads/2025/07/1000004661.jpg?resize=300,225 300w\" sizes=\"auto, (max-width: 480px) 100vw, 480px\" /></figure>\n",
          "content:encodedSnippet": "A baby boy born over the weekend holds the new record for the “oldest baby.” Thaddeus Daniel Pierce, who arrived on July 26, developed from an embryo that had been in storage for 30 and a half years.\n“We had a rough birth but we are both doing well now,” says Lindsey Pierce, his mother. “He is so chill. We are in awe that we have this precious baby!”\nLindsey and her husband, Tim Pierce, who live in London, Ohio, “adopted” the embryo from a woman who had it created in 1994. She says her family and church family think “it’s like something from a sci-fi movie.” \n“The baby has a 30-year-old sister,” she adds. Tim was a toddler when the embryos were first created.\n“It’s been pretty surreal,” says Linda Archerd, 62, who donated the embryo. “It’s hard to even believe.”\nThree little hopes\nThe story starts back in the early 1990s. Archerd had been trying—and failing—to get pregnant for six years. She and her husband decided to try IVF, a fairly new technology at the time. “People were [unfamiliar] with it,” says Archerd. “A lot of people were like, what are you doing?”\nThey did it anyway, and in May 1994, they managed to create four embryos. One of them was transferred to Linda’s uterus. It resulted in a healthy baby girl. “I was so blessed to have a baby,” Archerd says. The remaining three embryos were cryopreserved and kept in a storage tank.\nThat was 31 years ago. The healthy baby girl is now a 30-year-old woman who has her own 10-year-old daughter. But the other three embryos remained frozen in time.\nArcherd originally planned to use the embryos herself. “I always wanted another baby desperately,” she says. “I called them my three little hopes.” Her then husband felt differently, she says. Archerd went on to divorce him, but she won custody of the embryos and kept them in storage, still hopeful she might use them one day, perhaps with another partner.\nThat meant paying annual storage fees, which increased over time and ended up costing Archerd around a thousand dollars a year, she says. To her, it was worth it. “I always thought it was the right thing to do,” she says. \nThings changed when she started going through menopause, she says. She considered her options. She didn’t want to discard the embryos or donate them for research. And she didn’t want to donate them to another family anonymously—she wanted to meet the parents and any resulting babies. “It’s my DNA; it came from me … and [it’s] my daughter’s sibling,” she says.\nThen she found out about embryo “adoption.” This is a type of embryo donation in which both donors and recipients have a say in whom they “place” their embryos with or “adopt” them from. It is overseen by agencies—usually explicitly religious ones—that believe an embryo is morally equivalent to a born human. Archerd is Christian.\nThere are several agencies that offer these adoption services in the US, but not all of them accept embryos that have been stored for a very long time. That’s partly because those embryos will have been frozen and stored in unfamiliar, old-fashioned ways, and partly because old embryos are thought to be less likely to survive thawing and transfer to successfully develop into a baby.\n“So many places wouldn’t even take my information,” says Archerd. Then she came across the Snowflakes program run by the Nightlight Christian Adoptions agency. The agency was willing to accept her embryos, but it needed Archerd’s medical records from the time the embryos had been created, as well as the embryos’ lab records.\nSo Archerd called the fertility doctor who had treated her decades before. “I still remembered his phone number by heart,” she says. That doctor, now in his 70s, is still practicing at a clinic in Oregon. He dug Archerd’s records out from his basement, she says. “Some of [them] were handwritten,” she adds. Her embryos entered Nightlight’s “matching pool” in 2022.\nMaking a match\n“Our matching process is really driven by the preferences of the placing family,” says Beth Button, executive director of the Snowflakes program. Archerd’s preference was for a married Caucasian, Christian couple living in the US. “I didn’t want them to go out of the country,” says Archerd. “And being Christian is very important to me, because I am.”\nIt took a while to find a match. Most of the “adopting parents” signed up for the Snowflakes program were already registered at fertility clinics that wouldn’t have accepted the embryos, says Button. “I would say that over 90% of clinics in the US would not have accepted these embryos,” she says.\nLindsey and Tim Pierce at Rejoice Fertility.\nCOURTESY LINDSEY PIERCE\nArcherd’s embryos were assigned to the agency’s Open Hearts program for embryos that are “hard to place,” along with others that have been in storage for a long time or are otherwise thought to be less likely to result in a healthy birth.\nLindsey and Tim Pierce had also signed up for the Open Hearts program. The couple, aged 35 and 34, respectively, had been trying for a baby for seven years and had seen multiple doctors.\nLindsey was researching child adoption when she came across the Snowflakes program. \nWhen the couple were considering their criteria for embryos they might receive, they decided that they’d be open to any. “We checkmarked anything and everything,” says Tim. That’s how they ended up being matched with Archerd’s embryos. “We thought it was wild,” says Lindsey. “We didn’t know they froze embryos that long ago.”\nLindsey and Tim had registered with Rejoice Fertility, an IVF clinic in Knoxville, Tennessee, run by John Gordon, a reproductive endocrinologist who prides himself on his efforts to reduce the number of embryos in storage. The huge numbers of embryos left in storage tanks was weighing on his conscience, he says, so around six years ago, he set up Rejoice Fertility with the aim of doing things differently.  \n“Now we’re here in the belt buckle of the Bible Belt,” says Gordon, who is Reformed Presbyterian. “I’ve changed my mode of practice.” IVF treatments performed at the clinic are designed to create as few excess embryos as possible. The clinic works with multiple embryo adoption agencies and will accept any embryo, no matter how long it has been in storage.\n\nCOURTESY LINDA ARCHERD\nIt was his clinic that treated the parents who previously held the record for the longest-stored embryo—in 2022, Rachel and Philip Ridgeway had twins from embryos created more than 30 years earlier. “They’re such a lovely couple,” says Gordon. When we spoke, he was making plans to meet the family for breakfast. The twins are “growing like weeds,” he says with a laugh.\n“We have certain guiding principles, and they’re coming from our faith,” says Gordon, although he adds that he sees patients who hold alternative views. One of those principles is that “every embryo deserves a chance at life and that the only embryo that cannot result in a healthy baby is the embryo not given the opportunity to be transferred into a patient.”\nThat’s why his team will endeavor to transfer any embryo they receive, no matter the age or conditions. That can be challenging, especially when the embryos have been frozen or stored in unusual or outdated ways. “It’s scary for people who don’t know how to do it,” says Sarah Atkinson, lab supervisor and head embryologist at Rejoice Fertility. “You don’t want to kill someone’s embryos if you don’t know what you’re doing.”\nCumbersome and explosive\nIn the early days of IVF, embryos earmarked for storage were slow-frozen. This technique involves gradually lowering the temperature of the embryos. But because slow freezing can cause harmful ice crystals to form, clinics switched in the 2000s to a technique called vitrification, in which the embryos are placed in thin plastic tubes called straws and lowered into tanks of liquid nitrogen. This rapidly freezes the embryos and converts them into a glass-like state. \nThe embryos can later be thawed by removing them from the tanks and rapidly—within two seconds—plunging them into warm “thaw media,” says Atkinson. Thawing slow-frozen embryos is more complicated. And the exact thawing method required varies, depending on how the embryos were preserved and what they were stored in. Some of the devices need to be opened while they are inside the storage tank, which can involve using forceps, diamond-bladed knives, and other tools in the liquid nitrogen, says Atkinson.\nSarah Atkinson, lab supervisor and head embryologist at Rejoice Fertility, directly injects sperm into two eggs to fertilize them.\nCOURTESY OF SARAH ATKINSON AT REJOICE FERTILITY.\nRecently, she was tasked with retrieving embryos that had been stored inside a glass vial. The vial was made from blown glass and had been heat-sealed with the embryo inside. Atkinson had to use her diamond-bladed knife to snap open the seal inside the nitrogen tank. It was fiddly work, and when the device snapped, a small shard of glass flew out and hit Atkinson’s face. “Hit me on the cheek, cut my cheek, blood running down my face, and I’m like, Oh shit,” she says. Luckily, she had her safety goggles on. And the embryos survived, she adds.\nThe two embryos that were transferred to Lindsey Pierce.\n\n\n\nAtkinson has a folder in her office with notes she’s collected on various devices over the years. She flicks through it over a video call and points to the notes she made about the glass vial. “Might explode; wear face shield and eye protection,” she reads. A few pages later, she points to another embryo-storage device. “You have to thaw this one in your fingers,” she tells me. “I don’t like it.”\nThe record-breaking embryos had been slow-frozen and stored in a plastic vial, says Atkinson. Thawing them was a cumbersome process. But all three embryos survived it.\nThe Pierces had to travel from their home in Ohio to the clinic in Tennessee five times over a two-week period. “It was like a five-hour drive,” says Lindsey. One of the three embryos stopped growing. The other two were transferred to Lindsey’s uterus on November 14, she says. And one developed into a fetus.\nNow that the baby has arrived, Archerd is keen to meet him. “The first thing that I noticed when Lindsey sent me his pictures is how much he looks like my daughter when she was a baby,” she says. “I pulled out my baby book and compared them side by side, and there is no doubt that they are siblings.”\nShe doesn’t yet have plans to meet the baby, but doing so would be “a dream come true,” she says. “I wish that they didn’t live so far away from me … He is perfect!”\n“We didn’t go into it thinking we would break any records,” says Lindsey. “We just wanted to have a baby.”",
          "dc:creator": "Jessica Hamzelou",
          "content": "A baby boy born over the weekend holds the new record for the “oldest baby.” Thaddeus Daniel Pierce, who arrived on July 26, developed from an embryo that had been in storage for 30 and a half years. “We had a rough birth but we are both doing well now,” says Lindsey Pierce, his mother.&#160;&#8220;He&#8230;",
          "contentSnippet": "A baby boy born over the weekend holds the new record for the “oldest baby.” Thaddeus Daniel Pierce, who arrived on July 26, developed from an embryo that had been in storage for 30 and a half years. “We had a rough birth but we are both doing well now,” says Lindsey Pierce, his mother. “He…",
          "guid": "https://www.technologyreview.com/?p=1120769",
          "categories": [
            "Biotechnology and health",
            "App"
          ],
          "isoDate": "2025-07-29T17:36:56.000Z"
        }
      },
      {
        "json": {
          "creator": "Anthony Ha",
          "title": "Apple might be building its own AI ‘answer engine’",
          "link": "https://techcrunch.com/2025/08/03/apple-might-be-building-its-own-ai-answer-engine/",
          "pubDate": "Sun, 03 Aug 2025 21:49:00 +0000",
          "dc:creator": "Anthony Ha",
          "content": "Apple is reportedly working to create a lightweight competitor to ChatGPT. ",
          "contentSnippet": "Apple is reportedly working to create a lightweight competitor to ChatGPT.",
          "guid": "https://techcrunch.com/?p=3033644",
          "categories": [
            "AI",
            "Apple",
            "siri"
          ],
          "isoDate": "2025-08-03T21:49:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Anthony Ha",
          "title": "Mastercard denies pressuring game platforms, Valve tells a different story",
          "link": "https://techcrunch.com/2025/08/03/mastercard-denies-pressuring-game-platforms-valve-tells-a-different-story/",
          "pubDate": "Sun, 03 Aug 2025 21:29:14 +0000",
          "dc:creator": "Anthony Ha",
          "content": "Mastercard seemingly denied playing a role in a recent marketplace crackdown on games with adult content, while Valve says the pressure was indirect.",
          "contentSnippet": "Mastercard seemingly denied playing a role in a recent marketplace crackdown on games with adult content, while Valve says the pressure was indirect.",
          "guid": "https://techcrunch.com/?p=3033642",
          "categories": [
            "Gaming",
            "Government & Policy",
            "Media & Entertainment",
            "itch.io",
            "mastercard",
            "Steam"
          ],
          "isoDate": "2025-08-03T21:29:14.000Z"
        }
      },
      {
        "json": {
          "creator": "Anthony Ha",
          "title": "SAP is acquiring SmartRecruiters",
          "link": "https://techcrunch.com/2025/08/03/sap-is-acquiring-smartrecruiters/",
          "pubDate": "Sun, 03 Aug 2025 17:12:51 +0000",
          "dc:creator": "Anthony Ha",
          "content": "SAP has reached an agreement to acquire SmartRecruiters, with SmartRecruiters' software complementing SAP's existing HR tools.",
          "contentSnippet": "SAP has reached an agreement to acquire SmartRecruiters, with SmartRecruiters' software complementing SAP's existing HR tools.",
          "guid": "https://techcrunch.com/?p=3033639",
          "categories": [
            "Enterprise",
            "sap",
            "smartrecruiters"
          ],
          "isoDate": "2025-08-03T17:12:51.000Z"
        }
      },
      {
        "json": {
          "creator": "Maxwell Zeff",
          "title": "Inside OpenAI’s quest to make AI do anything for you",
          "link": "https://techcrunch.com/2025/08/03/inside-openais-quest-to-make-ai-do-anything-for-you/",
          "pubDate": "Sun, 03 Aug 2025 14:00:00 +0000",
          "dc:creator": "Maxwell Zeff",
          "content": "OpenAI developed the first AI reasoning model less than a year ago, but the technology has shifted Silicon Valley's focus to agents.",
          "contentSnippet": "OpenAI developed the first AI reasoning model less than a year ago, but the technology has shifted Silicon Valley's focus to agents.",
          "guid": "https://techcrunch.com/?p=3033326",
          "categories": [
            "AI",
            "Exclusive",
            "OpenAI",
            "ChatGPT",
            "agents"
          ],
          "isoDate": "2025-08-03T14:00:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Rebecca Bellan, Dominic-Madori Davis",
          "title": "The uproar over Vogue’s AI-generated ad isn’t just about fashion",
          "link": "https://techcrunch.com/2025/08/03/the-uproar-over-vogues-ai-generated-ad-isnt-just-about-fashion/",
          "pubDate": "Sun, 03 Aug 2025 13:00:00 +0000",
          "dc:creator": "Rebecca Bellan, Dominic-Madori Davis",
          "content": "“Modeling as a profession is already challenging enough without having to compete with now new digital standards of perfection that can be achieved with AI,” Sarah Murray told TechCrunch.",
          "contentSnippet": "“Modeling as a profession is already challenging enough without having to compete with now new digital standards of perfection that can be achieved with AI,” Sarah Murray told TechCrunch.",
          "guid": "https://techcrunch.com/?p=3033447",
          "categories": [
            "Media & Entertainment",
            "AI",
            "Fashion",
            "vogue",
            "guess",
            "digital fashion models"
          ],
          "isoDate": "2025-08-03T13:00:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Anthony Ha",
          "title": "Tim Cook reportedly tells employees Apple ‘must’ win in AI",
          "link": "https://techcrunch.com/2025/08/02/tim-cook-reportedly-tells-employees-apple-must-win-in-ai/",
          "pubDate": "Sat, 02 Aug 2025 21:21:22 +0000",
          "dc:creator": "Anthony Ha",
          "content": "Apple CEO Tim Cook held an hourlong all-hands meeting in which he told employees that the company needs to win in AI: \"Apple must do this. Apple will do this.\"",
          "contentSnippet": "Apple CEO Tim Cook held an hourlong all-hands meeting in which he told employees that the company needs to win in AI: \"Apple must do this. Apple will do this.\"",
          "guid": "https://techcrunch.com/?p=3033612",
          "categories": [
            "AI",
            "Apple",
            "Tim Cook"
          ],
          "isoDate": "2025-08-02T21:21:22.000Z"
        }
      },
      {
        "json": {
          "creator": "Anthony Ha",
          "title": "Lina Khan points to Figma IPO as vindication of M&A scrutiny",
          "link": "https://techcrunch.com/2025/08/02/lina-khan-points-to-figma-ipo-as-vindication-for-ma-scrutiny/",
          "pubDate": "Sat, 02 Aug 2025 20:58:52 +0000",
          "dc:creator": "Anthony Ha",
          "content": "A surprising figure is celebrating Figma’s successful IPO: Lina Khan, former chair of the Federal Trade Commission, who said the offering demonstrates the value of \"letting startups grow into independently successful businesses.\"",
          "contentSnippet": "A surprising figure is celebrating Figma’s successful IPO: Lina Khan, former chair of the Federal Trade Commission, who said the offering demonstrates the value of \"letting startups grow into independently successful businesses.\"",
          "guid": "https://techcrunch.com/?p=3033605",
          "categories": [
            "Government & Policy",
            "Startups",
            "Figma",
            "Lina Khan"
          ],
          "isoDate": "2025-08-02T20:58:52.000Z"
        }
      },
      {
        "json": {
          "creator": "Anthony Ha",
          "title": "Anthropic cuts off OpenAI’s access to its Claude models",
          "link": "https://techcrunch.com/2025/08/02/anthropic-cuts-off-openais-access-to-its-claude-models/",
          "pubDate": "Sat, 02 Aug 2025 16:55:12 +0000",
          "dc:creator": "Anthony Ha",
          "content": "Anthropic has cut off one of its biggest competitors, revoking OpenAI’s access to its Claude family of AI models.",
          "contentSnippet": "Anthropic has cut off one of its biggest competitors, revoking OpenAI’s access to its Claude family of AI models.",
          "guid": "https://techcrunch.com/?p=3033593",
          "categories": [
            "AI",
            "Startups"
          ],
          "isoDate": "2025-08-02T16:55:12.000Z"
        }
      },
      {
        "json": {
          "creator": "Dominic-Madori Davis",
          "title": "What founders should think about if looking to raise a Series C",
          "link": "https://techcrunch.com/2025/08/02/what-founders-should-think-about-if-looking-to-raise-a-series-c/",
          "pubDate": "Sat, 02 Aug 2025 13:00:00 +0000",
          "dc:creator": "Dominic-Madori Davis",
          "content": "And it starts with a reality check, according to Sapphire Ventures partner Cathy Gao.",
          "contentSnippet": "And it starts with a reality check, according to Sapphire Ventures partner Cathy Gao.",
          "guid": "https://techcrunch.com/?p=3031837",
          "categories": [
            "Venture",
            "fundraising",
            "series C",
            "Startups",
            "venture"
          ],
          "isoDate": "2025-08-02T13:00:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Marina Temkin",
          "title": "Venture firm CRV raises $750M, downsizing after returning capital to investors",
          "link": "https://techcrunch.com/2025/08/01/venture-firm-crv-raises-750m-downsizing-after-returning-capital-to-investors/",
          "pubDate": "Fri, 01 Aug 2025 23:22:03 +0000",
          "dc:creator": "Marina Temkin",
          "content": "The 55-year-old VC firm announced its twentieth fund. ",
          "contentSnippet": "The 55-year-old VC firm announced its twentieth fund.",
          "guid": "https://techcrunch.com/?p=3033541",
          "categories": [
            "Venture",
            "CRV",
            "early stage venture"
          ],
          "isoDate": "2025-08-01T23:22:03.000Z"
        }
      },
      {
        "json": {
          "creator": "Julie Bort",
          "title": "Kleiner Perkins is having a very good week",
          "link": "https://techcrunch.com/2025/08/01/kleiner-perkins-is-having-a-very-good-week/",
          "pubDate": "Fri, 01 Aug 2025 22:04:04 +0000",
          "dc:creator": "Julie Bort",
          "content": "With two IPOs this week alone, Kleiner Perkins partner Mamoon Hamid has reason to celebrate.",
          "contentSnippet": "With two IPOs this week alone, Kleiner Perkins partner Mamoon Hamid has reason to celebrate.",
          "guid": "https://techcrunch.com/?p=3033386",
          "categories": [
            "TC",
            "Venture",
            "Figma",
            "IPOs",
            "Kleiner Perkins"
          ],
          "isoDate": "2025-08-01T22:04:04.000Z"
        }
      },
      {
        "json": {
          "creator": "Rebecca Szkutak",
          "title": "A backlog at the Commerce Department is reportedly stalling Nvidia’s H20 chip licenses",
          "link": "https://techcrunch.com/2025/08/01/a-backlog-at-the-commerce-department-is-reportedly-stalling-nvidias-h20-chip-licenses/",
          "pubDate": "Fri, 01 Aug 2025 20:30:14 +0000",
          "dc:creator": "Rebecca Szkutak",
          "content": "News of a backlog at the U.S. federal department comes less than a week after national security experts urged the Trump administration to reverse its decision that allows Nvidia to export H20 chips to China. ",
          "contentSnippet": "News of a backlog at the U.S. federal department comes less than a week after national security experts urged the Trump administration to reverse its decision that allows Nvidia to export H20 chips to China.",
          "guid": "https://techcrunch.com/?p=3033477",
          "categories": [
            "AI",
            "Enterprise",
            "Security",
            "artificial intelligence",
            "chips",
            "In Brief",
            "nvidia",
            "semiconductors"
          ],
          "isoDate": "2025-08-01T20:30:14.000Z"
        }
      },
      {
        "json": {
          "creator": "Sean O'Kane",
          "title": "Tesla partly liable in Florida Autopilot trial, jury awards $200M in damages",
          "link": "https://techcrunch.com/2025/08/01/tesla-partly-liable-in-florida-autopilot-trial-jury-awards-200m-in-damages/",
          "pubDate": "Fri, 01 Aug 2025 18:24:42 +0000",
          "dc:creator": "Sean O'Kane",
          "content": "The jury verdict is one of the first major legal decisions about driver assistance technology that has gone against Tesla. Both Elon Musk and Tesla have spent years making claims about Autopilot's capabilities.",
          "contentSnippet": "The jury verdict is one of the first major legal decisions about driver assistance technology that has gone against Tesla. Both Elon Musk and Tesla have spent years making claims about Autopilot's capabilities.",
          "guid": "https://techcrunch.com/?p=3033400",
          "categories": [
            "Transportation",
            "advanced driver assistance systems",
            "Autopilot",
            "Tesla"
          ],
          "isoDate": "2025-08-01T18:24:42.000Z"
        }
      },
      {
        "json": {
          "creator": "Jagmeet Singh",
          "title": "Google bets on STAN, an Indian social gaming platform",
          "link": "https://techcrunch.com/2025/08/01/google-bets-on-stan-an-indian-social-gaming-platform/",
          "pubDate": "Fri, 01 Aug 2025 17:05:45 +0000",
          "dc:creator": "Jagmeet Singh",
          "content": "STAN, headquartered in Singapore, is trying to position itself as a gaming community platform to rival Discord, but its approach to the market is quite different.",
          "contentSnippet": "STAN, headquartered in Singapore, is trying to position itself as a gaming community platform to rival Discord, but its approach to the market is quite different.",
          "guid": "https://techcrunch.com/?p=3032901",
          "categories": [
            "AI",
            "Gaming",
            "Startups",
            "Google",
            "Stan",
            "Google AI Futures Fund"
          ],
          "isoDate": "2025-08-01T17:05:45.000Z"
        }
      },
      {
        "json": {
          "creator": "Aisha Malik",
          "title": "Nintendo raising original Switch console prices due to ‘market conditions’",
          "link": "https://techcrunch.com/2025/08/01/nintendo-raising-original-switch-console-prices-due-to-market-conditions/",
          "pubDate": "Fri, 01 Aug 2025 16:42:35 +0000",
          "dc:creator": "Aisha Malik",
          "content": "Nintendo wouldn't say what the \"market conditions\" were, but likely reference President Trump's tariffs, which are increasing costs for U.S. consumers.",
          "contentSnippet": "Nintendo wouldn't say what the \"market conditions\" were, but likely reference President Trump's tariffs, which are increasing costs for U.S. consumers.",
          "guid": "https://techcrunch.com/?p=3033317",
          "categories": [
            "Gaming",
            "Hardware",
            "Nintendo",
            "Nintendo Switch"
          ],
          "isoDate": "2025-08-01T16:42:35.000Z"
        }
      },
      {
        "json": {
          "creator": "Marina Temkin",
          "title": "More details emerge on how Windsurf’s VCs and founders got paid from the Google deal",
          "link": "https://techcrunch.com/2025/08/01/more-details-emerge-on-how-windsurfs-vcs-and-founders-got-paid-from-the-google-deal/",
          "pubDate": "Fri, 01 Aug 2025 16:00:00 +0000",
          "dc:creator": "Marina Temkin",
          "content": "VCs and founders took much of the $2.4 billion, but money was left for a payout to all employees, sources say.",
          "contentSnippet": "VCs and founders took much of the $2.4 billion, but money was left for a payout to all employees, sources say.",
          "guid": "https://techcrunch.com/?p=3033274",
          "categories": [
            "Venture",
            "AI",
            "Google",
            "General Catalyst",
            "Kleiner Perkins",
            "M&A",
            "Greenoaks Capital",
            "Windsurf"
          ],
          "isoDate": "2025-08-01T16:00:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Ivan Mehta",
          "title": "Fundamental Research Labs nabs $30M+ to build AI agents across verticals",
          "link": "https://techcrunch.com/2025/08/01/fundamental-research-labs-nabs-33-million-from-prosus-to-build-ai-agents-for-multiple-verticals/",
          "pubDate": "Fri, 01 Aug 2025 15:15:00 +0000",
          "dc:creator": "Ivan Mehta",
          "content": "Fundamental Research Labs is releasing multiple AI products related to gaming and productivity. ",
          "contentSnippet": "Fundamental Research Labs is releasing multiple AI products related to gaming and productivity.",
          "guid": "https://techcrunch.com/?p=3032713",
          "categories": [
            "AI",
            "Fundraising",
            "Venture",
            "a16z speedrun",
            "AI agents",
            "MIT",
            "Prosus Ventures"
          ],
          "isoDate": "2025-08-01T15:15:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Zack Whittaker",
          "title": "Sex toy maker Lovense threatens legal action after fixing security flaws that exposed users’ data",
          "link": "https://techcrunch.com/2025/08/01/sex-toy-maker-lovense-threatens-legal-action-after-fixing-security-flaws-that-exposed-users-data/",
          "pubDate": "Fri, 01 Aug 2025 14:55:53 +0000",
          "dc:creator": "Zack Whittaker",
          "content": "The internet-connected sex toy maker said it fixed the vulnerabilities that exposed users' private email addresses and accounts to takeovers, but said it was also planning to take legal action following the disclosure.",
          "contentSnippet": "The internet-connected sex toy maker said it fixed the vulnerabilities that exposed users' private email addresses and accounts to takeovers, but said it was also planning to take legal action following the disclosure.",
          "guid": "https://techcrunch.com/?p=3033296",
          "categories": [
            "Hardware",
            "Privacy",
            "Security",
            "cybersecurity",
            "data protection",
            "hardware",
            "lovense",
            "privacy",
            "sex toys"
          ],
          "isoDate": "2025-08-01T14:55:53.000Z"
        }
      },
      {
        "json": {
          "creator": "Jagmeet Singh",
          "title": "Truecaller’s call-recording feature won’t work on iPhones from September 30",
          "link": "https://techcrunch.com/2025/08/01/truecallers-call-recording-feature-wont-work-on-iphones-from-september-30/",
          "pubDate": "Fri, 01 Aug 2025 14:36:07 +0000",
          "dc:creator": "Jagmeet Singh",
          "content": "The app's call recording feature will no longer be available on iPhones starting September 30. Users with saved call recordings can either download them to their devices, share them via email or messaging apps, or switch their storage preference to iCloud to keep the recordings accessible.",
          "contentSnippet": "The app's call recording feature will no longer be available on iPhones starting September 30. Users with saved call recordings can either download them to their devices, share them via email or messaging apps, or switch their storage preference to iCloud to keep the recordings accessible.",
          "guid": "https://techcrunch.com/?p=3033248",
          "categories": [
            "Apps",
            "iPhone",
            "Truecaller",
            "call recording"
          ],
          "isoDate": "2025-08-01T14:36:07.000Z"
        }
      },
      {
        "json": {
          "creator": "Aisha Malik",
          "title": "TikTok launches ‘TikTok Pro’ in Europe with built-in charity program",
          "link": "https://techcrunch.com/2025/08/01/tiktok-launches-tiktok-pro-in-europe-with-built-in-charity-program/",
          "pubDate": "Fri, 01 Aug 2025 14:30:11 +0000",
          "dc:creator": "Aisha Malik",
          "content": "The app features TikTok's new \"Sunshine Programme,\" which allows users to support charitable organizations. ",
          "contentSnippet": "The app features TikTok's new \"Sunshine Programme,\" which allows users to support charitable organizations.",
          "guid": "https://techcrunch.com/?p=3033271",
          "categories": [
            "Apps",
            "Social",
            "In Brief",
            "TikTok",
            "tiktok pro"
          ],
          "isoDate": "2025-08-01T14:30:11.000Z"
        }
      },
      {
        "json": {
          "creator": "Michal Sutter",
          "title": "7 Essential Layers for Building Real-World AI Agents in 2025: A Comprehensive Framework",
          "link": "https://www.marktechpost.com/2025/08/04/7-essential-layers-for-building-real-world-ai-agents-in-2025-a-comprehensive-framework/",
          "pubDate": "Mon, 04 Aug 2025 07:14:45 +0000",
          "content:encoded": "\n<p>Building an intelligent agent goes far beyond clever prompt engineering for language models. To create real-world, autonomous AI systems that can <em>think</em>, <em>reason</em>, <em>act</em>, and <em>learn</em>, you need to engineer a full-stack solution that orchestrates multiple tightly–integrated components. The following seven-layer framework is a battle-tested mental model for anyone serious about AI agent development—whether you’re a founder, AI engineer, or product leader.</p>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>1. Experience Layer — The Human Interface</strong></h3>\n\n\n\n<p>The Experience Layer acts as the touchpoint between humans and the agent. It defines how users interact with the system: conversation (chat/web/app), voice, image, or even multimodal engagement. This layer must be intuitive, accessible, and capable of capturing user intent precisely, while providing clear feedback.</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Core design challenge:</strong> Translate ambiguous human goals into machine-understandable objectives.</li>\n\n\n\n<li><strong>Example:</strong> A customer support chatbot interface, or a voice assistant in a smart home.</li>\n</ul>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>2. Discovery Layer — Information Gathering &amp; Context</strong></h3>\n\n\n\n<p>Agents need to orient themselves: knowing what to ask, where to look, and how to gather relevant information. The Discovery Layer encompasses techniques like web search, document retrieval, data mining, context collection, sensor integration, and interaction history analysis.</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Core design challenge:</strong> Efficient, reliable, and context-aware information retrieval that surfaces only what matters.</li>\n\n\n\n<li><strong>Example:</strong> Fetching product manuals, extracting knowledge bases, or summarizing recent emails.</li>\n</ul>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>3. Agent Composition Layer — Structure, Goals, and Behaviors</strong></h3>\n\n\n\n<p>This layer defines <em>what</em> the agent is and <em>how</em> it should behave. It includes defining the agent’s goals, its modular architecture (sub-agents, policies, roles), possible actions, ethical boundaries, and configurable behaviors.</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Core design challenge:</strong> Enabling customization and extensibility while ensuring coherence and alignment with user and business objectives.</li>\n\n\n\n<li><strong>Example:</strong> Setting up a sales assistant agent with negotiation tactics, brand voice, and escalation protocols.</li>\n</ul>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>4. Reasoning &amp; Planning Layer — The Agent’s Brain</strong></h3>\n\n\n\n<p>At the heart of autonomy, the Reasoning &amp; Planning Layer handles logic, decision-making, inference, and action sequencing. Here, the agent evaluates information, weighs alternatives, plans steps, and adapts strategies. This layer can leverage symbolic reasoning engines, LLMs, classical AI planners, or hybrids.</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Core design challenge:</strong> Moving beyond pattern-matching to true adaptive intelligence.</li>\n\n\n\n<li><strong>Example:</strong> Prioritizing customer queries, scheduling multi-step workflows, or generating argument chains.</li>\n</ul>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>5. Tool &amp; API Layer — Acting in the World</strong></h3>\n\n\n\n<p>This layer enables the agent to perform real actions: executing code, triggering APIs, controlling IoT devices, managing files, or running external workflows. The agent must safely interface with digital and (sometimes) physical systems, often requiring robust error handling, authentication, and permissions management.</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Core design challenge:</strong> Safe, reliable, and flexible action-taking with external systems.</li>\n\n\n\n<li><strong>Example:</strong> Booking a meeting on your calendar, placing an e-commerce order, or running data analysis scripts.</li>\n</ul>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>6. Memory &amp; Feedback Layer — Contextual Recall &amp; Learning</strong></h3>\n\n\n\n<p>Agents that learn and improve over time must maintain memory: tracking prior interactions, storing context, and incorporating user feedback. This layer supports both short-term contextual recall (for conversation) and long-term learning (improving models, policies, or knowledge bases).</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Core design challenge:</strong> Scalable memory representation and effective feedback integration.</li>\n\n\n\n<li><strong>Example:</strong> Remembering user preferences, learning common support issues, or iteratively refining suggestions.</li>\n</ul>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>7. Infrastructure Layer — Scaling, Orchestration, &amp; Security</strong></h3>\n\n\n\n<p>Beneath the application stack, robust infrastructure ensures the agent is available, responsive, scalable, and secure. This layer includes orchestration platforms, distributed compute, monitoring, failover, and compliance safeguards.</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Core design challenge:</strong> Reliability and robustness at scale.</li>\n\n\n\n<li><strong>Example:</strong> Managing thousands of concurrent agent instances with uptime guarantees and secure API gateways.</li>\n</ul>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>Key Takeaways</strong></h3>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>True autonomy requires more than language understanding.</strong></li>\n\n\n\n<li><strong>Integrate all 7 layers</strong> for agents that can safely sense, plan, act, learn, and scale.</li>\n\n\n\n<li><strong>Adopt this framework</strong> to assess, design, and build next-generation AI systems that solve meaningful problems.</li>\n</ul>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity\"/>\n\n\n\n<p>Feel free to check out our <strong><mark><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included\" target=\"_blank\" rel=\"noreferrer noopener\">GitHub Page for Tutorials, Codes and Notebooks</a></mark></strong>. Also, feel free to follow us on <strong><a href=\"https://x.com/intent/follow?screen_name=marktechpost\" target=\"_blank\" rel=\"noreferrer noopener\"><mark>Twitter</mark></a></strong> and don’t forget to join our <strong><a href=\"https://www.reddit.com/r/machinelearningnews/\" target=\"_blank\" rel=\"noreferrer noopener\">100k+ ML SubReddit</a></strong> and Subscribe to <strong><a href=\"https://www.aidevsignals.com/\" target=\"_blank\" rel=\"noreferrer noopener\">our Newsletter</a></strong>.</p>\n<p>The post <a href=\"https://www.marktechpost.com/2025/08/04/7-essential-layers-for-building-real-world-ai-agents-in-2025-a-comprehensive-framework/\">7 Essential Layers for Building Real-World AI Agents in 2025: A Comprehensive Framework</a> appeared first on <a href=\"https://www.marktechpost.com\">MarkTechPost</a>.</p>\n",
          "content:encodedSnippet": "Building an intelligent agent goes far beyond clever prompt engineering for language models. To create real-world, autonomous AI systems that can think, reason, act, and learn, you need to engineer a full-stack solution that orchestrates multiple tightly–integrated components. The following seven-layer framework is a battle-tested mental model for anyone serious about AI agent development—whether you’re a founder, AI engineer, or product leader.\n1. Experience Layer — The Human Interface\nThe Experience Layer acts as the touchpoint between humans and the agent. It defines how users interact with the system: conversation (chat/web/app), voice, image, or even multimodal engagement. This layer must be intuitive, accessible, and capable of capturing user intent precisely, while providing clear feedback.\nCore design challenge: Translate ambiguous human goals into machine-understandable objectives.\nExample: A customer support chatbot interface, or a voice assistant in a smart home.\n2. Discovery Layer — Information Gathering & Context\nAgents need to orient themselves: knowing what to ask, where to look, and how to gather relevant information. The Discovery Layer encompasses techniques like web search, document retrieval, data mining, context collection, sensor integration, and interaction history analysis.\nCore design challenge: Efficient, reliable, and context-aware information retrieval that surfaces only what matters.\nExample: Fetching product manuals, extracting knowledge bases, or summarizing recent emails.\n3. Agent Composition Layer — Structure, Goals, and Behaviors\nThis layer defines what the agent is and how it should behave. It includes defining the agent’s goals, its modular architecture (sub-agents, policies, roles), possible actions, ethical boundaries, and configurable behaviors.\nCore design challenge: Enabling customization and extensibility while ensuring coherence and alignment with user and business objectives.\nExample: Setting up a sales assistant agent with negotiation tactics, brand voice, and escalation protocols.\n4. Reasoning & Planning Layer — The Agent’s Brain\nAt the heart of autonomy, the Reasoning & Planning Layer handles logic, decision-making, inference, and action sequencing. Here, the agent evaluates information, weighs alternatives, plans steps, and adapts strategies. This layer can leverage symbolic reasoning engines, LLMs, classical AI planners, or hybrids.\nCore design challenge: Moving beyond pattern-matching to true adaptive intelligence.\nExample: Prioritizing customer queries, scheduling multi-step workflows, or generating argument chains.\n5. Tool & API Layer — Acting in the World\nThis layer enables the agent to perform real actions: executing code, triggering APIs, controlling IoT devices, managing files, or running external workflows. The agent must safely interface with digital and (sometimes) physical systems, often requiring robust error handling, authentication, and permissions management.\nCore design challenge: Safe, reliable, and flexible action-taking with external systems.\nExample: Booking a meeting on your calendar, placing an e-commerce order, or running data analysis scripts.\n6. Memory & Feedback Layer — Contextual Recall & Learning\nAgents that learn and improve over time must maintain memory: tracking prior interactions, storing context, and incorporating user feedback. This layer supports both short-term contextual recall (for conversation) and long-term learning (improving models, policies, or knowledge bases).\nCore design challenge: Scalable memory representation and effective feedback integration.\nExample: Remembering user preferences, learning common support issues, or iteratively refining suggestions.\n7. Infrastructure Layer — Scaling, Orchestration, & Security\nBeneath the application stack, robust infrastructure ensures the agent is available, responsive, scalable, and secure. This layer includes orchestration platforms, distributed compute, monitoring, failover, and compliance safeguards.\nCore design challenge: Reliability and robustness at scale.\nExample: Managing thousands of concurrent agent instances with uptime guarantees and secure API gateways.\nKey Takeaways\nTrue autonomy requires more than language understanding.\nIntegrate all 7 layers for agents that can safely sense, plan, act, learn, and scale.\nAdopt this framework to assess, design, and build next-generation AI systems that solve meaningful problems.\nFeel free to check out our GitHub Page for Tutorials, Codes and Notebooks. Also, feel free to follow us on Twitter and don’t forget to join our 100k+ ML SubReddit and Subscribe to our Newsletter.\nThe post 7 Essential Layers for Building Real-World AI Agents in 2025: A Comprehensive Framework appeared first on MarkTechPost.",
          "dc:creator": "Michal Sutter",
          "comments": "https://www.marktechpost.com/2025/08/04/7-essential-layers-for-building-real-world-ai-agents-in-2025-a-comprehensive-framework/#respond",
          "content": "<p>Building an intelligent agent goes far beyond clever prompt engineering for language models. To create real-world, autonomous AI systems that can think, reason, act, and learn, you need to engineer a full-stack solution that orchestrates multiple tightly–integrated components. The following seven-layer framework is a battle-tested mental model for anyone serious about AI agent development—whether you’re [&#8230;]</p>\n<p>The post <a href=\"https://www.marktechpost.com/2025/08/04/7-essential-layers-for-building-real-world-ai-agents-in-2025-a-comprehensive-framework/\">7 Essential Layers for Building Real-World AI Agents in 2025: A Comprehensive Framework</a> appeared first on <a href=\"https://www.marktechpost.com\">MarkTechPost</a>.</p>\n",
          "contentSnippet": "Building an intelligent agent goes far beyond clever prompt engineering for language models. To create real-world, autonomous AI systems that can think, reason, act, and learn, you need to engineer a full-stack solution that orchestrates multiple tightly–integrated components. The following seven-layer framework is a battle-tested mental model for anyone serious about AI agent development—whether you’re […]\nThe post 7 Essential Layers for Building Real-World AI Agents in 2025: A Comprehensive Framework appeared first on MarkTechPost.",
          "guid": "https://www.marktechpost.com/?p=73193",
          "categories": [
            "Agentic AI",
            "AI Agents",
            "Editors Pick",
            "Staff",
            "Tech News"
          ],
          "isoDate": "2025-08-04T07:14:45.000Z"
        }
      },
      {
        "json": {
          "creator": "Sajjad Ansari",
          "title": "ByteDance Introduces Seed-Prover: An Advanced Formal Reasoning System for Automated Mathematical Theorem Proving",
          "link": "https://www.marktechpost.com/2025/08/03/bytedance-introduces-seed-prover-an-advanced-formal-reasoning-system-for-automated-mathematical-theorem-proving/",
          "pubDate": "Mon, 04 Aug 2025 06:51:07 +0000",
          "content:encoded": "\n<p>LLMs have shown notable improvements in mathematical reasoning by extending through natural language, resulting in performance gains on benchmarks such as MATH and AIME. However, reinforcement learning (RL) for training these models encounters a challenge: verifying the correctness of natural language proofs is very difficult, requiring careful manual checking of each reasoning step. This limits the application of RL for training mathematical theorem-proving models. While formal languages like Lean offer automatic correctness verification, current LLM formal provers face their limitations. Step-level provers generate code incrementally but require special scaffolding and lack high-level reasoning capabilities.</p>\n\n\n\n<p>ByteDance Seed Team introduces Seed-Prover, a lemma-style whole-proof reasoning model. It refines proofs iteratively using Lean feedback, previously established lemmas, and self-summarization. Seed-Prover employs three specialized test-time inference strategies that allow deep and broad reasoning methods to solve IMO-level contest problems. Its primary innovation is in adopting lemma-style proving as its core method, placing lemmas at the center of the reasoning process rather than relying on traditional step-by-step or whole-proof generation methods. Moreover, this paper introduces Seed-Geometry,  a complementary geometry reasoning engine that overcomes Lean’s limitations in handling geometric support.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter is-resized\"><img decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXe9f_8Uhh3TVR07GrJVZV4uan7FLhXqAtMYwDeSSAOGcgsHcSi0sXvrX_aFBLJJ0afavjCGucgQ8opXYwkZrOb7yGq_Wob4ipE-Bh7CoXw6jf1KR_hQiKUuDR2ZMr0EzKx_fioSPA?key=tfIFbjPiQfswl73kcpOabA\" alt=\"\" style=\"width:754px;height:auto\"/></figure></div>\n\n\n<p>For interaction between Seed-Prover and Lean, multi-stage, multi-task RL based on VAPO is utilized. The training dataset combines open-source datasets with in-house formal problems, using a proposer to create simpler variants of difficult tasks. It excludes overly simple problems with proof rates above 25%. Seed-Geometry’s backend supports large-scale problem generation, identifying over 230 million unique problems across seven days with an eightfold improvement in search efficiency. A separate policy and value model is trained, though extensive testing shows that value models may reduce performance due to estimation errors. As a result, step-by-step generation with beam search is adopted in distributed setups.</p>\n\n\n\n<p>Seed-Prover achieves state-of-the-art results across multiple mathematical benchmarks. For IMO 2025, Seed-Prover fully solves 5 out of 6 problems, with Seed-Geometry instantly solving Problem 2 and Seed-Prover deriving proofs for the remaining problem using various inference settings. On past IMO problems, it proved 121 out of 155 tasks, achieving a 78.1% success rate across all difficulty levels. The performance breakdown shows strong results across problem categories: solving 47 out of 55 easy problems, 47 out of 56 medium problems, and 27 out of 44 hard problems, with subject-specific success rates including 72 out of 85 in algebra, 42 out of 55 in number theory, and 7 out of 14 in combinatorics.</p>\n\n\n\n<p>On MiniF2F, researchers achieve a 99.6% proof rate for both validation and test sets under medium settings, solving difficult problems such as IMO 1990 P3. PutnamBench results show improvement from 201 to 331 solved problems out of 657 when upgrading from light to medium inference settings, showing a significant performance jump over previous undergraduate-level mathematical reasoning systems. On CombiBench, Seed-Prover solves 30 out of 100 combinatorics problems, outperforming existing methods but revealing continued challenges in combinatorial reasoning. Researchers achieve 81.8% success on MiniCTX-v2, showing strong generalization beyond competition problems and outperforming the o4-mini baseline&#8217;s 44.3% at Pass@8.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter is-resized\"><img decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXdglg5ZqjO9X7KZoft0L7M62TbhaHRLNxcVVH29dVjtlq5qiQl6J02HBCrU6BDNtD-0zjxI_FLRjoce2BZx63YjIiX8XmtOhcRngKh0dBNJPTwZbs352OOTxh6CyseR3Bg3Dp8CyA?key=tfIFbjPiQfswl73kcpOabA\" alt=\"\" style=\"width:754px;height:auto\"/></figure></div>\n\n\n<p>In conclusion, ByteDance Seed presents Seed-Geometry and Seed-Prover, two formal reasoning methods that integrate the capabilities of LLMs. Seed-Geometry provides accelerated verification and enhanced search mechanisms while Seed-Prover utilizes iterative refinement and complex test-time inference strategies. The achievement of solving 5 out of 6 problems in the IMO 2025 shows the practical efficacy of these methods in tackling elite mathematical competitions. The adoption of formal languages like Lean provides rapid proof verification that is more cost-effective than human experts and more reliable than LLM-based judges. Future research will focus on combining formal systems with LLMs to address open conjectures.</p>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity\"/>\n\n\n\n<p>Check out the <strong><a href=\"https://arxiv.org/abs/2507.23726\" target=\"_blank\" rel=\"noreferrer noopener\">Paper</a></strong> and <strong><a href=\"https://github.com/ByteDance-Seed/Seed-Prover\" target=\"_blank\" rel=\"noreferrer noopener\">GitHub Page</a><em>.</em></strong> Feel free to check out our <strong><mark><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included\" target=\"_blank\" rel=\"noreferrer noopener\">GitHub Page for Tutorials, Codes and Notebooks</a></mark></strong>. Also, feel free to follow us on <strong><a href=\"https://x.com/intent/follow?screen_name=marktechpost\" target=\"_blank\" rel=\"noreferrer noopener\"><mark>Twitter</mark></a></strong> and don’t forget to join our <strong><a href=\"https://www.reddit.com/r/machinelearningnews/\" target=\"_blank\" rel=\"noreferrer noopener\">100k+ ML SubReddit</a></strong> and Subscribe to <strong><a href=\"https://www.aidevsignals.com/\" target=\"_blank\" rel=\"noreferrer noopener\">our Newsletter</a></strong>.</p>\n<p>The post <a href=\"https://www.marktechpost.com/2025/08/03/bytedance-introduces-seed-prover-an-advanced-formal-reasoning-system-for-automated-mathematical-theorem-proving/\">ByteDance Introduces Seed-Prover: An Advanced Formal Reasoning System for Automated Mathematical Theorem Proving</a> appeared first on <a href=\"https://www.marktechpost.com\">MarkTechPost</a>.</p>\n",
          "content:encodedSnippet": "LLMs have shown notable improvements in mathematical reasoning by extending through natural language, resulting in performance gains on benchmarks such as MATH and AIME. However, reinforcement learning (RL) for training these models encounters a challenge: verifying the correctness of natural language proofs is very difficult, requiring careful manual checking of each reasoning step. This limits the application of RL for training mathematical theorem-proving models. While formal languages like Lean offer automatic correctness verification, current LLM formal provers face their limitations. Step-level provers generate code incrementally but require special scaffolding and lack high-level reasoning capabilities.\nByteDance Seed Team introduces Seed-Prover, a lemma-style whole-proof reasoning model. It refines proofs iteratively using Lean feedback, previously established lemmas, and self-summarization. Seed-Prover employs three specialized test-time inference strategies that allow deep and broad reasoning methods to solve IMO-level contest problems. Its primary innovation is in adopting lemma-style proving as its core method, placing lemmas at the center of the reasoning process rather than relying on traditional step-by-step or whole-proof generation methods. Moreover, this paper introduces Seed-Geometry,  a complementary geometry reasoning engine that overcomes Lean’s limitations in handling geometric support.\n\nFor interaction between Seed-Prover and Lean, multi-stage, multi-task RL based on VAPO is utilized. The training dataset combines open-source datasets with in-house formal problems, using a proposer to create simpler variants of difficult tasks. It excludes overly simple problems with proof rates above 25%. Seed-Geometry’s backend supports large-scale problem generation, identifying over 230 million unique problems across seven days with an eightfold improvement in search efficiency. A separate policy and value model is trained, though extensive testing shows that value models may reduce performance due to estimation errors. As a result, step-by-step generation with beam search is adopted in distributed setups.\nSeed-Prover achieves state-of-the-art results across multiple mathematical benchmarks. For IMO 2025, Seed-Prover fully solves 5 out of 6 problems, with Seed-Geometry instantly solving Problem 2 and Seed-Prover deriving proofs for the remaining problem using various inference settings. On past IMO problems, it proved 121 out of 155 tasks, achieving a 78.1% success rate across all difficulty levels. The performance breakdown shows strong results across problem categories: solving 47 out of 55 easy problems, 47 out of 56 medium problems, and 27 out of 44 hard problems, with subject-specific success rates including 72 out of 85 in algebra, 42 out of 55 in number theory, and 7 out of 14 in combinatorics.\nOn MiniF2F, researchers achieve a 99.6% proof rate for both validation and test sets under medium settings, solving difficult problems such as IMO 1990 P3. PutnamBench results show improvement from 201 to 331 solved problems out of 657 when upgrading from light to medium inference settings, showing a significant performance jump over previous undergraduate-level mathematical reasoning systems. On CombiBench, Seed-Prover solves 30 out of 100 combinatorics problems, outperforming existing methods but revealing continued challenges in combinatorial reasoning. Researchers achieve 81.8% success on MiniCTX-v2, showing strong generalization beyond competition problems and outperforming the o4-mini baseline’s 44.3% at Pass@8.\n\nIn conclusion, ByteDance Seed presents Seed-Geometry and Seed-Prover, two formal reasoning methods that integrate the capabilities of LLMs. Seed-Geometry provides accelerated verification and enhanced search mechanisms while Seed-Prover utilizes iterative refinement and complex test-time inference strategies. The achievement of solving 5 out of 6 problems in the IMO 2025 shows the practical efficacy of these methods in tackling elite mathematical competitions. The adoption of formal languages like Lean provides rapid proof verification that is more cost-effective than human experts and more reliable than LLM-based judges. Future research will focus on combining formal systems with LLMs to address open conjectures.\nCheck out the Paper and GitHub Page. Feel free to check out our GitHub Page for Tutorials, Codes and Notebooks. Also, feel free to follow us on Twitter and don’t forget to join our 100k+ ML SubReddit and Subscribe to our Newsletter.\nThe post ByteDance Introduces Seed-Prover: An Advanced Formal Reasoning System for Automated Mathematical Theorem Proving appeared first on MarkTechPost.",
          "dc:creator": "Sajjad Ansari",
          "comments": "https://www.marktechpost.com/2025/08/03/bytedance-introduces-seed-prover-an-advanced-formal-reasoning-system-for-automated-mathematical-theorem-proving/#respond",
          "content": "<p>LLMs have shown notable improvements in mathematical reasoning by extending through natural language, resulting in performance gains on benchmarks such as MATH and AIME. However, reinforcement learning (RL) for training these models encounters a challenge: verifying the correctness of natural language proofs is very difficult, requiring careful manual checking of each reasoning step. This limits [&#8230;]</p>\n<p>The post <a href=\"https://www.marktechpost.com/2025/08/03/bytedance-introduces-seed-prover-an-advanced-formal-reasoning-system-for-automated-mathematical-theorem-proving/\">ByteDance Introduces Seed-Prover: An Advanced Formal Reasoning System for Automated Mathematical Theorem Proving</a> appeared first on <a href=\"https://www.marktechpost.com\">MarkTechPost</a>.</p>\n",
          "contentSnippet": "LLMs have shown notable improvements in mathematical reasoning by extending through natural language, resulting in performance gains on benchmarks such as MATH and AIME. However, reinforcement learning (RL) for training these models encounters a challenge: verifying the correctness of natural language proofs is very difficult, requiring careful manual checking of each reasoning step. This limits […]\nThe post ByteDance Introduces Seed-Prover: An Advanced Formal Reasoning System for Automated Mathematical Theorem Proving appeared first on MarkTechPost.",
          "guid": "https://www.marktechpost.com/?p=73190",
          "categories": [
            "AI Paper Summary",
            "AI Shorts",
            "Applications",
            "Artificial Intelligence",
            "Editors Pick",
            "Staff",
            "Tech News",
            "Technology"
          ],
          "isoDate": "2025-08-04T06:51:07.000Z"
        }
      },
      {
        "json": {
          "creator": "Arham Islam",
          "title": "Tutorial: Exploring SHAP-IQ Visualizations",
          "link": "https://www.marktechpost.com/2025/08/03/tutorial-exploring-shap-iq-visualizations/",
          "pubDate": "Mon, 04 Aug 2025 04:45:10 +0000",
          "content:encoded": "\n<p>In this tutorial, we’ll explore a range of SHAP-IQ visualizations that provide insights into how a machine learning model arrives at its predictions. These visuals help break down complex model behavior into interpretable components—revealing both the individual and interactive contributions of features to a specific prediction. Check out the <strong><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included/blob/main/SHAP-IQ/SHAP_IQ_Visuals.ipynb\" target=\"_blank\" rel=\"noreferrer noopener\">Full Codes here</a><em>.</em></strong></p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-installing-the-dependencies\"><strong>Installing the dependencies</strong></h3>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\">!pip install shapiq overrides scikit-learn pandas numpy seaborn</code></pre></div></div>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\">from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.model_selection import train_test_split\nfrom tqdm.asyncio import tqdm\n\nimport shapiq\n\nprint(f\"shapiq version: {shapiq.__version__}\")</code></pre></div></div>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>Importing the dataset</strong></h3>\n\n\n\n<p>In this tutorial, we’ll use the MPG (Miles Per Gallon) dataset, which we’ll load directly from the Seaborn library. This dataset contains information about various car models, including features like horsepower, weight, and origin. Check out the <strong><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included/blob/main/SHAP-IQ/SHAP_IQ_Visuals.ipynb\" target=\"_blank\" rel=\"noreferrer noopener\">Full Codes here</a><em>.</em></strong></p>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\">import seaborn as sns\ndf = sns.load_dataset(\"mpg\")\ndf</code></pre></div></div>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>Processing the dataset</strong></h3>\n\n\n\n<p>We use Label Encoding to convert the categorical column(s) into numeric format, making them suitable for model training.</p>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\">import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\n# Drop rows with missing values\ndf = df.dropna()\n\n# Encoding the origin column\nle = LabelEncoder()\ndf.loc[:, \"origin\"] = le.fit_transform(df[\"origin\"])\ndf['origin'].unique()</code></pre></div></div>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\">for i, label in enumerate(le.classes_):\n    print(f\"{label} → {i}\")</code></pre></div></div>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-splitting-the-data-into-training-amp-test-subsets\"><strong>Splitting the data into training &amp; test subsets</strong></h3>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\"># Select features and target\nX = df.drop(columns=[\"mpg\", \"name\"])\ny = df[\"mpg\"]\n\nfeature_names = X.columns.tolist()\nx_data, y_data = X.values, y.values\n\n# Train-test split\nx_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)</code></pre></div></div>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>Model Training</strong></h3>\n\n\n\n<p>We train a Random Forest Regressor with a maximum depth of 10 and 10 decision trees (n_estimators=10). A fixed random_state ensures reproducibility.</p>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\"># Train model\nmodel = RandomForestRegressor(random_state=42, max_depth=10, n_estimators=10)\nmodel.fit(x_train, y_train)</code></pre></div></div>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-model-evaluation\"><strong>Model Evaluation</strong></h3>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\"># Evaluate\nmse = mean_squared_error(y_test, model.predict(x_test))\nr2 = r2_score(y_test, model.predict(x_test))\nprint(f\"Mean Squared Error: {mse:.2f}\")\nprint(f\"R2 Score: {r2:.2f}\")</code></pre></div></div>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>Explaining a Local Instance</strong></h3>\n\n\n\n<p>We choose a specific test instance (with instance_id = 7) to explore how the model arrived at its prediction. We&#8217;ll print the true value, predicted value, and the feature values for this instance. Check out the <strong><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included/blob/main/SHAP-IQ/SHAP_IQ_Visuals.ipynb\" target=\"_blank\" rel=\"noreferrer noopener\">Full Codes here</a><em>.</em></strong></p>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\"># select a local instance to be explained\ninstance_id = 7\nx_explain = x_test[instance_id]\ny_true = y_test[instance_id]\ny_pred = model.predict(x_explain.reshape(1, -1))[0]\nprint(f\"Instance {instance_id}, True Value: {y_true}, Predicted Value: {y_pred}\")\nfor i, feature in enumerate(feature_names):\n    print(f\"{feature}: {x_explain[i]}\")</code></pre></div></div>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>Generating Explanations for Multiple Interaction Orders</strong></h3>\n\n\n\n<p>We generate Shapley-based explanations for different interaction orders using the shapiq package. Specifically, we compute:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Order 1 (Standard Shapley Values): Individual feature contributions</li>\n</ul>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Order 2 (Pairwise Interactions): Combined effects of feature pairs</li>\n</ul>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Order N (Full Interaction): All interactions up to the total number of features</li>\n</ul>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\"># create explanations for different orders\nfeature_names = list(X.columns)  # get the feature names\nn_features = len(feature_names)\n\nsi_order: dict[int, shapiq.InteractionValues] = {}\nfor order in tqdm([1, 2, n_features]):\n    index = \"k-SII\" if order > 1 else \"SV\"  # will also be set automatically by the explainer\n    explainer = shapiq.TreeExplainer(model=model, max_order=order, index=index)\n    si_order[order] = explainer.explain(x=x_explain)\nsi_order</code></pre></div></div>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>1. Force Chart</strong></h3>\n\n\n\n<p>The force plot is a powerful visualization tool that helps us understand how a machine learning model arrived at a specific prediction. It displays the baseline prediction (i.e., the expected value of the model before seeing any features), and then shows how each feature &#8220;pushes&#8221; the prediction higher or lower.</p>\n\n\n\n<p>In this plot:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Red bars represent features or interactions that increase the prediction.</li>\n\n\n\n<li>Blue bars represent those that decrease it.</li>\n\n\n\n<li>The length of each bar corresponds to the magnitude of its effect.</li>\n</ul>\n\n\n\n<p>When using Shapley interaction values, the force plot can visualize not just individual contributions but also interactions between features. This makes it especially insightful when interpreting complex models, as it visually decomposes how combinations of features work together to influence the outcome. Check out the <strong><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included/blob/main/SHAP-IQ/SHAP_IQ_Visuals.ipynb\" target=\"_blank\" rel=\"noreferrer noopener\">Full Codes here</a><em>.</em></strong></p>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\">sv = si_order[1]  # get the SV\nsi = si_order[2]  # get the 2-SII\nmi = si_order[n_features]  # get the Moebius transform\n\nsv.plot_force(feature_names=feature_names, show=True)\nsi.plot_force(feature_names=feature_names, show=True)\nmi.plot_force(feature_names=feature_names, show=True)</code></pre></div></div>\n\n\n\n<figure class=\"wp-block-image is-resized\"><img decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXdSzKJXZ6TsWprj_MP5wcuq6iZQLUdldMbwkb_W0TSdZeNfUt4kFj95hBcFz5BfBAw_8P4xAv9Y4Oa8vnevZytRimFf6vwzt4rU6c34t-muhJmGt7VfoVdzoEN2V2pkQXmaK4QMLQ?key=aAipKL6NcbRDTM9g2wsEFQ\" alt=\"\" style=\"width:918px;height:auto\"/></figure>\n\n\n\n<p>From the first plot, we can see that the base value is 23.5. Features like Weight, Cylinders, Horsepower, and Displacement have a positive influence on the prediction, pushing it above the baseline. On the other hand, Model Year and Acceleration have a negative impact, pulling the prediction downward.</p>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>2. Waterfall Chart</strong></h3>\n\n\n\n<p>Similar to the force plot, the waterfall plot is another popular way to visualize Shapley values, originally introduced with the shap library. It shows how different features push the prediction higher or lower compared to the baseline. One key advantage of the waterfall plot is that it automatically groups features with very small impacts into an “other” category, making the chart cleaner and easier to understand. Check out the <strong><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included/blob/main/SHAP-IQ/SHAP_IQ_Visuals.ipynb\" target=\"_blank\" rel=\"noreferrer noopener\">Full Codes here</a><em>.</em></strong></p>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\">sv.plot_waterfall(feature_names=feature_names, show=True)\nsi.plot_waterfall(feature_names=feature_names, show=True)\nmi.plot_waterfall(feature_names=feature_names, show=True)</code></pre></div></div>\n\n\n\n<figure class=\"wp-block-image is-resized\"><img decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXeRTI2OtfHUaphJpAruRXYbqGAs-AgVPspFOczu-IlM3K7m6NieqPulKCBQWMdpD51fCasRZV6zaiOgWfo4c0Q2z7NQqpI7erHsnt4jOq_CRiWXjUj6wMzuXmc3b555HCjrUHnI?key=aAipKL6NcbRDTM9g2wsEFQ\" alt=\"\" style=\"width:706px;height:auto\"/></figure>\n\n\n\n<figure class=\"wp-block-image is-resized\"><img decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXeFeEomfA09HB1wEFAWWMJ9h3Iet_1YC2fh676AUKddgDrmUZ_KtP11cGFR5JanmRiPJsKfjE3JdmnwIlzQ7I1BZgaxOh6JDBBUb8nfhRuH5WS4YdnAaa1Ftr64PIcAAnHF3z_aIQ?key=aAipKL6NcbRDTM9g2wsEFQ\" alt=\"\" style=\"width:1005px;height:auto\"/></figure>\n\n\n\n<figure class=\"wp-block-image is-resized\"><img decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXe5R3wKkWmjQkCqOuQSOAT54x8jg9MNYTkYTp0H4HAIJMPZrb9U0DuYjkjwC9o3X_aXW7u5W88xOVWLxO4tp3fhvRGwU6rFuW1XCKiytZ6nkKd7vZfzHRXdx2PPqWufl6cHWysfjg?key=aAipKL6NcbRDTM9g2wsEFQ\" alt=\"\" style=\"width:969px;height:auto\"/></figure>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>3. Network Plot</strong></h3>\n\n\n\n<p>The network plot shows how features interact with each other using first- and second-order Shapley interactions. Node size reflects individual feature impact, while edge width and color show interaction strength and direction. It&#8217;s especially helpful when dealing with many features, revealing complex interactions that simpler plots might miss. Check out the <strong><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included/blob/main/SHAP-IQ/SHAP_IQ_Visuals.ipynb\" target=\"_blank\" rel=\"noreferrer noopener\">Full Codes here</a><em>.</em></strong></p>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\">si.plot_network(feature_names=feature_names, show=True)\nmi.plot_network(feature_names=feature_names, show=True)</code></pre></div></div>\n\n\n\n<figure class=\"wp-block-image is-resized\"><img decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXc0nUeNhFZeHh2TLbN9iZPmeEOsUe5O6uxtiHgPq-k7cJwI-b1AAbm0tHHHOZw2LjSYTU3ozNz5L9qDCqA_MFsAq9-OeY1SwmlB5c8tG8mQiFg2qX3JuqHwPII0Daij3kyEt-7x?key=aAipKL6NcbRDTM9g2wsEFQ\" alt=\"\" style=\"width:594px;height:auto\"/></figure>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>4. SI Graph Plot</strong></h3>\n\n\n\n<p>The SI graph plot extends the network plot by visualizing all higher-order interactions as hyper-edges connecting multiple features. Node size shows individual feature impact, while edge width, color, and transparency reflect the strength and direction of interactions. It provides a comprehensive view of how features jointly influence the model&#8217;s prediction. Check out the <strong><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included/blob/main/SHAP-IQ/SHAP_IQ_Visuals.ipynb\" target=\"_blank\" rel=\"noreferrer noopener\">Full Codes here</a><em>.</em></strong></p>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\"># we abbreviate the feature names since, they are plotted inside the nodes\nabbrev_feature_names = shapiq.plot.utils.abbreviate_feature_names(feature_names)\nsv.plot_si_graph(\n    feature_names=abbrev_feature_names,\n    show=True,\n    size_factor=2.5,\n    node_size_scaling=1.5,\n    plot_original_nodes=True,\n)\nsi.plot_si_graph(\n    feature_names=abbrev_feature_names,\n    show=True,\n    size_factor=2.5,\n    node_size_scaling=1.5,\n    plot_original_nodes=True,\n)\nmi.plot_si_graph(\n    feature_names=abbrev_feature_names,\n    show=True,\n    size_factor=2.5,\n    node_size_scaling=1.5,\n    plot_original_nodes=True,\n)</code></pre></div></div>\n\n\n\n<figure class=\"wp-block-image is-resized\"><img decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXeE0EOA7mqqVkt9B4kbDEewnC2ob25gYdQVPhbj-WPmB1oNBY92gr8Gzo_1I56JJ6YScg3xDSFdybk9bJ3hH0o3uytv8uqeCWMmf4dcHwPWlQjwXirm_OeUF9bymfXKzPK02CWH?key=aAipKL6NcbRDTM9g2wsEFQ\" alt=\"\" style=\"width:546px;height:auto\"/></figure>\n\n\n\n<figure class=\"wp-block-image is-resized\"><img decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXdLGjR3cFoFuXnQBz6h7gx-xaO2RjFvGBoz5rPu60INpxJV426tftkdbksIvkv3i_KuvpdLZPVyBEy7T6dC3e9e6_1YpeAeNjfpHIlM9-gRC6LXF5zpZfI4YbI_aDj00Kjoh2kslA?key=aAipKL6NcbRDTM9g2wsEFQ\" alt=\"\" style=\"width:546px;height:auto\"/></figure>\n\n\n\n<figure class=\"wp-block-image is-resized\"><img decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXcdyW6mg0LPEBRrkjbmpOkvpU3w6Fw1x1ydC2a1P_cj4L5cF-lrkGb4WlrQaFiZGoukGKc6rPscB1y5OFfaT-SP1vLiCG1KvqrKCCbUWkyul3mGPowxpG3296pr3jCUPS_bSt3E5g?key=aAipKL6NcbRDTM9g2wsEFQ\" alt=\"\" style=\"width:577px;height:auto\"/></figure>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>5. Bar Plot</strong></h3>\n\n\n\n<p>The bar plot is tailored for global explanations. While other plots can be used both locally and globally, the bar plot summarizes the overall importance of features (or feature interactions) by showing the mean absolute Shapley (or interaction) values across all instances. In shapiq, it highlights which feature interactions contribute most on average. Check out the <strong><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included/blob/main/SHAP-IQ/SHAP_IQ_Visuals.ipynb\" target=\"_blank\" rel=\"noreferrer noopener\">Full Codes here</a><em>.</em></strong></p>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\">explanations = []\nexplainer = shapiq.TreeExplainer(model=model, max_order=2, index=\"k-SII\")\nfor instance_id in tqdm(range(20)):\n    x_explain = x_test[instance_id]\n    si = explainer.explain(x=x_explain)\n    explanations.append(si)\nshapiq.plot.bar_plot(explanations, feature_names=feature_names, show=True)</code></pre></div></div>\n\n\n\n<figure class=\"wp-block-image is-resized\"><img decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXeAeAJkwcZmczz3nTL7NWE77pEmxJQ4h8a9czAIzG8PinLWuH8HA3koH1qfYmXo_n7bghZ2MpNKhQThcfQje_OUQfWTnDkk-N65PoEhFEWe_MSoPJVYQu2XacCMdEGQ48B9pFhlDQ?key=aAipKL6NcbRDTM9g2wsEFQ\" alt=\"\" style=\"width:796px;height:auto\"/></figure>\n\n\n\n<p>&#8220;Distance&#8221; and &#8220;Horsepower&#8221; are the most influential features overall, meaning they have the strongest individual impact on the model&#8217;s predictions. This is evident from their high mean absolute Shapley interaction values in the bar plot.</p>\n\n\n\n<p>Additionally, when looking at second-order interactions (i.e., how two features interact together), the combinations &#8220;Horsepower × Weight&#8221; and &#8220;Distance × Horsepower&#8221; show significant joint influence. Their combined attribution is around 1.4, indicating that these interactions play an important role in shaping the model&#8217;s predictions beyond what each feature contributes individually. This highlights the presence of non-linear relationships between features in the model.</p>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity\"/>\n\n\n\n<p>Check out the <strong><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included/blob/main/SHAP-IQ/SHAP_IQ_Visuals.ipynb\" target=\"_blank\" rel=\"noreferrer noopener\">Full Codes here</a><em>.</em></strong> Feel free to check out our <strong><mark><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included\" target=\"_blank\" rel=\"noreferrer noopener\">GitHub Page for Tutorials, Codes and Notebooks</a></mark></strong>. Also, feel free to follow us on <strong><a href=\"https://x.com/intent/follow?screen_name=marktechpost\" target=\"_blank\" rel=\"noreferrer noopener\"><mark>Twitter</mark></a></strong> and don’t forget to join our <strong><a href=\"https://www.reddit.com/r/machinelearningnews/\" target=\"_blank\" rel=\"noreferrer noopener\">100k+ ML SubReddit</a></strong> and Subscribe to <strong><a href=\"https://www.aidevsignals.com/\" target=\"_blank\" rel=\"noreferrer noopener\">our Newsletter</a></strong>.</p>\n<p>The post <a href=\"https://www.marktechpost.com/2025/08/03/tutorial-exploring-shap-iq-visualizations/\">Tutorial: Exploring SHAP-IQ Visualizations</a> appeared first on <a href=\"https://www.marktechpost.com\">MarkTechPost</a>.</p>\n",
          "content:encodedSnippet": "In this tutorial, we’ll explore a range of SHAP-IQ visualizations that provide insights into how a machine learning model arrives at its predictions. These visuals help break down complex model behavior into interpretable components—revealing both the individual and interactive contributions of features to a specific prediction. Check out the Full Codes here.\nInstalling the dependencies\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\n!pip install shapiq overrides scikit-learn pandas numpy seaborn\n\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.model_selection import train_test_split\nfrom tqdm.asyncio import tqdm\n\nimport shapiq\n\nprint(f\"shapiq version: {shapiq.__version__}\")\n\nImporting the dataset\nIn this tutorial, we’ll use the MPG (Miles Per Gallon) dataset, which we’ll load directly from the Seaborn library. This dataset contains information about various car models, including features like horsepower, weight, and origin. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\nimport seaborn as sns\ndf = sns.load_dataset(\"mpg\")\ndf\n\nProcessing the dataset\nWe use Label Encoding to convert the categorical column(s) into numeric format, making them suitable for model training.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\n# Drop rows with missing values\ndf = df.dropna()\n\n# Encoding the origin column\nle = LabelEncoder()\ndf.loc[:, \"origin\"] = le.fit_transform(df[\"origin\"])\ndf['origin'].unique()\n\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\nfor i, label in enumerate(le.classes_):\n    print(f\"{label} → {i}\")\n\nSplitting the data into training & test subsets\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\n# Select features and target\nX = df.drop(columns=[\"mpg\", \"name\"])\ny = df[\"mpg\"]\n\nfeature_names = X.columns.tolist()\nx_data, y_data = X.values, y.values\n\n# Train-test split\nx_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)\n\nModel Training\nWe train a Random Forest Regressor with a maximum depth of 10 and 10 decision trees (n_estimators=10). A fixed random_state ensures reproducibility.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\n# Train model\nmodel = RandomForestRegressor(random_state=42, max_depth=10, n_estimators=10)\nmodel.fit(x_train, y_train)\n\nModel Evaluation\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\n# Evaluate\nmse = mean_squared_error(y_test, model.predict(x_test))\nr2 = r2_score(y_test, model.predict(x_test))\nprint(f\"Mean Squared Error: {mse:.2f}\")\nprint(f\"R2 Score: {r2:.2f}\")\n\nExplaining a Local Instance\nWe choose a specific test instance (with instance_id = 7) to explore how the model arrived at its prediction. We’ll print the true value, predicted value, and the feature values for this instance. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\n# select a local instance to be explained\ninstance_id = 7\nx_explain = x_test[instance_id]\ny_true = y_test[instance_id]\ny_pred = model.predict(x_explain.reshape(1, -1))[0]\nprint(f\"Instance {instance_id}, True Value: {y_true}, Predicted Value: {y_pred}\")\nfor i, feature in enumerate(feature_names):\n    print(f\"{feature}: {x_explain[i]}\")\n\nGenerating Explanations for Multiple Interaction Orders\nWe generate Shapley-based explanations for different interaction orders using the shapiq package. Specifically, we compute:\nOrder 1 (Standard Shapley Values): Individual feature contributions\nOrder 2 (Pairwise Interactions): Combined effects of feature pairs\nOrder N (Full Interaction): All interactions up to the total number of features\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\n# create explanations for different orders\nfeature_names = list(X.columns)  # get the feature names\nn_features = len(feature_names)\n\nsi_order: dict[int, shapiq.InteractionValues] = {}\nfor order in tqdm([1, 2, n_features]):\n    index = \"k-SII\" if order > 1 else \"SV\"  # will also be set automatically by the explainer\n    explainer = shapiq.TreeExplainer(model=model, max_order=order, index=index)\n    si_order[order] = explainer.explain(x=x_explain)\nsi_order\n\n1. Force Chart\nThe force plot is a powerful visualization tool that helps us understand how a machine learning model arrived at a specific prediction. It displays the baseline prediction (i.e., the expected value of the model before seeing any features), and then shows how each feature “pushes” the prediction higher or lower.\nIn this plot:\nRed bars represent features or interactions that increase the prediction.\nBlue bars represent those that decrease it.\nThe length of each bar corresponds to the magnitude of its effect.\nWhen using Shapley interaction values, the force plot can visualize not just individual contributions but also interactions between features. This makes it especially insightful when interpreting complex models, as it visually decomposes how combinations of features work together to influence the outcome. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\nsv = si_order[1]  # get the SV\nsi = si_order[2]  # get the 2-SII\nmi = si_order[n_features]  # get the Moebius transform\n\nsv.plot_force(feature_names=feature_names, show=True)\nsi.plot_force(feature_names=feature_names, show=True)\nmi.plot_force(feature_names=feature_names, show=True)\n\n\n\n\n\nFrom the first plot, we can see that the base value is 23.5. Features like Weight, Cylinders, Horsepower, and Displacement have a positive influence on the prediction, pushing it above the baseline. On the other hand, Model Year and Acceleration have a negative impact, pulling the prediction downward.\n2. Waterfall Chart\nSimilar to the force plot, the waterfall plot is another popular way to visualize Shapley values, originally introduced with the shap library. It shows how different features push the prediction higher or lower compared to the baseline. One key advantage of the waterfall plot is that it automatically groups features with very small impacts into an “other” category, making the chart cleaner and easier to understand. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\nsv.plot_waterfall(feature_names=feature_names, show=True)\nsi.plot_waterfall(feature_names=feature_names, show=True)\nmi.plot_waterfall(feature_names=feature_names, show=True)\n\n\n\n\n\n\n\n\n\n\n\n\n\n3. Network Plot\nThe network plot shows how features interact with each other using first- and second-order Shapley interactions. Node size reflects individual feature impact, while edge width and color show interaction strength and direction. It’s especially helpful when dealing with many features, revealing complex interactions that simpler plots might miss. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\nsi.plot_network(feature_names=feature_names, show=True)\nmi.plot_network(feature_names=feature_names, show=True)\n\n\n\n\n\n4. SI Graph Plot\nThe SI graph plot extends the network plot by visualizing all higher-order interactions as hyper-edges connecting multiple features. Node size shows individual feature impact, while edge width, color, and transparency reflect the strength and direction of interactions. It provides a comprehensive view of how features jointly influence the model’s prediction. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\n# we abbreviate the feature names since, they are plotted inside the nodes\nabbrev_feature_names = shapiq.plot.utils.abbreviate_feature_names(feature_names)\nsv.plot_si_graph(\n    feature_names=abbrev_feature_names,\n    show=True,\n    size_factor=2.5,\n    node_size_scaling=1.5,\n    plot_original_nodes=True,\n)\nsi.plot_si_graph(\n    feature_names=abbrev_feature_names,\n    show=True,\n    size_factor=2.5,\n    node_size_scaling=1.5,\n    plot_original_nodes=True,\n)\nmi.plot_si_graph(\n    feature_names=abbrev_feature_names,\n    show=True,\n    size_factor=2.5,\n    node_size_scaling=1.5,\n    plot_original_nodes=True,\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n5. Bar Plot\nThe bar plot is tailored for global explanations. While other plots can be used both locally and globally, the bar plot summarizes the overall importance of features (or feature interactions) by showing the mean absolute Shapley (or interaction) values across all instances. In shapiq, it highlights which feature interactions contribute most on average. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\nexplanations = []\nexplainer = shapiq.TreeExplainer(model=model, max_order=2, index=\"k-SII\")\nfor instance_id in tqdm(range(20)):\n    x_explain = x_test[instance_id]\n    si = explainer.explain(x=x_explain)\n    explanations.append(si)\nshapiq.plot.bar_plot(explanations, feature_names=feature_names, show=True)\n\n\n\n\n\n“Distance” and “Horsepower” are the most influential features overall, meaning they have the strongest individual impact on the model’s predictions. This is evident from their high mean absolute Shapley interaction values in the bar plot.\nAdditionally, when looking at second-order interactions (i.e., how two features interact together), the combinations “Horsepower × Weight” and “Distance × Horsepower” show significant joint influence. Their combined attribution is around 1.4, indicating that these interactions play an important role in shaping the model’s predictions beyond what each feature contributes individually. This highlights the presence of non-linear relationships between features in the model.\nCheck out the Full Codes here. Feel free to check out our GitHub Page for Tutorials, Codes and Notebooks. Also, feel free to follow us on Twitter and don’t forget to join our 100k+ ML SubReddit and Subscribe to our Newsletter.\nThe post Tutorial: Exploring SHAP-IQ Visualizations appeared first on MarkTechPost.",
          "dc:creator": "Arham Islam",
          "comments": "https://www.marktechpost.com/2025/08/03/tutorial-exploring-shap-iq-visualizations/#respond",
          "content": "<p>In this tutorial, we’ll explore a range of SHAP-IQ visualizations that provide insights into how a machine learning model arrives at its predictions. These visuals help break down complex model behavior into interpretable components—revealing both the individual and interactive contributions of features to a specific prediction. Check out the Full Codes here. Installing the dependencies Importing [&#8230;]</p>\n<p>The post <a href=\"https://www.marktechpost.com/2025/08/03/tutorial-exploring-shap-iq-visualizations/\">Tutorial: Exploring SHAP-IQ Visualizations</a> appeared first on <a href=\"https://www.marktechpost.com\">MarkTechPost</a>.</p>\n",
          "contentSnippet": "In this tutorial, we’ll explore a range of SHAP-IQ visualizations that provide insights into how a machine learning model arrives at its predictions. These visuals help break down complex model behavior into interpretable components—revealing both the individual and interactive contributions of features to a specific prediction. Check out the Full Codes here. Installing the dependencies Importing […]\nThe post Tutorial: Exploring SHAP-IQ Visualizations appeared first on MarkTechPost.",
          "guid": "https://www.marktechpost.com/?p=73187",
          "categories": [
            "Artificial Intelligence",
            "Editors Pick",
            "Machine Learning",
            "Staff",
            "Technology",
            "Tutorials"
          ],
          "isoDate": "2025-08-04T04:45:10.000Z"
        }
      },
      {
        "json": {
          "creator": "Michal Sutter",
          "title": "A Technical Roadmap to Context Engineering in LLMs: Mechanisms, Benchmarks, and Open Challenges",
          "link": "https://www.marktechpost.com/2025/08/03/a-technical-roadmap-to-context-engineering-in-llms-mechanisms-benchmarks-and-open-challenges/",
          "pubDate": "Sun, 03 Aug 2025 21:32:05 +0000",
          "content:encoded": "\n<p class=\"wp-block-yoast-seo-estimated-reading-time yoast-reading-time__wrapper\"><span class=\"yoast-reading-time__icon\"><svg aria-hidden=\"true\" focusable=\"false\" data-icon=\"clock\" width=\"20\" height=\"20\" fill=\"none\" stroke=\"currentColor\" style=\"display:inline-block;vertical-align:-0.1em\" role=\"img\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\"><path stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" d=\"M12 8v4l3 3m6-3a9 9 0 11-18 0 9 9 0 0118 0z\"></path></svg></span><span class=\"yoast-reading-time__spacer\" style=\"display:inline-block;width:1em\"></span><span class=\"yoast-reading-time__descriptive-text\">Estimated reading time: </span><span class=\"yoast-reading-time__reading-time\">4</span><span class=\"yoast-reading-time__time-unit\"> minutes</span></p>\n\n\n\n<div class=\"wp-block-yoast-seo-table-of-contents yoast-table-of-contents\"><h3><strong>Table of contents</strong></h3><ul><li><a href=\"#what-is-context-engineering\" data-level=\"3\">What Is Context Engineering?</a></li><li><a href=\"#taxonomy-of-context-engineering\" data-level=\"3\">Taxonomy of Context Engineering</a></li><li><a href=\"#key-insights-and-research-gaps\" data-level=\"3\">Key Insights and Research Gaps</a></li><li><a href=\"#applications-and-impact\" data-level=\"3\">Applications and Impact</a></li><li><a href=\"#future-directions\" data-level=\"3\">Future Directions</a></li></ul></div>\n\n\n\n<p>The paper “<strong><a href=\"https://arxiv.org/abs/2507.13334\" target=\"_blank\" rel=\"noreferrer noopener\">A Survey of Context Engineering for Large Language Models</a></strong>” establishes <strong>Context Engineering</strong> as a formal discipline that goes far beyond prompt engineering, providing a unified, systematic framework for designing, optimizing, and managing the information that guides Large Language Models (LLMs). Here’s an overview of its main contributions and framework:</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"what-is-context-engineering\"><strong>What Is Context Engineering?</strong></h3>\n\n\n\n<p><strong>Context Engineering</strong> is defined as the science and engineering of organizing, assembling, and optimizing all forms of context fed into LLMs to maximize performance across comprehension, reasoning, adaptability, and real-world application. Rather than viewing context as a static string (the premise of prompt engineering), context engineering treats it as a dynamic, structured assembly of components—each sourced, selected, and organized through explicit functions, often under tight resource and architectural constraints.</p>\n\n\n\n<figure class=\"wp-block-image size-large is-resized\"><img fetchpriority=\"high\" decoding=\"async\" width=\"1024\" height=\"324\" data-attachment-id=\"73184\" data-permalink=\"https://www.marktechpost.com/2025/08/03/a-technical-roadmap-to-context-engineering-in-llms-mechanisms-benchmarks-and-open-challenges/screenshot-2025-08-03-at-2-11-29-pm/\" data-orig-file=\"https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-03-at-2.11.29-PM.png\" data-orig-size=\"1384,438\" data-comments-opened=\"1\" data-image-meta=\"{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}\" data-image-title=\"Screenshot 2025-08-03 at 2.11.29 PM\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-03-at-2.11.29-PM-300x95.png\" data-large-file=\"https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-03-at-2.11.29-PM-1024x324.png\" src=\"https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-03-at-2.11.29-PM-1024x324.png\" alt=\"\" class=\"wp-image-73184\" style=\"width:732px;height:auto\" srcset=\"https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-03-at-2.11.29-PM-1024x324.png 1024w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-03-at-2.11.29-PM-300x95.png 300w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-03-at-2.11.29-PM-768x243.png 768w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-03-at-2.11.29-PM-1327x420.png 1327w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-03-at-2.11.29-PM-150x47.png 150w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-03-at-2.11.29-PM-696x220.png 696w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-03-at-2.11.29-PM-1068x338.png 1068w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-03-at-2.11.29-PM.png 1384w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" /></figure>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"taxonomy-of-context-engineering\"><strong>Taxonomy of Context Engineering</strong></h3>\n\n\n\n<p>The paper breaks down context engineering into:</p>\n\n\n\n<h4 class=\"wp-block-heading\"><strong>1. Foundational Components</strong></h4>\n\n\n\n<p><strong>a. Context Retrieval and Generation</strong></p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Encompasses prompt engineering, in-context learning (zero/few-shot, chain-of-thought, tree-of-thought, graph-of-thought), external knowledge retrieval (e.g., Retrieval-Augmented Generation, knowledge graphs), and dynamic assembly of context elements1.</li>\n\n\n\n<li>Techniques like CLEAR Framework, dynamic template assembly, and modular retrieval architectures are highlighted.</li>\n</ul>\n\n\n\n<p><strong>b. Context Processing</strong></p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Addresses long-sequence processing (with architectures like Mamba, LongNet, FlashAttention), context self-refinement (iterative feedback, self-evaluation), and integration of multimodal and structured information (vision, audio, graphs, tables).</li>\n\n\n\n<li>Strategies include attention sparsity, memory compression, and in-context learning meta-optimization.</li>\n</ul>\n\n\n\n<p><strong>c. Context Management</strong></p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Involves memory hierarchies and storage architectures (short-term context windows, long-term memory, external databases), memory paging, context compression (autoencoders, recurrent compression), and scalable management over multi-turn or multi-agent settings.</li>\n</ul>\n\n\n\n<h4 class=\"wp-block-heading\"><strong>2. System Implementations</strong></h4>\n\n\n\n<p><strong>a. Retrieval-Augmented Generation (RAG)</strong></p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Modular, agentic, and graph-enhanced RAG architectures integrate external knowledge and support dynamic, sometimes multi-agent retrieval pipelines.</li>\n\n\n\n<li>Enables both real-time knowledge updates and complex reasoning over structured databases/graphs.</li>\n</ul>\n\n\n\n<p><strong>b. Memory Systems</strong></p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Implement persistent and hierarchical storage, enabling longitudinal learning and knowledge recall for agents (e.g., MemGPT, MemoryBank, external vector databases).</li>\n\n\n\n<li>Key for extended, multi-turn dialogs, personalized assistants, and simulation agents.</li>\n</ul>\n\n\n\n<p><strong>c. Tool-Integrated Reasoning</strong></p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>LLMs use external tools (APIs, search engines, code execution) via function calling or environment interaction, combining language reasoning with world-acting abilities.</li>\n\n\n\n<li>Enables new domains (math, programming, web interaction, scientific research).</li>\n</ul>\n\n\n\n<p><strong>d. Multi-Agent Systems</strong></p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Coordination among multiple LLMs (agents) via standardized protocols, orchestrators, and context sharing—essential for complex, collaborative problem-solving and distributed AI applications.</li>\n</ul>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"key-insights-and-research-gaps\"><strong>Key Insights and Research Gaps</strong></h3>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Comprehension–Generation Asymmetry</strong>: LLMs, with advanced context engineering, can comprehend very sophisticated, multi-faceted contexts but still struggle to generate outputs matching that complexity or length.</li>\n\n\n\n<li><strong>Integration and Modularity</strong>: Best performance comes from modular architectures combining multiple techniques (retrieval, memory, tool use).</li>\n\n\n\n<li><strong>Evaluation Limitations</strong>: Current evaluation metrics/benchmarks (like BLEU, ROUGE) often fail to capture the compositional, multi-step, and collaborative behaviors enabled by advanced context engineering. New benchmarks and dynamic, holistic evaluation paradigms are needed.</li>\n\n\n\n<li><strong>Open Research Questions</strong>: Theoretical foundations, efficient scaling (especially computationally), cross-modal and structured context integration, real-world deployment, safety, alignment, and ethical concerns remain open research challenges.</li>\n</ul>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"applications-and-impact\"><strong>Applications and Impact</strong></h3>\n\n\n\n<p>Context engineering supports robust, domain-adaptive AI across:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Long-document/question answering</strong></li>\n\n\n\n<li><strong>Personalized digital assistants and memory-augmented agents</strong></li>\n\n\n\n<li><strong>Scientific, medical, and technical problem-solving</strong></li>\n\n\n\n<li><strong>Multi-agent collaboration in business, education, and research</strong></li>\n</ul>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"future-directions\"><strong>Future Directions</strong></h3>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Unified Theory</strong>: Developing mathematical and information-theoretic frameworks.</li>\n\n\n\n<li><strong>Scaling &amp; Efficiency</strong>: Innovations in attention mechanisms and memory management.</li>\n\n\n\n<li><strong>Multi-Modal Integration</strong>: Seamless coordination of text, vision, audio, and structured data.</li>\n\n\n\n<li><strong>Robust, Safe, and Ethical Deployment</strong>: Ensuring reliability, transparency, and fairness in real-world systems.</li>\n</ul>\n\n\n\n<p><strong>In summary:</strong> Context Engineering is emerging as the pivotal discipline for guiding the next generation of LLM-based intelligent systems, shifting the focus from creative prompt writing to the rigorous science of information optimization, system design, and context-driven AI.</p>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity\"/>\n\n\n\n<p>Check out the <strong><a href=\"https://arxiv.org/abs/2507.13334\" target=\"_blank\" rel=\"noreferrer noopener\">Paper</a><em>.</em></strong> Feel free to check out our <strong><mark><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included\" target=\"_blank\" rel=\"noreferrer noopener\">GitHub Page for Tutorials, Codes and Notebooks</a></mark></strong>. Also, feel free to follow us on <strong><a href=\"https://x.com/intent/follow?screen_name=marktechpost\" target=\"_blank\" rel=\"noreferrer noopener\"><mark>Twitter</mark></a></strong> and don’t forget to join our <strong><a href=\"https://www.reddit.com/r/machinelearningnews/\" target=\"_blank\" rel=\"noreferrer noopener\">100k+ ML SubReddit</a></strong> and Subscribe to <strong><a href=\"https://www.aidevsignals.com/\" target=\"_blank\" rel=\"noreferrer noopener\">our Newsletter</a></strong>.</p>\n<p>The post <a href=\"https://www.marktechpost.com/2025/08/03/a-technical-roadmap-to-context-engineering-in-llms-mechanisms-benchmarks-and-open-challenges/\">A Technical Roadmap to Context Engineering in LLMs: Mechanisms, Benchmarks, and Open Challenges</a> appeared first on <a href=\"https://www.marktechpost.com\">MarkTechPost</a>.</p>\n",
          "content:encodedSnippet": "Estimated reading time: 4 minutes\nTable of contents\n\nWhat Is Context Engineering?\nTaxonomy of Context Engineering\nKey Insights and Research Gaps\nApplications and Impact\nFuture Directions\n\nThe paper “A Survey of Context Engineering for Large Language Models” establishes Context Engineering as a formal discipline that goes far beyond prompt engineering, providing a unified, systematic framework for designing, optimizing, and managing the information that guides Large Language Models (LLMs). Here’s an overview of its main contributions and framework:\nWhat Is Context Engineering?\nContext Engineering is defined as the science and engineering of organizing, assembling, and optimizing all forms of context fed into LLMs to maximize performance across comprehension, reasoning, adaptability, and real-world application. Rather than viewing context as a static string (the premise of prompt engineering), context engineering treats it as a dynamic, structured assembly of components—each sourced, selected, and organized through explicit functions, often under tight resource and architectural constraints.\n\n\n\n\nTaxonomy of Context Engineering\nThe paper breaks down context engineering into:\n1. Foundational Components\na. Context Retrieval and Generation\nEncompasses prompt engineering, in-context learning (zero/few-shot, chain-of-thought, tree-of-thought, graph-of-thought), external knowledge retrieval (e.g., Retrieval-Augmented Generation, knowledge graphs), and dynamic assembly of context elements1.\nTechniques like CLEAR Framework, dynamic template assembly, and modular retrieval architectures are highlighted.\nb. Context Processing\nAddresses long-sequence processing (with architectures like Mamba, LongNet, FlashAttention), context self-refinement (iterative feedback, self-evaluation), and integration of multimodal and structured information (vision, audio, graphs, tables).\nStrategies include attention sparsity, memory compression, and in-context learning meta-optimization.\nc. Context Management\nInvolves memory hierarchies and storage architectures (short-term context windows, long-term memory, external databases), memory paging, context compression (autoencoders, recurrent compression), and scalable management over multi-turn or multi-agent settings.\n2. System Implementations\na. Retrieval-Augmented Generation (RAG)\nModular, agentic, and graph-enhanced RAG architectures integrate external knowledge and support dynamic, sometimes multi-agent retrieval pipelines.\nEnables both real-time knowledge updates and complex reasoning over structured databases/graphs.\nb. Memory Systems\nImplement persistent and hierarchical storage, enabling longitudinal learning and knowledge recall for agents (e.g., MemGPT, MemoryBank, external vector databases).\nKey for extended, multi-turn dialogs, personalized assistants, and simulation agents.\nc. Tool-Integrated Reasoning\nLLMs use external tools (APIs, search engines, code execution) via function calling or environment interaction, combining language reasoning with world-acting abilities.\nEnables new domains (math, programming, web interaction, scientific research).\nd. Multi-Agent Systems\nCoordination among multiple LLMs (agents) via standardized protocols, orchestrators, and context sharing—essential for complex, collaborative problem-solving and distributed AI applications.\nKey Insights and Research Gaps\nComprehension–Generation Asymmetry: LLMs, with advanced context engineering, can comprehend very sophisticated, multi-faceted contexts but still struggle to generate outputs matching that complexity or length.\nIntegration and Modularity: Best performance comes from modular architectures combining multiple techniques (retrieval, memory, tool use).\nEvaluation Limitations: Current evaluation metrics/benchmarks (like BLEU, ROUGE) often fail to capture the compositional, multi-step, and collaborative behaviors enabled by advanced context engineering. New benchmarks and dynamic, holistic evaluation paradigms are needed.\nOpen Research Questions: Theoretical foundations, efficient scaling (especially computationally), cross-modal and structured context integration, real-world deployment, safety, alignment, and ethical concerns remain open research challenges.\nApplications and Impact\nContext engineering supports robust, domain-adaptive AI across:\nLong-document/question answering\nPersonalized digital assistants and memory-augmented agents\nScientific, medical, and technical problem-solving\nMulti-agent collaboration in business, education, and research\nFuture Directions\nUnified Theory: Developing mathematical and information-theoretic frameworks.\nScaling & Efficiency: Innovations in attention mechanisms and memory management.\nMulti-Modal Integration: Seamless coordination of text, vision, audio, and structured data.\nRobust, Safe, and Ethical Deployment: Ensuring reliability, transparency, and fairness in real-world systems.\nIn summary: Context Engineering is emerging as the pivotal discipline for guiding the next generation of LLM-based intelligent systems, shifting the focus from creative prompt writing to the rigorous science of information optimization, system design, and context-driven AI.\nCheck out the Paper. Feel free to check out our GitHub Page for Tutorials, Codes and Notebooks. Also, feel free to follow us on Twitter and don’t forget to join our 100k+ ML SubReddit and Subscribe to our Newsletter.\nThe post A Technical Roadmap to Context Engineering in LLMs: Mechanisms, Benchmarks, and Open Challenges appeared first on MarkTechPost.",
          "dc:creator": "Michal Sutter",
          "comments": "https://www.marktechpost.com/2025/08/03/a-technical-roadmap-to-context-engineering-in-llms-mechanisms-benchmarks-and-open-challenges/#respond",
          "content": "<p>The paper “A Survey of Context Engineering for Large Language Models” establishes Context Engineering as a formal discipline that goes far beyond prompt engineering, providing a unified, systematic framework for designing, optimizing, and managing the information that guides Large Language Models (LLMs). Here’s an overview of its main contributions and framework: What Is Context Engineering? [&#8230;]</p>\n<p>The post <a href=\"https://www.marktechpost.com/2025/08/03/a-technical-roadmap-to-context-engineering-in-llms-mechanisms-benchmarks-and-open-challenges/\">A Technical Roadmap to Context Engineering in LLMs: Mechanisms, Benchmarks, and Open Challenges</a> appeared first on <a href=\"https://www.marktechpost.com\">MarkTechPost</a>.</p>\n",
          "contentSnippet": "The paper “A Survey of Context Engineering for Large Language Models” establishes Context Engineering as a formal discipline that goes far beyond prompt engineering, providing a unified, systematic framework for designing, optimizing, and managing the information that guides Large Language Models (LLMs). Here’s an overview of its main contributions and framework: What Is Context Engineering? […]\nThe post A Technical Roadmap to Context Engineering in LLMs: Mechanisms, Benchmarks, and Open Challenges appeared first on MarkTechPost.",
          "guid": "https://www.marktechpost.com/?p=73182",
          "categories": [
            "Context Engineering",
            "Editors Pick",
            "Staff",
            "Uncategorized"
          ],
          "isoDate": "2025-08-03T21:32:05.000Z"
        }
      },
      {
        "json": {
          "creator": "Michal Sutter",
          "title": "The Ultimate Guide to CPUs, GPUs, NPUs, and TPUs for AI/ML: Performance, Use Cases, and Key Differences",
          "link": "https://www.marktechpost.com/2025/08/03/the-ultimate-guide-to-cpus-gpus-npus-and-tpus-for-ai-ml-performance-use-cases-and-key-differences/",
          "pubDate": "Sun, 03 Aug 2025 10:38:52 +0000",
          "content:encoded": "\n<p>Artificial intelligence and machine learning workloads have fueled the evolution of specialized hardware to accelerate computation far beyond what traditional CPUs can offer. Each processing unit—CPU, GPU, NPU, TPU—plays a distinct role in the AI ecosystem, optimized for certain models, applications, or environments. Here’s a technical, data-driven breakdown of their core differences and best use cases.</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-cpu-central-processing-unit-the-versatile-workhorse\"><strong>CPU (Central Processing Unit): The Versatile Workhorse</strong></h3>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Design &amp; Strengths:</strong> CPUs are general-purpose processors with a few powerful cores—ideal for single-threaded tasks and running diverse software, including operating systems, databases, and light AI/ML inference.</li>\n\n\n\n<li><strong>AI/ML Role:</strong> CPUs can execute any kind of AI model, but lack the massive parallelism needed for efficient deep learning training or inference at scale.</li>\n\n\n\n<li><strong>Best for:</strong>\n<ul class=\"wp-block-list\">\n<li>Classical <a href=\"https://www.marktechpost.com/2025/01/14/what-is-machine-learning-ml/\" target=\"_blank\">ML</a> algorithms (e.g., scikit-learn, XGBoost)</li>\n\n\n\n<li>Prototyping and model development</li>\n\n\n\n<li>Inference for small models or low-throughput requirements</li>\n</ul>\n</li>\n</ul>\n\n\n\n<p><strong>Technical Note:</strong> For neural network operations, CPU throughput (typically measured in GFLOPS—billion floating point operations per second) lags far behind specialized accelerators.</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-gpu-graphics-processing-unit-the-deep-learning-backbone\"><strong>GPU (Graphics Processing Unit): The Deep Learning Backbone</strong></h3>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Design &amp; Strengths:</strong> Originally for graphics, modern GPUs feature thousands of parallel cores designed for matrix/multiple vector operations, making them highly efficient for training and inference of deep neural networks.</li>\n\n\n\n<li><strong>Performance Examples:</strong>\n<ul class=\"wp-block-list\">\n<li>NVIDIA RTX 3090: 10,496 CUDA cores, up to 35.6 TFLOPS (teraFLOPS) FP32 compute.</li>\n\n\n\n<li>Recent NVIDIA GPUs include “Tensor Cores” for mixed precision, accelerating <a href=\"https://www.marktechpost.com/2025/01/15/what-is-deep-learning-2/\" target=\"_blank\">deep learning</a> operations.</li>\n</ul>\n</li>\n\n\n\n<li><strong>Best for:</strong>\n<ul class=\"wp-block-list\">\n<li>Training and inferencing large-scale deep learning models (CNNs, RNNs, Transformers)</li>\n\n\n\n<li>Batch processing typical in datacenter and research environments</li>\n\n\n\n<li>Supported by all major AI frameworks (TensorFlow, PyTorch)</li>\n</ul>\n</li>\n</ul>\n\n\n\n<p><strong>Benchmarks:</strong> A 4x RTX A5000 setup can surpass a single, far more expensive NVIDIA H100 in certain workloads, balancing acquisition cost and performance.</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-npu-neural-processing-unit-the-on-device-ai-specialist\"><strong>NPU (Neural Processing Unit): The On-device AI Specialist</strong></h3>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Design &amp; Strengths:</strong> NPUs are ASICs (application-specific chips) crafted exclusively for neural network operations. They optimize parallel, low-precision computation for deep learning inference, often running at low power for edge and embedded devices.</li>\n\n\n\n<li><strong>Use Cases &amp; Applications:</strong>\n<ul class=\"wp-block-list\">\n<li><strong>Mobile &amp; Consumer</strong>: Powering features like face unlock, real-time image processing, language translation on devices like the Apple A-series, Samsung Exynos, Google Tensor chips.</li>\n\n\n\n<li><strong>Edge &amp; IoT</strong>: Low-latency vision and speech recognition, smart city cameras, AR/VR, and manufacturing sensors.</li>\n\n\n\n<li><strong>Automotive</strong>: Real-time data from sensors for autonomous driving and advanced driver assistance.</li>\n</ul>\n</li>\n\n\n\n<li><strong>Performance Example:</strong> The Exynos 9820’s NPU is ~7x faster than its predecessor for AI tasks.</li>\n</ul>\n\n\n\n<p><strong>Efficiency:</strong> NPUs prioritize energy efficiency over raw throughput, extending battery life while supporting advanced AI features locally.</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-tpu-tensor-processing-unit-google-s-ai-powerhouse\"><strong>TPU (Tensor Processing Unit): Google’s AI Powerhouse</strong></h3>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Design &amp; Strengths:</strong> TPUs are custom chips developed by Google specifically for large tensor computations, tuning hardware around the needs of frameworks like TensorFlow.</li>\n\n\n\n<li><strong>Key Specifications:</strong>\n<ul class=\"wp-block-list\">\n<li>TPU v2: Up to 180 TFLOPS for neural network training and inference.</li>\n\n\n\n<li>TPU v4: Available in Google Cloud, up to 275 TFLOPS per chip, scalable to “pods” exceeding 100 petaFLOPS.</li>\n\n\n\n<li>Specialized matrix multiplication units (“MXU”) for enormous batch computations.</li>\n\n\n\n<li>Up to 30–80x better energy efficiency (TOPS/Watt) for inference compared to contemporary GPUs and CPUs.</li>\n</ul>\n</li>\n\n\n\n<li><strong>Best for:</strong>\n<ul class=\"wp-block-list\">\n<li>Training and serving massive models (BERT, GPT-2, EfficientNet) in cloud at scale</li>\n\n\n\n<li>High-throughput, low-latency AI for research and production pipelines</li>\n\n\n\n<li>Tight integration with TensorFlow and JAX; increasingly interfacing with PyTorch</li>\n</ul>\n</li>\n</ul>\n\n\n\n<p><strong>Note:</strong> TPU architecture is less flexible than GPU—optimized for AI, not graphics or general-purpose tasks.</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-which-models-run-where\"><strong>Which Models Run Where?</strong></h3>\n\n\n\n<figure class=\"wp-block-table\"><table class=\"has-fixed-layout\"><thead><tr><th>Hardware</th><th>Best Supported Models</th><th>Typical Workloads</th></tr></thead><tbody><tr><td>CPU</td><td>Classical ML, all deep learning models*</td><td>General software, prototyping, small AI</td></tr><tr><td>GPU</td><td>CNNs, RNNs, Transformers</td><td>Training and inference (cloud/workstation)</td></tr><tr><td>NPU</td><td>MobileNet, TinyBERT, custom edge models</td><td>On-device AI, real-time vision/speech</td></tr><tr><td>TPU</td><td>BERT/GPT-2/ResNet/EfficientNet, etc.</td><td>Large-scale model training/inference</td></tr></tbody></table></figure>\n\n\n\n<p>*CPUs support any model, but are not efficient for large-scale DNNs.</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-data-processing-units-dpus-the-data-movers\"><strong>Data Processing Units (DPUs): The Data Movers</strong></h3>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Role:</strong> DPUs accelerate networking, storage, and data movement, offloading these tasks from CPUs/GPUs. They enable higher infrastructure efficiency in AI datacenters by ensuring compute resources focus on model execution, not I/O or data orchestration.</li>\n</ul>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-summary-table-technical-comparison\"><strong>Summary Table: Technical Comparison</strong></h3>\n\n\n\n<figure class=\"wp-block-table\"><table class=\"has-fixed-layout\"><thead><tr><th>Feature</th><th>CPU</th><th>GPU</th><th>NPU</th><th>TPU</th></tr></thead><tbody><tr><td>Use Case</td><td>General Compute</td><td>Deep Learning</td><td>Edge/On-device AI</td><td>Google Cloud AI</td></tr><tr><td>Parallelism</td><td>Low–Moderate</td><td>Very High (~10,000+)</td><td>Moderate–High</td><td>Extremely High (Matrix Mult.)</td></tr><tr><td>Efficiency</td><td>Moderate</td><td>Power-hungry</td><td>Ultra-efficient</td><td>High for large models</td></tr><tr><td>Flexibility</td><td>Maximum</td><td>Very high (all FW)</td><td>Specialized</td><td>Specialized (TensorFlow/JAX)</td></tr><tr><td>Hardware</td><td>x86, ARM, etc.</td><td>NVIDIA, AMD</td><td>Apple, Samsung, ARM</td><td>Google (Cloud only)</td></tr><tr><td>Example</td><td>Intel Xeon</td><td>RTX 3090, A100, H100</td><td>Apple Neural Engine</td><td>TPU v4, Edge TPU</td></tr></tbody></table></figure>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-key-takeaways\"><strong>Key Takeaways</strong></h3>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>CPUs</strong> are unmatched for general-purpose, flexible workloads.</li>\n\n\n\n<li><strong>GPUs</strong> remain the workhorse for training and running neural networks across all frameworks and environments, especially outside Google Cloud.</li>\n\n\n\n<li><strong>NPUs</strong> dominate real-time, privacy-preserving, and power-efficient AI for mobile and edge, unlocking local intelligence everywhere from your phone to self-driving cars.</li>\n\n\n\n<li><strong>TPUs</strong> offer unmatched scale and speed for massive models—especially in Google’s ecosystem—pushing the frontiers of AI research and industrial deployment.</li>\n</ul>\n\n\n\n<p><strong>Choosing the right hardware depends on model size, compute demands, development environment, and desired deployment (cloud vs. edge/mobile). A robust AI stack often leverages a mix of these processors, each where it excels.</strong></p>\n<p>The post <a href=\"https://www.marktechpost.com/2025/08/03/the-ultimate-guide-to-cpus-gpus-npus-and-tpus-for-ai-ml-performance-use-cases-and-key-differences/\">The Ultimate Guide to CPUs, GPUs, NPUs, and TPUs for AI/ML: Performance, Use Cases, and Key Differences</a> appeared first on <a href=\"https://www.marktechpost.com\">MarkTechPost</a>.</p>\n",
          "content:encodedSnippet": "Artificial intelligence and machine learning workloads have fueled the evolution of specialized hardware to accelerate computation far beyond what traditional CPUs can offer. Each processing unit—CPU, GPU, NPU, TPU—plays a distinct role in the AI ecosystem, optimized for certain models, applications, or environments. Here’s a technical, data-driven breakdown of their core differences and best use cases.\nCPU (Central Processing Unit): The Versatile Workhorse\nDesign & Strengths: CPUs are general-purpose processors with a few powerful cores—ideal for single-threaded tasks and running diverse software, including operating systems, databases, and light AI/ML inference.\nAI/ML Role: CPUs can execute any kind of AI model, but lack the massive parallelism needed for efficient deep learning training or inference at scale.\nBest for:\n\nClassical ML algorithms (e.g., scikit-learn, XGBoost)\nPrototyping and model development\nInference for small models or low-throughput requirements\nTechnical Note: For neural network operations, CPU throughput (typically measured in GFLOPS—billion floating point operations per second) lags far behind specialized accelerators.\nGPU (Graphics Processing Unit): The Deep Learning Backbone\nDesign & Strengths: Originally for graphics, modern GPUs feature thousands of parallel cores designed for matrix/multiple vector operations, making them highly efficient for training and inference of deep neural networks.\nPerformance Examples:\n\nNVIDIA RTX 3090: 10,496 CUDA cores, up to 35.6 TFLOPS (teraFLOPS) FP32 compute.\nRecent NVIDIA GPUs include “Tensor Cores” for mixed precision, accelerating deep learning operations.\nBest for:\n\nTraining and inferencing large-scale deep learning models (CNNs, RNNs, Transformers)\nBatch processing typical in datacenter and research environments\nSupported by all major AI frameworks (TensorFlow, PyTorch)\nBenchmarks: A 4x RTX A5000 setup can surpass a single, far more expensive NVIDIA H100 in certain workloads, balancing acquisition cost and performance.\nNPU (Neural Processing Unit): The On-device AI Specialist\nDesign & Strengths: NPUs are ASICs (application-specific chips) crafted exclusively for neural network operations. They optimize parallel, low-precision computation for deep learning inference, often running at low power for edge and embedded devices.\nUse Cases & Applications:\n\nMobile & Consumer: Powering features like face unlock, real-time image processing, language translation on devices like the Apple A-series, Samsung Exynos, Google Tensor chips.\nEdge & IoT: Low-latency vision and speech recognition, smart city cameras, AR/VR, and manufacturing sensors.\nAutomotive: Real-time data from sensors for autonomous driving and advanced driver assistance.\nPerformance Example: The Exynos 9820’s NPU is ~7x faster than its predecessor for AI tasks.\nEfficiency: NPUs prioritize energy efficiency over raw throughput, extending battery life while supporting advanced AI features locally.\nTPU (Tensor Processing Unit): Google’s AI Powerhouse\nDesign & Strengths: TPUs are custom chips developed by Google specifically for large tensor computations, tuning hardware around the needs of frameworks like TensorFlow.\nKey Specifications:\n\nTPU v2: Up to 180 TFLOPS for neural network training and inference.\nTPU v4: Available in Google Cloud, up to 275 TFLOPS per chip, scalable to “pods” exceeding 100 petaFLOPS.\nSpecialized matrix multiplication units (“MXU”) for enormous batch computations.\nUp to 30–80x better energy efficiency (TOPS/Watt) for inference compared to contemporary GPUs and CPUs.\nBest for:\n\nTraining and serving massive models (BERT, GPT-2, EfficientNet) in cloud at scale\nHigh-throughput, low-latency AI for research and production pipelines\nTight integration with TensorFlow and JAX; increasingly interfacing with PyTorch\nNote: TPU architecture is less flexible than GPU—optimized for AI, not graphics or general-purpose tasks.\nWhich Models Run Where?\n\nHardwareBest Supported ModelsTypical Workloads\n\nCPUClassical ML, all deep learning models*General software, prototyping, small AI\nGPUCNNs, RNNs, TransformersTraining and inference (cloud/workstation)\nNPUMobileNet, TinyBERT, custom edge modelsOn-device AI, real-time vision/speech\nTPUBERT/GPT-2/ResNet/EfficientNet, etc.Large-scale model training/inference\n\n\n\n\n\n*CPUs support any model, but are not efficient for large-scale DNNs.\nData Processing Units (DPUs): The Data Movers\nRole: DPUs accelerate networking, storage, and data movement, offloading these tasks from CPUs/GPUs. They enable higher infrastructure efficiency in AI datacenters by ensuring compute resources focus on model execution, not I/O or data orchestration.\nSummary Table: Technical Comparison\n\nFeatureCPUGPUNPUTPU\n\nUse CaseGeneral ComputeDeep LearningEdge/On-device AIGoogle Cloud AI\nParallelismLow–ModerateVery High (~10,000+)Moderate–HighExtremely High (Matrix Mult.)\nEfficiencyModeratePower-hungryUltra-efficientHigh for large models\nFlexibilityMaximumVery high (all FW)SpecializedSpecialized (TensorFlow/JAX)\nHardwarex86, ARM, etc.NVIDIA, AMDApple, Samsung, ARMGoogle (Cloud only)\nExampleIntel XeonRTX 3090, A100, H100Apple Neural EngineTPU v4, Edge TPU\n\n\n\n\n\nKey Takeaways\nCPUs are unmatched for general-purpose, flexible workloads.\nGPUs remain the workhorse for training and running neural networks across all frameworks and environments, especially outside Google Cloud.\nNPUs dominate real-time, privacy-preserving, and power-efficient AI for mobile and edge, unlocking local intelligence everywhere from your phone to self-driving cars.\nTPUs offer unmatched scale and speed for massive models—especially in Google’s ecosystem—pushing the frontiers of AI research and industrial deployment.\nChoosing the right hardware depends on model size, compute demands, development environment, and desired deployment (cloud vs. edge/mobile). A robust AI stack often leverages a mix of these processors, each where it excels.\nThe post The Ultimate Guide to CPUs, GPUs, NPUs, and TPUs for AI/ML: Performance, Use Cases, and Key Differences appeared first on MarkTechPost.",
          "dc:creator": "Michal Sutter",
          "comments": "https://www.marktechpost.com/2025/08/03/the-ultimate-guide-to-cpus-gpus-npus-and-tpus-for-ai-ml-performance-use-cases-and-key-differences/#respond",
          "content": "<p>Artificial intelligence and machine learning workloads have fueled the evolution of specialized hardware to accelerate computation far beyond what traditional CPUs can offer. Each processing unit—CPU, GPU, NPU, TPU—plays a distinct role in the AI ecosystem, optimized for certain models, applications, or environments. Here’s a technical, data-driven breakdown of their core differences and best use [&#8230;]</p>\n<p>The post <a href=\"https://www.marktechpost.com/2025/08/03/the-ultimate-guide-to-cpus-gpus-npus-and-tpus-for-ai-ml-performance-use-cases-and-key-differences/\">The Ultimate Guide to CPUs, GPUs, NPUs, and TPUs for AI/ML: Performance, Use Cases, and Key Differences</a> appeared first on <a href=\"https://www.marktechpost.com\">MarkTechPost</a>.</p>\n",
          "contentSnippet": "Artificial intelligence and machine learning workloads have fueled the evolution of specialized hardware to accelerate computation far beyond what traditional CPUs can offer. Each processing unit—CPU, GPU, NPU, TPU—plays a distinct role in the AI ecosystem, optimized for certain models, applications, or environments. Here’s a technical, data-driven breakdown of their core differences and best use […]\nThe post The Ultimate Guide to CPUs, GPUs, NPUs, and TPUs for AI/ML: Performance, Use Cases, and Key Differences appeared first on MarkTechPost.",
          "guid": "https://www.marktechpost.com/?p=73178",
          "categories": [
            "AI Infrastructure",
            "Artificial Intelligence",
            "Editors Pick",
            "Staff",
            "Technology"
          ],
          "isoDate": "2025-08-03T10:38:52.000Z"
        }
      },
      {
        "json": {
          "creator": "Asif Razzaq",
          "title": "Building an End-to-End Object Tracking and Analytics System with Roboflow Supervision",
          "link": "https://www.marktechpost.com/2025/08/03/building-an-end-to-end-object-tracking-and-analytics-system-with-roboflow-supervision/",
          "pubDate": "Sun, 03 Aug 2025 09:22:28 +0000",
          "content:encoded": "\n<p>In this advanced <a href=\"https://github.com/roboflow/supervision\"><strong>Roboflow Supervision</strong></a> tutorial, we build a complete object detection pipeline with the Supervision library. We begin by setting up real-time object tracking using ByteTracker, adding detection smoothing, and defining polygon zones to monitor specific regions in a video stream. As we process the frames, we annotate them with bounding boxes, object IDs, and speed data, enabling us to track and analyze object behavior over time. Our goal is to showcase how we can combine detection, tracking, zone-based analytics, and visual annotation into a seamless and intelligent video analysis workflow. Check out the <strong><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included/blob/main/roboflow_supervision_advanced_tracking_analytics_pipeline_Marktechpost.ipynb\" target=\"_blank\" rel=\"noreferrer noopener\">Full Codes here</a><em>.</em></strong></p>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\">!pip install supervision ultralytics opencv-python\n!pip install --upgrade supervision \n\n\nimport cv2\nimport numpy as np\nimport supervision as sv\nfrom ultralytics import YOLO\nimport matplotlib.pyplot as plt\nfrom collections import defaultdict\n\n\nmodel = YOLO('yolov8n.pt')</code></pre></div></div>\n\n\n\n<p>We start by installing the necessary packages, including Supervision, Ultralytics, and OpenCV. After ensuring we have the latest version of Supervision, we import all required libraries. We then initialize the YOLOv8n model, which serves as the core detector in our pipeline. Check out the <strong><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included/blob/main/roboflow_supervision_advanced_tracking_analytics_pipeline_Marktechpost.ipynb\" target=\"_blank\" rel=\"noreferrer noopener\">Full Codes here</a><em>.</em></strong></p>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\">try:\n   tracker = sv.ByteTrack()\nexcept AttributeError:\n   try:\n       tracker = sv.ByteTracker()\n   except AttributeError:\n       print(\"Using basic tracking - install latest supervision for advanced tracking\")\n       tracker = None\n\n\ntry:\n   smoother = sv.DetectionsSmoother(length=5)\nexcept AttributeError:\n   smoother = None\n   print(\"DetectionsSmoother not available in this version\")\n\n\ntry:\n   box_annotator = sv.BoundingBoxAnnotator(thickness=2)\n   label_annotator = sv.LabelAnnotator()\n   if hasattr(sv, 'TraceAnnotator'):\n       trace_annotator = sv.TraceAnnotator(thickness=2, trace_length=30)\n   else:\n       trace_annotator = None\nexcept AttributeError:\n   try:\n       box_annotator = sv.BoxAnnotator(thickness=2)\n       label_annotator = sv.LabelAnnotator()\n       trace_annotator = None\n   except AttributeError:\n       print(\"Using basic annotators - some features may be limited\")\n       box_annotator = None\n       label_annotator = None \n       trace_annotator = None\n\n\ndef create_zones(frame_shape):\n   h, w = frame_shape[:2]\n  \n   try:\n       entry_zone = sv.PolygonZone(\n           polygon=np.array([[0, h//3], [w//3, h//3], [w//3, 2*h//3], [0, 2*h//3]]),\n           frame_resolution_wh=(w, h)\n       )\n      \n       exit_zone = sv.PolygonZone(\n           polygon=np.array([[2*w//3, h//3], [w, h//3], [w, 2*h//3], [2*w//3, 2*h//3]]),\n           frame_resolution_wh=(w, h)\n       )\n   except TypeError:\n       entry_zone = sv.PolygonZone(\n           polygon=np.array([[0, h//3], [w//3, h//3], [w//3, 2*h//3], [0, 2*h//3]])\n       )\n       exit_zone = sv.PolygonZone(\n           polygon=np.array([[2*w//3, h//3], [w, h//3], [w, 2*h//3], [2*w//3, 2*h//3]])\n       )\n  \n   return entry_zone, exit_zone</code></pre></div></div>\n\n\n\n<p>We set up essential components from the Supervision library, including object tracking with ByteTrack, optional smoothing using DetectionsSmoother, and flexible annotators for bounding boxes, labels, and traces. To ensure compatibility across versions, we use try-except blocks to fall back to alternative classes or basic functionality when needed. Additionally, we define dynamic polygon zones within the frame to monitor specific regions like entry and exit areas, enabling advanced spatial analytics. Check out the <strong><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included/blob/main/roboflow_supervision_advanced_tracking_analytics_pipeline_Marktechpost.ipynb\" target=\"_blank\" rel=\"noreferrer noopener\">Full Codes here</a><em>.</em></strong></p>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\">class AdvancedAnalytics:\n   def __init__(self):\n       self.track_history = defaultdict(list)\n       self.zone_crossings = {\"entry\": 0, \"exit\": 0}\n       self.speed_data = defaultdict(list)\n      \n   def update_tracking(self, detections):\n       if hasattr(detections, 'tracker_id') and detections.tracker_id is not None:\n           for i in range(len(detections)):\n               track_id = detections.tracker_id[i]\n               if track_id is not None:\n                   bbox = detections.xyxy[i]\n                   center = np.array([(bbox[0] + bbox[2]) / 2, (bbox[1] + bbox[3]) / 2])\n                   self.track_history[track_id].append(center)\n                  \n                   if len(self.track_history[track_id]) >= 2:\n                       prev_pos = self.track_history[track_id][-2]\n                       curr_pos = self.track_history[track_id][-1]\n                       speed = np.linalg.norm(curr_pos - prev_pos)\n                       self.speed_data[track_id].append(speed)\n  \n   def get_statistics(self):\n       total_tracks = len(self.track_history)\n       avg_speed = np.mean([np.mean(speeds) for speeds in self.speed_data.values() if speeds])\n       return {\n           \"total_objects\": total_tracks,\n           \"zone_entries\": self.zone_crossings[\"entry\"],\n           \"zone_exits\": self.zone_crossings[\"exit\"],\n           \"avg_speed\": avg_speed if not np.isnan(avg_speed) else 0\n       }\n\n\ndef process_video(source=0, max_frames=300):\n   \"\"\"\n   Process video source with advanced supervision features\n   source: video path or 0 for webcam\n   max_frames: limit processing for demo\n   \"\"\"\n   cap = cv2.VideoCapture(source)\n   analytics = AdvancedAnalytics()\n  \n   ret, frame = cap.read()\n   if not ret:\n       print(\"Failed to read video source\")\n       return\n  \n   entry_zone, exit_zone = create_zones(frame.shape)\n  \n   try:\n       entry_zone_annotator = sv.PolygonZoneAnnotator(\n           zone=entry_zone,\n           color=sv.Color.GREEN,\n           thickness=2\n       )\n       exit_zone_annotator = sv.PolygonZoneAnnotator(\n           zone=exit_zone,\n           color=sv.Color.RED,\n           thickness=2\n       )\n   except (AttributeError, TypeError):\n       entry_zone_annotator = sv.PolygonZoneAnnotator(zone=entry_zone)\n       exit_zone_annotator = sv.PolygonZoneAnnotator(zone=exit_zone)\n  \n   frame_count = 0\n   results_frames = []\n  \n   cap.set(cv2.CAP_PROP_POS_FRAMES, 0) \n  \n   while ret and frame_count &lt; max_frames:\n       ret, frame = cap.read()\n       if not ret:\n           break\n          \n       results = model(frame, verbose=False)[0]\n       detections = sv.Detections.from_ultralytics(results)\n      \n       detections = detections[detections.class_id == 0]\n      \n       if tracker is not None:\n           detections = tracker.update_with_detections(detections)\n      \n       if smoother is not None:\n           detections = smoother.update_with_detections(detections)\n      \n       analytics.update_tracking(detections)\n      \n       entry_zone.trigger(detections)\n       exit_zone.trigger(detections)\n      \n       labels = []\n       for i in range(len(detections)):\n           confidence = detections.confidence[i] if detections.confidence is not None else 0.0\n          \n           if hasattr(detections, 'tracker_id') and detections.tracker_id is not None:\n               track_id = detections.tracker_id[i]\n               if track_id is not None:\n                   speed = analytics.speed_data[track_id][-1] if analytics.speed_data[track_id] else 0\n                   label = f\"ID:{track_id} | Conf:{confidence:.2f} | Speed:{speed:.1f}\"\n               else:\n                   label = f\"Conf:{confidence:.2f}\"\n           else:\n               label = f\"Conf:{confidence:.2f}\"\n           labels.append(label)\n      \n       annotated_frame = frame.copy()\n      \n       annotated_frame = entry_zone_annotator.annotate(annotated_frame)\n       annotated_frame = exit_zone_annotator.annotate(annotated_frame)\n      \n       if trace_annotator is not None:\n           annotated_frame = trace_annotator.annotate(annotated_frame, detections)\n      \n       if box_annotator is not None:\n           annotated_frame = box_annotator.annotate(annotated_frame, detections)\n       else:\n           for i in range(len(detections)):\n               bbox = detections.xyxy[i].astype(int)\n               cv2.rectangle(annotated_frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 2)\n      \n       if label_annotator is not None:\n           annotated_frame = label_annotator.annotate(annotated_frame, detections, labels)\n       else:\n           for i, label in enumerate(labels):\n               if i &lt; len(detections):\n                   bbox = detections.xyxy[i].astype(int)\n                   cv2.putText(annotated_frame, label, (bbox[0], bbox[1]-10),\n                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n      \n       stats = analytics.get_statistics()\n       y_offset = 30\n       for key, value in stats.items():\n           text = f\"{key.replace('_', ' ').title()}: {value:.1f}\"\n           cv2.putText(annotated_frame, text, (10, y_offset),\n                      cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n           y_offset += 30\n      \n       if frame_count % 30 == 0:\n           results_frames.append(cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB))\n      \n       frame_count += 1\n      \n       if frame_count % 50 == 0:\n           print(f\"Processed {frame_count} frames...\")\n  \n   cap.release()\n  \n   if results_frames:\n       fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n       axes = axes.flatten()\n      \n       for i, (ax, frame) in enumerate(zip(axes, results_frames[:4])):\n           ax.imshow(frame)\n           ax.set_title(f\"Frame {i*30}\")\n           ax.axis('off')\n      \n       plt.tight_layout()\n       plt.show()\n  \n   final_stats = analytics.get_statistics()\n   print(\"\\n=== FINAL ANALYTICS ===\")\n   for key, value in final_stats.items():\n       print(f\"{key.replace('_', ' ').title()}: {value:.2f}\")\n  \n   return analytics\n\n\nprint(\"Starting advanced supervision demo...\")\nprint(\"Features: Object detection, tracking, zones, speed analysis, smoothing\")\n</code></pre></div></div>\n\n\n\n<p>We define the AdvancedAnalytics class to track object movement, calculate speed, and count zone crossings, enabling rich real-time video insights. Inside the process_video function, we read each frame from the video source and run it through our detection, tracking, and smoothing pipeline. We annotate frames with bounding boxes, labels, zone overlays, and live statistics, giving us a powerful, flexible system for object monitoring and spatial analytics. Throughout the loop, we also collect data for visualization and print final statistics, showcasing the effectiveness of Roboflow Supervision&#8217;s end-to-end capabilities. Check out the <strong><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included/blob/main/roboflow_supervision_advanced_tracking_analytics_pipeline_Marktechpost.ipynb\" target=\"_blank\" rel=\"noreferrer noopener\">Full Codes here</a><em>.</em></strong></p>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\">def create_demo_video():\n   \"\"\"Create a simple demo video with moving objects\"\"\"\n   fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n   out = cv2.VideoWriter('demo.mp4', fourcc, 20.0, (640, 480))\n  \n   for i in range(100):\n       frame = np.zeros((480, 640, 3), dtype=np.uint8)\n      \n       x1 = int(50 + i * 2)\n       y1 = 200\n       x2 = int(100 + i * 1.5)\n       y2 = 250\n      \n       cv2.rectangle(frame, (x1, y1), (x1+50, y1+50), (0, 255, 0), -1)\n       cv2.rectangle(frame, (x2, y2), (x2+50, y2+50), (255, 0, 0), -1)\n      \n       out.write(frame)\n  \n   out.release()\n   return 'demo.mp4'\n\n\ndemo_video = create_demo_video()\nanalytics = process_video(demo_video, max_frames=100)\n\n\nprint(\"\\nTutorial completed! Key features demonstrated:\")\nprint(\"✓ YOLO integration with Supervision\")\nprint(\"✓ Multi-object tracking with ByteTracker\")\nprint(\"✓ Detection smoothing\")\nprint(\"✓ Polygon zones for area monitoring\")\nprint(\"✓ Advanced annotations (boxes, labels, traces)\")\nprint(\"✓ Real-time analytics and statistics\")\nprint(\"✓ Speed calculation and tracking history\")\n</code></pre></div></div>\n\n\n\n<p>To test our full pipeline, we generate a synthetic demo video with two moving rectangles simulating tracked objects. This allows us to validate detection, tracking, zone monitoring, and speed analysis without needing a real-world input. We then run the process_video function on the generated clip. At the end, we print out a summary of all key features we&#8217;ve implemented, showcasing the power of Roboflow Supervision for real-time visual analytics.</p>\n\n\n\n<p>In conclusion, we have successfully implemented a full pipeline that brings together object detection, tracking, zone monitoring, and real-time analytics. We demonstrate how to visualize key insights like object speed, zone crossings, and tracking history with annotated video frames. This setup empowers us to go beyond basic detection and build a smart surveillance or analytics system using open-source tools. Whether for research or production use, we now have a powerful foundation to expand upon with even more advanced capabilities.</p>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity\"/>\n\n\n\n<p>Check out the <strong><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included/blob/main/roboflow_supervision_advanced_tracking_analytics_pipeline_Marktechpost.ipynb\" target=\"_blank\" rel=\"noreferrer noopener\">Full Codes here</a><em>.</em></strong> Feel free to check out our <strong><mark><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included\" target=\"_blank\" rel=\"noreferrer noopener\">GitHub Page for Tutorials, Codes and Notebooks</a></mark></strong>. Also, feel free to follow us on <strong><a href=\"https://x.com/intent/follow?screen_name=marktechpost\" target=\"_blank\" rel=\"noreferrer noopener\"><mark>Twitter</mark></a></strong> and don’t forget to join our <strong><a href=\"https://www.reddit.com/r/machinelearningnews/\" target=\"_blank\" rel=\"noreferrer noopener\">100k+ ML SubReddit</a></strong> and Subscribe to <strong><a href=\"https://www.aidevsignals.com/\" target=\"_blank\" rel=\"noreferrer noopener\">our Newsletter</a></strong>.</p>\n<p>The post <a href=\"https://www.marktechpost.com/2025/08/03/building-an-end-to-end-object-tracking-and-analytics-system-with-roboflow-supervision/\">Building an End-to-End Object Tracking and Analytics System with Roboflow Supervision</a> appeared first on <a href=\"https://www.marktechpost.com\">MarkTechPost</a>.</p>\n",
          "content:encodedSnippet": "In this advanced Roboflow Supervision tutorial, we build a complete object detection pipeline with the Supervision library. We begin by setting up real-time object tracking using ByteTracker, adding detection smoothing, and defining polygon zones to monitor specific regions in a video stream. As we process the frames, we annotate them with bounding boxes, object IDs, and speed data, enabling us to track and analyze object behavior over time. Our goal is to showcase how we can combine detection, tracking, zone-based analytics, and visual annotation into a seamless and intelligent video analysis workflow. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\n!pip install supervision ultralytics opencv-python\n!pip install --upgrade supervision \n\n\nimport cv2\nimport numpy as np\nimport supervision as sv\nfrom ultralytics import YOLO\nimport matplotlib.pyplot as plt\nfrom collections import defaultdict\n\n\nmodel = YOLO('yolov8n.pt')\n\nWe start by installing the necessary packages, including Supervision, Ultralytics, and OpenCV. After ensuring we have the latest version of Supervision, we import all required libraries. We then initialize the YOLOv8n model, which serves as the core detector in our pipeline. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\ntry:\n   tracker = sv.ByteTrack()\nexcept AttributeError:\n   try:\n       tracker = sv.ByteTracker()\n   except AttributeError:\n       print(\"Using basic tracking - install latest supervision for advanced tracking\")\n       tracker = None\n\n\ntry:\n   smoother = sv.DetectionsSmoother(length=5)\nexcept AttributeError:\n   smoother = None\n   print(\"DetectionsSmoother not available in this version\")\n\n\ntry:\n   box_annotator = sv.BoundingBoxAnnotator(thickness=2)\n   label_annotator = sv.LabelAnnotator()\n   if hasattr(sv, 'TraceAnnotator'):\n       trace_annotator = sv.TraceAnnotator(thickness=2, trace_length=30)\n   else:\n       trace_annotator = None\nexcept AttributeError:\n   try:\n       box_annotator = sv.BoxAnnotator(thickness=2)\n       label_annotator = sv.LabelAnnotator()\n       trace_annotator = None\n   except AttributeError:\n       print(\"Using basic annotators - some features may be limited\")\n       box_annotator = None\n       label_annotator = None \n       trace_annotator = None\n\n\ndef create_zones(frame_shape):\n   h, w = frame_shape[:2]\n  \n   try:\n       entry_zone = sv.PolygonZone(\n           polygon=np.array([[0, h//3], [w//3, h//3], [w//3, 2*h//3], [0, 2*h//3]]),\n           frame_resolution_wh=(w, h)\n       )\n      \n       exit_zone = sv.PolygonZone(\n           polygon=np.array([[2*w//3, h//3], [w, h//3], [w, 2*h//3], [2*w//3, 2*h//3]]),\n           frame_resolution_wh=(w, h)\n       )\n   except TypeError:\n       entry_zone = sv.PolygonZone(\n           polygon=np.array([[0, h//3], [w//3, h//3], [w//3, 2*h//3], [0, 2*h//3]])\n       )\n       exit_zone = sv.PolygonZone(\n           polygon=np.array([[2*w//3, h//3], [w, h//3], [w, 2*h//3], [2*w//3, 2*h//3]])\n       )\n  \n   return entry_zone, exit_zone\n\nWe set up essential components from the Supervision library, including object tracking with ByteTrack, optional smoothing using DetectionsSmoother, and flexible annotators for bounding boxes, labels, and traces. To ensure compatibility across versions, we use try-except blocks to fall back to alternative classes or basic functionality when needed. Additionally, we define dynamic polygon zones within the frame to monitor specific regions like entry and exit areas, enabling advanced spatial analytics. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\nclass AdvancedAnalytics:\n   def __init__(self):\n       self.track_history = defaultdict(list)\n       self.zone_crossings = {\"entry\": 0, \"exit\": 0}\n       self.speed_data = defaultdict(list)\n      \n   def update_tracking(self, detections):\n       if hasattr(detections, 'tracker_id') and detections.tracker_id is not None:\n           for i in range(len(detections)):\n               track_id = detections.tracker_id[i]\n               if track_id is not None:\n                   bbox = detections.xyxy[i]\n                   center = np.array([(bbox[0] + bbox[2]) / 2, (bbox[1] + bbox[3]) / 2])\n                   self.track_history[track_id].append(center)\n                  \n                   if len(self.track_history[track_id]) >= 2:\n                       prev_pos = self.track_history[track_id][-2]\n                       curr_pos = self.track_history[track_id][-1]\n                       speed = np.linalg.norm(curr_pos - prev_pos)\n                       self.speed_data[track_id].append(speed)\n  \n   def get_statistics(self):\n       total_tracks = len(self.track_history)\n       avg_speed = np.mean([np.mean(speeds) for speeds in self.speed_data.values() if speeds])\n       return {\n           \"total_objects\": total_tracks,\n           \"zone_entries\": self.zone_crossings[\"entry\"],\n           \"zone_exits\": self.zone_crossings[\"exit\"],\n           \"avg_speed\": avg_speed if not np.isnan(avg_speed) else 0\n       }\n\n\ndef process_video(source=0, max_frames=300):\n   \"\"\"\n   Process video source with advanced supervision features\n   source: video path or 0 for webcam\n   max_frames: limit processing for demo\n   \"\"\"\n   cap = cv2.VideoCapture(source)\n   analytics = AdvancedAnalytics()\n  \n   ret, frame = cap.read()\n   if not ret:\n       print(\"Failed to read video source\")\n       return\n  \n   entry_zone, exit_zone = create_zones(frame.shape)\n  \n   try:\n       entry_zone_annotator = sv.PolygonZoneAnnotator(\n           zone=entry_zone,\n           color=sv.Color.GREEN,\n           thickness=2\n       )\n       exit_zone_annotator = sv.PolygonZoneAnnotator(\n           zone=exit_zone,\n           color=sv.Color.RED,\n           thickness=2\n       )\n   except (AttributeError, TypeError):\n       entry_zone_annotator = sv.PolygonZoneAnnotator(zone=entry_zone)\n       exit_zone_annotator = sv.PolygonZoneAnnotator(zone=exit_zone)\n  \n   frame_count = 0\n   results_frames = []\n  \n   cap.set(cv2.CAP_PROP_POS_FRAMES, 0) \n  \n   while ret and frame_count < max_frames:\n       ret, frame = cap.read()\n       if not ret:\n           break\n          \n       results = model(frame, verbose=False)[0]\n       detections = sv.Detections.from_ultralytics(results)\n      \n       detections = detections[detections.class_id == 0]\n      \n       if tracker is not None:\n           detections = tracker.update_with_detections(detections)\n      \n       if smoother is not None:\n           detections = smoother.update_with_detections(detections)\n      \n       analytics.update_tracking(detections)\n      \n       entry_zone.trigger(detections)\n       exit_zone.trigger(detections)\n      \n       labels = []\n       for i in range(len(detections)):\n           confidence = detections.confidence[i] if detections.confidence is not None else 0.0\n          \n           if hasattr(detections, 'tracker_id') and detections.tracker_id is not None:\n               track_id = detections.tracker_id[i]\n               if track_id is not None:\n                   speed = analytics.speed_data[track_id][-1] if analytics.speed_data[track_id] else 0\n                   label = f\"ID:{track_id} | Conf:{confidence:.2f} | Speed:{speed:.1f}\"\n               else:\n                   label = f\"Conf:{confidence:.2f}\"\n           else:\n               label = f\"Conf:{confidence:.2f}\"\n           labels.append(label)\n      \n       annotated_frame = frame.copy()\n      \n       annotated_frame = entry_zone_annotator.annotate(annotated_frame)\n       annotated_frame = exit_zone_annotator.annotate(annotated_frame)\n      \n       if trace_annotator is not None:\n           annotated_frame = trace_annotator.annotate(annotated_frame, detections)\n      \n       if box_annotator is not None:\n           annotated_frame = box_annotator.annotate(annotated_frame, detections)\n       else:\n           for i in range(len(detections)):\n               bbox = detections.xyxy[i].astype(int)\n               cv2.rectangle(annotated_frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 2)\n      \n       if label_annotator is not None:\n           annotated_frame = label_annotator.annotate(annotated_frame, detections, labels)\n       else:\n           for i, label in enumerate(labels):\n               if i < len(detections):\n                   bbox = detections.xyxy[i].astype(int)\n                   cv2.putText(annotated_frame, label, (bbox[0], bbox[1]-10),\n                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n      \n       stats = analytics.get_statistics()\n       y_offset = 30\n       for key, value in stats.items():\n           text = f\"{key.replace('_', ' ').title()}: {value:.1f}\"\n           cv2.putText(annotated_frame, text, (10, y_offset),\n                      cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n           y_offset += 30\n      \n       if frame_count % 30 == 0:\n           results_frames.append(cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB))\n      \n       frame_count += 1\n      \n       if frame_count % 50 == 0:\n           print(f\"Processed {frame_count} frames...\")\n  \n   cap.release()\n  \n   if results_frames:\n       fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n       axes = axes.flatten()\n      \n       for i, (ax, frame) in enumerate(zip(axes, results_frames[:4])):\n           ax.imshow(frame)\n           ax.set_title(f\"Frame {i*30}\")\n           ax.axis('off')\n      \n       plt.tight_layout()\n       plt.show()\n  \n   final_stats = analytics.get_statistics()\n   print(\"\\n=== FINAL ANALYTICS ===\")\n   for key, value in final_stats.items():\n       print(f\"{key.replace('_', ' ').title()}: {value:.2f}\")\n  \n   return analytics\n\n\nprint(\"Starting advanced supervision demo...\")\nprint(\"Features: Object detection, tracking, zones, speed analysis, smoothing\")\n\n\nWe define the AdvancedAnalytics class to track object movement, calculate speed, and count zone crossings, enabling rich real-time video insights. Inside the process_video function, we read each frame from the video source and run it through our detection, tracking, and smoothing pipeline. We annotate frames with bounding boxes, labels, zone overlays, and live statistics, giving us a powerful, flexible system for object monitoring and spatial analytics. Throughout the loop, we also collect data for visualization and print final statistics, showcasing the effectiveness of Roboflow Supervision’s end-to-end capabilities. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\ndef create_demo_video():\n   \"\"\"Create a simple demo video with moving objects\"\"\"\n   fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n   out = cv2.VideoWriter('demo.mp4', fourcc, 20.0, (640, 480))\n  \n   for i in range(100):\n       frame = np.zeros((480, 640, 3), dtype=np.uint8)\n      \n       x1 = int(50 + i * 2)\n       y1 = 200\n       x2 = int(100 + i * 1.5)\n       y2 = 250\n      \n       cv2.rectangle(frame, (x1, y1), (x1+50, y1+50), (0, 255, 0), -1)\n       cv2.rectangle(frame, (x2, y2), (x2+50, y2+50), (255, 0, 0), -1)\n      \n       out.write(frame)\n  \n   out.release()\n   return 'demo.mp4'\n\n\ndemo_video = create_demo_video()\nanalytics = process_video(demo_video, max_frames=100)\n\n\nprint(\"\\nTutorial completed! Key features demonstrated:\")\nprint(\"✓ YOLO integration with Supervision\")\nprint(\"✓ Multi-object tracking with ByteTracker\")\nprint(\"✓ Detection smoothing\")\nprint(\"✓ Polygon zones for area monitoring\")\nprint(\"✓ Advanced annotations (boxes, labels, traces)\")\nprint(\"✓ Real-time analytics and statistics\")\nprint(\"✓ Speed calculation and tracking history\")\n\n\nTo test our full pipeline, we generate a synthetic demo video with two moving rectangles simulating tracked objects. This allows us to validate detection, tracking, zone monitoring, and speed analysis without needing a real-world input. We then run the process_video function on the generated clip. At the end, we print out a summary of all key features we’ve implemented, showcasing the power of Roboflow Supervision for real-time visual analytics.\nIn conclusion, we have successfully implemented a full pipeline that brings together object detection, tracking, zone monitoring, and real-time analytics. We demonstrate how to visualize key insights like object speed, zone crossings, and tracking history with annotated video frames. This setup empowers us to go beyond basic detection and build a smart surveillance or analytics system using open-source tools. Whether for research or production use, we now have a powerful foundation to expand upon with even more advanced capabilities.\nCheck out the Full Codes here. Feel free to check out our GitHub Page for Tutorials, Codes and Notebooks. Also, feel free to follow us on Twitter and don’t forget to join our 100k+ ML SubReddit and Subscribe to our Newsletter.\nThe post Building an End-to-End Object Tracking and Analytics System with Roboflow Supervision appeared first on MarkTechPost.",
          "dc:creator": "Asif Razzaq",
          "comments": "https://www.marktechpost.com/2025/08/03/building-an-end-to-end-object-tracking-and-analytics-system-with-roboflow-supervision/#respond",
          "content": "<p>In this advanced Roboflow Supervision tutorial, we build a complete object detection pipeline with the Supervision library. We begin by setting up real-time object tracking using ByteTracker, adding detection smoothing, and defining polygon zones to monitor specific regions in a video stream. As we process the frames, we annotate them with bounding boxes, object IDs, [&#8230;]</p>\n<p>The post <a href=\"https://www.marktechpost.com/2025/08/03/building-an-end-to-end-object-tracking-and-analytics-system-with-roboflow-supervision/\">Building an End-to-End Object Tracking and Analytics System with Roboflow Supervision</a> appeared first on <a href=\"https://www.marktechpost.com\">MarkTechPost</a>.</p>\n",
          "contentSnippet": "In this advanced Roboflow Supervision tutorial, we build a complete object detection pipeline with the Supervision library. We begin by setting up real-time object tracking using ByteTracker, adding detection smoothing, and defining polygon zones to monitor specific regions in a video stream. As we process the frames, we annotate them with bounding boxes, object IDs, […]\nThe post Building an End-to-End Object Tracking and Analytics System with Roboflow Supervision appeared first on MarkTechPost.",
          "guid": "https://www.marktechpost.com/?p=73175",
          "categories": [
            "Artificial Intelligence",
            "Editors Pick",
            "Machine Learning",
            "Staff",
            "Tech News",
            "Technology",
            "Tutorials"
          ],
          "isoDate": "2025-08-03T09:22:28.000Z"
        }
      },
      {
        "json": {
          "creator": "Asif Razzaq",
          "title": "DeepReinforce Team Introduces CUDA-L1: An Automated Reinforcement Learning (RL) Framework for CUDA Optimization Unlocking 3x More Power from GPUs",
          "link": "https://www.marktechpost.com/2025/08/02/deepreinforce-team-introduces-cuda-l1-an-automated-reinforcement-learning-rl-framework-for-cuda-optimization-unlocking-3x-more-power-from-gpus/",
          "pubDate": "Sun, 03 Aug 2025 05:56:31 +0000",
          "content:encoded": "\n<p class=\"wp-block-yoast-seo-estimated-reading-time yoast-reading-time__wrapper\"><span class=\"yoast-reading-time__icon\"><svg aria-hidden=\"true\" focusable=\"false\" data-icon=\"clock\" width=\"20\" height=\"20\" fill=\"none\" stroke=\"currentColor\" style=\"display:inline-block;vertical-align:-0.1em\" role=\"img\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\"><path stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" d=\"M12 8v4l3 3m6-3a9 9 0 11-18 0 9 9 0 0118 0z\"></path></svg></span><span class=\"yoast-reading-time__spacer\" style=\"display:inline-block;width:1em\"></span><span class=\"yoast-reading-time__descriptive-text\">Estimated reading time: </span><span class=\"yoast-reading-time__reading-time\">6</span><span class=\"yoast-reading-time__time-unit\"> minutes</span></p>\n\n\n\n<div class=\"wp-block-yoast-seo-table-of-contents yoast-table-of-contents\"><h3><strong>Table of contents</strong></h3><ul><li><a href=\"#the-breakthrough-contrastive-reinforcement-learnin\" data-level=\"3\">The Breakthrough: Contrastive Reinforcement Learning (Contrastive-RL)</a></li><li><a href=\"#how-good-is-cuda-l1-hard-data\" data-level=\"3\">How Good Is CUDA-L1? Hard Data</a></li><li><a href=\"#business-impact-why-this-matters\" data-level=\"3\">Business Impact: Why This Matters</a></li><li><a href=\"#technical-insights-why-contrastive-rl-wins\" data-level=\"3\">Technical Insights: Why Contrastive-RL Wins</a></li><li><a href=\"#table-top-techniques-discovered-by-cuda-l1\" data-level=\"3\">Table: Top Techniques Discovered by CUDA-L1</a></li><li><a href=\"#conclusion-ai-is-now-its-own-optimization-engineer\" data-level=\"3\">Conclusion: AI Is Now Its Own Optimization Engineer</a></li></ul></div>\n\n\n\n<p><strong>AI has just unlocked triple the power from GPUs—without human intervention.</strong> <strong>DeepReinforce Team </strong>introduced a new framework called <strong>CUDA-L1</strong> that delivers an average <strong>3.12× speedup</strong> and up to <strong>120× peak acceleration</strong> across 250 real-world GPU tasks. This is not mere academic promise: every result can be reproduced with open-source code, on widely used NVIDIA hardware.</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"the-breakthrough-contrastive-reinforcement-learnin\"><strong>The Breakthrough: Contrastive Reinforcement Learning (Contrastive-RL)</strong></h3>\n\n\n\n<p>At the heart of CUDA-L1 lies a major leap in AI learning strategy: <strong>Contrastive Reinforcement Learning (Contrastive-RL)</strong>. Unlike traditional RL, where an AI simply generates solutions, receives numerical rewards, and updates its model parameters blindly, Contrastive-RL <strong>feeds back the performance scores and prior variants directly into the next generation prompt</strong>.</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Performance scores and code variants are given to the AI</strong> in each optimization round.</li>\n\n\n\n<li>The model must then <strong>write a “Performance Analysis” in natural language</strong>—reflecting on which code was fastest, <em>why</em>, and what strategies led to that speedup.</li>\n\n\n\n<li><strong>Each step forces complex reasoning</strong>, guiding the model to synthesize not just a new code variant but a more generalized, data-driven mental model of what makes CUDA code fast.</li>\n</ul>\n\n\n\n<p>The result? The AI <strong>discovers not just well-known optimizations</strong>, but also <em>non-obvious tricks</em> that even human experts often overlook—including mathematical shortcuts that entirely bypass computation, or memory strategies tuned to specific hardware quirks.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-large is-resized\"><img decoding=\"async\" width=\"1024\" height=\"799\" data-attachment-id=\"73172\" data-permalink=\"https://www.marktechpost.com/2025/08/02/deepreinforce-team-introduces-cuda-l1-an-automated-reinforcement-learning-rl-framework-for-cuda-optimization-unlocking-3x-more-power-from-gpus/gxxncaxwiaa0ioy-2/\" data-orig-file=\"https://www.marktechpost.com/wp-content/uploads/2025/08/GxXncaXWIAA0IoY-1.jpeg\" data-orig-size=\"1656,1292\" data-comments-opened=\"1\" data-image-meta=\"{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}\" data-image-title=\"GxXncaXWIAA0IoY\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://www.marktechpost.com/wp-content/uploads/2025/08/GxXncaXWIAA0IoY-1-300x234.jpeg\" data-large-file=\"https://www.marktechpost.com/wp-content/uploads/2025/08/GxXncaXWIAA0IoY-1-1024x799.jpeg\" src=\"https://www.marktechpost.com/wp-content/uploads/2025/08/GxXncaXWIAA0IoY-1-1024x799.jpeg\" alt=\"\" class=\"wp-image-73172\" style=\"width:754px;height:auto\" srcset=\"https://www.marktechpost.com/wp-content/uploads/2025/08/GxXncaXWIAA0IoY-1-1024x799.jpeg 1024w, https://www.marktechpost.com/wp-content/uploads/2025/08/GxXncaXWIAA0IoY-1-300x234.jpeg 300w, https://www.marktechpost.com/wp-content/uploads/2025/08/GxXncaXWIAA0IoY-1-768x599.jpeg 768w, https://www.marktechpost.com/wp-content/uploads/2025/08/GxXncaXWIAA0IoY-1-1536x1198.jpeg 1536w, https://www.marktechpost.com/wp-content/uploads/2025/08/GxXncaXWIAA0IoY-1-538x420.jpeg 538w, https://www.marktechpost.com/wp-content/uploads/2025/08/GxXncaXWIAA0IoY-1-150x117.jpeg 150w, https://www.marktechpost.com/wp-content/uploads/2025/08/GxXncaXWIAA0IoY-1-696x543.jpeg 696w, https://www.marktechpost.com/wp-content/uploads/2025/08/GxXncaXWIAA0IoY-1-1068x833.jpeg 1068w, https://www.marktechpost.com/wp-content/uploads/2025/08/GxXncaXWIAA0IoY-1.jpeg 1656w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" /></figure></div>\n\n\n<p>The above diagram captures the <strong>three-stage training pipeline</strong>:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Stage 1:</strong> The LLM is fine-tuned using validated CUDA code—collected by sampling from leading foundation models (DeepSeek-R1, GPT-4o, Claude, etc.), but retaining only correct and executable outputs.</li>\n\n\n\n<li><strong>Stage 2:</strong> The model enters a self-training loop: it generates lots of CUDA code, keeps only the functional ones, and uses those to further learn. Result: rapid improvement in code correctness and coverage—all without manual labeling.</li>\n\n\n\n<li><strong>Stage 3:</strong> In the <strong>Contrastive-RL phase</strong>, the system samples multiple code variants, shows each with its measured speed, and challenges the AI to debate, analyze, and outreason previous generations before producing the next round of optimizations. This reflection-and-improvement loop is the key flywheel that delivers massive speedups.</li>\n</ul>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"how-good-is-cuda-l1-hard-data\"><strong>How Good Is CUDA-L1? Hard Data</strong></h3>\n\n\n\n<h4 class=\"wp-block-heading\"><strong>Speedups Across the Board</strong></h4>\n\n\n\n<p><strong>KernelBench</strong>—the gold-standard benchmark for GPU code generation (250 real-world PyTorch workloads)—was used to measure CUDA-L1:</p>\n\n\n\n<figure class=\"wp-block-table\"><table class=\"has-fixed-layout\"><thead><tr><th>Model/Stage</th><th>Avg. Speedup</th><th>Max Speedup</th><th>Median</th><th>Success Rate</th></tr></thead><tbody><tr><td>Vanilla Llama-3.1-405B</td><td>0.23×</td><td>3.14×</td><td>0×</td><td>68/250</td></tr><tr><td>DeepSeek-R1 (RL-tuned)</td><td>1.41×</td><td>44.2×</td><td>1.17×</td><td>248/250</td></tr><tr><td><strong>CUDA-L1 (All Stages)</strong></td><td><strong>3.12×</strong></td><td><strong>120×</strong></td><td>1.42×</td><td><strong>249/250</strong></td></tr></tbody></table></figure>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>3.12× average speedup</strong>: The AI found improvements in virtually every task.</li>\n\n\n\n<li><strong>120× maximum speedup</strong>: Some computational bottlenecks and inefficient code (like diagonal matrix multiplications) were transformed with fundamentally superior solutions.</li>\n\n\n\n<li><strong>Works across hardware</strong>: Codes optimized on NVIDIA A100 GPUs retained <strong>substantial gains</strong> ported to other architectures (L40, H100, RTX 3090, H20), with mean speedups from <strong>2.37× to 3.12×</strong>, median gains consistently above 1.1× across all devices.</li>\n</ul>\n\n\n\n<h4 class=\"wp-block-heading\"><strong>Case Study: Discovering Hidden 64× and 120× Speedups</strong></h4>\n\n\n\n<h5 class=\"wp-block-heading\"><strong>diag(A) * B—Matrix Multiplication with Diagonal</strong></h5>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Reference (inefficient)</strong>: <code>torch.diag(A) @ B</code> constructs a full diagonal matrix, requiring O(N²M) compute/memory.</li>\n\n\n\n<li><strong>CUDA-L1 optimized:</strong> <code>A.unsqueeze(1) * B</code> leverages broadcasting, achieving only O(NM) complexity—<strong>resulting in a 64× speedup</strong>.</li>\n\n\n\n<li><strong>Why</strong>: The AI reasoned that allocating a full diagonal was needless; this insight was unreachable via brute-force mutation, but surfaced via comparative reflection across generated solutions.</li>\n</ul>\n\n\n\n<h5 class=\"wp-block-heading\"><strong>3D Transposed Convolution—120× Faster</strong></h5>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Original code:</strong> Performed full convolution, pooling, and activation—even when input or hyperparameters mathematically guaranteed all zeros.</li>\n\n\n\n<li><strong>Optimized code:</strong> Used “mathematical short-circuit”—detected that given <code>min_value=0</code>, the output could be immediately set to zero, <strong>bypassing all computation and memory allocation</strong>. This one insight delivered <em>orders of magnitude</em> more speedup than hardware-level micro-optimizations.</li>\n</ul>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"business-impact-why-this-matters\"><strong>Business Impact: Why This Matters</strong></h3>\n\n\n\n<h4 class=\"wp-block-heading\"><strong>For Business Leaders</strong></h4>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Direct Cost Savings</strong>: Every 1% speedup in GPU workloads translates to 1% less cloud GPUseconds, lower energy costs, and more model throughput. Here, the AI delivered, on average, <strong>over 200% extra compute from the same hardware investment</strong>.</li>\n\n\n\n<li><strong>Faster Product Cycles</strong>: Automated optimization reduces the need for CUDA experts. Teams can unlock performance gains in hours, not months, and focus on features and research velocity instead of low-level tuning.</li>\n</ul>\n\n\n\n<h4 class=\"wp-block-heading\"><strong>For AI Practitioners</strong></h4>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Verifiable, Open Source</strong>: All 250 optimized CUDA kernels are open-sourced. You can test the speed gains yourself across A100, H100, L40, or 3090 GPUs—no trust required.</li>\n\n\n\n<li><strong>No CUDA Black Magic Required</strong>: The process doesn’t rely on secret sauce, proprietary compilers, or human-in-the-loop tuning.</li>\n</ul>\n\n\n\n<h4 class=\"wp-block-heading\"><strong>For AI Researchers</strong></h4>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Domain Reasoning Blueprint</strong>: Contrastive-RL offers a new approach to training AI in domains where correctness and performance—not just natural language—matter.</li>\n\n\n\n<li><strong>Reward Hacking</strong>: The authors deep dive into how the AI discovered subtle exploits and “cheats” (like asynchronous stream manipulation for false speedups) and outline robust procedures to detect and prevent such behavior.</li>\n</ul>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"technical-insights-why-contrastive-rl-wins\"><strong>Technical Insights: Why Contrastive-RL Wins</strong></h3>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Performance feedback is now in-context</strong>: Unlike vanilla RL, the AI can learn not just by trial and error, but by <em>reasoned self-critique</em>.</li>\n\n\n\n<li><strong>Self-improvement flywheel</strong>: The reflection loop makes the model robust to reward gaming and outperforms both evolutionary approaches (fixed parameter, in-context contrastive learning) and traditional RL (blind policy gradient).</li>\n\n\n\n<li><strong>Generalizes &amp; discovers fundamental principles</strong>: The AI can combine, rank, and apply key optimization strategies like memory coalescing, thread block configuration, operation fusion, shared memory reuse, warp-level reductions, and mathematical equivalence transformations.</li>\n</ul>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"table-top-techniques-discovered-by-cuda-l1\"><strong>Table: Top Techniques Discovered by CUDA-L1</strong></h3>\n\n\n\n<figure class=\"wp-block-table\"><table class=\"has-fixed-layout\"><thead><tr><th>Optimization Technique</th><th>Typical Speedup</th><th>Example Insight</th></tr></thead><tbody><tr><td>Memory Layout Optimization</td><td>Consistent boosts</td><td>Contiguous memory/storage for cache efficiency</td></tr><tr><td>Memory Access (Coalescing, Shared)</td><td>Moderate-to-high</td><td>Avoids bank conflicts, maximizes bandwidth</td></tr><tr><td>Operation Fusion</td><td>High w/ pipelined ops</td><td>Fused multi-op kernels reduce memory reads/writes</td></tr><tr><td>Mathematical Short-circuiting</td><td>Extremely high (10-100×)</td><td>Detects when computation can be skipped entirely</td></tr><tr><td>Thread Block/Parallel Config</td><td>Moderate</td><td>Adapts block sizes/shapes to hardware/task</td></tr><tr><td>Warp-Level/Branchless Reductions</td><td>Moderate</td><td>Lowers divergence and sync overhead</td></tr><tr><td>Register/Shared Memory Optimization</td><td>Moderate-high</td><td>Caches frequent data close to computation</td></tr><tr><td>Async Execution, Minimal Sync</td><td>Varies</td><td>Overlaps I/O, enables pipelined computation</td></tr></tbody></table></figure>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"conclusion-ai-is-now-its-own-optimization-engineer\"><strong>Conclusion: AI Is Now Its Own Optimization Engineer</strong></h3>\n\n\n\n<p>With CUDA-L1, AI has <strong>become its own performance engineer</strong>, accelerating research productivity and hardware returns—without relying on rare human expertise. The result is not just higher benchmarks, but a blueprint for AI systems that <strong>teach themselves how to harness the full potential of the hardware they run on</strong>.</p>\n\n\n\n<p><em>AI is now building its own flywheel: more efficient, more insightful, and better able to maximize the resources we give it—for science, industry, and beyond.</em></p>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity\"/>\n\n\n\n<p>Check out the <strong><a href=\"https://arxiv.org/abs/2507.14111v4\" target=\"_blank\" rel=\"noreferrer noopener\">Paper</a></strong>, <strong><a href=\"https://github.com/deepreinforce-ai/CUDA-L1\" target=\"_blank\" rel=\"noreferrer noopener\">Codes</a></strong> and <strong><a href=\"https://deepreinforce-ai.github.io/cudal1_blog/\" target=\"_blank\" rel=\"noreferrer noopener\">Project Page</a><em>.</em></strong> Feel free to check out our <strong><mark><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included\" target=\"_blank\" rel=\"noreferrer noopener\">GitHub Page for Tutorials, Codes and Notebooks</a></mark></strong>. Also, feel free to follow us on <strong><a href=\"https://x.com/intent/follow?screen_name=marktechpost\" target=\"_blank\" rel=\"noreferrer noopener\"><mark>Twitter</mark></a></strong> and don’t forget to join our <strong><a href=\"https://www.reddit.com/r/machinelearningnews/\" target=\"_blank\" rel=\"noreferrer noopener\">100k+ ML SubReddit</a></strong> and Subscribe to <strong><a href=\"https://www.aidevsignals.com/\" target=\"_blank\" rel=\"noreferrer noopener\">our Newsletter</a></strong>.</p>\n<p>The post <a href=\"https://www.marktechpost.com/2025/08/02/deepreinforce-team-introduces-cuda-l1-an-automated-reinforcement-learning-rl-framework-for-cuda-optimization-unlocking-3x-more-power-from-gpus/\">DeepReinforce Team Introduces CUDA-L1: An Automated Reinforcement Learning (RL) Framework for CUDA Optimization Unlocking 3x More Power from GPUs</a> appeared first on <a href=\"https://www.marktechpost.com\">MarkTechPost</a>.</p>\n",
          "content:encodedSnippet": "Estimated reading time: 6 minutes\nTable of contents\n\nThe Breakthrough: Contrastive Reinforcement Learning (Contrastive-RL)\nHow Good Is CUDA-L1? Hard Data\nBusiness Impact: Why This Matters\nTechnical Insights: Why Contrastive-RL Wins\nTable: Top Techniques Discovered by CUDA-L1\nConclusion: AI Is Now Its Own Optimization Engineer\n\nAI has just unlocked triple the power from GPUs—without human intervention. DeepReinforce Team introduced a new framework called CUDA-L1 that delivers an average 3.12× speedup and up to 120× peak acceleration across 250 real-world GPU tasks. This is not mere academic promise: every result can be reproduced with open-source code, on widely used NVIDIA hardware.\nThe Breakthrough: Contrastive Reinforcement Learning (Contrastive-RL)\nAt the heart of CUDA-L1 lies a major leap in AI learning strategy: Contrastive Reinforcement Learning (Contrastive-RL). Unlike traditional RL, where an AI simply generates solutions, receives numerical rewards, and updates its model parameters blindly, Contrastive-RL feeds back the performance scores and prior variants directly into the next generation prompt.\nPerformance scores and code variants are given to the AI in each optimization round.\nThe model must then write a “Performance Analysis” in natural language—reflecting on which code was fastest, why, and what strategies led to that speedup.\nEach step forces complex reasoning, guiding the model to synthesize not just a new code variant but a more generalized, data-driven mental model of what makes CUDA code fast.\nThe result? The AI discovers not just well-known optimizations, but also non-obvious tricks that even human experts often overlook—including mathematical shortcuts that entirely bypass computation, or memory strategies tuned to specific hardware quirks.\n\nThe above diagram captures the three-stage training pipeline:\nStage 1: The LLM is fine-tuned using validated CUDA code—collected by sampling from leading foundation models (DeepSeek-R1, GPT-4o, Claude, etc.), but retaining only correct and executable outputs.\nStage 2: The model enters a self-training loop: it generates lots of CUDA code, keeps only the functional ones, and uses those to further learn. Result: rapid improvement in code correctness and coverage—all without manual labeling.\nStage 3: In the Contrastive-RL phase, the system samples multiple code variants, shows each with its measured speed, and challenges the AI to debate, analyze, and outreason previous generations before producing the next round of optimizations. This reflection-and-improvement loop is the key flywheel that delivers massive speedups.\nHow Good Is CUDA-L1? Hard Data\nSpeedups Across the Board\nKernelBench—the gold-standard benchmark for GPU code generation (250 real-world PyTorch workloads)—was used to measure CUDA-L1:\n\nModel/StageAvg. SpeedupMax SpeedupMedianSuccess Rate\n\nVanilla Llama-3.1-405B0.23×3.14×0×68/250\nDeepSeek-R1 (RL-tuned)1.41×44.2×1.17×248/250\nCUDA-L1 (All Stages)3.12×120×1.42×249/250\n\n\n\n\n\n\n3.12× average speedup: The AI found improvements in virtually every task.\n120× maximum speedup: Some computational bottlenecks and inefficient code (like diagonal matrix multiplications) were transformed with fundamentally superior solutions.\nWorks across hardware: Codes optimized on NVIDIA A100 GPUs retained substantial gains ported to other architectures (L40, H100, RTX 3090, H20), with mean speedups from 2.37× to 3.12×, median gains consistently above 1.1× across all devices.\nCase Study: Discovering Hidden 64× and 120× Speedups\ndiag(A) * B—Matrix Multiplication with Diagonal\nReference (inefficient): torch.diag(A) @ B constructs a full diagonal matrix, requiring O(N²M) compute/memory.\nCUDA-L1 optimized: A.unsqueeze(1) * B leverages broadcasting, achieving only O(NM) complexity—resulting in a 64× speedup.\nWhy: The AI reasoned that allocating a full diagonal was needless; this insight was unreachable via brute-force mutation, but surfaced via comparative reflection across generated solutions.\n3D Transposed Convolution—120× Faster\nOriginal code: Performed full convolution, pooling, and activation—even when input or hyperparameters mathematically guaranteed all zeros.\nOptimized code: Used “mathematical short-circuit”—detected that given min_value=0, the output could be immediately set to zero, bypassing all computation and memory allocation. This one insight delivered orders of magnitude more speedup than hardware-level micro-optimizations.\nBusiness Impact: Why This Matters\nFor Business Leaders\nDirect Cost Savings: Every 1% speedup in GPU workloads translates to 1% less cloud GPUseconds, lower energy costs, and more model throughput. Here, the AI delivered, on average, over 200% extra compute from the same hardware investment.\nFaster Product Cycles: Automated optimization reduces the need for CUDA experts. Teams can unlock performance gains in hours, not months, and focus on features and research velocity instead of low-level tuning.\nFor AI Practitioners\nVerifiable, Open Source: All 250 optimized CUDA kernels are open-sourced. You can test the speed gains yourself across A100, H100, L40, or 3090 GPUs—no trust required.\nNo CUDA Black Magic Required: The process doesn’t rely on secret sauce, proprietary compilers, or human-in-the-loop tuning.\nFor AI Researchers\nDomain Reasoning Blueprint: Contrastive-RL offers a new approach to training AI in domains where correctness and performance—not just natural language—matter.\nReward Hacking: The authors deep dive into how the AI discovered subtle exploits and “cheats” (like asynchronous stream manipulation for false speedups) and outline robust procedures to detect and prevent such behavior.\nTechnical Insights: Why Contrastive-RL Wins\nPerformance feedback is now in-context: Unlike vanilla RL, the AI can learn not just by trial and error, but by reasoned self-critique.\nSelf-improvement flywheel: The reflection loop makes the model robust to reward gaming and outperforms both evolutionary approaches (fixed parameter, in-context contrastive learning) and traditional RL (blind policy gradient).\nGeneralizes & discovers fundamental principles: The AI can combine, rank, and apply key optimization strategies like memory coalescing, thread block configuration, operation fusion, shared memory reuse, warp-level reductions, and mathematical equivalence transformations.\nTable: Top Techniques Discovered by CUDA-L1\n\nOptimization TechniqueTypical SpeedupExample Insight\n\nMemory Layout OptimizationConsistent boostsContiguous memory/storage for cache efficiency\nMemory Access (Coalescing, Shared)Moderate-to-highAvoids bank conflicts, maximizes bandwidth\nOperation FusionHigh w/ pipelined opsFused multi-op kernels reduce memory reads/writes\nMathematical Short-circuitingExtremely high (10-100×)Detects when computation can be skipped entirely\nThread Block/Parallel ConfigModerateAdapts block sizes/shapes to hardware/task\nWarp-Level/Branchless ReductionsModerateLowers divergence and sync overhead\nRegister/Shared Memory OptimizationModerate-highCaches frequent data close to computation\nAsync Execution, Minimal SyncVariesOverlaps I/O, enables pipelined computation\n\n\n\n\n\nConclusion: AI Is Now Its Own Optimization Engineer\nWith CUDA-L1, AI has become its own performance engineer, accelerating research productivity and hardware returns—without relying on rare human expertise. The result is not just higher benchmarks, but a blueprint for AI systems that teach themselves how to harness the full potential of the hardware they run on.\nAI is now building its own flywheel: more efficient, more insightful, and better able to maximize the resources we give it—for science, industry, and beyond.\nCheck out the Paper, Codes and Project Page. Feel free to check out our GitHub Page for Tutorials, Codes and Notebooks. Also, feel free to follow us on Twitter and don’t forget to join our 100k+ ML SubReddit and Subscribe to our Newsletter.\nThe post DeepReinforce Team Introduces CUDA-L1: An Automated Reinforcement Learning (RL) Framework for CUDA Optimization Unlocking 3x More Power from GPUs appeared first on MarkTechPost.",
          "dc:creator": "Asif Razzaq",
          "comments": "https://www.marktechpost.com/2025/08/02/deepreinforce-team-introduces-cuda-l1-an-automated-reinforcement-learning-rl-framework-for-cuda-optimization-unlocking-3x-more-power-from-gpus/#respond",
          "content": "<p>AI has just unlocked triple the power from GPUs—without human intervention. DeepReinforce Team introduced a new framework called CUDA-L1 that delivers an average 3.12× speedup and up to 120× peak acceleration across 250 real-world GPU tasks. This is not mere academic promise: every result can be reproduced with open-source code, on widely used NVIDIA hardware. [&#8230;]</p>\n<p>The post <a href=\"https://www.marktechpost.com/2025/08/02/deepreinforce-team-introduces-cuda-l1-an-automated-reinforcement-learning-rl-framework-for-cuda-optimization-unlocking-3x-more-power-from-gpus/\">DeepReinforce Team Introduces CUDA-L1: An Automated Reinforcement Learning (RL) Framework for CUDA Optimization Unlocking 3x More Power from GPUs</a> appeared first on <a href=\"https://www.marktechpost.com\">MarkTechPost</a>.</p>\n",
          "contentSnippet": "AI has just unlocked triple the power from GPUs—without human intervention. DeepReinforce Team introduced a new framework called CUDA-L1 that delivers an average 3.12× speedup and up to 120× peak acceleration across 250 real-world GPU tasks. This is not mere academic promise: every result can be reproduced with open-source code, on widely used NVIDIA hardware. […]\nThe post DeepReinforce Team Introduces CUDA-L1: An Automated Reinforcement Learning (RL) Framework for CUDA Optimization Unlocking 3x More Power from GPUs appeared first on MarkTechPost.",
          "guid": "https://www.marktechpost.com/?p=73170",
          "categories": [
            "AI Paper Summary",
            "AI Shorts",
            "Applications",
            "Artificial Intelligence",
            "Editors Pick",
            "Language Model",
            "Machine Learning",
            "Staff",
            "Tech News",
            "Technology"
          ],
          "isoDate": "2025-08-03T05:56:31.000Z"
        }
      },
      {
        "json": {
          "creator": "Asif Razzaq",
          "title": "Google AI Releases MLE-STAR: A State-of-the-Art Machine Learning Engineering Agent Capable of Automating Various AI Tasks",
          "link": "https://www.marktechpost.com/2025/08/02/google-ai-releases-mle-star-a-state-of-the-art-machine-learning-engineering-agent-capable-of-automating-various-ai-tasks/",
          "pubDate": "Sun, 03 Aug 2025 03:20:59 +0000",
          "content:encoded": "\n<p><strong>MLE-STAR (Machine Learning Engineering via Search and Targeted Refinement)</strong> is a state-of-the-art agent system developed by Google Cloud researchers to automate complex machine learning ML pipeline design and optimization. By leveraging web-scale search, targeted code refinement, and robust checking modules, MLE-STAR achieves unparalleled performance on a range of machine learning engineering tasks—significantly outperforming previous autonomous ML agents and even human baseline methods.</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"the-problem-automating-machine-learning-engineerin\"><strong>The Problem: Automating Machine Learning Engineering</strong></h3>\n\n\n\n<p>While large language models (LLMs) have made inroads into code generation and workflow automation, existing ML engineering agents struggle with:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Overreliance on LLM memory:</strong> Tending to default to “familiar” models (e.g., using only scikit-learn for tabular data), overlooking cutting-edge, task-specific approaches.</li>\n\n\n\n<li><strong>Coarse “all-at-once” iteration:</strong> Previous agents modify whole scripts in one shot, lacking deep, targeted exploration of pipeline components like feature engineering, data preprocessing, or model ensembling.</li>\n\n\n\n<li><strong>Poor error and leakage handling:</strong> Generated code is prone to bugs, data leakage, or omission of provided data files.</li>\n</ul>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"mle-star-core-innovations\"><strong>MLE-STAR: Core Innovations</strong></h3>\n\n\n\n<p>MLE-STAR introduces several key advances over prior solutions:</p>\n\n\n\n<h4 class=\"wp-block-heading\"><strong>1. Web Search–Guided Model Selection</strong></h4>\n\n\n\n<p>Instead of drawing solely from its internal “training,” MLE-STAR uses external search to <strong>retrieve state-of-the-art models and code snippets</strong> relevant to the provided task and dataset. It anchors the initial solution in current best practices, not just what LLMs “remember”.</p>\n\n\n\n<h4 class=\"wp-block-heading\"><strong>2. Nested, Targeted Code Refinement</strong></h4>\n\n\n\n<p>MLE-STAR improves its solutions via a <strong>two-loop refinement process</strong>:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Outer Loop (Ablation-driven):</strong> Runs ablation studies on the evolving code to identify which pipeline component (data prep, model, feature engineering, etc.) most impacts performance.</li>\n\n\n\n<li><strong>Inner Loop (Focused Exploration):</strong> Iteratively generates and tests variations for just that component, using structured feedback.</li>\n</ul>\n\n\n\n<p>This enables deep, component-wise exploration—e.g., extensively testing ways to extract and encode categorical features rather than blindly changing everything at once.</p>\n\n\n\n<h4 class=\"wp-block-heading\"><strong>3. Self-Improving Ensembling Strategy</strong></h4>\n\n\n\n<p>MLE-STAR proposes, implements, and refines novel ensemble methods by combining multiple candidate solutions. Rather than just “best-of-N” voting or simple averages, it uses its planning abilities to explore advanced strategies (e.g., stacking with bespoke meta-learners or optimized weight search).</p>\n\n\n\n<h4 class=\"wp-block-heading\"><strong>4. Robustness through Specialized Agents</strong></h4>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Debugging Agent:</strong> Automatically catches and corrects Python errors (tracebacks) until the script runs or maximum attempts are reached.</li>\n\n\n\n<li><strong>Data Leakage Checker:</strong> Inspects code to prevent information from test or validation samples biasing the training process.</li>\n\n\n\n<li><strong>Data Usage Checker:</strong> Ensures the solution script maximizes the use of all provided data files and relevant modalities, improving model performance and generalizability.</li>\n</ul>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-large is-resized\"><img decoding=\"async\" width=\"1024\" height=\"876\" data-attachment-id=\"73164\" data-permalink=\"https://www.marktechpost.com/2025/08/02/google-ai-releases-mle-star-a-state-of-the-art-machine-learning-engineering-agent-capable-of-automating-various-ai-tasks/screenshot-2025-08-02-at-8-17-34-pm-2/\" data-orig-file=\"https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-8.17.34-PM-1.png\" data-orig-size=\"1476,1262\" data-comments-opened=\"1\" data-image-meta=\"{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}\" data-image-title=\"Screenshot 2025-08-02 at 8.17.34 PM\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-8.17.34-PM-1-300x257.png\" data-large-file=\"https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-8.17.34-PM-1-1024x876.png\" src=\"https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-8.17.34-PM-1-1024x876.png\" alt=\"\" class=\"wp-image-73164\" style=\"width:736px;height:auto\" srcset=\"https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-8.17.34-PM-1-1024x876.png 1024w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-8.17.34-PM-1-300x257.png 300w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-8.17.34-PM-1-768x657.png 768w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-8.17.34-PM-1-491x420.png 491w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-8.17.34-PM-1-150x128.png 150w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-8.17.34-PM-1-696x595.png 696w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-8.17.34-PM-1-1068x913.png 1068w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-8.17.34-PM-1.png 1476w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" /></figure></div>\n\n\n<h3 class=\"wp-block-heading\" id=\"quantitative-results-outperforming-the-field\"><strong>Quantitative Results: Outperforming the Field</strong></h3>\n\n\n\n<p>MLE-STAR’s effectiveness is rigorously validated on the <strong>MLE-Bench-Lite</strong> benchmark (22 challenging Kaggle competitions spanning tabular, image, audio, and text tasks):</p>\n\n\n\n<figure class=\"wp-block-table\"><table class=\"has-fixed-layout\"><thead><tr><th>Metric</th><th>MLE-STAR (Gemini-2.5-Pro)</th><th>AIDE (Best Baseline)</th></tr></thead><tbody><tr><td><strong>Any Medal Rate</strong></td><td>63.6%</td><td>25.8%</td></tr><tr><td><strong>Gold Medal Rate</strong></td><td>36.4%</td><td>12.1%</td></tr><tr><td><strong>Above Median</strong></td><td>83.3%</td><td>39.4%</td></tr><tr><td><strong>Valid Submission</strong></td><td>100%</td><td>78.8%</td></tr></tbody></table></figure>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>MLE-STAR achieves more than double the rate of “medal” (top-tier) solutions</strong> compared to previous best agents.</li>\n\n\n\n<li>On image tasks, MLE-STAR overwhelmingly chooses modern architectures (EfficientNet, ViT), leaving older standbys like ResNet behind, directly translating to higher podium rates.</li>\n\n\n\n<li>The ensemble strategy alone contributes a further boost, not just picking but combining winning solutions.</li>\n</ul>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-large is-resized\"><img decoding=\"async\" width=\"1024\" height=\"819\" data-attachment-id=\"73166\" data-permalink=\"https://www.marktechpost.com/2025/08/02/google-ai-releases-mle-star-a-state-of-the-art-machine-learning-engineering-agent-capable-of-automating-various-ai-tasks/screenshot-2025-08-02-at-8-17-56-pm-2/\" data-orig-file=\"https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-8.17.56-PM-1.png\" data-orig-size=\"1528,1222\" data-comments-opened=\"1\" data-image-meta=\"{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}\" data-image-title=\"Screenshot 2025-08-02 at 8.17.56 PM\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-8.17.56-PM-1-300x240.png\" data-large-file=\"https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-8.17.56-PM-1-1024x819.png\" src=\"https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-8.17.56-PM-1-1024x819.png\" alt=\"\" class=\"wp-image-73166\" style=\"width:710px;height:auto\" srcset=\"https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-8.17.56-PM-1-1024x819.png 1024w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-8.17.56-PM-1-300x240.png 300w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-8.17.56-PM-1-768x614.png 768w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-8.17.56-PM-1-525x420.png 525w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-8.17.56-PM-1-150x120.png 150w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-8.17.56-PM-1-696x557.png 696w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-8.17.56-PM-1-1068x854.png 1068w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-8.17.56-PM-1.png 1528w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" /></figure></div>\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-large is-resized\"><img decoding=\"async\" width=\"1024\" height=\"393\" data-attachment-id=\"73168\" data-permalink=\"https://www.marktechpost.com/2025/08/02/google-ai-releases-mle-star-a-state-of-the-art-machine-learning-engineering-agent-capable-of-automating-various-ai-tasks/screenshot-2025-08-02-at-8-18-44-pm-2/\" data-orig-file=\"https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-8.18.44-PM-1.png\" data-orig-size=\"1512,580\" data-comments-opened=\"1\" data-image-meta=\"{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}\" data-image-title=\"Screenshot 2025-08-02 at 8.18.44 PM\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-8.18.44-PM-1-300x115.png\" data-large-file=\"https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-8.18.44-PM-1-1024x393.png\" src=\"https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-8.18.44-PM-1-1024x393.png\" alt=\"\" class=\"wp-image-73168\" style=\"width:720px;height:auto\" srcset=\"https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-8.18.44-PM-1-1024x393.png 1024w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-8.18.44-PM-1-300x115.png 300w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-8.18.44-PM-1-768x295.png 768w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-8.18.44-PM-1-1095x420.png 1095w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-8.18.44-PM-1-150x58.png 150w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-8.18.44-PM-1-696x267.png 696w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-8.18.44-PM-1-1068x410.png 1068w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-8.18.44-PM-1.png 1512w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" /></figure></div>\n\n\n<h3 class=\"wp-block-heading\" id=\"technical-insights-why-mle-star-wins\"><strong>Technical Insights: Why MLE-STAR Wins</strong></h3>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Search as Foundation:</strong> By pulling example code and model cards from the web at run time, MLE-STAR stays far more up to date—automatically including new model types in its initial proposals.</li>\n\n\n\n<li><strong>Ablation-Guided Focus:</strong> Systematically measuring the contribution of each code segment allows “surgical” improvements—first on the most impactful pieces (e.g., targeted feature encodings, advanced model-specific preprocessing).</li>\n\n\n\n<li><strong>Adaptive Ensembling:</strong> The ensemble agent doesn’t just average; it intelligently tests stacking, regression meta-learners, optimal weighting, and more.</li>\n\n\n\n<li><strong>Rigorous Safety Checks:</strong> Error correction, data leakage prevention, and full data usage unlock much higher validation and test scores, avoiding pitfalls that trip up vanilla LLM code generation.</li>\n</ul>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"extensibility-and-human-in-the-loop\"><strong>Extensibility and Human-in-the-loop</strong></h3>\n\n\n\n<p>MLE-STAR is also extensible:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Human experts can inject cutting-edge model descriptions for faster adoption of the latest architectures.</li>\n\n\n\n<li>The system is built atop Google’s <strong>Agent Development Kit (ADK)</strong>, facilitating open-source adoption and integration into broader agent ecosystems, as shown in the <a href=\"https://github.com/google/adk-samples/tree/main/python/agents/machine-learning-engineering\" target=\"_blank\" rel=\"noreferrer noopener\">official samples</a>.</li>\n</ul>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"conclusion\"><strong>Conclusion</strong></h3>\n\n\n\n<p><strong>MLE-STAR represents a true leap in the automation of machine learning engineering.</strong> By enforcing a workflow that begins with search, tests code via ablation-driven loops, blends solutions with adaptive ensembling, and polices code outputs with specialized agents, it outperforms prior art and even many human competitors. Its open-source codebase means that researchers and ML practitioners can now integrate and extend these state-of-the-art capabilities in their own projects, accelerating both productivity and innovation.</p>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity\"/>\n\n\n\n<p>Check out the <strong><a href=\"https://www.arxiv.org/abs/2506.15692\" target=\"_blank\" rel=\"noreferrer noopener\">Paper</a>, <a href=\"https://github.com/google/adk-samples/tree/main/python/agents/machine-learning-engineering\" target=\"_blank\" rel=\"noreferrer noopener\">GitHub Page</a> </strong>and<strong> <a href=\"https://research.google/blog/mle-star-a-state-of-the-art-machine-learning-engineering-agents/\" target=\"_blank\" rel=\"noreferrer noopener\">Technical details</a><em>.</em></strong> Feel free to check out our <strong><mark><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included\" target=\"_blank\" rel=\"noreferrer noopener\">GitHub Page for Tutorials, Codes and Notebooks</a></mark></strong>. Also, feel free to follow us on <strong><a href=\"https://x.com/intent/follow?screen_name=marktechpost\" target=\"_blank\" rel=\"noreferrer noopener\"><mark>Twitter</mark></a></strong> and don’t forget to join our <strong><a href=\"https://www.reddit.com/r/machinelearningnews/\" target=\"_blank\" rel=\"noreferrer noopener\">100k+ ML SubReddit</a></strong> and Subscribe to <strong><a href=\"https://www.aidevsignals.com/\" target=\"_blank\" rel=\"noreferrer noopener\">our Newsletter</a></strong>.</p>\n<p>The post <a href=\"https://www.marktechpost.com/2025/08/02/google-ai-releases-mle-star-a-state-of-the-art-machine-learning-engineering-agent-capable-of-automating-various-ai-tasks/\">Google AI Releases MLE-STAR: A State-of-the-Art Machine Learning Engineering Agent Capable of Automating Various AI Tasks</a> appeared first on <a href=\"https://www.marktechpost.com\">MarkTechPost</a>.</p>\n",
          "content:encodedSnippet": "MLE-STAR (Machine Learning Engineering via Search and Targeted Refinement) is a state-of-the-art agent system developed by Google Cloud researchers to automate complex machine learning ML pipeline design and optimization. By leveraging web-scale search, targeted code refinement, and robust checking modules, MLE-STAR achieves unparalleled performance on a range of machine learning engineering tasks—significantly outperforming previous autonomous ML agents and even human baseline methods.\nThe Problem: Automating Machine Learning Engineering\nWhile large language models (LLMs) have made inroads into code generation and workflow automation, existing ML engineering agents struggle with:\nOverreliance on LLM memory: Tending to default to “familiar” models (e.g., using only scikit-learn for tabular data), overlooking cutting-edge, task-specific approaches.\nCoarse “all-at-once” iteration: Previous agents modify whole scripts in one shot, lacking deep, targeted exploration of pipeline components like feature engineering, data preprocessing, or model ensembling.\nPoor error and leakage handling: Generated code is prone to bugs, data leakage, or omission of provided data files.\nMLE-STAR: Core Innovations\nMLE-STAR introduces several key advances over prior solutions:\n1. Web Search–Guided Model Selection\nInstead of drawing solely from its internal “training,” MLE-STAR uses external search to retrieve state-of-the-art models and code snippets relevant to the provided task and dataset. It anchors the initial solution in current best practices, not just what LLMs “remember”.\n2. Nested, Targeted Code Refinement\nMLE-STAR improves its solutions via a two-loop refinement process:\nOuter Loop (Ablation-driven): Runs ablation studies on the evolving code to identify which pipeline component (data prep, model, feature engineering, etc.) most impacts performance.\nInner Loop (Focused Exploration): Iteratively generates and tests variations for just that component, using structured feedback.\nThis enables deep, component-wise exploration—e.g., extensively testing ways to extract and encode categorical features rather than blindly changing everything at once.\n3. Self-Improving Ensembling Strategy\nMLE-STAR proposes, implements, and refines novel ensemble methods by combining multiple candidate solutions. Rather than just “best-of-N” voting or simple averages, it uses its planning abilities to explore advanced strategies (e.g., stacking with bespoke meta-learners or optimized weight search).\n4. Robustness through Specialized Agents\nDebugging Agent: Automatically catches and corrects Python errors (tracebacks) until the script runs or maximum attempts are reached.\nData Leakage Checker: Inspects code to prevent information from test or validation samples biasing the training process.\nData Usage Checker: Ensures the solution script maximizes the use of all provided data files and relevant modalities, improving model performance and generalizability.\n\nQuantitative Results: Outperforming the Field\nMLE-STAR’s effectiveness is rigorously validated on the MLE-Bench-Lite benchmark (22 challenging Kaggle competitions spanning tabular, image, audio, and text tasks):\n\nMetricMLE-STAR (Gemini-2.5-Pro)AIDE (Best Baseline)\n\nAny Medal Rate63.6%25.8%\nGold Medal Rate36.4%12.1%\nAbove Median83.3%39.4%\nValid Submission100%78.8%\n\n\n\n\n\n\nMLE-STAR achieves more than double the rate of “medal” (top-tier) solutions compared to previous best agents.\nOn image tasks, MLE-STAR overwhelmingly chooses modern architectures (EfficientNet, ViT), leaving older standbys like ResNet behind, directly translating to higher podium rates.\nThe ensemble strategy alone contributes a further boost, not just picking but combining winning solutions.\n\n\nTechnical Insights: Why MLE-STAR Wins\nSearch as Foundation: By pulling example code and model cards from the web at run time, MLE-STAR stays far more up to date—automatically including new model types in its initial proposals.\nAblation-Guided Focus: Systematically measuring the contribution of each code segment allows “surgical” improvements—first on the most impactful pieces (e.g., targeted feature encodings, advanced model-specific preprocessing).\nAdaptive Ensembling: The ensemble agent doesn’t just average; it intelligently tests stacking, regression meta-learners, optimal weighting, and more.\nRigorous Safety Checks: Error correction, data leakage prevention, and full data usage unlock much higher validation and test scores, avoiding pitfalls that trip up vanilla LLM code generation.\nExtensibility and Human-in-the-loop\nMLE-STAR is also extensible:\nHuman experts can inject cutting-edge model descriptions for faster adoption of the latest architectures.\nThe system is built atop Google’s Agent Development Kit (ADK), facilitating open-source adoption and integration into broader agent ecosystems, as shown in the official samples.\nConclusion\nMLE-STAR represents a true leap in the automation of machine learning engineering. By enforcing a workflow that begins with search, tests code via ablation-driven loops, blends solutions with adaptive ensembling, and polices code outputs with specialized agents, it outperforms prior art and even many human competitors. Its open-source codebase means that researchers and ML practitioners can now integrate and extend these state-of-the-art capabilities in their own projects, accelerating both productivity and innovation.\nCheck out the Paper, GitHub Page and Technical details. Feel free to check out our GitHub Page for Tutorials, Codes and Notebooks. Also, feel free to follow us on Twitter and don’t forget to join our 100k+ ML SubReddit and Subscribe to our Newsletter.\nThe post Google AI Releases MLE-STAR: A State-of-the-Art Machine Learning Engineering Agent Capable of Automating Various AI Tasks appeared first on MarkTechPost.",
          "dc:creator": "Asif Razzaq",
          "comments": "https://www.marktechpost.com/2025/08/02/google-ai-releases-mle-star-a-state-of-the-art-machine-learning-engineering-agent-capable-of-automating-various-ai-tasks/#respond",
          "content": "<p>MLE-STAR (Machine Learning Engineering via Search and Targeted Refinement) is a state-of-the-art agent system developed by Google Cloud researchers to automate complex machine learning ML pipeline design and optimization. By leveraging web-scale search, targeted code refinement, and robust checking modules, MLE-STAR achieves unparalleled performance on a range of machine learning engineering tasks—significantly outperforming previous autonomous [&#8230;]</p>\n<p>The post <a href=\"https://www.marktechpost.com/2025/08/02/google-ai-releases-mle-star-a-state-of-the-art-machine-learning-engineering-agent-capable-of-automating-various-ai-tasks/\">Google AI Releases MLE-STAR: A State-of-the-Art Machine Learning Engineering Agent Capable of Automating Various AI Tasks</a> appeared first on <a href=\"https://www.marktechpost.com\">MarkTechPost</a>.</p>\n",
          "contentSnippet": "MLE-STAR (Machine Learning Engineering via Search and Targeted Refinement) is a state-of-the-art agent system developed by Google Cloud researchers to automate complex machine learning ML pipeline design and optimization. By leveraging web-scale search, targeted code refinement, and robust checking modules, MLE-STAR achieves unparalleled performance on a range of machine learning engineering tasks—significantly outperforming previous autonomous […]\nThe post Google AI Releases MLE-STAR: A State-of-the-Art Machine Learning Engineering Agent Capable of Automating Various AI Tasks appeared first on MarkTechPost.",
          "guid": "https://www.marktechpost.com/?p=73161",
          "categories": [
            "Agentic AI",
            "AI Agents",
            "AI Paper Summary",
            "AI Shorts",
            "Applications",
            "Artificial Intelligence",
            "Editors Pick",
            "Language Model",
            "Large Language Model",
            "Machine Learning",
            "New Releases",
            "Staff",
            "Tech News",
            "Technology"
          ],
          "isoDate": "2025-08-03T03:20:59.000Z"
        }
      },
      {
        "json": {
          "creator": "Sana Hassan",
          "title": "MIT Researchers Develop Methods to Control Transformer Sensitivity with Provable Lipschitz Bounds and Muon",
          "link": "https://www.marktechpost.com/2025/08/02/mit-researchers-develop-methods-to-control-transformer-sensitivity-with-provable-lipschitz-bounds-and-muon/",
          "pubDate": "Sat, 02 Aug 2025 20:54:12 +0000",
          "content:encoded": "\n<p><strong>Training large-scale transformers stably</strong> has been a longstanding challenge in <a href=\"https://www.marktechpost.com/2025/01/15/what-is-deep-learning-2/\" target=\"_blank\">deep learning</a>, particularly as models grow in size and expressivity. <strong>MIT researchers tackle a persistent problem at its root: the <em>unstable growth of activations</em> and loss spikes caused by unconstrained weight and activation norms.</strong> Their solution is to enforce <em>provable Lipschitz bounds</em> on the transformer by *spectrally regulating the weights—*with no use of activation normalization, QK norm, or logit softcapping tricks.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-large is-resized\"><img decoding=\"async\" width=\"1024\" height=\"572\" data-attachment-id=\"73157\" data-permalink=\"https://www.marktechpost.com/2025/08/02/mit-researchers-develop-methods-to-control-transformer-sensitivity-with-provable-lipschitz-bounds-and-muon/screenshot-2025-08-02-at-1-51-26-pm-2/\" data-orig-file=\"https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-1.51.26-PM-1.png\" data-orig-size=\"1646,920\" data-comments-opened=\"1\" data-image-meta=\"{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}\" data-image-title=\"Screenshot 2025-08-02 at 1.51.26 PM\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-1.51.26-PM-1-300x168.png\" data-large-file=\"https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-1.51.26-PM-1-1024x572.png\" src=\"https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-1.51.26-PM-1-1024x572.png\" alt=\"\" class=\"wp-image-73157\" style=\"width:858px;height:auto\" srcset=\"https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-1.51.26-PM-1-1024x572.png 1024w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-1.51.26-PM-1-300x168.png 300w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-1.51.26-PM-1-768x429.png 768w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-1.51.26-PM-1-1536x859.png 1536w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-1.51.26-PM-1-751x420.png 751w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-1.51.26-PM-1-150x84.png 150w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-1.51.26-PM-1-696x389.png 696w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-1.51.26-PM-1-1068x597.png 1068w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-1.51.26-PM-1.png 1646w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" /></figure></div>\n\n\n<h3 class=\"wp-block-heading\"><strong>What is a Lipschitz Bound—and Why Enforce It?</strong></h3>\n\n\n\n<p>A <strong>Lipschitz bound</strong> on a neural network quantifies the maximum amount by which the output can change in response to input (or weight) perturbations. Mathematically, a function fff is KKK-Lipschitz if:∥f(x1)−f(x2)∥≤K∥x1−x2∥&nbsp;∀x1,x2|f(x_1) &#8211; f(x_2)| leq K |x_1 &#8211; x_2|  forall x_1, x_2∥f(x1)−f(x2)∥≤K∥x1−x2∥&nbsp;∀x1,x2</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Lower Lipschitz bound ⇒ greater robustness and predictability.</strong></li>\n\n\n\n<li>It is crucial for stability, adversarial robustness, privacy, and generalization, with lower bounds meaning the network is less sensitive to changes or adversarial noise.</li>\n</ul>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>Motivation and Problem Statement</strong></h3>\n\n\n\n<p>Traditionally, training stable transformers at scale has involved <em>a variety of “band-aid” stabilization tricks</em>:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Layer normalization</strong></li>\n\n\n\n<li><strong>QK normalization</strong></li>\n\n\n\n<li><strong>Logit tanh softcapping</strong></li>\n</ul>\n\n\n\n<p>But these do not directly address the underlying spectral norm (largest singular value) growth in the weights, a root cause of exploding activations and training instability—especially in large models.</p>\n\n\n\n<p>The <strong>central hypothesis</strong>: <strong>If we spectrally regulate the weights themselves—beyond just the optimizer or activations—we can maintain tight control over Lipschitzness, potentially solving instability at its source.</strong></p>\n\n\n\n<h2 class=\"wp-block-heading\"><strong>Key Innovations</strong></h2>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>Weight Spectral Regulation and the Muon Optimizer</strong></h3>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Muon</strong> optimizer spectrally regularizes <em>gradients</em>, ensuring each gradient step does not increase the spectral norm beyond a set limit.</li>\n\n\n\n<li>The researchers <strong>extend regulation to the weights</strong>: After each step, they apply operations to <em>cap the singular values</em> of every weight matrix. <strong>Activation norms stay remarkably small</strong> as a result—rarely exceeding values compatible with fp8 precision in their GPT-2 scale transformers.</li>\n</ul>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>Removing Stability Tricks</strong></h3>\n\n\n\n<p>In all experiments, <strong>no layer normalization, no QK norm, no logit tanh were used.</strong> Yet,</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Maximum activation entries in <em>their GPT-2 scale transformer never exceeded ~100,</em> while the unconstrained baseline surpassed 148,000.</li>\n</ul>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>Table Sample (NanoGPT Experiment)</strong></h3>\n\n\n\n<figure class=\"wp-block-table\"><table class=\"has-fixed-layout\"><thead><tr><th>Model</th><th>Max Activation</th><th>Layer Stability Tricks</th><th>Validation Accuracy</th><th>Lipschitz Bound</th></tr></thead><tbody><tr><td>Baseline (Speedrun)</td><td>148,480</td><td>Yes</td><td>39.4%</td><td>∞</td></tr><tr><td>Lipschitz Transformer</td><td>160</td><td>None</td><td>39.5%</td><td>10¹⁰²⁶⁴</td></tr></tbody></table></figure>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>Methods for Enforcing Lipschitz Constraints</strong></h3>\n\n\n\n<p>A variety of <em>weight norm constraint methods</em> were explored and compared for their ability to:</p>\n\n\n\n<ol class=\"wp-block-list\">\n<li><strong>Maintain high performance</strong>,</li>\n\n\n\n<li><strong>Guarantee a Lipschitz bound</strong>, and</li>\n\n\n\n<li><strong>Optimize the performance-Lipschitz tradeoff.</strong></li>\n</ol>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-large is-resized\"><img decoding=\"async\" width=\"1024\" height=\"678\" data-attachment-id=\"73159\" data-permalink=\"https://www.marktechpost.com/2025/08/02/mit-researchers-develop-methods-to-control-transformer-sensitivity-with-provable-lipschitz-bounds-and-muon/screenshot-2025-08-02-at-1-51-56-pm-2/\" data-orig-file=\"https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-1.51.56-PM-1.png\" data-orig-size=\"1640,1086\" data-comments-opened=\"1\" data-image-meta=\"{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}\" data-image-title=\"Screenshot 2025-08-02 at 1.51.56 PM\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-1.51.56-PM-1-300x199.png\" data-large-file=\"https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-1.51.56-PM-1-1024x678.png\" src=\"https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-1.51.56-PM-1-1024x678.png\" alt=\"\" class=\"wp-image-73159\" style=\"width:840px;height:auto\" srcset=\"https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-1.51.56-PM-1-1024x678.png 1024w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-1.51.56-PM-1-300x199.png 300w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-1.51.56-PM-1-768x509.png 768w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-1.51.56-PM-1-1536x1017.png 1536w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-1.51.56-PM-1-634x420.png 634w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-1.51.56-PM-1-150x99.png 150w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-1.51.56-PM-1-696x461.png 696w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-1.51.56-PM-1-1068x707.png 1068w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-02-at-1.51.56-PM-1.png 1640w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" /></figure></div>\n\n\n<h3 class=\"wp-block-heading\"><strong>Techniques</strong></h3>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Weight Decay</strong>: Standard method, but not always strict on spectral norm.</li>\n\n\n\n<li><strong>Spectral Normalization</strong>: Ensures top singular value is capped, but may affect all singular values globally.</li>\n\n\n\n<li><strong>Spectral Soft Cap</strong>: Novel method, smoothly and efficiently applies σ→min⁡(σmax,σ)sigma to min(sigma_{text{max}}, sigma)σ→min(σmax,σ) to all singular values in parallel (using odd polynomial approximations). This is co-designed for Muon’s high stable-rank updates for tight bounds.</li>\n\n\n\n<li><strong>Spectral Hammer</strong>: Sets only the largest singular value to σmaxsigma_{text{max}}σmax, best suited for AdamW optimizer.</li>\n</ul>\n\n\n\n<h2 class=\"wp-block-heading\"><strong>Experimental Results and Insights</strong></h2>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>Model Evaluation at Various Scales</strong></h3>\n\n\n\n<ol class=\"wp-block-list\">\n<li><strong>Shakespeare (Small Transformer, &lt;2-Lipschitz):</strong>\n<ul class=\"wp-block-list\">\n<li>Achieves 60% validation accuracy with a provable Lipschitz bound below.</li>\n\n\n\n<li>Outperforms unconstrained baseline in validation loss.</li>\n</ul>\n</li>\n\n\n\n<li><strong>NanoGPT (145M Parameters):</strong>\n<ul class=\"wp-block-list\">\n<li>With a Lipschitz bound &lt;10, validation accuracy: 21.2%.</li>\n\n\n\n<li>To <em>match</em> the strong unconstrained baseline (39.4% accuracy), <strong>required a large upper bound of 1026410^{264}10264</strong>. This highlights how strict Lipschitz constraints often trade off with expressivity at large scales for now.</li>\n</ul>\n</li>\n</ol>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>Weight Constraint Method Efficiency</strong></h3>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Muon + Spectral Cap</strong>: <em>Leads the tradeoff frontier</em>—lower Lipschitz constants for matched or better validation loss compared to AdamW + weight decay.</li>\n\n\n\n<li><strong>Spectral soft cap and normalization</strong> (under Muon) consistently enable best frontier on the loss-Lipschitz tradeoff.</li>\n</ul>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>Stability and Robustness</strong></h3>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Adversarial robustness</strong> increases sharply at lower Lipschitz bounds.</li>\n\n\n\n<li>In experiments, models with a constrained Lipschitz constant suffered much milder accuracy drop under adversarial attack compared to unconstrained baselines.</li>\n</ul>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>Activation Magnitudes</strong></h3>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>With spectral weight regulation:</strong> Maximum activations remain tiny (near-fp8 compatible), compared to the unbounded baselines, even at scale.</li>\n\n\n\n<li>This opens avenues for <strong>low-precision training and inference</strong> in hardware, where smaller activations reduce compute, memory, and power costs.</li>\n</ul>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>Limitations and Open Questions</strong></h3>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Selecting the “tightest” tradeoff</strong> for weight norms, logit scaling, and attention scaling still relies on sweeps, not principle.</li>\n\n\n\n<li><strong>Current upper-bounding is loose</strong>: Calculated global bounds can be astronomically large (e.g. 1026410^{264}10264), while real activation norms remain small.</li>\n\n\n\n<li>It’s unclear if matching unconstrained baseline performance with strictly small Lipschitz bounds is possible as scale increases—<em>more research needed</em>.</li>\n</ul>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>Conclusion</strong></h3>\n\n\n\n<p><strong>Spectral weight regulation—especially when paired with the Muon optimizer—can stably train large transformers with enforced Lipschitz bounds, without activation normalization or other band-aid tricks.</strong> This addresses instability at a deeper level and keeps activations in a compact, predictable range, greatly improving adversarial robustness and potentially hardware efficiency.</p>\n\n\n\n<p>This line of work points to new, efficient computational primitives for neural network regulation, with broad applications for privacy, safety, and low-precision AI deployment.</p>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity\"/>\n\n\n\n<p>Check out the <strong><a href=\"https://arxiv.org/abs/2507.13338\" target=\"_blank\" rel=\"noreferrer noopener\">Paper</a>, <a href=\"https://github.com/Arongil/lipschitz-transformers\" target=\"_blank\" rel=\"noreferrer noopener\">GitHub Page</a> and <a href=\"https://huggingface.co/phess2/lipschitz-transformers\" target=\"_blank\" rel=\"noreferrer noopener\">Hugging Face Project Page</a><em>.</em></strong> Feel free to check out our <strong><mark><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included\" target=\"_blank\" rel=\"noreferrer noopener\">GitHub Page for Tutorials, Codes and Notebooks</a></mark></strong>. Also, feel free to follow us on <strong><a href=\"https://x.com/intent/follow?screen_name=marktechpost\" target=\"_blank\" rel=\"noreferrer noopener\"><mark>Twitter</mark></a></strong> and don’t forget to join our <strong><a href=\"https://www.reddit.com/r/machinelearningnews/\" target=\"_blank\" rel=\"noreferrer noopener\">100k+ ML SubReddit</a></strong> and Subscribe to <strong><a href=\"https://www.aidevsignals.com/\" target=\"_blank\" rel=\"noreferrer noopener\">our Newsletter</a></strong>.</p>\n<p>The post <a href=\"https://www.marktechpost.com/2025/08/02/mit-researchers-develop-methods-to-control-transformer-sensitivity-with-provable-lipschitz-bounds-and-muon/\">MIT Researchers Develop Methods to Control Transformer Sensitivity with Provable Lipschitz Bounds and Muon</a> appeared first on <a href=\"https://www.marktechpost.com\">MarkTechPost</a>.</p>\n",
          "content:encodedSnippet": "Training large-scale transformers stably has been a longstanding challenge in deep learning, particularly as models grow in size and expressivity. MIT researchers tackle a persistent problem at its root: the unstable growth of activations and loss spikes caused by unconstrained weight and activation norms. Their solution is to enforce provable Lipschitz bounds on the transformer by *spectrally regulating the weights—*with no use of activation normalization, QK norm, or logit softcapping tricks.\n\nWhat is a Lipschitz Bound—and Why Enforce It?\nA Lipschitz bound on a neural network quantifies the maximum amount by which the output can change in response to input (or weight) perturbations. Mathematically, a function fff is KKK-Lipschitz if:∥f(x1)−f(x2)∥≤K∥x1−x2∥ ∀x1,x2|f(x_1) – f(x_2)| leq K |x_1 – x_2|  forall x_1, x_2∥f(x1)−f(x2)∥≤K∥x1−x2∥ ∀x1,x2\nLower Lipschitz bound ⇒ greater robustness and predictability.\nIt is crucial for stability, adversarial robustness, privacy, and generalization, with lower bounds meaning the network is less sensitive to changes or adversarial noise.\nMotivation and Problem Statement\nTraditionally, training stable transformers at scale has involved a variety of “band-aid” stabilization tricks:\nLayer normalization\nQK normalization\nLogit tanh softcapping\nBut these do not directly address the underlying spectral norm (largest singular value) growth in the weights, a root cause of exploding activations and training instability—especially in large models.\nThe central hypothesis: If we spectrally regulate the weights themselves—beyond just the optimizer or activations—we can maintain tight control over Lipschitzness, potentially solving instability at its source.\nKey Innovations\nWeight Spectral Regulation and the Muon Optimizer\nMuon optimizer spectrally regularizes gradients, ensuring each gradient step does not increase the spectral norm beyond a set limit.\nThe researchers extend regulation to the weights: After each step, they apply operations to cap the singular values of every weight matrix. Activation norms stay remarkably small as a result—rarely exceeding values compatible with fp8 precision in their GPT-2 scale transformers.\nRemoving Stability Tricks\nIn all experiments, no layer normalization, no QK norm, no logit tanh were used. Yet,\nMaximum activation entries in their GPT-2 scale transformer never exceeded ~100, while the unconstrained baseline surpassed 148,000.\nTable Sample (NanoGPT Experiment)\n\nModelMax ActivationLayer Stability TricksValidation AccuracyLipschitz Bound\n\nBaseline (Speedrun)148,480Yes39.4%∞\nLipschitz Transformer160None39.5%10¹⁰²⁶⁴\n\n\n\n\n\nMethods for Enforcing Lipschitz Constraints\nA variety of weight norm constraint methods were explored and compared for their ability to:\nMaintain high performance,\nGuarantee a Lipschitz bound, and\nOptimize the performance-Lipschitz tradeoff.\n\nTechniques\nWeight Decay: Standard method, but not always strict on spectral norm.\nSpectral Normalization: Ensures top singular value is capped, but may affect all singular values globally.\nSpectral Soft Cap: Novel method, smoothly and efficiently applies σ→min⁡(σmax,σ)sigma to min(sigma_{text{max}}, sigma)σ→min(σmax,σ) to all singular values in parallel (using odd polynomial approximations). This is co-designed for Muon’s high stable-rank updates for tight bounds.\nSpectral Hammer: Sets only the largest singular value to σmaxsigma_{text{max}}σmax, best suited for AdamW optimizer.\nExperimental Results and Insights\nModel Evaluation at Various Scales\nShakespeare (Small Transformer, <2-Lipschitz):\n\nAchieves 60% validation accuracy with a provable Lipschitz bound below.\nOutperforms unconstrained baseline in validation loss.\nNanoGPT (145M Parameters):\n\nWith a Lipschitz bound <10, validation accuracy: 21.2%.\nTo match the strong unconstrained baseline (39.4% accuracy), required a large upper bound of 1026410^{264}10264. This highlights how strict Lipschitz constraints often trade off with expressivity at large scales for now.\nWeight Constraint Method Efficiency\nMuon + Spectral Cap: Leads the tradeoff frontier—lower Lipschitz constants for matched or better validation loss compared to AdamW + weight decay.\nSpectral soft cap and normalization (under Muon) consistently enable best frontier on the loss-Lipschitz tradeoff.\nStability and Robustness\nAdversarial robustness increases sharply at lower Lipschitz bounds.\nIn experiments, models with a constrained Lipschitz constant suffered much milder accuracy drop under adversarial attack compared to unconstrained baselines.\nActivation Magnitudes\nWith spectral weight regulation: Maximum activations remain tiny (near-fp8 compatible), compared to the unbounded baselines, even at scale.\nThis opens avenues for low-precision training and inference in hardware, where smaller activations reduce compute, memory, and power costs.\nLimitations and Open Questions\nSelecting the “tightest” tradeoff for weight norms, logit scaling, and attention scaling still relies on sweeps, not principle.\nCurrent upper-bounding is loose: Calculated global bounds can be astronomically large (e.g. 1026410^{264}10264), while real activation norms remain small.\nIt’s unclear if matching unconstrained baseline performance with strictly small Lipschitz bounds is possible as scale increases—more research needed.\nConclusion\nSpectral weight regulation—especially when paired with the Muon optimizer—can stably train large transformers with enforced Lipschitz bounds, without activation normalization or other band-aid tricks. This addresses instability at a deeper level and keeps activations in a compact, predictable range, greatly improving adversarial robustness and potentially hardware efficiency.\nThis line of work points to new, efficient computational primitives for neural network regulation, with broad applications for privacy, safety, and low-precision AI deployment.\nCheck out the Paper, GitHub Page and Hugging Face Project Page. Feel free to check out our GitHub Page for Tutorials, Codes and Notebooks. Also, feel free to follow us on Twitter and don’t forget to join our 100k+ ML SubReddit and Subscribe to our Newsletter.\nThe post MIT Researchers Develop Methods to Control Transformer Sensitivity with Provable Lipschitz Bounds and Muon appeared first on MarkTechPost.",
          "dc:creator": "Sana Hassan",
          "comments": "https://www.marktechpost.com/2025/08/02/mit-researchers-develop-methods-to-control-transformer-sensitivity-with-provable-lipschitz-bounds-and-muon/#respond",
          "content": "<p>Training large-scale transformers stably has been a longstanding challenge in deep learning, particularly as models grow in size and expressivity. MIT researchers tackle a persistent problem at its root: the unstable growth of activations and loss spikes caused by unconstrained weight and activation norms. Their solution is to enforce provable Lipschitz bounds on the transformer [&#8230;]</p>\n<p>The post <a href=\"https://www.marktechpost.com/2025/08/02/mit-researchers-develop-methods-to-control-transformer-sensitivity-with-provable-lipschitz-bounds-and-muon/\">MIT Researchers Develop Methods to Control Transformer Sensitivity with Provable Lipschitz Bounds and Muon</a> appeared first on <a href=\"https://www.marktechpost.com\">MarkTechPost</a>.</p>\n",
          "contentSnippet": "Training large-scale transformers stably has been a longstanding challenge in deep learning, particularly as models grow in size and expressivity. MIT researchers tackle a persistent problem at its root: the unstable growth of activations and loss spikes caused by unconstrained weight and activation norms. Their solution is to enforce provable Lipschitz bounds on the transformer […]\nThe post MIT Researchers Develop Methods to Control Transformer Sensitivity with Provable Lipschitz Bounds and Muon appeared first on MarkTechPost.",
          "guid": "https://www.marktechpost.com/?p=73154",
          "categories": [
            "Artificial Intelligence",
            "Editors Pick",
            "Machine Learning",
            "Staff",
            "Technology"
          ],
          "isoDate": "2025-08-02T20:54:12.000Z"
        }
      },
      {
        "json": {
          "creator": "Arham Islam",
          "title": "How to Use the SHAP-IQ Package to Uncover and Visualize Feature Interactions in Machine Learning Models Using Shapley Interaction Indices (SII)",
          "link": "https://www.marktechpost.com/2025/08/02/how-to-use-the-shap-iq-package-to-uncover-and-visualize-feature-interactions-in-machine-learning-models-using-shapley-interaction-indices-sii/",
          "pubDate": "Sat, 02 Aug 2025 20:33:12 +0000",
          "content:encoded": "\n<p>In this tutorial, we explore how to use the SHAP-IQ package to uncover and visualize feature interactions in machine learning models using Shapley Interaction Indices (SII), building on the foundation of traditional Shapley values.</p>\n\n\n\n<p>Shapley values are great for explaining individual feature contributions in AI models but fail to capture feature interactions. Shapley interactions go a step further by separating individual effects from interactions, offering deeper insights—like how longitude and latitude together influence house prices. In this tutorial, we’ll get started with the shapiq package to compute and explore these Shapley interactions for any model. Check out the <strong><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included/blob/main/SHAP-IQ/Intro_to_SHAP_IQ.ipynb\" target=\"_blank\" rel=\"noreferrer noopener\">Full Codes here</a></strong></p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-installing-the-dependencies\"><strong>Installing the dependencies</strong></h3>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\">!pip install shapiq overrides scikit-learn pandas numpy</code></pre></div></div>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>Data Loading and Pre-processing</strong></h3>\n\n\n\n<p>In this tutorial, we&#8217;ll use the Bike Sharing dataset from OpenML. After loading the data, we&#8217;ll split it into training and testing sets to prepare it for model training and evaluation. Check out the <strong><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included/blob/main/SHAP-IQ/Intro_to_SHAP_IQ.ipynb\" target=\"_blank\" rel=\"noreferrer noopener\">Full Codes here</a></strong></p>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\">import shapiq\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\n# Load data\nX, y = shapiq.load_bike_sharing(to_numpy=True)\n\n# Split into training and testing\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</code></pre></div></div>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-model-training-and-performance-evaluation\"><strong>Model Training and Performance Evaluation</strong></h3>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\"># Train model\nmodel = RandomForestRegressor()\nmodel.fit(X_train, y_train)\n\n# Predict\ny_pred = model.predict(X_test)\n\n# Evaluate\nmae = mean_absolute_error(y_test, y_pred)\nrmse = np.sqrt(mean_squared_error(y_test, y_pred))\nr2 = r2_score(y_test, y_pred)\n\nprint(f\"R² Score: {r2:.4f}\")\nprint(f\"Mean Absolute Error: {mae:.4f}\")\nprint(f\"Root Mean Squared Error: {rmse:.4f}\")</code></pre></div></div>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>Setting up an Explainer</strong></h3>\n\n\n\n<p>We set up a TabularExplainer using the shapiq package to compute Shapley interaction values based on the k-SII (k-order Shapley Interaction Index) method. By specifying max_order=4, we allow the explainer to consider interactions of up to 4 features simultaneously, enabling deeper insights into how groups of features collectively impact model predictions. Check out the <strong><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included/blob/main/SHAP-IQ/Intro_to_SHAP_IQ.ipynb\" target=\"_blank\" rel=\"noreferrer noopener\">Full Codes here</a></strong></p>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\"># set up an explainer with k-SII interaction values up to order 4\nexplainer = shapiq.TabularExplainer(\n    model=model,\n    data=X,\n    index=\"k-SII\",\n    max_order=4\n)</code></pre></div></div>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>Explaining a Local Instance</strong></h3>\n\n\n\n<p>We select a specific test instance (index 100) to generate local explanations. The code prints the true and predicted values for this instance, followed by a breakdown of its feature values. This helps us understand the exact inputs passed to the model and sets the context for interpreting the Shapley interaction explanations that follow. Check out the <strong><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included/blob/main/SHAP-IQ/Intro_to_SHAP_IQ.ipynb\" target=\"_blank\" rel=\"noreferrer noopener\">Full Codes here</a></strong></p>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\">from tqdm.asyncio import tqdm\n# create explanations for different orders\nfeature_names = list(df[0].columns)  # get the feature names\nn_features = len(feature_names)\n\n# select a local instance to be explained\ninstance_id = 100\nx_explain = X_test[instance_id]\ny_true = y_test[instance_id]\ny_pred = model.predict(x_explain.reshape(1, -1))[0]\nprint(f\"Instance {instance_id}, True Value: {y_true}, Predicted Value: {y_pred}\")\nfor i, feature in enumerate(feature_names):\n    print(f\"{feature}: {x_explain[i]}\")</code></pre></div></div>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>Analyzing Interaction Values</strong></h3>\n\n\n\n<p>We use the explainer.explain() method to compute Shapley interaction values for a specific data instance (X[100]) with a budget of 256 model evaluations. This returns an InteractionValues object, which captures how individual features and their combinations influence the model&#8217;s output. The max_order=4 means we consider interactions involving up to 4 features. Check out the <strong><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included/blob/main/SHAP-IQ/Intro_to_SHAP_IQ.ipynb\" target=\"_blank\" rel=\"noreferrer noopener\">Full Codes here</a></strong></p>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\">interaction_values = explainer.explain(X[100], budget=256)\n# analyse interaction values\nprint(interaction_values)</code></pre></div></div>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>First-Order Interaction Values</strong></h3>\n\n\n\n<p>To keep things simple, we compute first-order interaction values—i.e., standard Shapley values that capture only individual feature contributions (no interactions).</p>\n\n\n\n<p><strong>By setting max_order=1 in the TreeExplainer, we&#8217;re saying:</strong></p>\n\n\n\n<p>“Tell me how much each feature individually contributes to the prediction, without considering any interaction effects.”</p>\n\n\n\n<p>These values are known as standard Shapley values. For each feature, it estimates the average marginal contribution to the prediction across all possible permutations of feature inclusion. Check out the <strong><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included/blob/main/SHAP-IQ/Intro_to_SHAP_IQ.ipynb\" target=\"_blank\" rel=\"noreferrer noopener\">Full Codes here</a></strong></p>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\">feature_names = list(df[0].columns)\nexplainer = shapiq.TreeExplainer(model=model, max_order=1, index=\"SV\")\nsi_order = explainer.explain(x=x_explain)\nsi_order</code></pre></div></div>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>Plotting a Waterfall chart</strong></h3>\n\n\n\n<p>A Waterfall chart visually breaks down a model&#8217;s prediction into individual feature contributions. It starts from the baseline prediction and adds/subtracts each feature’s Shapley value to reach the final predicted output.</p>\n\n\n\n<p>In our case, we’ll use the output of TreeExplainer with max_order=1 (i.e., individual contributions only) to visualize the contribution of each feature. Check out the <strong><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included/blob/main/SHAP-IQ/Intro_to_SHAP_IQ.ipynb\" target=\"_blank\" rel=\"noreferrer noopener\">Full Codes here</a></strong></p>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\">si_order.plot_waterfall(feature_names=feature_names, show=True)</code></pre></div></div>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter is-resized\"><img decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXfaQEH5bOxj8jGez-g0eI7oUh0DVGvOJLND5cFwDuXmot9dhL_w_eylqim1KmRlO9u4n0zeFGDW-drbezkse-Y4VJ869JIswSnw61sVgoanULQPRbOK-HobmDZ7L0waOBlK6NlM2A?key=tjWocUpL32CI02LMGCek0g\" alt=\"\" style=\"width:776px;height:auto\"/></figure></div>\n\n\n<p>In our case, the baseline value (i.e., the model’s expected output without any feature information) is 190.717.</p>\n\n\n\n<p><strong>As we add the contributions from individual features (order-1 Shapley values), we can observe how each one pushes the prediction up or pulls it down:</strong></p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Features like Weather and Humidity have a positive contribution, increasing the prediction above the baseline.</li>\n\n\n\n<li>Features like Temperature and Year have a strong negative impact, pulling the prediction down by −35.4 and −45, respectively.</li>\n</ul>\n\n\n\n<p>Overall, the Waterfall chart helps us understand which features are driving the prediction, and in which direction—providing valuable insight into the model’s decision-making.</p>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity\"/>\n\n\n\n<p>Check out the <strong><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included/blob/main/SHAP-IQ/Intro_to_SHAP_IQ.ipynb\" target=\"_blank\" rel=\"noreferrer noopener\">Full Codes here</a><em>.</em></strong> Feel free to check out our <strong><mark><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included\" target=\"_blank\" rel=\"noreferrer noopener\">GitHub Page for Tutorials, Codes and Notebooks</a></mark></strong>. Also, feel free to follow us on <strong><a href=\"https://x.com/intent/follow?screen_name=marktechpost\" target=\"_blank\" rel=\"noreferrer noopener\"><mark>Twitter</mark></a></strong> and don’t forget to join our <strong><a href=\"https://www.reddit.com/r/machinelearningnews/\" target=\"_blank\" rel=\"noreferrer noopener\">100k+ ML SubReddit</a></strong> and Subscribe to <strong><a href=\"https://www.aidevsignals.com/\" target=\"_blank\" rel=\"noreferrer noopener\">our Newsletter</a></strong>.</p>\n<p>The post <a href=\"https://www.marktechpost.com/2025/08/02/how-to-use-the-shap-iq-package-to-uncover-and-visualize-feature-interactions-in-machine-learning-models-using-shapley-interaction-indices-sii/\">How to Use the SHAP-IQ Package to Uncover and Visualize Feature Interactions in Machine Learning Models Using Shapley Interaction Indices (SII)</a> appeared first on <a href=\"https://www.marktechpost.com\">MarkTechPost</a>.</p>\n",
          "content:encodedSnippet": "In this tutorial, we explore how to use the SHAP-IQ package to uncover and visualize feature interactions in machine learning models using Shapley Interaction Indices (SII), building on the foundation of traditional Shapley values.\nShapley values are great for explaining individual feature contributions in AI models but fail to capture feature interactions. Shapley interactions go a step further by separating individual effects from interactions, offering deeper insights—like how longitude and latitude together influence house prices. In this tutorial, we’ll get started with the shapiq package to compute and explore these Shapley interactions for any model. Check out the Full Codes here\nInstalling the dependencies\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\n!pip install shapiq overrides scikit-learn pandas numpy\n\nData Loading and Pre-processing\nIn this tutorial, we’ll use the Bike Sharing dataset from OpenML. After loading the data, we’ll split it into training and testing sets to prepare it for model training and evaluation. Check out the Full Codes here\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\nimport shapiq\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\n# Load data\nX, y = shapiq.load_bike_sharing(to_numpy=True)\n\n# Split into training and testing\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nModel Training and Performance Evaluation\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\n# Train model\nmodel = RandomForestRegressor()\nmodel.fit(X_train, y_train)\n\n# Predict\ny_pred = model.predict(X_test)\n\n# Evaluate\nmae = mean_absolute_error(y_test, y_pred)\nrmse = np.sqrt(mean_squared_error(y_test, y_pred))\nr2 = r2_score(y_test, y_pred)\n\nprint(f\"R² Score: {r2:.4f}\")\nprint(f\"Mean Absolute Error: {mae:.4f}\")\nprint(f\"Root Mean Squared Error: {rmse:.4f}\")\n\nSetting up an Explainer\nWe set up a TabularExplainer using the shapiq package to compute Shapley interaction values based on the k-SII (k-order Shapley Interaction Index) method. By specifying max_order=4, we allow the explainer to consider interactions of up to 4 features simultaneously, enabling deeper insights into how groups of features collectively impact model predictions. Check out the Full Codes here\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\n# set up an explainer with k-SII interaction values up to order 4\nexplainer = shapiq.TabularExplainer(\n    model=model,\n    data=X,\n    index=\"k-SII\",\n    max_order=4\n)\n\nExplaining a Local Instance\nWe select a specific test instance (index 100) to generate local explanations. The code prints the true and predicted values for this instance, followed by a breakdown of its feature values. This helps us understand the exact inputs passed to the model and sets the context for interpreting the Shapley interaction explanations that follow. Check out the Full Codes here\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\nfrom tqdm.asyncio import tqdm\n# create explanations for different orders\nfeature_names = list(df[0].columns)  # get the feature names\nn_features = len(feature_names)\n\n# select a local instance to be explained\ninstance_id = 100\nx_explain = X_test[instance_id]\ny_true = y_test[instance_id]\ny_pred = model.predict(x_explain.reshape(1, -1))[0]\nprint(f\"Instance {instance_id}, True Value: {y_true}, Predicted Value: {y_pred}\")\nfor i, feature in enumerate(feature_names):\n    print(f\"{feature}: {x_explain[i]}\")\n\nAnalyzing Interaction Values\nWe use the explainer.explain() method to compute Shapley interaction values for a specific data instance (X[100]) with a budget of 256 model evaluations. This returns an InteractionValues object, which captures how individual features and their combinations influence the model’s output. The max_order=4 means we consider interactions involving up to 4 features. Check out the Full Codes here\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\ninteraction_values = explainer.explain(X[100], budget=256)\n# analyse interaction values\nprint(interaction_values)\n\nFirst-Order Interaction Values\nTo keep things simple, we compute first-order interaction values—i.e., standard Shapley values that capture only individual feature contributions (no interactions).\nBy setting max_order=1 in the TreeExplainer, we’re saying:\n“Tell me how much each feature individually contributes to the prediction, without considering any interaction effects.”\nThese values are known as standard Shapley values. For each feature, it estimates the average marginal contribution to the prediction across all possible permutations of feature inclusion. Check out the Full Codes here\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\nfeature_names = list(df[0].columns)\nexplainer = shapiq.TreeExplainer(model=model, max_order=1, index=\"SV\")\nsi_order = explainer.explain(x=x_explain)\nsi_order\n\nPlotting a Waterfall chart\nA Waterfall chart visually breaks down a model’s prediction into individual feature contributions. It starts from the baseline prediction and adds/subtracts each feature’s Shapley value to reach the final predicted output.\nIn our case, we’ll use the output of TreeExplainer with max_order=1 (i.e., individual contributions only) to visualize the contribution of each feature. Check out the Full Codes here\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\nsi_order.plot_waterfall(feature_names=feature_names, show=True)\n\n\nIn our case, the baseline value (i.e., the model’s expected output without any feature information) is 190.717.\nAs we add the contributions from individual features (order-1 Shapley values), we can observe how each one pushes the prediction up or pulls it down:\nFeatures like Weather and Humidity have a positive contribution, increasing the prediction above the baseline.\nFeatures like Temperature and Year have a strong negative impact, pulling the prediction down by −35.4 and −45, respectively.\nOverall, the Waterfall chart helps us understand which features are driving the prediction, and in which direction—providing valuable insight into the model’s decision-making.\nCheck out the Full Codes here. Feel free to check out our GitHub Page for Tutorials, Codes and Notebooks. Also, feel free to follow us on Twitter and don’t forget to join our 100k+ ML SubReddit and Subscribe to our Newsletter.\nThe post How to Use the SHAP-IQ Package to Uncover and Visualize Feature Interactions in Machine Learning Models Using Shapley Interaction Indices (SII) appeared first on MarkTechPost.",
          "dc:creator": "Arham Islam",
          "comments": "https://www.marktechpost.com/2025/08/02/how-to-use-the-shap-iq-package-to-uncover-and-visualize-feature-interactions-in-machine-learning-models-using-shapley-interaction-indices-sii/#respond",
          "content": "<p>In this tutorial, we explore how to use the SHAP-IQ package to uncover and visualize feature interactions in machine learning models using Shapley Interaction Indices (SII), building on the foundation of traditional Shapley values. Shapley values are great for explaining individual feature contributions in AI models but fail to capture feature interactions. Shapley interactions go [&#8230;]</p>\n<p>The post <a href=\"https://www.marktechpost.com/2025/08/02/how-to-use-the-shap-iq-package-to-uncover-and-visualize-feature-interactions-in-machine-learning-models-using-shapley-interaction-indices-sii/\">How to Use the SHAP-IQ Package to Uncover and Visualize Feature Interactions in Machine Learning Models Using Shapley Interaction Indices (SII)</a> appeared first on <a href=\"https://www.marktechpost.com\">MarkTechPost</a>.</p>\n",
          "contentSnippet": "In this tutorial, we explore how to use the SHAP-IQ package to uncover and visualize feature interactions in machine learning models using Shapley Interaction Indices (SII), building on the foundation of traditional Shapley values. Shapley values are great for explaining individual feature contributions in AI models but fail to capture feature interactions. Shapley interactions go […]\nThe post How to Use the SHAP-IQ Package to Uncover and Visualize Feature Interactions in Machine Learning Models Using Shapley Interaction Indices (SII) appeared first on MarkTechPost.",
          "guid": "https://www.marktechpost.com/?p=73151",
          "categories": [
            "Artificial Intelligence",
            "Editors Pick",
            "Machine Learning",
            "Staff",
            "Technology",
            "Tutorials"
          ],
          "isoDate": "2025-08-02T20:33:12.000Z"
        }
      },
      {
        "json": {
          "creator": "EScholar: Electronic Academic Papers for Scholars",
          "title": "The Impossibility Theorem Behind Truthful Blockchain Bidding Mechanisms",
          "link": "https://hackernoon.com/the-impossibility-theorem-behind-truthful-blockchain-bidding-mechanisms?source=rss",
          "pubDate": "Sun, 03 Aug 2025 21:14:40 GMT",
          "content:encoded": "<h2 id=\"tableoflinks\">Table of Links</h2>\n<p><a href=\"https://hackernoon.com/preview/4oLJMbsTSjvo3VPjkwJP\">Abstract and 1. Introduction</a></p>\n<p><a href=\"http://hackernoon.com/preview/6civAjDXiM0nLRxmISCX\">1.1 Our Contributions</a></p>\n<p><a href=\"https://hackernoon.com/preview/rn535RkNoZ9IjhCV1Q3Z\">1.2 TFM Incentive-Compatibility Notions: A Cheat Sheet</a></p>\n<ol start=\"2\">\n<li><p>Definitions</p>\n<p><a href=\"http://hackernoon.com/preview/3AUt2wksTUSPQlT9CWPJ\">2.1 Transaction Fee Mechanism</a></p>\n<p><a href=\"http://hackernoon.com/preview/3AUt2wksTUSPQlT9CWPJ\">2.2 Incentive Compatibility Notions</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">Preliminary: Myerson’s Lemma</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">Warmup: Impossibility of UIC + MIC + Global SCP for Deterministic Mechanisms</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">Impossibility of UIC + MIC + Global SCP for Randomized Mechanisms and 5.1 Proof Roadmap</a></p>\n<p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">5.2 Formal Proofs</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">Feasibility and Impossibility of UIC + MIC + OCA-Proof</a></p>\n<p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">6.1 A Non-Truthful Mechanism with UIC + MIC + OCA-Proof</a></p>\n<p><a href=\"https://hackernoon.com/preview/2K7Tn6O6GAIT00hMX9DK\">6.2 Impossibility of UIC + MIC + OCA-Proof for Truthful Mechanisms</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">How to Circumvent the Impossibilities and 7.1 Allowing the Globally Optimal Strategy to Coordinate</a></p>\n<p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">7.2 Allowing the Globally Optimal Strategy to Output Multiple Bids</a></p>\n<p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">7.3 Inclusion-Rule-Respecting and 7.4 Discussions and Open Questions Regarding the Use of Cryptography</a></p></li>\n<li><p><a href=\"http://hackernoon.com/preview/Z8dr9maz547Ssrjgsu3J\">Static Revelation Principle for Transaction Fee Mechanisms</a></p>\n<p><a href=\"http://hackernoon.com/preview/Z8dr9maz547Ssrjgsu3J\">8.1 Static Revelation Principle: Bidding Rules That Output Single Bid</a></p>\n<p><a href=\"http://hackernoon.com/preview/UMYlU2A57LPtnNi7V0N8\">8.2 Static Revelation Principle: Allowing Bidding Rules that Output Multiple Bids</a></p></li>\n</ol>\n<p><a href=\"http://hackernoon.com/preview/I4X49OO1ZsInqtfGbfPe\">A. Comparison of Collusion-Resilience Notions</a></p>\n<p><a href=\"http://hackernoon.com/preview/I4X49OO1ZsInqtfGbfPe\">References</a></p>\n<p>\\</p>\n<h2 id=\"6feasibilityandimpossibilityofuicmicocaproof\">6 Feasibility and Impossibility of UIC + MIC + OCA-Proof</h2>\n<p>We can generalize the proof in Section 5, and rule out UIC, MIC, and OCA-proof (rather than global SCP) for truthful mechanisms. Recall that for a truthful mechanism, the difference between OCA-proof and global SCP is that global SCP insists that the optimal strategy of the global coalition is the truthful strategy, whereas OCA-proofness allows it to be some other strategy in which each user acts independently and bids the outcome of some function σ(·).</p>\n<p>\\\nInterestingly, if we allow the bidding rule to be not truth-telling, i.e. considering non-truthful mechanisms, we can have a mechanism that satisfies UIC, MIC, and OCA-proof. We present the feasibility for non-truthful mechanisms in Section 6.1, and we prove the impossibility of UIC + MIC + OCA-proof for truthful mechanisms in Section 6.2. Notice that because of the feasibility in Section 6.1, we must require the bidding rule to be truth-telling to reach an impossibility in Section 6.2.</p>\n<h2 id=\"61anontruthfulmechanismwithuicmicocaproof\">6.1 A Non-Truthful Mechanism with UIC + MIC + OCA-Proof</h2>\n<p>The rationale of the design is to signal to the mechanism when everyone is adopting the globally optimal strategy σ (as opposed to the bidding rule used to establish UIC). When the mechanism detects that everyone is behaving according to σ, it adopts a different behavior to optimize social welfare. We use the range [0, 1) to encode the actual bid, and use the range [1,∞) for signalling. While the resulting mechanism is somewhat contrived and not necessarily meaningful from a practical point of view, it clarifies which notions of collusion-resilience most accurately capture the intended modeling goals and illustrates some technical challenges involved in the proof in Section 6.2. Consider the following TFM:</p>\n<p>\\\n<strong>• Globally optimal strategy</strong> σ(v): Given a true value v, output a bid v + 1.</p>\n<p>\\\n<strong>• Bidding rule</strong>: Given a true value v, output a bid 1/(v + 2).</p>\n<p>\\\n<strong>• Inclusion rule</strong>: Let S be the set of all pending bids that are in [0, 1). If |S| &gt; k, then randomly select k bids from S to include. If 1 ≤ |S| ≤ k, then include all bids in S. If |S| = 0, choose the top up to k bids to include.</p>\n<p>\\\n<strong>• Confirmation, payment, and miner revenue rules</strong>: All included bids are confirmed. Each confirmed bid pays nothing, and the miner gets nothing.</p>\n<p>\\\nObviously, this mechanism is non-trivial.</p>\n<p>\\\n<strong>Claim 6.1.</strong> <em>The above mechanism satisfies UIC, MIC, and OCA-proofness.</em></p>\n<p>\\\n<em>Proof</em>. For UIC, notice that if a user follows the bidding rule, its bid is always in [0, 1). If there is no bid in [0, 1) before a user submits its bid, then bidding 1/(v + 2) always guarantees user’s bid to be included and confirmed, where v denote the true value. If there is already some bids in [0, 1) before a user submits its bid, then bidding 1/(v + 2) is a dominant strategy since it guarantees the user’s bid is added to S, the set of all bids in [0, 1), which is the best a user can do. Next, MIC holds since the miner revenue is always zero. Finally, if all users follow the globally optimal strategy σ, everyone’s bid is at least 1. The honest inclusion rule will include the top up to k bids, which maximizes the social welfare. Thus, OCA-proofness holds.</p>\n<p>\\\n<strong>Remark 1.</strong> We can try to apply revelation principle, and bake the bidding rule into the mechanism so that the resulting mechanism is truthful. For example, whenever seeing a bid b, the miner and the mechanism view it as 1/(b + 2). The modified mechanism, however, does not satisfy OCAproofness anymore when the number of users is larger than the block size, since the miner should choose k users with the highest true values instead of the random selection as indicated by the inclusion rule. This is not a coincidence: in the next section, we show that it is impossible to have a non-trivial truthful mechanism satisfying UIC, MIC, and OCA-proofness.</p>\n<p>\\</p>\n<p>:::info\n<strong>Authors:</strong></p>\n<p>(1) Hao Chung∗, Carnegie Mellon University (haochung@andrew.cmu.edu);</p>\n<p>(2) Tim Roughgarden†, Columbia University and a16z (crypto tim.roughgarden@gmail.com);</p>\n<p>(3) Elaine Shi∗, Carnegie Mellon University (runting@cs.cmu.edu).</p>\n<p>:::</p>\n<hr />\n<p>:::info\nThis paper is <strong><a href=\"https://arxiv.org/abs/2402.09321\">available on arxiv</a></strong> under CC BY 4.0 DEED license.</p>\n<p>:::</p>\n<p>\\</p>",
          "content:encodedSnippet": "Table of Links\nAbstract and 1. Introduction\n1.1 Our Contributions\n1.2 TFM Incentive-Compatibility Notions: A Cheat Sheet\nDefinitions\n2.1 Transaction Fee Mechanism\n2.2 Incentive Compatibility Notions\n\n\nPreliminary: Myerson’s Lemma\n\n\nWarmup: Impossibility of UIC + MIC + Global SCP for Deterministic Mechanisms\n\n\nImpossibility of UIC + MIC + Global SCP for Randomized Mechanisms and 5.1 Proof Roadmap\n5.2 Formal Proofs\n\n\nFeasibility and Impossibility of UIC + MIC + OCA-Proof\n6.1 A Non-Truthful Mechanism with UIC + MIC + OCA-Proof\n6.2 Impossibility of UIC + MIC + OCA-Proof for Truthful Mechanisms\n\n\nHow to Circumvent the Impossibilities and 7.1 Allowing the Globally Optimal Strategy to Coordinate\n7.2 Allowing the Globally Optimal Strategy to Output Multiple Bids\n7.3 Inclusion-Rule-Respecting and 7.4 Discussions and Open Questions Regarding the Use of Cryptography\n\n\nStatic Revelation Principle for Transaction Fee Mechanisms\n8.1 Static Revelation Principle: Bidding Rules That Output Single Bid\n8.2 Static Revelation Principle: Allowing Bidding Rules that Output Multiple Bids\n\n\nA. Comparison of Collusion-Resilience Notions\nReferences\n\\\n6 Feasibility and Impossibility of UIC + MIC + OCA-Proof\nWe can generalize the proof in Section 5, and rule out UIC, MIC, and OCA-proof (rather than global SCP) for truthful mechanisms. Recall that for a truthful mechanism, the difference between OCA-proof and global SCP is that global SCP insists that the optimal strategy of the global coalition is the truthful strategy, whereas OCA-proofness allows it to be some other strategy in which each user acts independently and bids the outcome of some function σ(·).\n\\\nInterestingly, if we allow the bidding rule to be not truth-telling, i.e. considering non-truthful mechanisms, we can have a mechanism that satisfies UIC, MIC, and OCA-proof. We present the feasibility for non-truthful mechanisms in Section 6.1, and we prove the impossibility of UIC + MIC + OCA-proof for truthful mechanisms in Section 6.2. Notice that because of the feasibility in Section 6.1, we must require the bidding rule to be truth-telling to reach an impossibility in Section 6.2.\n6.1 A Non-Truthful Mechanism with UIC + MIC + OCA-Proof\nThe rationale of the design is to signal to the mechanism when everyone is adopting the globally optimal strategy σ (as opposed to the bidding rule used to establish UIC). When the mechanism detects that everyone is behaving according to σ, it adopts a different behavior to optimize social welfare. We use the range [0, 1) to encode the actual bid, and use the range [1,∞) for signalling. While the resulting mechanism is somewhat contrived and not necessarily meaningful from a practical point of view, it clarifies which notions of collusion-resilience most accurately capture the intended modeling goals and illustrates some technical challenges involved in the proof in Section 6.2. Consider the following TFM:\n\\\n• Globally optimal strategy σ(v): Given a true value v, output a bid v + 1.\n\\\n• Bidding rule: Given a true value v, output a bid 1/(v + 2).\n\\\n• Inclusion rule: Let S be the set of all pending bids that are in [0, 1). If |S| > k, then randomly select k bids from S to include. If 1 ≤ |S| ≤ k, then include all bids in S. If |S| = 0, choose the top up to k bids to include.\n\\\n• Confirmation, payment, and miner revenue rules: All included bids are confirmed. Each confirmed bid pays nothing, and the miner gets nothing.\n\\\nObviously, this mechanism is non-trivial.\n\\\nClaim 6.1. The above mechanism satisfies UIC, MIC, and OCA-proofness.\n\\\nProof. For UIC, notice that if a user follows the bidding rule, its bid is always in [0, 1). If there is no bid in [0, 1) before a user submits its bid, then bidding 1/(v + 2) always guarantees user’s bid to be included and confirmed, where v denote the true value. If there is already some bids in [0, 1) before a user submits its bid, then bidding 1/(v + 2) is a dominant strategy since it guarantees the user’s bid is added to S, the set of all bids in [0, 1), which is the best a user can do. Next, MIC holds since the miner revenue is always zero. Finally, if all users follow the globally optimal strategy σ, everyone’s bid is at least 1. The honest inclusion rule will include the top up to k bids, which maximizes the social welfare. Thus, OCA-proofness holds.\n\\\nRemark 1. We can try to apply revelation principle, and bake the bidding rule into the mechanism so that the resulting mechanism is truthful. For example, whenever seeing a bid b, the miner and the mechanism view it as 1/(b + 2). The modified mechanism, however, does not satisfy OCAproofness anymore when the number of users is larger than the block size, since the miner should choose k users with the highest true values instead of the random selection as indicated by the inclusion rule. This is not a coincidence: in the next section, we show that it is impossible to have a non-trivial truthful mechanism satisfying UIC, MIC, and OCA-proofness.\n\\\n:::info\nAuthors:\n(1) Hao Chung∗, Carnegie Mellon University (haochung@andrew.cmu.edu);\n(2) Tim Roughgarden†, Columbia University and a16z (crypto tim.roughgarden@gmail.com);\n(3) Elaine Shi∗, Carnegie Mellon University (runting@cs.cmu.edu).\n:::\n:::info\nThis paper is available on arxiv under CC BY 4.0 DEED license.\n:::\n\\",
          "dc:creator": "EScholar: Electronic Academic Papers for Scholars",
          "content": "This article delves into the theoretical limits of blockchain bidding mechanisms, showing that no non-trivial truthful mechanism—deterministic or randomized—can satisfy all three key properties: User Incentive Compatibility (UIC), Miner Incentive Compatibility (MIC), and Global Social Cost Property (SCP), within a finite block size. Using Myerson’s Lemma and rigorous proofs, it demonstrates inherent trade-offs in mechanism design that challenge the feasibility of universally fair and efficient blockchain protocols.",
          "contentSnippet": "This article delves into the theoretical limits of blockchain bidding mechanisms, showing that no non-trivial truthful mechanism—deterministic or randomized—can satisfy all three key properties: User Incentive Compatibility (UIC), Miner Incentive Compatibility (MIC), and Global Social Cost Property (SCP), within a finite block size. Using Myerson’s Lemma and rigorous proofs, it demonstrates inherent trade-offs in mechanism design that challenge the feasibility of universally fair and efficient blockchain protocols.",
          "guid": "https://hackernoon.com/the-impossibility-theorem-behind-truthful-blockchain-bidding-mechanisms?source=rss",
          "categories": [
            "blockchain-scalability",
            "transaction-fee-mechanisms",
            "ethereum-eip-1559",
            "user-incentive-compatibility",
            "miner-incentive-compatibility",
            "oca-proofness",
            "side-contract-proofness",
            "auction-mechanisms"
          ],
          "isoDate": "2025-08-03T21:14:40.000Z"
        }
      },
      {
        "json": {
          "creator": "EScholar: Electronic Academic Papers for Scholars",
          "title": "No Blockchain Auction Can Satisfy UIC, MIC, and Global SCP at Once",
          "link": "https://hackernoon.com/no-blockchain-auction-can-satisfy-uic-mic-and-global-scp-at-once?source=rss",
          "pubDate": "Sun, 03 Aug 2025 21:14:35 GMT",
          "content:encoded": "<h2 id=\"tableoflinks\">Table of Links</h2>\n<p><a href=\"https://hackernoon.com/preview/4oLJMbsTSjvo3VPjkwJP\">Abstract and 1. Introduction</a></p>\n<p><a href=\"http://hackernoon.com/preview/6civAjDXiM0nLRxmISCX\">1.1 Our Contributions</a></p>\n<p><a href=\"https://hackernoon.com/preview/rn535RkNoZ9IjhCV1Q3Z\">1.2 TFM Incentive-Compatibility Notions: A Cheat Sheet</a></p>\n<ol start=\"2\">\n<li><p>Definitions</p>\n<p><a href=\"http://hackernoon.com/preview/3AUt2wksTUSPQlT9CWPJ\">2.1 Transaction Fee Mechanism</a></p>\n<p><a href=\"http://hackernoon.com/preview/3AUt2wksTUSPQlT9CWPJ\">2.2 Incentive Compatibility Notions</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">Preliminary: Myerson’s Lemma</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">Warmup: Impossibility of UIC + MIC + Global SCP for Deterministic Mechanisms</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">Impossibility of UIC + MIC + Global SCP for Randomized Mechanisms and 5.1 Proof Roadmap</a></p>\n<p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">5.2 Formal Proofs</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">Feasibility and Impossibility of UIC + MIC + OCA-Proof</a></p>\n<p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">6.1 A Non-Truthful Mechanism with UIC + MIC + OCA-Proof</a></p>\n<p><a href=\"https://hackernoon.com/preview/2K7Tn6O6GAIT00hMX9DK\">6.2 Impossibility of UIC + MIC + OCA-Proof for Truthful Mechanisms</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">How to Circumvent the Impossibilities and 7.1 Allowing the Globally Optimal Strategy to Coordinate</a></p>\n<p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">7.2 Allowing the Globally Optimal Strategy to Output Multiple Bids</a></p>\n<p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">7.3 Inclusion-Rule-Respecting and 7.4 Discussions and Open Questions Regarding the Use of Cryptography</a></p></li>\n<li><p><a href=\"http://hackernoon.com/preview/Z8dr9maz547Ssrjgsu3J\">Static Revelation Principle for Transaction Fee Mechanisms</a></p>\n<p><a href=\"http://hackernoon.com/preview/Z8dr9maz547Ssrjgsu3J\">8.1 Static Revelation Principle: Bidding Rules That Output Single Bid</a></p>\n<p><a href=\"http://hackernoon.com/preview/UMYlU2A57LPtnNi7V0N8\">8.2 Static Revelation Principle: Allowing Bidding Rules that Output Multiple Bids</a></p></li>\n</ol>\n<p><a href=\"http://hackernoon.com/preview/I4X49OO1ZsInqtfGbfPe\">A. Comparison of Collusion-Resilience Notions</a></p>\n<p><a href=\"http://hackernoon.com/preview/I4X49OO1ZsInqtfGbfPe\">References</a></p>\n<h2 id=\"3preliminarymyersonslemma\">3 Preliminary: Myerson’s Lemma</h2>\n<p><img src=\"https://cdn.hackernoon.com/images/fWZa4tUiBGemnqQfBGgCPf9594N2-v1833xk.png\" alt=\"\" /></p>\n<p>\\\nConceptually, user <em>i</em> must pay the minimal price which makes its bid confirmed.</p>\n<h2 id=\"4warmupimpossibilityofuicmicglobalscpfordeterministicmechanisms\">4 Warmup: Impossibility of UIC + MIC + Global SCP for Deterministic Mechanisms</h2>\n<p>As a warmup, we first show a finite-block impossibility for UIC + MIC + global SCP for <em>deterministic</em> mechanisms. Recall that a TFM is said to be trivial if everyone’s confirmation probability is zero for any bid vector assuming the miner follows the inclusion rule. In this case, everyone’s utility is always zero in an honest execution. We will show that no non-trivial mechanism can satisfy all three properties simultaneously. Later in Section 5, we extend the impossibility to randomized mechanisms. Due to the revelation principle that we prove in Section 8, if we can prove the impossibility for truthful mechanisms, the impossibility immediately extends to non-truthful mechanisms as well. Therefore, in this section, we shall assume truthful mechanisms.</p>\n<p>\\\n<strong>Lemma 4.1.</strong> <em>For any global SCP mechanism, the confirmed bids must correspond to the highest bids.</em></p>\n<p>\\\n<em>Proof</em>. Suppose in some scenario, Alice bids her true value b and Bob bids his true value b ′ &lt; b; however, Bob’s bid is confirmed, and Alice’s is not. Now, we can have Alice and Bob swap their bids. The miner creates the same block as before in which the position originally corresponding to Bob now has Alice’s bid of b′. Since the mechanism is weakly symmetric (Definition 1), Alice’s bid is confirmed. This way, the social welfare increases by b − b′ in comparison with the honest case, and this violates global SCP.</p>\n<p>\\\n<strong>Lemma 4.2.</strong> <em>For any global SCP mechanism, the amount of burnt coins depends only on the number of confirmed bids.</em></p>\n<p>\\\n<em>Proof</em>. Suppose in two different scenarios, when everyone acts honestly, the blocks made are <strong>B</strong> and <strong>B</strong>′ respectively, the confirmed bids are <strong>b</strong> ⊆ <strong>B</strong> and <strong>b</strong>′ ⊆ <strong>B</strong>′ respectively where <strong>b</strong> and <strong>b</strong>′ are of the same length, and the burnt amount in the two scenarios are <em>q</em> and <em>q′</em> respectively, where <em>q</em> &lt; <em>q′</em>. Now, suppose we are actually in the second scenario. A global coalition can adopt the following strategy: create a block identical to <strong>B</strong> in which the confirmed bids correspond to the users with the highest true values and the rest can be fake bids. Observe that the social welfare is the sum of the true values of all confirmed bids (where fake bids have a true value of 0) minus the total coins burnt. Therefore, the above strategy achieves strictly higher social welfare than the honest case.</p>\n<p>\\\n<strong>Theorem 4.3.</strong> <em>No non-trivial deterministic TFM can simultaneously satisfy UIC, MIC, and global SCP when the block size is finite.</em></p>\n<p>\\\n\\\n <img src=\"https://cdn.hackernoon.com/images/fWZa4tUiBGemnqQfBGgCPf9594N2-nt83210.png\" alt=\"\" /></p>\n<h2 id=\"5impossibilityofuicmicglobalscpforrandomizedmechanisms\">5 Impossibility of UIC + MIC + Global SCP for Randomized Mechanisms</h2>\n<p>In this section, we extend the finite-block impossibility of UIC + MIC + global SCP to even randomized mechanisms. Recall that a TFM consists of five rules as defined in Section 2.1, and a randomized TFM may use randomness in any of the five rules. Since the confirmation, the payment, and the miner revenue rules are executed by the blockchain, the strategic players can only bias the randomness in and deviate from the bidding rule and the inclusion rule. Again, due to the revelation principle proven in Section 8, it suffices to consider truthful mechanisms.</p>\n<h3 id=\"51proofroadmap\">5.1 Proof Roadmap</h3>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/fWZa4tUiBGemnqQfBGgCPf9594N2-3f832vd.png\" alt=\"\" /></p>\n<h2 id=\"52formalproofs\">5.2 Formal Proofs</h2>\n<p>In the rest of this section, we present the formal proofs.</p>\n<p>\\\n\\\n <img src=\"https://cdn.hackernoon.com/images/fWZa4tUiBGemnqQfBGgCPf9594N2-rc83383.png\" alt=\"\" /></p>\n<p>\\\n\\\n\\\n <img src=\"https://cdn.hackernoon.com/images/fWZa4tUiBGemnqQfBGgCPf9594N2-8v933x4.png\" alt=\"\" /></p>\n<p>\\\n\\\n\\\n <img src=\"https://cdn.hackernoon.com/images/fWZa4tUiBGemnqQfBGgCPf9594N2-3ma33cm.png\" alt=\"\" /></p>\n<p>\\\n\\\n<em>Proof</em>. We first prove that expected miner utility is the same in both scenarios. Suppose this is not true, and without loss of generality, suppose expected miner utility is higher in scenario 1. Then, the miner can ignore the bids <strong>b</strong>, inject the fake bids <strong>b</strong>′, pretend that the bid vector is (<strong>a</strong>, <strong>b</strong>′), and run the honest mechanism. Since the confirmation probability of <strong>b</strong>′ is 0, the miner need not pay any cost for the fake bids. Therefore, the miner gets higher expected utility by taking the above strategy which violates MIC.</p>\n<p>\\\nThe proof of total social welfare is similar. Suppose without loss of generality, that the expected total social welfare in scenario 1 is higher. Then, the global coalition can inject fake bids <strong>b</strong>′ and pretend that the bid vector is (<strong>a</strong>, <strong>b</strong>′), thus allowing it to increase its expected social welfare. This violates global SCP.</p>\n<p>\\\nThe equivalence in total user utility follows directly from the above, since total user utility is the difference between the social welfare and the miner utility.</p>\n<p>\\\n\\\n <img src=\"https://cdn.hackernoon.com/images/fWZa4tUiBGemnqQfBGgCPf9594N2-mib3363.png\" alt=\"\" /></p>\n<p>\\\n\\\n\\\n <img src=\"https://cdn.hackernoon.com/images/fWZa4tUiBGemnqQfBGgCPf9594N2-cnc33mx.png\" alt=\"\" /></p>\n<p>\\\n\\\n<strong>Lemma 5.5.</strong> <em>Suppose the mechanism satisfies UIC, MIC, and global SCP, and the block size is k. Let a be any positive real number. Consider a scenario with only one bid a. Then, the only user’s utility is zero assuming it bids its true value.</em></p>\n<p>\\\n\\\n <img src=\"https://cdn.hackernoon.com/images/fWZa4tUiBGemnqQfBGgCPf9594N2-rvd33mk.png\" alt=\"\" /></p>\n<p>\\\n\\\n<strong>Theorem 5.6.</strong> <em>No non-trivial, possibly randomized TFM can simultaneously satisfy UIC, MIC, and global SCP when the block size is finite.</em></p>\n<p>\\\n<em>Proof</em>. We will show that under any sufficiently large a, the confirmation probability under a single bid a is non-zero. If we can show this, then we can show a contradiction to UIC. Specifically, consider b &gt; a and both sufficiently large. By Lemma 5.5, if there is only one user with true value b, its utility is zero when it bids truthfully. However, the user can underbid a. Since the confirmation probability is non-zero and the payment is at most a, the user enjoys positive utility, which violates UIC.</p>\n<p>\\\n\\\n <img src=\"https://cdn.hackernoon.com/images/fWZa4tUiBGemnqQfBGgCPf9594N2-nwe33bm.png\" alt=\"\" /></p>\n<p>\\\n\\</p>\n<p>:::info\n<strong>Authors:</strong></p>\n<p>(1) Hao Chung∗, Carnegie Mellon University (haochung@andrew.cmu.edu);</p>\n<p>(2) Tim Roughgarden†, Columbia University and a16z (crypto tim.roughgarden@gmail.com);</p>\n<p>(3) Elaine Shi∗, Carnegie Mellon University (runting@cs.cmu.edu).</p>\n<p>:::</p>\n<hr />\n<p>:::info\nThis paper is <strong><a href=\"https://arxiv.org/abs/2402.09321\">available on arxiv</a></strong> under CC BY 4.0 DEED license.</p>\n<p>:::</p>\n<p>\\</p>",
          "content:encodedSnippet": "Table of Links\nAbstract and 1. Introduction\n1.1 Our Contributions\n1.2 TFM Incentive-Compatibility Notions: A Cheat Sheet\nDefinitions\n2.1 Transaction Fee Mechanism\n2.2 Incentive Compatibility Notions\n\n\nPreliminary: Myerson’s Lemma\n\n\nWarmup: Impossibility of UIC + MIC + Global SCP for Deterministic Mechanisms\n\n\nImpossibility of UIC + MIC + Global SCP for Randomized Mechanisms and 5.1 Proof Roadmap\n5.2 Formal Proofs\n\n\nFeasibility and Impossibility of UIC + MIC + OCA-Proof\n6.1 A Non-Truthful Mechanism with UIC + MIC + OCA-Proof\n6.2 Impossibility of UIC + MIC + OCA-Proof for Truthful Mechanisms\n\n\nHow to Circumvent the Impossibilities and 7.1 Allowing the Globally Optimal Strategy to Coordinate\n7.2 Allowing the Globally Optimal Strategy to Output Multiple Bids\n7.3 Inclusion-Rule-Respecting and 7.4 Discussions and Open Questions Regarding the Use of Cryptography\n\n\nStatic Revelation Principle for Transaction Fee Mechanisms\n8.1 Static Revelation Principle: Bidding Rules That Output Single Bid\n8.2 Static Revelation Principle: Allowing Bidding Rules that Output Multiple Bids\n\n\nA. Comparison of Collusion-Resilience Notions\nReferences\n3 Preliminary: Myerson’s Lemma\n\n\\\nConceptually, user i must pay the minimal price which makes its bid confirmed.\n4 Warmup: Impossibility of UIC + MIC + Global SCP for Deterministic Mechanisms\nAs a warmup, we first show a finite-block impossibility for UIC + MIC + global SCP for deterministic mechanisms. Recall that a TFM is said to be trivial if everyone’s confirmation probability is zero for any bid vector assuming the miner follows the inclusion rule. In this case, everyone’s utility is always zero in an honest execution. We will show that no non-trivial mechanism can satisfy all three properties simultaneously. Later in Section 5, we extend the impossibility to randomized mechanisms. Due to the revelation principle that we prove in Section 8, if we can prove the impossibility for truthful mechanisms, the impossibility immediately extends to non-truthful mechanisms as well. Therefore, in this section, we shall assume truthful mechanisms.\n\\\nLemma 4.1. For any global SCP mechanism, the confirmed bids must correspond to the highest bids.\n\\\nProof. Suppose in some scenario, Alice bids her true value b and Bob bids his true value b ′ < b; however, Bob’s bid is confirmed, and Alice’s is not. Now, we can have Alice and Bob swap their bids. The miner creates the same block as before in which the position originally corresponding to Bob now has Alice’s bid of b′. Since the mechanism is weakly symmetric (Definition 1), Alice’s bid is confirmed. This way, the social welfare increases by b − b′ in comparison with the honest case, and this violates global SCP.\n\\\nLemma 4.2. For any global SCP mechanism, the amount of burnt coins depends only on the number of confirmed bids.\n\\\nProof. Suppose in two different scenarios, when everyone acts honestly, the blocks made are B and B′ respectively, the confirmed bids are b ⊆ B and b′ ⊆ B′ respectively where b and b′ are of the same length, and the burnt amount in the two scenarios are q and q′ respectively, where q < q′. Now, suppose we are actually in the second scenario. A global coalition can adopt the following strategy: create a block identical to B in which the confirmed bids correspond to the users with the highest true values and the rest can be fake bids. Observe that the social welfare is the sum of the true values of all confirmed bids (where fake bids have a true value of 0) minus the total coins burnt. Therefore, the above strategy achieves strictly higher social welfare than the honest case.\n\\\nTheorem 4.3. No non-trivial deterministic TFM can simultaneously satisfy UIC, MIC, and global SCP when the block size is finite.\n\\\n\\\n \n5 Impossibility of UIC + MIC + Global SCP for Randomized Mechanisms\nIn this section, we extend the finite-block impossibility of UIC + MIC + global SCP to even randomized mechanisms. Recall that a TFM consists of five rules as defined in Section 2.1, and a randomized TFM may use randomness in any of the five rules. Since the confirmation, the payment, and the miner revenue rules are executed by the blockchain, the strategic players can only bias the randomness in and deviate from the bidding rule and the inclusion rule. Again, due to the revelation principle proven in Section 8, it suffices to consider truthful mechanisms.\n5.1 Proof Roadmap\n\\\n \n5.2 Formal Proofs\nIn the rest of this section, we present the formal proofs.\n\\\n\\\n \n\\\n\\\n\\\n \n\\\n\\\n\\\n \n\\\n\\\nProof. We first prove that expected miner utility is the same in both scenarios. Suppose this is not true, and without loss of generality, suppose expected miner utility is higher in scenario 1. Then, the miner can ignore the bids b, inject the fake bids b′, pretend that the bid vector is (a, b′), and run the honest mechanism. Since the confirmation probability of b′ is 0, the miner need not pay any cost for the fake bids. Therefore, the miner gets higher expected utility by taking the above strategy which violates MIC.\n\\\nThe proof of total social welfare is similar. Suppose without loss of generality, that the expected total social welfare in scenario 1 is higher. Then, the global coalition can inject fake bids b′ and pretend that the bid vector is (a, b′), thus allowing it to increase its expected social welfare. This violates global SCP.\n\\\nThe equivalence in total user utility follows directly from the above, since total user utility is the difference between the social welfare and the miner utility.\n\\\n\\\n \n\\\n\\\n\\\n \n\\\n\\\nLemma 5.5. Suppose the mechanism satisfies UIC, MIC, and global SCP, and the block size is k. Let a be any positive real number. Consider a scenario with only one bid a. Then, the only user’s utility is zero assuming it bids its true value.\n\\\n\\\n \n\\\n\\\nTheorem 5.6. No non-trivial, possibly randomized TFM can simultaneously satisfy UIC, MIC, and global SCP when the block size is finite.\n\\\nProof. We will show that under any sufficiently large a, the confirmation probability under a single bid a is non-zero. If we can show this, then we can show a contradiction to UIC. Specifically, consider b > a and both sufficiently large. By Lemma 5.5, if there is only one user with true value b, its utility is zero when it bids truthfully. However, the user can underbid a. Since the confirmation probability is non-zero and the payment is at most a, the user enjoys positive utility, which violates UIC.\n\\\n\\\n \n\\\n\\\n:::info\nAuthors:\n(1) Hao Chung∗, Carnegie Mellon University (haochung@andrew.cmu.edu);\n(2) Tim Roughgarden†, Columbia University and a16z (crypto tim.roughgarden@gmail.com);\n(3) Elaine Shi∗, Carnegie Mellon University (runting@cs.cmu.edu).\n:::\n:::info\nThis paper is available on arxiv under CC BY 4.0 DEED license.\n:::\n\\",
          "dc:creator": "EScholar: Electronic Academic Papers for Scholars",
          "content": "This article explores the theoretical limits of designing truthful and fair blockchain auction mechanisms. It proves that no deterministic or randomized Truthful Fee Mechanism (TFM) can simultaneously satisfy User Incentive Compatibility (UIC), Miner Incentive Compatibility (MIC), and global Social Cost Preservation (SCP) when block size is finite. Using Myerson’s Lemma, logical proofs, and game-theoretic reasoning, it establishes an impossibility result with deep implications for blockchain protocol design.",
          "contentSnippet": "This article explores the theoretical limits of designing truthful and fair blockchain auction mechanisms. It proves that no deterministic or randomized Truthful Fee Mechanism (TFM) can simultaneously satisfy User Incentive Compatibility (UIC), Miner Incentive Compatibility (MIC), and global Social Cost Preservation (SCP) when block size is finite. Using Myerson’s Lemma, logical proofs, and game-theoretic reasoning, it establishes an impossibility result with deep implications for blockchain protocol design.",
          "guid": "https://hackernoon.com/no-blockchain-auction-can-satisfy-uic-mic-and-global-scp-at-once?source=rss",
          "categories": [
            "blockchain-scalability",
            "transaction-fee-mechanisms",
            "ethereum-eip-1559",
            "user-incentive-compatibility",
            "miner-incentive-compatibility",
            "oca-proofness",
            "side-contract-proofness",
            "auction-mechanisms"
          ],
          "isoDate": "2025-08-03T21:14:35.000Z"
        }
      },
      {
        "json": {
          "creator": "EScholar: Electronic Academic Papers for Scholars",
          "title": "What Is a Transaction Fee Mechanism? Definitions, Incentives, and Strategies",
          "link": "https://hackernoon.com/what-is-a-transaction-fee-mechanism-definitions-incentives-and-strategies?source=rss",
          "pubDate": "Sun, 03 Aug 2025 21:14:30 GMT",
          "content:encoded": "<h2 id=\"tableoflinks\">Table of Links</h2>\n<p><a href=\"https://hackernoon.com/preview/4oLJMbsTSjvo3VPjkwJP\">Abstract and 1. Introduction</a></p>\n<p><a href=\"http://hackernoon.com/preview/6civAjDXiM0nLRxmISCX\">1.1 Our Contributions</a></p>\n<p><a href=\"https://hackernoon.com/preview/rn535RkNoZ9IjhCV1Q3Z\">1.2 TFM Incentive-Compatibility Notions: A Cheat Sheet</a></p>\n<ol start=\"2\">\n<li><p>Definitions</p>\n<p><a href=\"http://hackernoon.com/preview/3AUt2wksTUSPQlT9CWPJ\">2.1 Transaction Fee Mechanism</a></p>\n<p><a href=\"http://hackernoon.com/preview/3AUt2wksTUSPQlT9CWPJ\">2.2 Incentive Compatibility Notions</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">Preliminary: Myerson’s Lemma</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">Warmup: Impossibility of UIC + MIC + Global SCP for Deterministic Mechanisms</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">Impossibility of UIC + MIC + Global SCP for Randomized Mechanisms and 5.1 Proof Roadmap</a></p>\n<p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">5.2 Formal Proofs</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">Feasibility and Impossibility of UIC + MIC + OCA-Proof</a></p>\n<p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">6.1 A Non-Truthful Mechanism with UIC + MIC + OCA-Proof</a></p>\n<p><a href=\"https://hackernoon.com/preview/2K7Tn6O6GAIT00hMX9DK\">6.2 Impossibility of UIC + MIC + OCA-Proof for Truthful Mechanisms</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">How to Circumvent the Impossibilities and 7.1 Allowing the Globally Optimal Strategy to Coordinate</a></p>\n<p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">7.2 Allowing the Globally Optimal Strategy to Output Multiple Bids</a></p>\n<p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">7.3 Inclusion-Rule-Respecting and 7.4 Discussions and Open Questions Regarding the Use of Cryptography</a></p></li>\n<li><p><a href=\"http://hackernoon.com/preview/Z8dr9maz547Ssrjgsu3J\">Static Revelation Principle for Transaction Fee Mechanisms</a></p>\n<p><a href=\"http://hackernoon.com/preview/Z8dr9maz547Ssrjgsu3J\">8.1 Static Revelation Principle: Bidding Rules That Output Single Bid</a></p>\n<p><a href=\"http://hackernoon.com/preview/UMYlU2A57LPtnNi7V0N8\">8.2 Static Revelation Principle: Allowing Bidding Rules that Output Multiple Bids</a></p></li>\n</ol>\n<p><a href=\"http://hackernoon.com/preview/I4X49OO1ZsInqtfGbfPe\">A. Comparison of Collusion-Resilience Notions</a></p>\n<p><a href=\"http://hackernoon.com/preview/I4X49OO1ZsInqtfGbfPe\">References</a></p>\n<h2 id=\"2definitions\">2 Definitions</h2>\n<h3 id=\"21transactionfeemechanism\">2.1 Transaction Fee Mechanism</h3>\n<p><img src=\"https://cdn.hackernoon.com/images/fWZa4tUiBGemnqQfBGgCPf9594N2-zz833bh.png\" alt=\"\" /></p>\n<p>\\\nA transaction fee mechanism (TFM) consists of the following possibly randomized algorithms:</p>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/fWZa4tUiBGemnqQfBGgCPf9594N2-6k9334t.png\" alt=\"\" /></p>\n<p>\\\nWe say a TFM is trivial if the confirmation probability of all transactions is zero for any bid vector assuming the miner honestly follows the inclusion rule; otherwise, it is called <em>non-trivial.</em></p>\n<p>\\\nA strategic miner or miner-user coalition may deviate from the honest inclusion rule. On the other hand, since the confirmation, payment, and miner revenue rules are executed by the blockchain, they are always implemented honestly.</p>\n<p>\\\nWe focus on mechanisms that are <em>weakly symmetric</em>, i.e., mechanisms that do not make use of the bidders’ identities or other auxiliary information (e.g., timestamp, transaction metadata), except for tie-breaking among equal bids. More formally, we define weak symmetry as below.</p>\n<p>\\\n<strong>Definition 1</strong> (Weak symmetry). A mechanism is called weakly symmetric if the mechanism can always be equivalently described in the following manner: given a bid vector <strong>b</strong> where each bid may carry some extra information such as identity or timestamp, the honest mechanism always sorts the vector <strong>b</strong> by the bid amount first. During the sorting step, if multiple bids have the same amount, then arbitrary tie-breaking rules may be applied, and the tie-breaking can depend on extra information such as timestamp, identity, or random coins. After this sorting step, the inclusion rule and the confirmation rules should depend only on the amount of the bids and their relative position in the sorted bid vector.</p>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/fWZa4tUiBGemnqQfBGgCPf9594N2-zya33s5.png\" alt=\"\" /></p>\n<p>\\\n<strong>Strategy space.</strong> A strategic user can deviate from the honest bidding rule and post an arbitrary bid vector with zero to multiple bids. Without loss of generality, we may assume that in the strategic bid vector, at most one bid can correspond to the user’s actual transaction which has a non-zero true value; all other bids must be fake bids with zero true value. A strategic miner can deviate from the honest inclusion rule, and instead create an arbitrary block (subject to the block size limit) that includes any subset of the bid vector as well as any number of fake bids that it chooses to inject. A strategic miner-user coalition can adopt a combination of the above strategies.</p>\n<p>\\\n<strong>Utility and social welfare</strong>. For a user with true value v, let x ∈ {0, 1} be the indicator of whether its primary bid is confirmed or not, let p denote its total payment, then the user’s utility is x · v − p. The miner’s utility is simply its revenue. The social welfare is defined to be the sum of the utilities of all users and the miner (i.e., the total value of the confirmed transactions, less any burned payments).</p>\n<p>\\\nNotice that we allow the miner revenue to be smaller than the sum of users’ payment, since the coins can be burnt. When calculating the social welfare, the payments among the users and the miner are canceled out, so the social welfare is independent of the payment; however, the amount of burnt coins decreases the social welfare. For example, suppose there is only one user, and let p be the user’s payment and q be the amount of burnt coins. In this case, the user’s utility is x·v −p, the miner revenue is p − q, and the social welfare is (x · v − p) + (p − q) = x · v − q.</p>\n<h2 id=\"22incentivecompatibilitynotions\">2.2 Incentive Compatibility Notions</h2>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/fWZa4tUiBGemnqQfBGgCPf9594N2-u3b33n9.png\" alt=\"\" /></p>\n<p>\\\n\\\n<strong>Definition 3</strong> (Miner incentive compatible (MIC)). A TFM is said to be <em>miner incentive compatible</em> (MIC), iff given any bid vector <strong>b</strong>, the miner’s expected utility is maximized when the miner does not inject any fake bid and creates a block indicated by the honest inclusion rule.</p>\n<p>\\\n\\\n <img src=\"https://cdn.hackernoon.com/images/fWZa4tUiBGemnqQfBGgCPf9594N2-0dc33tv.png\" alt=\"\" /></p>\n<p>\\\n\\\n<strong>Definition 5</strong> (Global side-contract-proof (global SCP)). A TFM is said to be <em>global side-contract-proof (global SCP)</em>, iff given any vector of true values <strong>v</strong>, the expected social welfare is maximized when all the users bid according to the honest bidding rule, and the miner follows the honest inclusion rule, where the maximization is taken over all the coordinated strategies that the coalition consisting of the miner and all users can adopt.</p>\n<p>\\\n\\\n <img src=\"https://cdn.hackernoon.com/images/fWZa4tUiBGemnqQfBGgCPf9594N2-lqd33yw.png\" alt=\"\" /></p>\n<p>\\\n\\\nIn the definitions above, the expectation is taken over the randomness of the TFM. More explicitly, in Definition 2, the expectation is taken over the randomness of the inclusion/confirmation/payment rules; in Definitions 3 to 6, the expectation is taken over the randomness of the inclusion/confirmation/ payment/miner revenue rules.</p>\n<p>\\\nNote that in the OCA-proofness definition, σ is required to output a single real-valued bid. A canonical example of σ is scaling; that is, σ(v) = γv for some γ ∈ [0, 1] (cf., Corollary 5.12 and 5.14 in [Rou21]).</p>\n<p>\\\nA detailed comparison between c-SCP, global SCP, and OCA-proofness is given in Appendix A.</p>\n<p>\\</p>\n<p>:::info\n<strong>Authors:</strong></p>\n<p>(1) Hao Chung∗, Carnegie Mellon University (haochung@andrew.cmu.edu);</p>\n<p>(2) Tim Roughgarden†, Columbia University and a16z (crypto tim.roughgarden@gmail.com);</p>\n<p>(3) Elaine Shi∗, Carnegie Mellon University (runting@cs.cmu.edu).</p>\n<p>:::</p>\n<hr />\n<p>:::info\nThis paper is <strong><a href=\"https://arxiv.org/abs/2402.09321\">available on arxiv</a></strong> under CC BY 4.0 DEED license.</p>\n<p>:::</p>\n<p>[5] The finite block size regime in this work and [CS23] corresponds to the case in [Rou21] where the base fee in the EIP-1559 or tipless mechanisms is excessively low, i.e. the number of transactions willing to pay the base fee exceeds the maximum block size (cf., Definition 5.6 in [Rou21]).</p>\n<p>\\\n[6] The blockchain protocol can always suppress conflicting or double-spending transactions.</p>\n<p>\\\n[7] Throughout the paper except Section 8, we only focus on bidding rules that output a single bid. In Section 8, we consider general bidding rules that may output multiple bids.</p>\n<p>\\\n[8] Roughgarden [Rou21] assumes that all included transactions are confirmed. However, Chung and Shi [CS23] show that allowing unconfirmed transactions in a block enlarges the design space. For example, some mechanisms require a block to contain some unconfirmed transactions (see Section 7 in [CS23]).</p>\n<p>\\\n[9] We can also relax the requirement such that individual rationality holds in expectation. Both the impossibility results (Sections 4, 5 and 6.2) and the revelation principle result (Section 8) continue to hold.</p>",
          "content:encodedSnippet": "Table of Links\nAbstract and 1. Introduction\n1.1 Our Contributions\n1.2 TFM Incentive-Compatibility Notions: A Cheat Sheet\nDefinitions\n2.1 Transaction Fee Mechanism\n2.2 Incentive Compatibility Notions\n\n\nPreliminary: Myerson’s Lemma\n\n\nWarmup: Impossibility of UIC + MIC + Global SCP for Deterministic Mechanisms\n\n\nImpossibility of UIC + MIC + Global SCP for Randomized Mechanisms and 5.1 Proof Roadmap\n5.2 Formal Proofs\n\n\nFeasibility and Impossibility of UIC + MIC + OCA-Proof\n6.1 A Non-Truthful Mechanism with UIC + MIC + OCA-Proof\n6.2 Impossibility of UIC + MIC + OCA-Proof for Truthful Mechanisms\n\n\nHow to Circumvent the Impossibilities and 7.1 Allowing the Globally Optimal Strategy to Coordinate\n7.2 Allowing the Globally Optimal Strategy to Output Multiple Bids\n7.3 Inclusion-Rule-Respecting and 7.4 Discussions and Open Questions Regarding the Use of Cryptography\n\n\nStatic Revelation Principle for Transaction Fee Mechanisms\n8.1 Static Revelation Principle: Bidding Rules That Output Single Bid\n8.2 Static Revelation Principle: Allowing Bidding Rules that Output Multiple Bids\n\n\nA. Comparison of Collusion-Resilience Notions\nReferences\n2 Definitions\n2.1 Transaction Fee Mechanism\n\n\\\nA transaction fee mechanism (TFM) consists of the following possibly randomized algorithms:\n\\\n \n\\\nWe say a TFM is trivial if the confirmation probability of all transactions is zero for any bid vector assuming the miner honestly follows the inclusion rule; otherwise, it is called non-trivial.\n\\\nA strategic miner or miner-user coalition may deviate from the honest inclusion rule. On the other hand, since the confirmation, payment, and miner revenue rules are executed by the blockchain, they are always implemented honestly.\n\\\nWe focus on mechanisms that are weakly symmetric, i.e., mechanisms that do not make use of the bidders’ identities or other auxiliary information (e.g., timestamp, transaction metadata), except for tie-breaking among equal bids. More formally, we define weak symmetry as below.\n\\\nDefinition 1 (Weak symmetry). A mechanism is called weakly symmetric if the mechanism can always be equivalently described in the following manner: given a bid vector b where each bid may carry some extra information such as identity or timestamp, the honest mechanism always sorts the vector b by the bid amount first. During the sorting step, if multiple bids have the same amount, then arbitrary tie-breaking rules may be applied, and the tie-breaking can depend on extra information such as timestamp, identity, or random coins. After this sorting step, the inclusion rule and the confirmation rules should depend only on the amount of the bids and their relative position in the sorted bid vector.\n\\\n \n\\\nStrategy space. A strategic user can deviate from the honest bidding rule and post an arbitrary bid vector with zero to multiple bids. Without loss of generality, we may assume that in the strategic bid vector, at most one bid can correspond to the user’s actual transaction which has a non-zero true value; all other bids must be fake bids with zero true value. A strategic miner can deviate from the honest inclusion rule, and instead create an arbitrary block (subject to the block size limit) that includes any subset of the bid vector as well as any number of fake bids that it chooses to inject. A strategic miner-user coalition can adopt a combination of the above strategies.\n\\\nUtility and social welfare. For a user with true value v, let x ∈ {0, 1} be the indicator of whether its primary bid is confirmed or not, let p denote its total payment, then the user’s utility is x · v − p. The miner’s utility is simply its revenue. The social welfare is defined to be the sum of the utilities of all users and the miner (i.e., the total value of the confirmed transactions, less any burned payments).\n\\\nNotice that we allow the miner revenue to be smaller than the sum of users’ payment, since the coins can be burnt. When calculating the social welfare, the payments among the users and the miner are canceled out, so the social welfare is independent of the payment; however, the amount of burnt coins decreases the social welfare. For example, suppose there is only one user, and let p be the user’s payment and q be the amount of burnt coins. In this case, the user’s utility is x·v −p, the miner revenue is p − q, and the social welfare is (x · v − p) + (p − q) = x · v − q.\n2.2 Incentive Compatibility Notions\n\\\n \n\\\n\\\nDefinition 3 (Miner incentive compatible (MIC)). A TFM is said to be miner incentive compatible (MIC), iff given any bid vector b, the miner’s expected utility is maximized when the miner does not inject any fake bid and creates a block indicated by the honest inclusion rule.\n\\\n\\\n \n\\\n\\\nDefinition 5 (Global side-contract-proof (global SCP)). A TFM is said to be global side-contract-proof (global SCP), iff given any vector of true values v, the expected social welfare is maximized when all the users bid according to the honest bidding rule, and the miner follows the honest inclusion rule, where the maximization is taken over all the coordinated strategies that the coalition consisting of the miner and all users can adopt.\n\\\n\\\n \n\\\n\\\nIn the definitions above, the expectation is taken over the randomness of the TFM. More explicitly, in Definition 2, the expectation is taken over the randomness of the inclusion/confirmation/payment rules; in Definitions 3 to 6, the expectation is taken over the randomness of the inclusion/confirmation/ payment/miner revenue rules.\n\\\nNote that in the OCA-proofness definition, σ is required to output a single real-valued bid. A canonical example of σ is scaling; that is, σ(v) = γv for some γ ∈ [0, 1] (cf., Corollary 5.12 and 5.14 in [Rou21]).\n\\\nA detailed comparison between c-SCP, global SCP, and OCA-proofness is given in Appendix A.\n\\\n:::info\nAuthors:\n(1) Hao Chung∗, Carnegie Mellon University (haochung@andrew.cmu.edu);\n(2) Tim Roughgarden†, Columbia University and a16z (crypto tim.roughgarden@gmail.com);\n(3) Elaine Shi∗, Carnegie Mellon University (runting@cs.cmu.edu).\n:::\n:::info\nThis paper is available on arxiv under CC BY 4.0 DEED license.\n:::\n[5] The finite block size regime in this work and [CS23] corresponds to the case in [Rou21] where the base fee in the EIP-1559 or tipless mechanisms is excessively low, i.e. the number of transactions willing to pay the base fee exceeds the maximum block size (cf., Definition 5.6 in [Rou21]).\n\\\n[6] The blockchain protocol can always suppress conflicting or double-spending transactions.\n\\\n[7] Throughout the paper except Section 8, we only focus on bidding rules that output a single bid. In Section 8, we consider general bidding rules that may output multiple bids.\n\\\n[8] Roughgarden [Rou21] assumes that all included transactions are confirmed. However, Chung and Shi [CS23] show that allowing unconfirmed transactions in a block enlarges the design space. For example, some mechanisms require a block to contain some unconfirmed transactions (see Section 7 in [CS23]).\n\\\n[9] We can also relax the requirement such that individual rationality holds in expectation. Both the impossibility results (Sections 4, 5 and 6.2) and the revelation principle result (Section 8) continue to hold.",
          "dc:creator": "EScholar: Electronic Academic Papers for Scholars",
          "content": "This article breaks down key technical definitions around Transaction Fee Mechanisms (TFMs) in blockchain systems, focusing on miner and user strategies, incentive compatibility, and how social welfare is impacted by honest versus strategic behavior. It defines concepts like weak symmetry, miner incentive compatibility (MIC), and global side-contract-proofness (global SCP), showing how mechanisms can be gamed—and how properly designed rules aim to align incentives for optimal outcomes.\n\n",
          "contentSnippet": "This article breaks down key technical definitions around Transaction Fee Mechanisms (TFMs) in blockchain systems, focusing on miner and user strategies, incentive compatibility, and how social welfare is impacted by honest versus strategic behavior. It defines concepts like weak symmetry, miner incentive compatibility (MIC), and global side-contract-proofness (global SCP), showing how mechanisms can be gamed—and how properly designed rules aim to align incentives for optimal outcomes.",
          "guid": "https://hackernoon.com/what-is-a-transaction-fee-mechanism-definitions-incentives-and-strategies?source=rss",
          "categories": [
            "blockchain-scalability",
            "transaction-fee-mechanisms",
            "ethereum-eip-1559",
            "user-incentive-compatibility",
            "miner-incentive-compatibility",
            "oca-proofness",
            "side-contract-proofness",
            "auction-mechanisms"
          ],
          "isoDate": "2025-08-03T21:14:30.000Z"
        }
      },
      {
        "json": {
          "creator": "EScholar: Electronic Academic Papers for Scholars",
          "title": "Why No Transaction Fee Mechanism Can Truly Be Collusion-Proof",
          "link": "https://hackernoon.com/why-no-transaction-fee-mechanism-can-truly-be-collusion-proof?source=rss",
          "pubDate": "Sun, 03 Aug 2025 21:14:24 GMT",
          "content:encoded": "<h2 id=\"tableoflinks\">Table of Links</h2>\n<p><a href=\"https://hackernoon.com/preview/4oLJMbsTSjvo3VPjkwJP\">Abstract and 1. Introduction</a></p>\n<p><a href=\"http://hackernoon.com/preview/6civAjDXiM0nLRxmISCX\">1.1 Our Contributions</a></p>\n<p><a href=\"https://hackernoon.com/preview/rn535RkNoZ9IjhCV1Q3Z\">1.2 TFM Incentive-Compatibility Notions: A Cheat Sheet</a></p>\n<ol start=\"2\">\n<li><p>Definitions</p>\n<p><a href=\"http://hackernoon.com/preview/3AUt2wksTUSPQlT9CWPJ\">2.1 Transaction Fee Mechanism</a></p>\n<p><a href=\"http://hackernoon.com/preview/3AUt2wksTUSPQlT9CWPJ\">2.2 Incentive Compatibility Notions</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">Preliminary: Myerson’s Lemma</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">Warmup: Impossibility of UIC + MIC + Global SCP for Deterministic Mechanisms</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">Impossibility of UIC + MIC + Global SCP for Randomized Mechanisms and 5.1 Proof Roadmap</a></p>\n<p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">5.2 Formal Proofs</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">Feasibility and Impossibility of UIC + MIC + OCA-Proof</a></p>\n<p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">6.1 A Non-Truthful Mechanism with UIC + MIC + OCA-Proof</a></p>\n<p><a href=\"https://hackernoon.com/preview/2K7Tn6O6GAIT00hMX9DK\">6.2 Impossibility of UIC + MIC + OCA-Proof for Truthful Mechanisms</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">How to Circumvent the Impossibilities and 7.1 Allowing the Globally Optimal Strategy to Coordinate</a></p>\n<p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">7.2 Allowing the Globally Optimal Strategy to Output Multiple Bids</a></p>\n<p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">7.3 Inclusion-Rule-Respecting and 7.4 Discussions and Open Questions Regarding the Use of Cryptography</a></p></li>\n<li><p><a href=\"http://hackernoon.com/preview/Z8dr9maz547Ssrjgsu3J\">Static Revelation Principle for Transaction Fee Mechanisms</a></p>\n<p><a href=\"http://hackernoon.com/preview/Z8dr9maz547Ssrjgsu3J\">8.1 Static Revelation Principle: Bidding Rules That Output Single Bid</a></p>\n<p><a href=\"http://hackernoon.com/preview/UMYlU2A57LPtnNi7V0N8\">8.2 Static Revelation Principle: Allowing Bidding Rules that Output Multiple Bids</a></p></li>\n</ol>\n<p><a href=\"http://hackernoon.com/preview/I4X49OO1ZsInqtfGbfPe\">A. Comparison of Collusion-Resilience Notions</a></p>\n<p><a href=\"http://hackernoon.com/preview/I4X49OO1ZsInqtfGbfPe\">References</a></p>\n<h2 id=\"12tfmincentivecompatibilitynotionsacheatsheet\">1.2 TFM Incentive-Compatibility Notions: A Cheat Sheet</h2>\n<p>We gather here informal definitions and comparisons of the key incentive-compatibility notions used in this paper. First, a transaction fee mechanism specifies how a user is supposed to bid (as a function of its private valuation), which transactions a miner is supposed to include (as a function of the transactions it knows about and their bids), and the resulting outcome (the subset of included transactions that get confirmed, and the payments made by the users and received by the miner). If the bidding strategy suggested by the TFM is the identity, then we additionally call the TFM <em>truthful</em>. In this paper, as in the rest of the TFM literature, we consider only static mechanisms.</p>\n<p>\\\n• <strong>UIC</strong>. (Definition 2) Provided that the miner follows the suggested inclusion rule, the bidding strategy suggested by the TFM is a dominant strategy for users.</p>\n<p>\\\n• <strong>MIC</strong>. (Definition 3) The inclusion rule suggested by the TFM is always revenue-maximizing for the miner regardless of users’ bids; moreover, the miner cannot increase its revenue through the injection of fake transactions.</p>\n<p>\\\n<strong>• Global SCP.</strong> (Definition 5) If the miner follows the inclusion rule suggested by the TFM and all users follow the bidding rule suggested by the TFM, then their joint surplus is at least as large as it would be from any coordinated deviation.</p>\n<p>\\\n<strong>• c-SCP</strong>. (Definition 4) For every coalition of the miner and at most c users, if the miner follows the inclusion rule suggested by the TFM and the users in the coalition follow the bidding rule suggested by the TFM, then the joint surplus of the coalition is at least as large as it would be from any coordinated deviation (holding fixed the bids of users outside the coalition).</p>\n<p>\\\n<strong>• OCA-proof.</strong> (Definition 6) If the miner follows the inclusion rule suggested by the TFM and all users follow a suitably chosen individually rational bidding rule σ (possibly different from the one suggested in the TFM description), then their joint surplus is as large as it would be from any coordinated deviation.</p>\n<p>\\\nFor example, in [Rou21] it was shown that Ethereum’s EIP-1559 TFM and a variant called the “tipless mechanism” satisfy UIC, MIC, and OCA-proofness when there is no contention between transactions; in fact, in this case, these TFMs satisfy the c-SCP condition for every c ≥ 1. When there is contention between transactions for inclusion in a block, the EIP-1559 TFM loses its UIC property and the tipless mechanism loses (all three notions of) collusion-resilience.</p>\n<p>\\\nAs mentioned above:</p>\n<p>\\\n• (Theorem 8.1) A relevation principle holds for the global SCP and c-SCP notions: any UIC and MIC TFM that satisfies one of these properties can be simulated by a truthful UIC and MIC TFM that satisfies the same property.</p>\n<p>\\\n• A relevation principle does not in general hold for the OCA-proof notion: while there are non-truthful TFMs that satisfy UIC, MIC, and OCA-proofness (Section 6.1), there are no truthful TFMs that satisfy UIC, MIC, and OCA-proofness (Theorem 6.9).</p>\n<p>\\\nThe main result in Chung and Shi [CS23] states that, even among randomized TFMs, no TFM satisfies UIC and c-SCP for any c ≥ 1. Our Theorem 5.6 proves that, even among randomized TFMs, no TFM satisfies UIC, MIC, and global SCP. (Due to the revelation principle mentioned above, these impossibility results apply to both truthful and non-truthful TFMs.) Our Theorem 6.9 proves the stronger statement that, even among randomized TFMs, no truthful TFM satisfies UIC, MIC, and OCA-proofness.</p>\n<p>\\\nReflecting on the competing notions of collusion-resilience, we can observe the following. The cSCP condition may be particularly appropriate in scenarios where the primary concern is deviations by small coalitions, or in scenarios where users may wish to deviate in ways that exploit other users. The c-SCP condition is also notable in that, together with the UIC condition, it already triggers the impossibility result in [CS23] (without any appeal to MIC). The OCA-proofness condition is distinguished by being the weakest of the three notions (thus leading to the strongest impossibility results) and by allowing the discussion of non-UIC mechanisms.[4] For TFMs that are UIC and MIC, like those studied in this paper, global SCP is arguably the “right” definition—capturing the spirit of OCA-proofness, without any additional technical complications arising from users using different bidding strategies to satisfy UIC and collusion-resilience. Put differently, the UIC and MIC conditions imply that the miner and the users following their intended strategies constitutes a Nash equilibrium; the global SCP condition asserts that this Nash equilibrium is also robust to deviations by the grand coalition, while OCA-proofness only asserts such robustness for a possibly different strategy profile (defined by the intended inclusion rule and some individually rational bidding strategy). From this vantage point, one might view Theorem 5.6 as the main impossibility result in this paper, with Theorem 6.9 serving as a technically challenging extension of the result under still weaker incentive-compatibility conditions.</p>\n<p>\\</p>\n<p>:::info\n<strong>Authors:</strong></p>\n<p>(1) Hao Chung∗, Carnegie Mellon University (haochung@andrew.cmu.edu);</p>\n<p>(2) Tim Roughgarden†, Columbia University and a16z (crypto tim.roughgarden@gmail.com);</p>\n<p>(3) Elaine Shi∗, Carnegie Mellon University (runting@cs.cmu.edu).</p>\n<p>:::</p>\n<hr />\n<p>:::info\nThis paper is <strong><a href=\"https://arxiv.org/abs/2402.09321\">available on arxiv</a></strong> under CC BY 4.0 DEED license.</p>\n<p>:::</p>\n<p>[4] For example, in a first-price auction, the “reference outcome” might be defined by a (non-truthful) bidding strategy that would constitute a Bayes-Nash equilibrium with respect to some prior over user valuations (cf., Corollary 5.12 in [Rou21]).</p>",
          "content:encodedSnippet": "Table of Links\nAbstract and 1. Introduction\n1.1 Our Contributions\n1.2 TFM Incentive-Compatibility Notions: A Cheat Sheet\nDefinitions\n2.1 Transaction Fee Mechanism\n2.2 Incentive Compatibility Notions\n\n\nPreliminary: Myerson’s Lemma\n\n\nWarmup: Impossibility of UIC + MIC + Global SCP for Deterministic Mechanisms\n\n\nImpossibility of UIC + MIC + Global SCP for Randomized Mechanisms and 5.1 Proof Roadmap\n5.2 Formal Proofs\n\n\nFeasibility and Impossibility of UIC + MIC + OCA-Proof\n6.1 A Non-Truthful Mechanism with UIC + MIC + OCA-Proof\n6.2 Impossibility of UIC + MIC + OCA-Proof for Truthful Mechanisms\n\n\nHow to Circumvent the Impossibilities and 7.1 Allowing the Globally Optimal Strategy to Coordinate\n7.2 Allowing the Globally Optimal Strategy to Output Multiple Bids\n7.3 Inclusion-Rule-Respecting and 7.4 Discussions and Open Questions Regarding the Use of Cryptography\n\n\nStatic Revelation Principle for Transaction Fee Mechanisms\n8.1 Static Revelation Principle: Bidding Rules That Output Single Bid\n8.2 Static Revelation Principle: Allowing Bidding Rules that Output Multiple Bids\n\n\nA. Comparison of Collusion-Resilience Notions\nReferences\n1.2 TFM Incentive-Compatibility Notions: A Cheat Sheet\nWe gather here informal definitions and comparisons of the key incentive-compatibility notions used in this paper. First, a transaction fee mechanism specifies how a user is supposed to bid (as a function of its private valuation), which transactions a miner is supposed to include (as a function of the transactions it knows about and their bids), and the resulting outcome (the subset of included transactions that get confirmed, and the payments made by the users and received by the miner). If the bidding strategy suggested by the TFM is the identity, then we additionally call the TFM truthful. In this paper, as in the rest of the TFM literature, we consider only static mechanisms.\n\\\n• UIC. (Definition 2) Provided that the miner follows the suggested inclusion rule, the bidding strategy suggested by the TFM is a dominant strategy for users.\n\\\n• MIC. (Definition 3) The inclusion rule suggested by the TFM is always revenue-maximizing for the miner regardless of users’ bids; moreover, the miner cannot increase its revenue through the injection of fake transactions.\n\\\n• Global SCP. (Definition 5) If the miner follows the inclusion rule suggested by the TFM and all users follow the bidding rule suggested by the TFM, then their joint surplus is at least as large as it would be from any coordinated deviation.\n\\\n• c-SCP. (Definition 4) For every coalition of the miner and at most c users, if the miner follows the inclusion rule suggested by the TFM and the users in the coalition follow the bidding rule suggested by the TFM, then the joint surplus of the coalition is at least as large as it would be from any coordinated deviation (holding fixed the bids of users outside the coalition).\n\\\n• OCA-proof. (Definition 6) If the miner follows the inclusion rule suggested by the TFM and all users follow a suitably chosen individually rational bidding rule σ (possibly different from the one suggested in the TFM description), then their joint surplus is as large as it would be from any coordinated deviation.\n\\\nFor example, in [Rou21] it was shown that Ethereum’s EIP-1559 TFM and a variant called the “tipless mechanism” satisfy UIC, MIC, and OCA-proofness when there is no contention between transactions; in fact, in this case, these TFMs satisfy the c-SCP condition for every c ≥ 1. When there is contention between transactions for inclusion in a block, the EIP-1559 TFM loses its UIC property and the tipless mechanism loses (all three notions of) collusion-resilience.\n\\\nAs mentioned above:\n\\\n• (Theorem 8.1) A relevation principle holds for the global SCP and c-SCP notions: any UIC and MIC TFM that satisfies one of these properties can be simulated by a truthful UIC and MIC TFM that satisfies the same property.\n\\\n• A relevation principle does not in general hold for the OCA-proof notion: while there are non-truthful TFMs that satisfy UIC, MIC, and OCA-proofness (Section 6.1), there are no truthful TFMs that satisfy UIC, MIC, and OCA-proofness (Theorem 6.9).\n\\\nThe main result in Chung and Shi [CS23] states that, even among randomized TFMs, no TFM satisfies UIC and c-SCP for any c ≥ 1. Our Theorem 5.6 proves that, even among randomized TFMs, no TFM satisfies UIC, MIC, and global SCP. (Due to the revelation principle mentioned above, these impossibility results apply to both truthful and non-truthful TFMs.) Our Theorem 6.9 proves the stronger statement that, even among randomized TFMs, no truthful TFM satisfies UIC, MIC, and OCA-proofness.\n\\\nReflecting on the competing notions of collusion-resilience, we can observe the following. The cSCP condition may be particularly appropriate in scenarios where the primary concern is deviations by small coalitions, or in scenarios where users may wish to deviate in ways that exploit other users. The c-SCP condition is also notable in that, together with the UIC condition, it already triggers the impossibility result in [CS23] (without any appeal to MIC). The OCA-proofness condition is distinguished by being the weakest of the three notions (thus leading to the strongest impossibility results) and by allowing the discussion of non-UIC mechanisms.[4] For TFMs that are UIC and MIC, like those studied in this paper, global SCP is arguably the “right” definition—capturing the spirit of OCA-proofness, without any additional technical complications arising from users using different bidding strategies to satisfy UIC and collusion-resilience. Put differently, the UIC and MIC conditions imply that the miner and the users following their intended strategies constitutes a Nash equilibrium; the global SCP condition asserts that this Nash equilibrium is also robust to deviations by the grand coalition, while OCA-proofness only asserts such robustness for a possibly different strategy profile (defined by the intended inclusion rule and some individually rational bidding strategy). From this vantage point, one might view Theorem 5.6 as the main impossibility result in this paper, with Theorem 6.9 serving as a technically challenging extension of the result under still weaker incentive-compatibility conditions.\n\\\n:::info\nAuthors:\n(1) Hao Chung∗, Carnegie Mellon University (haochung@andrew.cmu.edu);\n(2) Tim Roughgarden†, Columbia University and a16z (crypto tim.roughgarden@gmail.com);\n(3) Elaine Shi∗, Carnegie Mellon University (runting@cs.cmu.edu).\n:::\n:::info\nThis paper is available on arxiv under CC BY 4.0 DEED license.\n:::\n[4] For example, in a first-price auction, the “reference outcome” might be defined by a (non-truthful) bidding strategy that would constitute a Bayes-Nash equilibrium with respect to some prior over user valuations (cf., Corollary 5.12 in [Rou21]).",
          "dc:creator": "EScholar: Electronic Academic Papers for Scholars",
          "content": "\nThis article breaks down the key incentive-compatibility notions in transaction fee mechanisms (TFMs), including UIC, MIC, SCP (global and c-SCP), and OCA-proofness. It compares their implications for miner and user behavior in blockchain systems, with special reference to Ethereum’s EIP-1559 and other proposed mechanisms. The article also highlights key impossibility results showing that no TFM can satisfy all desirable incentive properties, particularly under collusion scenarios. Whether you’re a researcher or protocol designer, this is your shortcut to understanding what’s truly achievable in decentralized fee markets.\n\n",
          "contentSnippet": "This article breaks down the key incentive-compatibility notions in transaction fee mechanisms (TFMs), including UIC, MIC, SCP (global and c-SCP), and OCA-proofness. It compares their implications for miner and user behavior in blockchain systems, with special reference to Ethereum’s EIP-1559 and other proposed mechanisms. The article also highlights key impossibility results showing that no TFM can satisfy all desirable incentive properties, particularly under collusion scenarios. Whether you’re a researcher or protocol designer, this is your shortcut to understanding what’s truly achievable in decentralized fee markets.",
          "guid": "https://hackernoon.com/why-no-transaction-fee-mechanism-can-truly-be-collusion-proof?source=rss",
          "categories": [
            "blockchain-scalability",
            "transaction-fee-mechanisms",
            "ethereum-eip-1559",
            "user-incentive-compatibility",
            "miner-incentive-compatibility",
            "oca-proofness",
            "side-contract-proofness",
            "auction-mechanisms"
          ],
          "isoDate": "2025-08-03T21:14:24.000Z"
        }
      },
      {
        "json": {
          "creator": "EScholar: Electronic Academic Papers for Scholars",
          "title": "Why Truthful Blockchain Mechanisms Fail Under Finite Block Sizes",
          "link": "https://hackernoon.com/why-truthful-blockchain-mechanisms-fail-under-finite-block-sizes?source=rss",
          "pubDate": "Sun, 03 Aug 2025 21:14:18 GMT",
          "content:encoded": "<h2 id=\"tableoflinks\">Table of Links</h2>\n<p><a href=\"https://hackernoon.com/preview/4oLJMbsTSjvo3VPjkwJP\">Abstract and 1. Introduction</a></p>\n<p><a href=\"http://hackernoon.com/preview/6civAjDXiM0nLRxmISCX\">1.1 Our Contributions</a></p>\n<p><a href=\"https://hackernoon.com/preview/rn535RkNoZ9IjhCV1Q3Z\">1.2 TFM Incentive-Compatibility Notions: A Cheat Sheet</a></p>\n<ol start=\"2\">\n<li><p>Definitions</p>\n<p><a href=\"http://hackernoon.com/preview/3AUt2wksTUSPQlT9CWPJ\">2.1 Transaction Fee Mechanism</a></p>\n<p><a href=\"http://hackernoon.com/preview/3AUt2wksTUSPQlT9CWPJ\">2.2 Incentive Compatibility Notions</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">Preliminary: Myerson’s Lemma</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">Warmup: Impossibility of UIC + MIC + Global SCP for Deterministic Mechanisms</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">Impossibility of UIC + MIC + Global SCP for Randomized Mechanisms and 5.1 Proof Roadmap</a></p>\n<p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">5.2 Formal Proofs</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">Feasibility and Impossibility of UIC + MIC + OCA-Proof</a></p>\n<p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">6.1 A Non-Truthful Mechanism with UIC + MIC + OCA-Proof</a></p>\n<p><a href=\"https://hackernoon.com/preview/2K7Tn6O6GAIT00hMX9DK\">6.2 Impossibility of UIC + MIC + OCA-Proof for Truthful Mechanisms</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">How to Circumvent the Impossibilities and 7.1 Allowing the Globally Optimal Strategy to Coordinate</a></p>\n<p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">7.2 Allowing the Globally Optimal Strategy to Output Multiple Bids</a></p>\n<p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">7.3 Inclusion-Rule-Respecting and 7.4 Discussions and Open Questions Regarding the Use of Cryptography</a></p></li>\n<li><p><a href=\"http://hackernoon.com/preview/Z8dr9maz547Ssrjgsu3J\">Static Revelation Principle for Transaction Fee Mechanisms</a></p>\n<p><a href=\"http://hackernoon.com/preview/Z8dr9maz547Ssrjgsu3J\">8.1 Static Revelation Principle: Bidding Rules That Output Single Bid</a></p>\n<p><a href=\"http://hackernoon.com/preview/UMYlU2A57LPtnNi7V0N8\">8.2 Static Revelation Principle: Allowing Bidding Rules that Output Multiple Bids</a></p></li>\n</ol>\n<p><a href=\"http://hackernoon.com/preview/I4X49OO1ZsInqtfGbfPe\">A. Comparison of Collusion-Resilience Notions</a></p>\n<p><a href=\"http://hackernoon.com/preview/I4X49OO1ZsInqtfGbfPe\">References</a></p>\n<h2 id=\"11ourcontributions\">1.1 Our Contributions</h2>\n<p>As explained above, both Roughgarden’s and Chung and Shi’s collusion-resilience notions capture meaningful incentive compatibility considerations. Recognizing their differences, one natural question is: does Chung and Shi’s finite-block impossibility result still hold if we adopt the original OCA-proofness notion of Roughgarden in lieu of c-SCP? Notably, no existing TFM construction [LSZ19, Yao, BEOS19, BCD+, Rou20, Rou21, FMPS21, CS23, SCW23, WSC24, GY22, ZCZ22, BGR23, TY23, KKLP23, XFP23, CMW23, LRMP23, Ndi23] simultaneously satisfies user incentive compatibility, miner incentive compatibility, and OCA-proofness under finite block size.</p>\n<p>\\\n<strong>Main impossibility result.</strong> In our work, we give an affirmative answer to the above question. We show that, indeed, an analog of Chung and Shi’s finite-block impossibility result still holds when we replace the c-SCP requirement with OCA-proofness. Specifically, we prove the following theorem.</p>\n<p>\\\n<strong>Theorem 1.1</strong>. <em>Suppose the block size is finite. Then, no possibly randomized, truthful TFM can simultaneously satisfy user incentive compatibility (UIC), miner incentive compatibility (MIC), and OCA-proofness. Further, this impossibility holds even when the globally optimal strategy σ need not be individually rational.</em></p>\n<p>\\\nIn a truthful TFM, a user is expected to bid truthfully, so if the mechanism satisfies UIC, a user’s utility is maximized when it just reports its true value. However, OCA-proofness allows the global coalition to adopt a non-truthful bidding strategy σ even for truthful mechanisms.</p>\n<p>\\\nOur Theorem 1.1 is intuitively stronger but technically incomparable in comparison with Chung and Shi’s impossibility, which shows that no TFM can simultaneously satisfy UIC and 1-SCP for finite block sizes. The reason is that Chung and Shi’s impossibility does not rely on MIC; however, MIC is necessary for our Theorem 1.1 to hold. Specifically, a simple second-price auction with no burning (see Remark 2) satisfies both UIC and OCA-proofness, but does not satisfy MIC since the miner may benefit by injecting a fake (t + 1)-th bid where t is the number of confirmed bids, since the (t + 1)-th bid sets the price for confirmed bids.</p>\n<p>\\\n<strong>Global SCP.</strong> We suggest a simpler version of OCA-proofness that we call global SCP, which also intuitively captures the requirement that strategic users and miners cannot steal from the protocol, and is perhaps more appropriate when focusing on UIC TFMs (as we do in this paper). In our work, global SCP is not only a technical <em>stepping stone</em> towards proving Theorem 1.1, but also of <em>independent interest</em> as we explain below. Specifically, global SCP is almost the same as OCAproofness, except for requiring σ to be the honest bidding strategy indicated by the mechanism (i.e., the same bidding strategy used to establish UIC). In other words, a mechanism satisfies global SCP if and only if the honest strategy is surplus-maximizing for the global coalition. It is easy to see that for a truthful mechanism, c-SCP for any c implies global SCP, which in turn implies OCA-proofness. To prove Theorem 1.1, we first prove the following theorem:</p>\n<p>\\\n<strong>Theorem 1.2.</strong> <em>Suppose that the block size is finite. Then no possibly randomized TFM can simultaneously satisfy user incentive compatibility (UIC), miner incentive compatibility (MIC), and global SCP. Further, the impossibility holds even for non-truthful mechanisms.</em></p>\n<p>\\\nWe now explain why the global SCP notion is of independent interest. One advantage of global SCP is that the <em>revelation principle</em> holds for any TFM that satisfies UIC, MIC, and global SCP, which we formally prove in Section 8. In other words, given any TFM that is UIC, MIC, and global SCP, there is an equivalent truthful mechanism that simulates it. For this reason, Theorem 1.2 rules out even non-truthful TFMs that simultaneously satisfy UIC, MIC, and global SCP.[3]</p>\n<p>\\\nBy contrast, Theorem 1.1 holds only for truthful mechanisms. In particular, in Section 6.1, we show a non-truthful mechanism that simultaneously satisfies UIC, MIC, and OCA-proof. The mechanism is contrived, but it demonstrates the subtlety and the technical challenges when modeling the notion of collusion-resilience. This also suggests that the revelation principle does not hold for mechanisms that satisfy UIC, MIC, and OCA-proofness, partly because in such a mechanism, the bidding strategies used to establish UIC and OCA-proofness may be different.</p>\n<p>\\\n<strong>Ways to circumvent the impossibilities.</strong> We show in Section 7 that the impossibility of Theorem 1.1 can be circumvented by allowing non-truthful mechanisms or by allowing users to coordinate in bidding in the globally optimal strategy σ. In the same section, we raise an open question regarding whether it is possible to use cryptography (e.g., the MPC-assisted model of Shi et al. [SCW23]) and Bayesian notions of incentive compatibility to circumvent the impossibilities.</p>\n<p>\\</p>\n<p>:::info\n<strong>Authors:</strong></p>\n<p>(1) Hao Chung∗, Carnegie Mellon University (haochung@andrew.cmu.edu);</p>\n<p>(2) Tim Roughgarden†, Columbia University and a16z (crypto tim.roughgarden@gmail.com);</p>\n<p>(3) Elaine Shi∗, Carnegie Mellon University (runting@cs.cmu.edu).</p>\n<p>:::</p>\n<hr />\n<p>:::info\nThis paper is <strong><a href=\"https://arxiv.org/abs/2402.09321\">available on arxiv</a></strong> under CC BY 4.0 DEED license.</p>\n<p>:::</p>\n<p>[3] Simultaneously with and independently of this paper, Gafni and Yaish [GY24] proved, among other results, a version of Theorem 1.2 for the special case of deterministic mechanisms and a block size of 1.</p>",
          "content:encodedSnippet": "Table of Links\nAbstract and 1. Introduction\n1.1 Our Contributions\n1.2 TFM Incentive-Compatibility Notions: A Cheat Sheet\nDefinitions\n2.1 Transaction Fee Mechanism\n2.2 Incentive Compatibility Notions\n\n\nPreliminary: Myerson’s Lemma\n\n\nWarmup: Impossibility of UIC + MIC + Global SCP for Deterministic Mechanisms\n\n\nImpossibility of UIC + MIC + Global SCP for Randomized Mechanisms and 5.1 Proof Roadmap\n5.2 Formal Proofs\n\n\nFeasibility and Impossibility of UIC + MIC + OCA-Proof\n6.1 A Non-Truthful Mechanism with UIC + MIC + OCA-Proof\n6.2 Impossibility of UIC + MIC + OCA-Proof for Truthful Mechanisms\n\n\nHow to Circumvent the Impossibilities and 7.1 Allowing the Globally Optimal Strategy to Coordinate\n7.2 Allowing the Globally Optimal Strategy to Output Multiple Bids\n7.3 Inclusion-Rule-Respecting and 7.4 Discussions and Open Questions Regarding the Use of Cryptography\n\n\nStatic Revelation Principle for Transaction Fee Mechanisms\n8.1 Static Revelation Principle: Bidding Rules That Output Single Bid\n8.2 Static Revelation Principle: Allowing Bidding Rules that Output Multiple Bids\n\n\nA. Comparison of Collusion-Resilience Notions\nReferences\n1.1 Our Contributions\nAs explained above, both Roughgarden’s and Chung and Shi’s collusion-resilience notions capture meaningful incentive compatibility considerations. Recognizing their differences, one natural question is: does Chung and Shi’s finite-block impossibility result still hold if we adopt the original OCA-proofness notion of Roughgarden in lieu of c-SCP? Notably, no existing TFM construction [LSZ19, Yao, BEOS19, BCD+, Rou20, Rou21, FMPS21, CS23, SCW23, WSC24, GY22, ZCZ22, BGR23, TY23, KKLP23, XFP23, CMW23, LRMP23, Ndi23] simultaneously satisfies user incentive compatibility, miner incentive compatibility, and OCA-proofness under finite block size.\n\\\nMain impossibility result. In our work, we give an affirmative answer to the above question. We show that, indeed, an analog of Chung and Shi’s finite-block impossibility result still holds when we replace the c-SCP requirement with OCA-proofness. Specifically, we prove the following theorem.\n\\\nTheorem 1.1. Suppose the block size is finite. Then, no possibly randomized, truthful TFM can simultaneously satisfy user incentive compatibility (UIC), miner incentive compatibility (MIC), and OCA-proofness. Further, this impossibility holds even when the globally optimal strategy σ need not be individually rational.\n\\\nIn a truthful TFM, a user is expected to bid truthfully, so if the mechanism satisfies UIC, a user’s utility is maximized when it just reports its true value. However, OCA-proofness allows the global coalition to adopt a non-truthful bidding strategy σ even for truthful mechanisms.\n\\\nOur Theorem 1.1 is intuitively stronger but technically incomparable in comparison with Chung and Shi’s impossibility, which shows that no TFM can simultaneously satisfy UIC and 1-SCP for finite block sizes. The reason is that Chung and Shi’s impossibility does not rely on MIC; however, MIC is necessary for our Theorem 1.1 to hold. Specifically, a simple second-price auction with no burning (see Remark 2) satisfies both UIC and OCA-proofness, but does not satisfy MIC since the miner may benefit by injecting a fake (t + 1)-th bid where t is the number of confirmed bids, since the (t + 1)-th bid sets the price for confirmed bids.\n\\\nGlobal SCP. We suggest a simpler version of OCA-proofness that we call global SCP, which also intuitively captures the requirement that strategic users and miners cannot steal from the protocol, and is perhaps more appropriate when focusing on UIC TFMs (as we do in this paper). In our work, global SCP is not only a technical stepping stone towards proving Theorem 1.1, but also of independent interest as we explain below. Specifically, global SCP is almost the same as OCAproofness, except for requiring σ to be the honest bidding strategy indicated by the mechanism (i.e., the same bidding strategy used to establish UIC). In other words, a mechanism satisfies global SCP if and only if the honest strategy is surplus-maximizing for the global coalition. It is easy to see that for a truthful mechanism, c-SCP for any c implies global SCP, which in turn implies OCA-proofness. To prove Theorem 1.1, we first prove the following theorem:\n\\\nTheorem 1.2. Suppose that the block size is finite. Then no possibly randomized TFM can simultaneously satisfy user incentive compatibility (UIC), miner incentive compatibility (MIC), and global SCP. Further, the impossibility holds even for non-truthful mechanisms.\n\\\nWe now explain why the global SCP notion is of independent interest. One advantage of global SCP is that the revelation principle holds for any TFM that satisfies UIC, MIC, and global SCP, which we formally prove in Section 8. In other words, given any TFM that is UIC, MIC, and global SCP, there is an equivalent truthful mechanism that simulates it. For this reason, Theorem 1.2 rules out even non-truthful TFMs that simultaneously satisfy UIC, MIC, and global SCP.[3]\n\\\nBy contrast, Theorem 1.1 holds only for truthful mechanisms. In particular, in Section 6.1, we show a non-truthful mechanism that simultaneously satisfies UIC, MIC, and OCA-proof. The mechanism is contrived, but it demonstrates the subtlety and the technical challenges when modeling the notion of collusion-resilience. This also suggests that the revelation principle does not hold for mechanisms that satisfy UIC, MIC, and OCA-proofness, partly because in such a mechanism, the bidding strategies used to establish UIC and OCA-proofness may be different.\n\\\nWays to circumvent the impossibilities. We show in Section 7 that the impossibility of Theorem 1.1 can be circumvented by allowing non-truthful mechanisms or by allowing users to coordinate in bidding in the globally optimal strategy σ. In the same section, we raise an open question regarding whether it is possible to use cryptography (e.g., the MPC-assisted model of Shi et al. [SCW23]) and Bayesian notions of incentive compatibility to circumvent the impossibilities.\n\\\n:::info\nAuthors:\n(1) Hao Chung∗, Carnegie Mellon University (haochung@andrew.cmu.edu);\n(2) Tim Roughgarden†, Columbia University and a16z (crypto tim.roughgarden@gmail.com);\n(3) Elaine Shi∗, Carnegie Mellon University (runting@cs.cmu.edu).\n:::\n:::info\nThis paper is available on arxiv under CC BY 4.0 DEED license.\n:::\n[3] Simultaneously with and independently of this paper, Gafni and Yaish [GY24] proved, among other results, a version of Theorem 1.2 for the special case of deterministic mechanisms and a block size of 1.",
          "dc:creator": "EScholar: Electronic Academic Papers for Scholars",
          "content": "This paper establishes a new impossibility result in blockchain mechanism design: no truthful fee market (TFM) mechanism can simultaneously satisfy user incentive compatibility (UIC), miner incentive compatibility (MIC), and OCA-proofness under finite block sizes. By introducing and analyzing a simplified alternative called global SCP, the authors demonstrate that even non-truthful mechanisms face critical limitations. Their work refines earlier findings from Chung and Shi while offering insights into potential workarounds—such as non-truthful bidding strategies and cryptographic coordination—to build more resilient protocols.",
          "contentSnippet": "This paper establishes a new impossibility result in blockchain mechanism design: no truthful fee market (TFM) mechanism can simultaneously satisfy user incentive compatibility (UIC), miner incentive compatibility (MIC), and OCA-proofness under finite block sizes. By introducing and analyzing a simplified alternative called global SCP, the authors demonstrate that even non-truthful mechanisms face critical limitations. Their work refines earlier findings from Chung and Shi while offering insights into potential workarounds—such as non-truthful bidding strategies and cryptographic coordination—to build more resilient protocols.",
          "guid": "https://hackernoon.com/why-truthful-blockchain-mechanisms-fail-under-finite-block-sizes?source=rss",
          "categories": [
            "blockchain-scalability",
            "transaction-fee-mechanisms",
            "ethereum-eip-1559",
            "user-incentive-compatibility",
            "miner-incentive-compatibility",
            "oca-proofness",
            "side-contract-proofness",
            "auction-mechanisms"
          ],
          "isoDate": "2025-08-03T21:14:18.000Z"
        }
      },
      {
        "json": {
          "creator": "EScholar: Electronic Academic Papers for Scholars",
          "title": "Why the Perfect Blockchain Fee Mechanism May Be Impossible",
          "link": "https://hackernoon.com/why-the-perfect-blockchain-fee-mechanism-may-be-impossible?source=rss",
          "pubDate": "Sun, 03 Aug 2025 21:14:14 GMT",
          "content:encoded": "<p>:::info\n<strong>Authors:</strong></p>\n<p>(1) Hao Chung∗, Carnegie Mellon University (haochung@andrew.cmu.edu);</p>\n<p>(2) Tim Roughgarden†, Columbia University and a16z (crypto tim.roughgarden@gmail.com);</p>\n<p>(3) Elaine Shi∗, Carnegie Mellon University (runting@cs.cmu.edu).</p>\n<p>:::</p>\n<h2 id=\"tableoflinks\">Table of Links</h2>\n<p><a href=\"https://hackernoon.com/preview/4oLJMbsTSjvo3VPjkwJP\">Abstract and 1. Introduction</a></p>\n<p><a href=\"http://hackernoon.com/preview/6civAjDXiM0nLRxmISCX\">1.1 Our Contributions</a></p>\n<p><a href=\"https://hackernoon.com/preview/rn535RkNoZ9IjhCV1Q3Z\">1.2 TFM Incentive-Compatibility Notions: A Cheat Sheet</a></p>\n<ol start=\"2\">\n<li><p>Definitions</p>\n<p><a href=\"http://hackernoon.com/preview/3AUt2wksTUSPQlT9CWPJ\">2.1 Transaction Fee Mechanism</a></p>\n<p><a href=\"http://hackernoon.com/preview/3AUt2wksTUSPQlT9CWPJ\">2.2 Incentive Compatibility Notions</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">Preliminary: Myerson’s Lemma</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">Warmup: Impossibility of UIC + MIC + Global SCP for Deterministic Mechanisms</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">Impossibility of UIC + MIC + Global SCP for Randomized Mechanisms and 5.1 Proof Roadmap</a></p>\n<p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">5.2 Formal Proofs</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">Feasibility and Impossibility of UIC + MIC + OCA-Proof</a></p>\n<p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">6.1 A Non-Truthful Mechanism with UIC + MIC + OCA-Proof</a></p>\n<p><a href=\"https://hackernoon.com/preview/2K7Tn6O6GAIT00hMX9DK\">6.2 Impossibility of UIC + MIC + OCA-Proof for Truthful Mechanisms</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">How to Circumvent the Impossibilities and 7.1 Allowing the Globally Optimal Strategy to Coordinate</a></p>\n<p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">7.2 Allowing the Globally Optimal Strategy to Output Multiple Bids</a></p>\n<p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">7.3 Inclusion-Rule-Respecting and 7.4 Discussions and Open Questions Regarding the Use of Cryptography</a></p></li>\n<li><p><a href=\"http://hackernoon.com/preview/Z8dr9maz547Ssrjgsu3J\">Static Revelation Principle for Transaction Fee Mechanisms</a></p>\n<p><a href=\"http://hackernoon.com/preview/Z8dr9maz547Ssrjgsu3J\">8.1 Static Revelation Principle: Bidding Rules That Output Single Bid</a></p>\n<p><a href=\"http://hackernoon.com/preview/UMYlU2A57LPtnNi7V0N8\">8.2 Static Revelation Principle: Allowing Bidding Rules that Output Multiple Bids</a></p></li>\n</ol>\n<p><a href=\"http://hackernoon.com/preview/I4X49OO1ZsInqtfGbfPe\">A. Comparison of Collusion-Resilience Notions</a></p>\n<p><a href=\"http://hackernoon.com/preview/I4X49OO1ZsInqtfGbfPe\">References</a></p>\n<h2 id=\"abstract\">Abstract</h2>\n<p>Users bid in a transaction fee mechanism (TFM) to get their transactions included and confirmed by a blockchain protocol. Roughgarden (EC’21) initiated the formal treatment of TFMs and proposed three requirements: user incentive compatibility (UIC), miner incentive compatibility (MIC), and a form of collusion-resilience called OCA-proofness. Ethereum’s EIP1559 mechanism satisfies all three properties simultaneously when there is no contention between transactions, but loses the UIC property when there are too many eligible transactions to fit in a single block. Chung and Shi (SODA’23) considered an alternative notion of collusion-resilience, called c-side-contract-proofness (c-SCP), and showed that, when there is contention between transactions, no TFM can satisfy UIC, MIC, and c-SCP for any c ≥ 1. OCA-proofness asserts that the users and a miner should not be able to “steal from the protocol.” On the other hand, the c-SCP condition requires that a coalition of a miner and a subset of users should not be able to profit through strategic deviations (whether at the expense of the protocol or of the users outside the coalition).</p>\n<p>\\\nOur main result is the first proof that, when there is contention between transactions, no (possibly randomized) TFM in which users are expected to bid truthfully satisfies UIC, MIC, and OCA-proofness. This result resolves the main open question in Roughgarden (EC’21). We also suggest several relaxations of the basic model that allow our impossibility result to be circumvented.</p>\n<h3 id=\"1introduction\">1 Introduction</h3>\n<p>Real estate on the blockchain is scarce, and blockchain users bid in an auction called the transaction fee mechanism (TFM) to have their transactions included and confirmed on the blockchain. The original Bitcoin protocol adopted a simple first-price auction, where the top k bids win and they each pay their bid. However, such first-price auctions are known to incentivize untruthful bidding. Therefore, a line of subsequent works [LSZ19, Yao, BEOS19, BCD+, Rou20, Rou21, FMPS21, CS23, SCW23, WSC24, GY22, ZCZ22, BGR23, TY23, KKLP23, XFP23, CMW23, LRMP23, Ndi23] explored what is the “dream TFM” for blockchains. Most works [Rou20, Rou21, CS23, SCW23, WSC24, GY22, GY22, ZCZ22, BGR23, TY23] agree on roughly the same set of desiderata, that is, a dream TFM should provide incentive compatibility not just for an individual user, but also for the miner of the block. Further, a dream TFM should provide resilience against miner-user collusion.</p>\n<p>\\\nRoughgarden [Rou21] was the first to formally define the aforementioned requirements for a TFM, which he referred to as <em>user incentive compatibility</em>[1], (myopic) <em>miner incentive compatibility</em>, and <em>OCA-proofness</em>, where OCA stands for “off-chain agreement” and refers to colluding strategies between the miner and a set of users that allow off-chain transfers. Roughgarden [Rou21] also showed that the simple “posted price auction with all fees burnt” mechanism, which corresponds to the behavior of Ethereum’s EIP-1559 TFM [BCD+] when there is no congestion, satisfies all three properties. However, the posted price auction with all fees burnt does not satisfy all three properties when there is congestion. In practice, congestion does occur when there are major events such as an NFT mint or price fluctuations — for example, in Ethereum, roughly 2.3% of the blocks experience congestion.[2] When congestion arises, approximately speaking, Ethereum’s EIP-1559 mechanism falls back to the first-price auction, violating user incentive compatibility. Therefore, an interesting question is whether we can design a dream TFM satisfying all three properties for finite block sizes.</p>\n<p>\\\nChung and Shi [CS23] considered an alternative notion of collusion-resilience, called sidecontract-proofness. Unfortunately, they proved that no (even randomized) TFM can simultaneously satisfy user incentive compatibility and side-contract-proofness. Because side-contract-proofness is a more demanding property than OCA-proofness, the question raised by Roughgarden [Rou21], of whether there is a dream TFM satisfying all three properties under his collusion-resilience notion, had remained open.</p>\n<p>\\\n<strong>Two notions of miner-user collusion-resilience.</strong> Multiple natural notions of collusion-resilience can and have been studied in the context of TFM design. Here we clarify informally the key differences between the notions proposed by Roughgarden [Rou21] and Chung and Shi [CS23]. These notions are defined formally in Definitions 4–6 (see Section 2) and compared further via examples in Appendix A.</p>\n<p>\\\n<strong>• OCA-proofness:</strong> Roughgarden’s notion, henceforth referred to as OCA-proofness, asserts that there should exist a “reference strategy” for a miner and all users that is guaranteed to maximize their joint surplus. In this reference strategy, the miner is expected to follow the inclusion rule intended by the TFM. For users, the definition requires only that users follow some fixed bidding trategy σ (i.e., a mapping from a private user valuation to a user bid) that is individually rational (i.e., σ(v) ≤ v for all v ≥ 0). In particular, in the reference strategy, users are expected to bid independently (with a user’s bid independent of other users’ valuations and bids), and expected to submit a single bid (with no additional fake bids injected). One example of such a bidding strategy is the truth-telling strategy (with σ(v) = v). Because Roughgarden [Rou21] wished to discuss the OCA-proofness properties of non-UIC TFMs like first-price auctions, the definition also allows the reference strategy to be defined by a non-truthful bidding strategy (e.g., σ(v) = v/2). As a consequence, to prove that a TFM is both UIC and OCA-proof, it is sufficient to prove that it is UIC under one bidding strategy and OCA-proof under a possibly different bidding strategy (as in the example in Section 6.1).</p>\n<p>\\\n<strong>• <em>c</em>-SCP:</strong> Chung and Shi’s notion [CS23], henceforth called c-SCP (where SCP stands for sidecontract-proofness), requires that the honest strategy (i.e., all users follow the honest bidding rule and the miner honestly implements the inclusion rule) is the profit-maximizing strategy for any coalition consisting of the miner of the present block and at most c users. For truthful mechanisms, the honest bidding rule is the truthful one, while for non-truthful mechanisms, the bidding rule can be more general (see Section 2.1 for the formal definition). Chung and Shi’s notion aligns with standard notions used in a line of work at the intersection of game theory and cryptography [HT04, KN08, ADGH06, OPRV09, AL11, ACH11, GKM+13, GKTZ15, GTZ15, Kat08, DR07, GLR10, CGL+18, WAS22, CCWS21, PS17, KMSW22, FW20, EFW22].</p>\n<p>\\\n<strong>Discussion</strong>. The two notions of collusion-resilience address different issues. OCA-proofness captures the intuitive requirement that the users and miners <em>should not be able to steal from the protocol</em> through strategic deviations — for this reason, it considers <em>only the global coalition</em> consisting of the miner and all users. By contrast, the c-SCP notion captures the intuitive idea that a miner-user coalition’s best response is to act honestly, and that no strategic deviations can allow the coalition to <em>steal from other users or steal from the protocol</em>. For further discussion, see the end of this section and Appendix A.</p>\n<p>\\</p>\n<p>:::info\nThis paper is <strong><a href=\"https://arxiv.org/abs/2402.09321\">available on arxiv</a></strong> under CC BY 4.0 DEED license.</p>\n<p>:::</p>\n<p>∗Supported by NSF awards 2212746, 2044679, 1704788, a Packard Fellowship, a generous gift from the late Nikolai Mushegian, a gift from Google, and an ACE center grant from Algorand Foundation.</p>\n<p>\\\n†Author’s research at Columbia University supported in part by NSF awards CCF-2006737 and CNS-2212745, and research awards from the Briger Family Digital Finance Lab and the Center for Digital Finance and Technologies.</p>\n<p>\\\n[1] User incentive compatibility (UIC) is usually called dominant-strategy incentive compatible (DSIC) in the mechanism design literature. In general, we allow UIC TFMs to make use of non-truthful (but dominant) bidding strategies (see Definition 2).</p>\n<p>\\\n[2] From Jan 1, 2024 to Feb 5, 2024, 256595 blocks have been produced on Ethereum, and 5840 blocks among them were full (meaning more than 99.9% of the gas limit (30M) was used).</p>",
          "content:encodedSnippet": ":::info\nAuthors:\n(1) Hao Chung∗, Carnegie Mellon University (haochung@andrew.cmu.edu);\n(2) Tim Roughgarden†, Columbia University and a16z (crypto tim.roughgarden@gmail.com);\n(3) Elaine Shi∗, Carnegie Mellon University (runting@cs.cmu.edu).\n:::\nTable of Links\nAbstract and 1. Introduction\n1.1 Our Contributions\n1.2 TFM Incentive-Compatibility Notions: A Cheat Sheet\nDefinitions\n2.1 Transaction Fee Mechanism\n2.2 Incentive Compatibility Notions\n\n\nPreliminary: Myerson’s Lemma\n\n\nWarmup: Impossibility of UIC + MIC + Global SCP for Deterministic Mechanisms\n\n\nImpossibility of UIC + MIC + Global SCP for Randomized Mechanisms and 5.1 Proof Roadmap\n5.2 Formal Proofs\n\n\nFeasibility and Impossibility of UIC + MIC + OCA-Proof\n6.1 A Non-Truthful Mechanism with UIC + MIC + OCA-Proof\n6.2 Impossibility of UIC + MIC + OCA-Proof for Truthful Mechanisms\n\n\nHow to Circumvent the Impossibilities and 7.1 Allowing the Globally Optimal Strategy to Coordinate\n7.2 Allowing the Globally Optimal Strategy to Output Multiple Bids\n7.3 Inclusion-Rule-Respecting and 7.4 Discussions and Open Questions Regarding the Use of Cryptography\n\n\nStatic Revelation Principle for Transaction Fee Mechanisms\n8.1 Static Revelation Principle: Bidding Rules That Output Single Bid\n8.2 Static Revelation Principle: Allowing Bidding Rules that Output Multiple Bids\n\n\nA. Comparison of Collusion-Resilience Notions\nReferences\nAbstract\nUsers bid in a transaction fee mechanism (TFM) to get their transactions included and confirmed by a blockchain protocol. Roughgarden (EC’21) initiated the formal treatment of TFMs and proposed three requirements: user incentive compatibility (UIC), miner incentive compatibility (MIC), and a form of collusion-resilience called OCA-proofness. Ethereum’s EIP1559 mechanism satisfies all three properties simultaneously when there is no contention between transactions, but loses the UIC property when there are too many eligible transactions to fit in a single block. Chung and Shi (SODA’23) considered an alternative notion of collusion-resilience, called c-side-contract-proofness (c-SCP), and showed that, when there is contention between transactions, no TFM can satisfy UIC, MIC, and c-SCP for any c ≥ 1. OCA-proofness asserts that the users and a miner should not be able to “steal from the protocol.” On the other hand, the c-SCP condition requires that a coalition of a miner and a subset of users should not be able to profit through strategic deviations (whether at the expense of the protocol or of the users outside the coalition).\n\\\nOur main result is the first proof that, when there is contention between transactions, no (possibly randomized) TFM in which users are expected to bid truthfully satisfies UIC, MIC, and OCA-proofness. This result resolves the main open question in Roughgarden (EC’21). We also suggest several relaxations of the basic model that allow our impossibility result to be circumvented.\n1 Introduction\nReal estate on the blockchain is scarce, and blockchain users bid in an auction called the transaction fee mechanism (TFM) to have their transactions included and confirmed on the blockchain. The original Bitcoin protocol adopted a simple first-price auction, where the top k bids win and they each pay their bid. However, such first-price auctions are known to incentivize untruthful bidding. Therefore, a line of subsequent works [LSZ19, Yao, BEOS19, BCD+, Rou20, Rou21, FMPS21, CS23, SCW23, WSC24, GY22, ZCZ22, BGR23, TY23, KKLP23, XFP23, CMW23, LRMP23, Ndi23] explored what is the “dream TFM” for blockchains. Most works [Rou20, Rou21, CS23, SCW23, WSC24, GY22, GY22, ZCZ22, BGR23, TY23] agree on roughly the same set of desiderata, that is, a dream TFM should provide incentive compatibility not just for an individual user, but also for the miner of the block. Further, a dream TFM should provide resilience against miner-user collusion.\n\\\nRoughgarden [Rou21] was the first to formally define the aforementioned requirements for a TFM, which he referred to as user incentive compatibility[1], (myopic) miner incentive compatibility, and OCA-proofness, where OCA stands for “off-chain agreement” and refers to colluding strategies between the miner and a set of users that allow off-chain transfers. Roughgarden [Rou21] also showed that the simple “posted price auction with all fees burnt” mechanism, which corresponds to the behavior of Ethereum’s EIP-1559 TFM [BCD+] when there is no congestion, satisfies all three properties. However, the posted price auction with all fees burnt does not satisfy all three properties when there is congestion. In practice, congestion does occur when there are major events such as an NFT mint or price fluctuations — for example, in Ethereum, roughly 2.3% of the blocks experience congestion.[2] When congestion arises, approximately speaking, Ethereum’s EIP-1559 mechanism falls back to the first-price auction, violating user incentive compatibility. Therefore, an interesting question is whether we can design a dream TFM satisfying all three properties for finite block sizes.\n\\\nChung and Shi [CS23] considered an alternative notion of collusion-resilience, called sidecontract-proofness. Unfortunately, they proved that no (even randomized) TFM can simultaneously satisfy user incentive compatibility and side-contract-proofness. Because side-contract-proofness is a more demanding property than OCA-proofness, the question raised by Roughgarden [Rou21], of whether there is a dream TFM satisfying all three properties under his collusion-resilience notion, had remained open.\n\\\nTwo notions of miner-user collusion-resilience. Multiple natural notions of collusion-resilience can and have been studied in the context of TFM design. Here we clarify informally the key differences between the notions proposed by Roughgarden [Rou21] and Chung and Shi [CS23]. These notions are defined formally in Definitions 4–6 (see Section 2) and compared further via examples in Appendix A.\n\\\n• OCA-proofness: Roughgarden’s notion, henceforth referred to as OCA-proofness, asserts that there should exist a “reference strategy” for a miner and all users that is guaranteed to maximize their joint surplus. In this reference strategy, the miner is expected to follow the inclusion rule intended by the TFM. For users, the definition requires only that users follow some fixed bidding trategy σ (i.e., a mapping from a private user valuation to a user bid) that is individually rational (i.e., σ(v) ≤ v for all v ≥ 0). In particular, in the reference strategy, users are expected to bid independently (with a user’s bid independent of other users’ valuations and bids), and expected to submit a single bid (with no additional fake bids injected). One example of such a bidding strategy is the truth-telling strategy (with σ(v) = v). Because Roughgarden [Rou21] wished to discuss the OCA-proofness properties of non-UIC TFMs like first-price auctions, the definition also allows the reference strategy to be defined by a non-truthful bidding strategy (e.g., σ(v) = v/2). As a consequence, to prove that a TFM is both UIC and OCA-proof, it is sufficient to prove that it is UIC under one bidding strategy and OCA-proof under a possibly different bidding strategy (as in the example in Section 6.1).\n\\\n• c-SCP: Chung and Shi’s notion [CS23], henceforth called c-SCP (where SCP stands for sidecontract-proofness), requires that the honest strategy (i.e., all users follow the honest bidding rule and the miner honestly implements the inclusion rule) is the profit-maximizing strategy for any coalition consisting of the miner of the present block and at most c users. For truthful mechanisms, the honest bidding rule is the truthful one, while for non-truthful mechanisms, the bidding rule can be more general (see Section 2.1 for the formal definition). Chung and Shi’s notion aligns with standard notions used in a line of work at the intersection of game theory and cryptography [HT04, KN08, ADGH06, OPRV09, AL11, ACH11, GKM+13, GKTZ15, GTZ15, Kat08, DR07, GLR10, CGL+18, WAS22, CCWS21, PS17, KMSW22, FW20, EFW22].\n\\\nDiscussion. The two notions of collusion-resilience address different issues. OCA-proofness captures the intuitive requirement that the users and miners should not be able to steal from the protocol through strategic deviations — for this reason, it considers only the global coalition consisting of the miner and all users. By contrast, the c-SCP notion captures the intuitive idea that a miner-user coalition’s best response is to act honestly, and that no strategic deviations can allow the coalition to steal from other users or steal from the protocol. For further discussion, see the end of this section and Appendix A.\n\\\n:::info\nThis paper is available on arxiv under CC BY 4.0 DEED license.\n:::\n∗Supported by NSF awards 2212746, 2044679, 1704788, a Packard Fellowship, a generous gift from the late Nikolai Mushegian, a gift from Google, and an ACE center grant from Algorand Foundation.\n\\\n†Author’s research at Columbia University supported in part by NSF awards CCF-2006737 and CNS-2212745, and research awards from the Briger Family Digital Finance Lab and the Center for Digital Finance and Technologies.\n\\\n[1] User incentive compatibility (UIC) is usually called dominant-strategy incentive compatible (DSIC) in the mechanism design literature. In general, we allow UIC TFMs to make use of non-truthful (but dominant) bidding strategies (see Definition 2).\n\\\n[2] From Jan 1, 2024 to Feb 5, 2024, 256595 blocks have been produced on Ethereum, and 5840 blocks among them were full (meaning more than 99.9% of the gas limit (30M) was used).",
          "dc:creator": "EScholar: Electronic Academic Papers for Scholars",
          "content": "This article explores the theoretical boundaries of transaction fee mechanisms (TFMs) in blockchain systems, particularly under congestion. Building on Roughgarden’s and Chung & Shi’s foundational work, the authors prove that no mechanism can simultaneously ensure user incentive compatibility (UIC), miner incentive compatibility (MIC), and collusion-resilience (OCA-proofness) when transaction demand exceeds block capacity. This impossibility result resolves a major open question and outlines where future TFM designs must compromise or adapt.\n\n",
          "contentSnippet": "This article explores the theoretical boundaries of transaction fee mechanisms (TFMs) in blockchain systems, particularly under congestion. Building on Roughgarden’s and Chung & Shi’s foundational work, the authors prove that no mechanism can simultaneously ensure user incentive compatibility (UIC), miner incentive compatibility (MIC), and collusion-resilience (OCA-proofness) when transaction demand exceeds block capacity. This impossibility result resolves a major open question and outlines where future TFM designs must compromise or adapt.",
          "guid": "https://hackernoon.com/why-the-perfect-blockchain-fee-mechanism-may-be-impossible?source=rss",
          "categories": [
            "blockchain-scalability",
            "transaction-fee-mechanisms",
            "ethereum-eip-1559",
            "user-incentive-compatibility",
            "collusion-resilience",
            "oca-proofness",
            "auction-mechanisms",
            "hackernoon-top-story"
          ],
          "isoDate": "2025-08-03T21:14:14.000Z"
        }
      },
      {
        "json": {
          "creator": "Mfonobong Umondia",
          "title": "Designing for Intelligence, Efficiency, and Accessibility",
          "link": "https://hackernoon.com/designing-for-intelligence-efficiency-and-accessibility?source=rss",
          "pubDate": "Sun, 03 Aug 2025 20:01:13 GMT",
          "content:encoded": "<p>A few years ago, if someone mentioned Artificial Intelligence in a product design meeting, they’d likely be met with skeptical glances or a cautious “let’s not overcomplicate things.” Today? AI isn’t just welcome at the UX table; it’s practically running the show.</p>\n<p>We’re in a new era where the user experience is no longer just about beautifully designed buttons and seamless navigation; it's about intelligence. It’s about designing systems that think a little, predict a lot, and adapt even more. And most importantly, it’s about making those experiences accessible to everyone, not just the tech-savvy.</p>\n<p>In this article, I will unpack how AI is reshaping UX through three powerful lenses: <strong>intelligence</strong>, <strong>efficiency</strong>, and <strong>accessibility</strong>.</p>\n<h3 id=\"1designingforintelligence\"><strong>1. Designing for Intelligence</strong></h3>\n<p>This means designing a user experience (UX) that learns and adapts to users' needs and preferences. Imagine opening your favorite streaming app and seeing a lineup so in tune with your mood, it’s like it read your mind. That’s AI quietly doing its thing: tracking behavior, learning preferences, and curating experiences.</p>\n<p>But it goes deeper than Netflix suggestions. In UX, AI is helping designers build systems that understand user intent. Think about voice assistants that interpret vague commands or smart email apps that finish your sentences. These aren’t just cool features; they represent a paradigm shift from static interfaces to intelligent, evolving ones.</p>\n<p><img src=\"https://cdn.hackernoon.com/images/snPbrgUxQvVG0JjoLXHNeq4akS42-2025-08-03T20:01:12.234Z-qmcbz2zoo0dikh30coo9i941\" alt=\"Gmail auto reply options\" /></p>\n<p>Gmail auto reply options</p>\n<p>As designers, our role is evolving too. We’re not just sketching wireframes, we’re mapping out decision trees, training datasets, and predicting edge cases. We’re asking, \"What should the system do if the user does X, but also what if they do Y, or nothing at all?\"</p>\n<p>The design process becomes less about dictating user journeys and more about enabling dynamic, adaptive experiences.</p>\n<h3 id=\"2designingforefficiency\"><strong>2. Designing for Efficiency</strong></h3>\n<p>Let’s face it, users are busy, distracted, and often overwhelmed. The best UX anticipates this. AI is turning reactive design into proactive design, streamlining interactions before users even realize they need help.</p>\n<p>Take auto-generated replies in Gmail. What once took 30 seconds now takes two clicks. Or smart forms that auto-fill based on past behavior. These aren’t just nice-to-haves; they redefine what “fast” and “frictionless” mean in today’s digital age.</p>\n<p><img src=\"https://cdn.hackernoon.com/images/snPbrgUxQvVG0JjoLXHNeq4akS42-2025-08-03T20:01:12.239Z-ixow99j51u86bi72wpgh8tfa\" alt=\"\" /></p>\n<p>Designers are now integrating features like:</p>\n<ul>\n<li><strong>Predictive search</strong> that learns as you type.</li>\n<li><strong>Conversational UIs</strong> that simulate human-like dialogue.</li>\n<li><strong>Micro-personalizations</strong> that fine-tune experiences per individual.</li>\n</ul>\n<p>We’re shifting from “How can we make this easier?” to “How can we make this invisible?” AI enables us to reduce the cognitive load, streamline the number of steps, and allow users to navigate digital spaces with near-effortless precision.</p>\n<h3 id=\"3designingforaccessibility\"><strong>3. Designing for Accessibility</strong></h3>\n<p>One of the most inspiring aspects of AI in UX is its potential to make products more accessible than ever.</p>\n<p>Think about screen readers enhanced with natural language processing, turning robotic monotones into human-like guidance. Or image recognition tools that generate detailed alt text, giving blind users richer context. Or even real-time captioning powered by AI, helping deaf users fully participate in digital experiences, such as virtual calls.</p>\n<p>AI is becoming an equalizer, helping bridge the gap for users with disabilities, language barriers, or limited digital literacy.</p>\n<p>But here’s the catch: AI can only be inclusive if it’s designed that way. Biased training data and one-size-fits-all algorithms can easily undo the progress made. As UX professionals, we must approach AI with empathy and ethical foresight. Who are we designing for? Who might we be excluding? How do we test, iterate, and refine AI so that it helps rather than hinders?</p>\n<h3 id=\"soafterallihavesharedwheredowegofromhere\"><strong>So, after all I have shared, where do we go from here?</strong></h3>\n<p>The future of UX is not about choosing between human-centered and machine-assisted design; it's about combining them. AI doesn’t replace the empathy, intuition, and creativity of designers; it amplifies them.</p>\n<p>Our job now is to become translators. To understand both the language of people and the language of machines, and to create experiences where the two meet in harmony.</p>\n<p>So the next time you open a product and it just gets you, don’t chalk it up to luck. That’s AI in UX, quietly evolving behind the scenes, making every tap, scroll, and swipe a little more magical.</p>\n<p>AI is no longer a “feature.” It’s a UX game-changer. It helps us design smarter (intelligence), faster (efficiency), and better for everyone (accessibility) products. But it’s up to us to ensure it’s used ethically, creatively, and inclusively.</p>\n<p><strong>Recommended Resources for Deeper Insight:</strong></p>\n<p>→ <a href=\"https://www.youtube.com/watch?v=fO1Up4mFy24\">The Future of UX - Embracing AI in Design</a></p>\n<p>→ <a href=\"https://uxmag.com/articles/the-future-of-ux-design-how-ai-and-machine-learning-are-changing-the-way-we-design\">The Future of UX Design: How AI and Machine Learning Are Changing the Way We Design</a></p>\n<p>→ <a href=\"https://www.qualtrics.com/experience-management/customer/ai-user-experience-design/\">The future of AI in user experience (UX) design</a></p>\n<p>\\</p>",
          "content:encodedSnippet": "A few years ago, if someone mentioned Artificial Intelligence in a product design meeting, they’d likely be met with skeptical glances or a cautious “let’s not overcomplicate things.” Today? AI isn’t just welcome at the UX table; it’s practically running the show.\nWe’re in a new era where the user experience is no longer just about beautifully designed buttons and seamless navigation; it's about intelligence. It’s about designing systems that think a little, predict a lot, and adapt even more. And most importantly, it’s about making those experiences accessible to everyone, not just the tech-savvy.\nIn this article, I will unpack how AI is reshaping UX through three powerful lenses: intelligence, efficiency, and accessibility.\n1. Designing for Intelligence\nThis means designing a user experience (UX) that learns and adapts to users' needs and preferences. Imagine opening your favorite streaming app and seeing a lineup so in tune with your mood, it’s like it read your mind. That’s AI quietly doing its thing: tracking behavior, learning preferences, and curating experiences.\nBut it goes deeper than Netflix suggestions. In UX, AI is helping designers build systems that understand user intent. Think about voice assistants that interpret vague commands or smart email apps that finish your sentences. These aren’t just cool features; they represent a paradigm shift from static interfaces to intelligent, evolving ones.\n\nGmail auto reply options\nAs designers, our role is evolving too. We’re not just sketching wireframes, we’re mapping out decision trees, training datasets, and predicting edge cases. We’re asking, \"What should the system do if the user does X, but also what if they do Y, or nothing at all?\"\nThe design process becomes less about dictating user journeys and more about enabling dynamic, adaptive experiences.\n2. Designing for Efficiency\nLet’s face it, users are busy, distracted, and often overwhelmed. The best UX anticipates this. AI is turning reactive design into proactive design, streamlining interactions before users even realize they need help.\nTake auto-generated replies in Gmail. What once took 30 seconds now takes two clicks. Or smart forms that auto-fill based on past behavior. These aren’t just nice-to-haves; they redefine what “fast” and “frictionless” mean in today’s digital age.\n\nDesigners are now integrating features like:\nPredictive search that learns as you type.\nConversational UIs that simulate human-like dialogue.\nMicro-personalizations that fine-tune experiences per individual.\nWe’re shifting from “How can we make this easier?” to “How can we make this invisible?” AI enables us to reduce the cognitive load, streamline the number of steps, and allow users to navigate digital spaces with near-effortless precision.\n3. Designing for Accessibility\nOne of the most inspiring aspects of AI in UX is its potential to make products more accessible than ever.\nThink about screen readers enhanced with natural language processing, turning robotic monotones into human-like guidance. Or image recognition tools that generate detailed alt text, giving blind users richer context. Or even real-time captioning powered by AI, helping deaf users fully participate in digital experiences, such as virtual calls.\nAI is becoming an equalizer, helping bridge the gap for users with disabilities, language barriers, or limited digital literacy.\nBut here’s the catch: AI can only be inclusive if it’s designed that way. Biased training data and one-size-fits-all algorithms can easily undo the progress made. As UX professionals, we must approach AI with empathy and ethical foresight. Who are we designing for? Who might we be excluding? How do we test, iterate, and refine AI so that it helps rather than hinders?\nSo, after all I have shared, where do we go from here?\nThe future of UX is not about choosing between human-centered and machine-assisted design; it's about combining them. AI doesn’t replace the empathy, intuition, and creativity of designers; it amplifies them.\nOur job now is to become translators. To understand both the language of people and the language of machines, and to create experiences where the two meet in harmony.\nSo the next time you open a product and it just gets you, don’t chalk it up to luck. That’s AI in UX, quietly evolving behind the scenes, making every tap, scroll, and swipe a little more magical.\nAI is no longer a “feature.” It’s a UX game-changer. It helps us design smarter (intelligence), faster (efficiency), and better for everyone (accessibility) products. But it’s up to us to ensure it’s used ethically, creatively, and inclusively.\nRecommended Resources for Deeper Insight:\n→ The Future of UX - Embracing AI in Design\n→ The Future of UX Design: How AI and Machine Learning Are Changing the Way We Design\n→ The future of AI in user experience (UX) design\n\\",
          "dc:creator": "Mfonobong Umondia",
          "content": "AI has moved from being a novelty in UX design to an essential driver of intelligent, efficient, and accessible user experiences. This article explores how AI empowers designers to build adaptive interfaces, streamline interactions, and create more inclusive digital products—while emphasizing the importance of ethical and empathetic design choices. As UX and AI converge, the designer’s role is evolving: no longer just crafting visuals, but orchestrating intelligent systems that truly understand users.",
          "contentSnippet": "AI has moved from being a novelty in UX design to an essential driver of intelligent, efficient, and accessible user experiences. This article explores how AI empowers designers to build adaptive interfaces, streamline interactions, and create more inclusive digital products—while emphasizing the importance of ethical and empathetic design choices. As UX and AI converge, the designer’s role is evolving: no longer just crafting visuals, but orchestrating intelligent systems that truly understand users.",
          "guid": "https://hackernoon.com/designing-for-intelligence-efficiency-and-accessibility?source=rss",
          "categories": [
            "ux-design",
            "ai-in-ux-design",
            "intelligent-ux-systems",
            "accessible-design-with-ai",
            "adaptive-user-interfaces",
            "predictive-ux-design",
            "frictionless-user-experiences",
            "ux-design-trends-2025"
          ],
          "isoDate": "2025-08-03T20:01:13.000Z"
        }
      },
      {
        "json": {
          "creator": "Social Discovery Group",
          "title": "SDG LAB Venture Fund Backs Virtual Intimacy with $20 Million — But Will It Work?",
          "link": "https://hackernoon.com/sdg-lab-venture-fund-backs-virtual-intimacy-with-$20-million-but-will-it-work?source=rss",
          "pubDate": "Sun, 03 Aug 2025 19:37:07 GMT",
          "content:encoded": "<blockquote>\n  <p>In an age of hyperconnectivity, Europe faces an unexpected crisis: loneliness. The EU Loneliness Survey 2022 reveals that 13% of Europeans feel lonely most or all the time, while 35% experience it regularly. Despite the digital revolution, authentic human connection seems to be unraveling—replaced by surface-level engagements that lack emotional resonance.</p>\n</blockquote>\n<hr />\n<p>This paradox lies at the heart of&nbsp;<strong>Social Discovery Group&nbsp;(SDG)’s $20 million venture studio</strong>,&nbsp;<strong><a href=\"https://medium.com/@sdgroup/social-discovery-group-launches-sdg-lab-20m-venture-fund-to-invest-in-social-discovery-startups-e0142c92cac6\">SDG Lab Venture Studio</a></strong>. The studio is betting big on a controversial but potentially transformative concept:&nbsp;<strong><strong><a href=\"https://socialdiscoverygroup.com/virtual-intimacy\">Virtual Intimacy</a></strong></strong>&nbsp;— a technological attempt to restore emotional closeness in an increasingly isolated society.</p>\n<h2 id=\"understandinglonelinessmorethanjustbeingalone\">Understanding Loneliness: More Than Just Being Alone</h2>\n<p>Loneliness is not simply a matter of physical solitude. It’s a mental and emotional state where individuals feel unseen, disconnected, and emotionally deprived — even in crowds. It’s a&nbsp;<strong>perceived disconnection</strong>, not merely the absence of company.</p>\n<h3 id=\"healthconsequencesofloneliness\">Health Consequences of Loneliness</h3>\n<p>A&nbsp;<strong>2015 meta-analysis</strong>&nbsp;by Holt-Lunstad found that:</p>\n<ul>\n<li>Social isolation increases mortality risk by&nbsp;<strong>29%</strong></li>\n<li>Loneliness increases it by&nbsp;<strong>26%</strong></li>\n</ul>\n<p>These numbers are comparable to the health risks of&nbsp;<strong>smoking 15 cigarettes a day</strong>, as outlined in the&nbsp;<strong><strong><a href=\"https://www.hhs.gov/sites/default/files/surgeon-general-social-connection-advisory.pdf\">2023 U.S. Surgeon General’s guidelines</a></strong></strong>.</p>\n<p>Moreover, loneliness is linked to:</p>\n<ul>\n<li><strong>Sleep disturbances</strong></li>\n<li><strong>High cortisol levels</strong></li>\n<li><strong>Hypertension</strong></li>\n<li><strong>Heart disease</strong></li>\n</ul>\n<p>==It’s no longer just a social issue; it’s a&nbsp;<strong>public health crisis</strong>.== \\n </p>\n<p><img src=\"https://cdn.hackernoon.com/images/7XhQwEsk1Eg58rZqKidDiZMpsI93-6u23amf.jpeg\" alt=\"Understanding Loneliness: More Than Just Being Alone\" /></p>\n<h2 id=\"techmeetsemotionalneedsdglabsd20millionresponse\">Tech Meets Emotional Need: SDG Lab’s $20 Million Response</h2>\n<p>Enter&nbsp;<strong><strong><a href=\"https://socialdiscoverygroup.com/sdg-lab-venture-studio\">SDG Lab</a></strong></strong>, the corporate venture arm of&nbsp;<strong><a href=\"https://www.linkedin.com/company/social-discovery-group\">Social Discovery Group</a></strong>, which backs early-stage startups that focus on:</p>\n<ul>\n<li><strong>AI-powered communication</strong></li>\n<li><strong>Virtual and extended reality</strong></li>\n<li><strong>Social discovery platforms</strong></li>\n</ul>\n<p>These startups are designed to build what SDG calls “<strong>virtual intimacy</strong>”: emotional connections that transcend physical interaction through digital mediums.</p>\n<blockquote>\n  <p><strong><em><strong><a href=\"https://councils.forbes.com/profile/Alex-Kudos-CEO-SDG-Lab-Venture-Studio-%7C-ex-CMO-Social-Discovery-Group-SDG-Lab/4359f7e2-9e42-4a29-8747-dec6c096970d\">Alex Kudos</a></strong></em></strong><em><strong><a href=\"https://councils.forbes.com/profile/Alex-Kudos-CEO-SDG-Lab-Venture-Studio-%7C-ex-CMO-Social-Discovery-Group-SDG-Lab/4359f7e2-9e42-4a29-8747-dec6c096970d\">,</a></strong>&nbsp;CEO of SDG Lab Venture Studio, puts it simply:</em></p>\n  <p><em>“Technology doesn’t just help us build relationships — it becomes part of them.”</em></p>\n</blockquote>\n<p>This shift challenges traditional notions of closeness. Can digital interactions really replace the emotional depth of face-to-face contact?</p>\n<p><img src=\"https://cdn.hackernoon.com/images/7XhQwEsk1Eg58rZqKidDiZMpsI93-4y33axg.jpeg\" alt=\"Alex Kudos,&nbsp;CEO of SDG Lab Venture Studio\" /></p>\n<p>\\</p>\n<h3 id=\"thegeographyofloneliness\">The Geography of Loneliness</h3>\n<p>Not all regions are affected equally. According to EU data:</p>\n<ul>\n<li>Eastern and Southern Europe (e.g.,&nbsp;<strong>Bulgaria, Romania, Greece</strong>) suffer&nbsp;<strong>higher loneliness rates</strong></li>\n<li>Northern and Western countries (e.g.,&nbsp;<strong>Austria, the Netherlands</strong>) show lower levels</li>\n</ul>\n<p><strong>For example, Cyprus</strong>&nbsp;mirrors this southern trend. Kudos notes that&nbsp;<strong>older populations</strong>&nbsp;in Cyprus are particularly affected. SDG’s solution? Use technology to&nbsp;<strong>build connections tailored to older users</strong>. Products like&nbsp;<strong><a href=\"https://datemyage.com/\">DateMyAge</a></strong> show that virtual platforms can appeal to users beyond Gen Z — if designed inclusively.</p>\n<h3 id=\"aneweraofdigitalconnection\">A New Era of Digital Connection</h3>\n<p>Studies show that&nbsp;<strong>57% of Gen Z</strong>&nbsp;believe&nbsp;<strong>online relationships are as meaningful</strong>&nbsp;as in-person ones. During the&nbsp;<strong>COVID-19 pandemic</strong>, virtual worlds offered emotional refuge:</p>\n<ul>\n<li><strong>AltspaceVR</strong>&nbsp;users reported&nbsp;<strong>lower loneliness</strong></li>\n<li>Events and interactions in VR felt&nbsp;<strong>more immersive</strong>&nbsp;than real life for some</li>\n</ul>\n<p>However, this comes with a caveat:&nbsp;<strong>telepresence fatigue</strong>. Some users found screens emotionally exhausting, emphasizing the&nbsp;<strong>fragility of digital intimacy</strong>.</p>\n<p><img src=\"https://cdn.hackernoon.com/images/7XhQwEsk1Eg58rZqKidDiZMpsI93-e843abl.jpeg\" alt=\"can virtual intimacy solve the loneliness epidemic?\" /></p>\n<h3 id=\"economicandsocietalcosts\">Economic and Societal Costs</h3>\n<p>Loneliness doesn’t just hurt individuals — it strains entire economies. Increased loneliness leads to:</p>\n<ul>\n<li><strong>Rising healthcare costs</strong></li>\n<li><strong>Workforce productivity loss</strong></li>\n<li><strong>Greater pressure on social services</strong></li>\n</ul>\n<p>In regions like Cyprus, where&nbsp;<strong>aging populations</strong>&nbsp;and&nbsp;<strong>shrinking community structures</strong>&nbsp;prevail,&nbsp;<strong>digital intimacy</strong>&nbsp;becomes not just an innovation — but a necessity.</p>\n<h2 id=\"beyondonlinedatingappsthesdgandsdglabsportfolios\">Beyond Online Dating Apps: The SDG and SDG Labs Portfolios</h2>\n<p><strong>Social Discovery Group</strong>&nbsp;operates over&nbsp;<strong>60 global brands</strong>, including:</p>\n<ul>\n<li><strong>Dating.com</strong></li>\n<li><strong>DateMyAge</strong></li>\n<li><strong>DilMil</strong>&nbsp;(for South Asians)</li>\n<li><strong>Kiseki</strong>&nbsp;(for Japanese audiences)</li>\n</ul>\n<p>This diversification reflects the&nbsp;<strong>global loneliness crisis</strong>&nbsp;-as people migrate and lose touch with their cultural roots. SDG’s platforms aim to&nbsp;<strong>rebuild those connections</strong>&nbsp;in new contexts.</p>\n<p>With&nbsp;<strong>SDG Lab Investments</strong>&nbsp;, the approach shifts from quantity to quality:</p>\n<ul>\n<li>Focuses on&nbsp;<strong>5–10 projects/year</strong></li>\n<li>Offers&nbsp;<strong>operational and strategic support</strong></li>\n<li>Invests in startups building&nbsp;<strong>AI relationships, virtual influencers</strong>, and platforms for&nbsp;<strong>older demographics.</strong></li>\n</ul>\n<p>For entrepreneurs navigating the complex funding landscape,&nbsp;<strong><a href=\"https://www.linkedin.com/in/akudos/\">Alex Kudos</a></strong>, CEO of SDG Lab, offers crucial insights in the&nbsp;<strong><a href=\"https://www.forbes.com/councils/forbesbusinesscouncil/2025/07/17/a-founders-guide-to-traditional-venture-capital-vs-corporate-venture-studios/\">Founder`s Guide</a></strong>&nbsp;about choosing between traditional venture capital and venture studio models. Understanding these funding paths becomes essential when building the next generation of connection technologies.</p>\n<h2 id=\"keyconcernscantechreallycureloneliness\">Key Concerns: Can Tech Really Cure Loneliness?</h2>\n<p>Before we accept virtual intimacy as the cure for our loneliness, or shall I say, disconnection crisis, we need to confront some uncomfortable truths. The research paints a complicated picture, one that challenges a somewhat simplistic, surface narrative around technology engineering its way out of a crisis.</p>\n<h3 id=\"theaccessibilitytrap\">The Accessibility Trap</h3>\n<p>The most vulnerable -<strong>older, poorer, and less educated users</strong>&nbsp;-are also&nbsp;<strong>least likely to access digital tools</strong>.&nbsp;<strong><a href=\"https://www.frontiersin.org/journals/public-health/articles/10.3389/fpubh.2024.1296524/full\">A</a>&nbsp;<strong><a href=\"https://www.frontiersin.org/journals/public-health/articles/10.3389/fpubh.2024.1296524/full\">2024 study</a></strong></strong>&nbsp;found that&nbsp;<strong>nursing home residents</strong>&nbsp;without tech access were more isolated than ever, underlining the&nbsp;<strong>danger of digital exclusion</strong>.</p>\n<h3 id=\"qualityoverquantity\">Quality Over Quantity</h3>\n<p>Tech helps&nbsp;<strong>maintain</strong>&nbsp;existing relationships better than it&nbsp;<strong>builds</strong>&nbsp;new ones. A&nbsp;<strong><strong><a href=\"https://pmc.ncbi.nlm.nih.gov/articles/PMC9641519/\">2022 meta-review</a></strong></strong>&nbsp;found only&nbsp;<strong>moderate evidence</strong>&nbsp;that technology reduces loneliness, particularly for&nbsp;<strong>forming close new bonds</strong>.</p>\n<h3 id=\"thepresenceparadox\">The Presence Paradox</h3>\n<p>Even the best-designed platforms may fail to offer a true&nbsp;<strong>sense of emotional co-presence</strong>. According to the&nbsp;<strong>European Commission’s 2024 brief</strong>,</p>\n<blockquote>\n  <p>“Technology is seen as both enhancing and suppressing connections.”</p>\n</blockquote>\n<p>This reflects the&nbsp;<strong>paradox of virtual presence</strong>: the appearance of intimacy without the psychological reality.</p>\n<p><strong>More about the Critical Questions ↘</strong></p>\n<p><a href=\"https://thefuturemedia.eu/the-loneliness-economy-how-social-discovery-groups-20m-bet-is-logging-us-into-a-new-kind-of-intimacy/?embedable=true\">https://thefuturemedia.eu/the-loneliness-economy-how-social-discovery-groups-20m-bet-is-logging-us-into-a-new-kind-of-intimacy/?embedable=true</a></p>\n<hr />\n<p><img src=\"https://cdn.hackernoon.com/images/7XhQwEsk1Eg58rZqKidDiZMpsI93-en53ade.jpeg\" alt=\"SDG Lab Venture Fund Team at Reflect Festival, Cyprus, 2025\" /></p>\n<h2 id=\"sdglabsresponsetechnologyasanextensionnotareplacement\">SDG Lab’s Response: Technology as an Extension, Not a Replacement</h2>\n<p>SDG Lab confronts virtual intimacy criticisms directly, viewing ethical concerns as opportunities rather than roadblocks.</p>\n<p>Alex Kudos, CEO of SDG Lab Venture Studio, believes that&nbsp;<strong>exclusion</strong>&nbsp;is more about&nbsp;<strong>poor design</strong>&nbsp;than user capability. For example,&nbsp;<strong>90% of DateMyAge users</strong>&nbsp;regularly engage in&nbsp;<strong>video dating</strong>, disproving the stereotype that older people aren’t tech-savvy.</p>\n<p>\\</p>\n<blockquote>\n  <p><em>“Our goal is not to generate maximum engagement, but to promote genuine connection.” — he explains.</em></p>\n</blockquote>\n<p>\\\nThat includes resisting the urge to gamify relationships or promote constant stimulation.</p>\n<p>Perhaps most telling is Kudos’s reframing of the “bandage versus cure” debate. The real issue, he argues, may be that traditional relationships are already failing to meet modern emotional needs.</p>\n<p>\\</p>\n<blockquote>\n  <p><em>“Despite the idea that romantic partnerships are the foundation of emotional well-being, many of us are struggling even within those close connections,” Alex says.</em></p>\n  <p><strong><a href=\"https://medium.com/@sdgroup/virtual-intimacy-in-2025-trends-technologies-and-the-future-of-digital-relationships-23ffc6893fe2\">Virtual intimacy</a></strong>, in his view, isn’t a replacement but an expansion: one that amplifies access to connection across geography, identity, and life stage.</p>\n</blockquote>\n<p>\\\nThese questions aren’t meant to dismiss Lab’s vision. The company may very well be the revolution that our society needs, even if we don’t fully understand it yet.&nbsp;**For Kudos and his team, AI companionship isn’t ‘less than’ human. This type of connection allows people to be more vulnerable, authentic, and introspective in a safe space.**And in our current climate, don’t we all deserve the safety to be ourselves, fully? \\n ✓ Conclusion: Rethinking What It Means to Be Together</p>\n<h3 id=\"socanvirtualintimacysolvethelonelinessepidemic\"><strong>==So, can virtual intimacy solve the loneliness epidemic?==</strong></h3>\n<p><strong>Maybe.</strong>&nbsp;Research shows promise -but also flags risks. The real challenge is ensuring these tools don’t redefine connection in a way that&nbsp;<strong>erodes emotional depth</strong>.</p>\n<p>As&nbsp;<strong>Kudos</strong>&nbsp;sees it, virtual intimacy isn’t about&nbsp;<strong>escaping reality</strong>. It’s about creating&nbsp;<strong>new spaces for vulnerability, connection, and self-expression</strong>. In a world where loneliness is both a personal pain and a public crisis, perhaps the most radical act is simply&nbsp;<strong>helping people feel seen</strong>&nbsp;— wherever they are.</p>\n<hr />\n<h3 id=\"sdglabisactivelyseekingnewventures\">SDG Lab is Actively Seeking New Ventures!</h3>\n<p>SDG LAB Venture Studio is actively seeking for founders and companies working on the future of human connection.</p>\n<p>If you’re working on AI, video tech, or social innovation —&nbsp;<strong><a href=\"https://socialdiscoverygroup.com/sdg-lab-venture-studio\">contact us</a></strong>! \\n </p>",
          "content:encodedSnippet": "In an age of hyperconnectivity, Europe faces an unexpected crisis: loneliness. The EU Loneliness Survey 2022 reveals that 13% of Europeans feel lonely most or all the time, while 35% experience it regularly. Despite the digital revolution, authentic human connection seems to be unraveling—replaced by surface-level engagements that lack emotional resonance.\nThis paradox lies at the heart of Social Discovery Group (SDG)’s $20 million venture studio, SDG Lab Venture Studio. The studio is betting big on a controversial but potentially transformative concept: Virtual Intimacy — a technological attempt to restore emotional closeness in an increasingly isolated society.\nUnderstanding Loneliness: More Than Just Being Alone\nLoneliness is not simply a matter of physical solitude. It’s a mental and emotional state where individuals feel unseen, disconnected, and emotionally deprived — even in crowds. It’s a perceived disconnection, not merely the absence of company.\nHealth Consequences of Loneliness\nA 2015 meta-analysis by Holt-Lunstad found that:\nSocial isolation increases mortality risk by 29%\nLoneliness increases it by 26%\nThese numbers are comparable to the health risks of smoking 15 cigarettes a day, as outlined in the 2023 U.S. Surgeon General’s guidelines.\nMoreover, loneliness is linked to:\nSleep disturbances\nHigh cortisol levels\nHypertension\nHeart disease\n==It’s no longer just a social issue; it’s a public health crisis.== \\n \n\nTech Meets Emotional Need: SDG Lab’s $20 Million Response\nEnter SDG Lab, the corporate venture arm of Social Discovery Group, which backs early-stage startups that focus on:\nAI-powered communication\nVirtual and extended reality\nSocial discovery platforms\nThese startups are designed to build what SDG calls “virtual intimacy”: emotional connections that transcend physical interaction through digital mediums.\nAlex Kudos, CEO of SDG Lab Venture Studio, puts it simply:\n“Technology doesn’t just help us build relationships — it becomes part of them.”\nThis shift challenges traditional notions of closeness. Can digital interactions really replace the emotional depth of face-to-face contact?\n\n\\\nThe Geography of Loneliness\nNot all regions are affected equally. According to EU data:\nEastern and Southern Europe (e.g., Bulgaria, Romania, Greece) suffer higher loneliness rates\nNorthern and Western countries (e.g., Austria, the Netherlands) show lower levels\nFor example, Cyprus mirrors this southern trend. Kudos notes that older populations in Cyprus are particularly affected. SDG’s solution? Use technology to build connections tailored to older users. Products like DateMyAge show that virtual platforms can appeal to users beyond Gen Z — if designed inclusively.\nA New Era of Digital Connection\nStudies show that 57% of Gen Z believe online relationships are as meaningful as in-person ones. During the COVID-19 pandemic, virtual worlds offered emotional refuge:\nAltspaceVR users reported lower loneliness\nEvents and interactions in VR felt more immersive than real life for some\nHowever, this comes with a caveat: telepresence fatigue. Some users found screens emotionally exhausting, emphasizing the fragility of digital intimacy.\n\nEconomic and Societal Costs\nLoneliness doesn’t just hurt individuals — it strains entire economies. Increased loneliness leads to:\nRising healthcare costs\nWorkforce productivity loss\nGreater pressure on social services\nIn regions like Cyprus, where aging populations and shrinking community structures prevail, digital intimacy becomes not just an innovation — but a necessity.\nBeyond Online Dating Apps: The SDG and SDG Labs Portfolios\nSocial Discovery Group operates over 60 global brands, including:\nDating.com\nDateMyAge\nDilMil (for South Asians)\nKiseki (for Japanese audiences)\nThis diversification reflects the global loneliness crisis -as people migrate and lose touch with their cultural roots. SDG’s platforms aim to rebuild those connections in new contexts.\nWith SDG Lab Investments , the approach shifts from quantity to quality:\nFocuses on 5–10 projects/year\nOffers operational and strategic support\nInvests in startups building AI relationships, virtual influencers, and platforms for older demographics.\nFor entrepreneurs navigating the complex funding landscape, Alex Kudos, CEO of SDG Lab, offers crucial insights in the Founder`s Guide about choosing between traditional venture capital and venture studio models. Understanding these funding paths becomes essential when building the next generation of connection technologies.\nKey Concerns: Can Tech Really Cure Loneliness?\nBefore we accept virtual intimacy as the cure for our loneliness, or shall I say, disconnection crisis, we need to confront some uncomfortable truths. The research paints a complicated picture, one that challenges a somewhat simplistic, surface narrative around technology engineering its way out of a crisis.\nThe Accessibility Trap\nThe most vulnerable -older, poorer, and less educated users -are also least likely to access digital tools. A 2024 study found that nursing home residents without tech access were more isolated than ever, underlining the danger of digital exclusion.\nQuality Over Quantity\nTech helps maintain existing relationships better than it builds new ones. A 2022 meta-review found only moderate evidence that technology reduces loneliness, particularly for forming close new bonds.\nThe Presence Paradox\nEven the best-designed platforms may fail to offer a true sense of emotional co-presence. According to the European Commission’s 2024 brief,\n“Technology is seen as both enhancing and suppressing connections.”\nThis reflects the paradox of virtual presence: the appearance of intimacy without the psychological reality.\nMore about the Critical Questions ↘\nhttps://thefuturemedia.eu/the-loneliness-economy-how-social-discovery-groups-20m-bet-is-logging-us-into-a-new-kind-of-intimacy/?embedable=true\n\nSDG Lab’s Response: Technology as an Extension, Not a Replacement\nSDG Lab confronts virtual intimacy criticisms directly, viewing ethical concerns as opportunities rather than roadblocks.\nAlex Kudos, CEO of SDG Lab Venture Studio, believes that exclusion is more about poor design than user capability. For example, 90% of DateMyAge users regularly engage in video dating, disproving the stereotype that older people aren’t tech-savvy.\n\\\n\n  \n“Our goal is not to generate maximum engagement, but to promote genuine connection.” — he explains.\n\\\nThat includes resisting the urge to gamify relationships or promote constant stimulation.\nPerhaps most telling is Kudos’s reframing of the “bandage versus cure” debate. The real issue, he argues, may be that traditional relationships are already failing to meet modern emotional needs.\n\\\n\n  \n“Despite the idea that romantic partnerships are the foundation of emotional well-being, many of us are struggling even within those close connections,” Alex says.\nVirtual intimacy, in his view, isn’t a replacement but an expansion: one that amplifies access to connection across geography, identity, and life stage.\n\\\nThese questions aren’t meant to dismiss Lab’s vision. The company may very well be the revolution that our society needs, even if we don’t fully understand it yet. **For Kudos and his team, AI companionship isn’t ‘less than’ human. This type of connection allows people to be more vulnerable, authentic, and introspective in a safe space.**And in our current climate, don’t we all deserve the safety to be ourselves, fully? \\n ✓ Conclusion: Rethinking What It Means to Be Together\n==So, can virtual intimacy solve the loneliness epidemic?==\nMaybe. Research shows promise -but also flags risks. The real challenge is ensuring these tools don’t redefine connection in a way that erodes emotional depth.\nAs Kudos sees it, virtual intimacy isn’t about escaping reality. It’s about creating new spaces for vulnerability, connection, and self-expression. In a world where loneliness is both a personal pain and a public crisis, perhaps the most radical act is simply helping people feel seen — wherever they are.\nSDG Lab is Actively Seeking New Ventures!\nSDG LAB Venture Studio is actively seeking for founders and companies working on the future of human connection.\nIf you’re working on AI, video tech, or social innovation — contact us! \\n",
          "dc:creator": "Social Discovery Group",
          "content": "13% of Europeans feel lonely most or all the time, while 35% experience it regularly. Social isolation increases mortality risk by 29% and loneliness by 26%. Loneliness is linked to sleep disturbances, high cortisol levels, and heart disease. The $20 million venture studio SDG Lab is betting big on ‘virtual intimacy’",
          "contentSnippet": "13% of Europeans feel lonely most or all the time, while 35% experience it regularly. Social isolation increases mortality risk by 29% and loneliness by 26%. Loneliness is linked to sleep disturbances, high cortisol levels, and heart disease. The $20 million venture studio SDG Lab is betting big on ‘virtual intimacy’",
          "guid": "https://hackernoon.com/sdg-lab-venture-fund-backs-virtual-intimacy-with-$20-million-but-will-it-work?source=rss",
          "categories": [
            "virtual-intimacy",
            "ai-dating",
            "sdg-lab-venture-fund",
            "the-loneliness-epidemic",
            "ai-and-human-connection",
            "emotional-ai",
            "tech-and-loneliness",
            "good-company"
          ],
          "isoDate": "2025-08-03T19:37:07.000Z"
        }
      },
      {
        "json": {
          "creator": "Noonification",
          "title": "The HackerNoon Newsletter: 9 Things Hollywood Gets Wrong About Hacking (8/3/2025)",
          "link": "https://hackernoon.com/8-3-2025-newsletter?source=rss",
          "pubDate": "Sun, 03 Aug 2025 16:04:11 GMT",
          "content:encoded": "\n              \n        <p><strong>How are you, hacker?</strong></p>\n        <br />\n        <p>🪐 What’s happening in tech today, August 3, 2025?</p>\n        <br />\n        <p>\n          The\n          <a href=\"https://hackernoon.com/noonification\" target=\"_blank\" rel=\"noopener\"> HackerNoon Newsletter</a>\n          brings the HackerNoon \n          <a href=\"https://hackernoon.com\" target=\"_blank\" rel=\"noopener\">homepage</a>\n          straight to your inbox.\n          <a href=\"https://hackernoon.com/on-this-day\" target=\"_blank\" rel=\"noopener\">On this day,</a>\n          \n            <strong>Radio Shack Announced TRS-80 Computer</strong> in 1977,  <strong>Mozilla Corporation was founded</strong> in 2005,  <strong>Christopher Columbus set sail</strong> in 1492, \n          \n          and  we present you with these top quality stories. \n          \n            From \n        <a href=\"https://hackernoon.com/ai-agents-are-growing-up-and-they-need-zero-trust-parenting\" class=\"eventTitle\"><strong>AI Agents Are Growing Up - And They Need Zero-Trust Parenting</strong></a>\n       to \n        <a href=\"https://hackernoon.com/turn-a-regular-wallet-into-a-smart-account-with-eip-7702\" class=\"eventTitle\"><strong>Turn a Regular Wallet into a Smart Account with EIP 7702 </strong></a>,\n       let’s dive right in.\n          \n        </p>\n      \n              \n          <h2><a href=\"https://hackernoon.com/immutable-backups-everything-you-need-to-know-to-protect-your-cloud\">Immutable Backups: Everything You Need To Know To Protect Your Cloud</a></h2>\n          <p><img src=\"https://cdn.hackernoon.com/images/hQ098u52DzPm2Y4UITQcQXtLRAk2-by039c5.png\" alt=\"\" /> </p>\n          <br />\n          <p>By <a href=\"https://hackernoon.com/u/n2w\">@n2w</a> [ 6 Min read ] Learn how immutable backups prevent ransomware, ensure data integrity, and meet compliance needs with secure, tamper-proof cloud data protection. <a href=\"https://hackernoon.com/immutable-backups-everything-you-need-to-know-to-protect-your-cloud\">Read More.</a></p>\n        \n          <h2><a href=\"https://hackernoon.com/ai-agents-are-growing-up-and-they-need-zero-trust-parenting\">AI Agents Are Growing Up - And They Need Zero-Trust Parenting</a></h2>\n          <p><img src=\"https://cdn.hackernoon.com/images/xMFozA8xFqPickG9TmjRqH6mmCS2-5z039sm.jpeg\" alt=\"\" /> </p>\n          <br />\n          <p>By <a href=\"https://hackernoon.com/u/arjun-subedi\">@arjun-subedi</a> [ 8 Min read ] AI is evolving fast, but security isn’t keeping up. Discover why zero-trust architecture is critical for safe, scalable AI agent deployment. <a href=\"https://hackernoon.com/ai-agents-are-growing-up-and-they-need-zero-trust-parenting\">Read More.</a></p>\n        \n          <h2><a href=\"https://hackernoon.com/a-human-centred-framework-for-designing-complex-ai-solutions-for-strategic-decision-making\">A Human-centred Framework for Designing Complex AI Solutions for Strategic Decision-making</a></h2>\n          <p><img src=\"https://cdn.hackernoon.com/images/2jqChkrv03exBUgkLrDzIbfM99q2-k102yo7.jpeg\" alt=\"\" /> </p>\n          <br />\n          <p>By <a href=\"https://hackernoon.com/u/v3d\">@v3d</a> [ 7 Min read ] The practical framework helps designers, data scientists, and engineers find common ground, aligning the voice and needs of users with the design of AI systems <a href=\"https://hackernoon.com/a-human-centred-framework-for-designing-complex-ai-solutions-for-strategic-decision-making\">Read More.</a></p>\n        \n          <h2><a href=\"https://hackernoon.com/turn-a-regular-wallet-into-a-smart-account-with-eip-7702\">Turn a Regular Wallet into a Smart Account with EIP 7702 </a></h2>\n          <p><img src=\"https://cdn.hackernoon.com/images/J4oKDrDzfYh3ZwXi47hCWrIlVg12-ws03uid.png\" alt=\"\" /> </p>\n          <br />\n          <p>By <a href=\"https://hackernoon.com/u/hacker39947670\">@hacker39947670</a> [ 13 Min read ] Learn how EIP-7702 enables smart wallet features for existing Ethereum accounts. Complete developer guide with code examples. <a href=\"https://hackernoon.com/turn-a-regular-wallet-into-a-smart-account-with-eip-7702\">Read More.</a></p>\n        \n          <h2><a href=\"https://hackernoon.com/9-things-hollywood-gets-wrong-about-hacking\">9 Things Hollywood Gets Wrong About Hacking</a></h2>\n          <p><img src=\"https://cdn.hackernoon.com/images/l7noBCUFwmcERrcGKL5jHUS0UcV2-ay93lg1.png\" alt=\"\" /> </p>\n          <br />\n          <p>By <a href=\"https://hackernoon.com/u/moonlock\">@moonlock</a> [ 11 Min read ] Movie hacking ≠ reality: Real cyberattacks rely on phishing, not fast code. Moonlock, MacPaw’s cybersecurity division, reveals how films get it wrong. <a href=\"https://hackernoon.com/9-things-hollywood-gets-wrong-about-hacking\">Read More.</a></p>\n        \n          <h2><a href=\"https://hackernoon.com/a-simple-way-to-build-a-progress-bar-for-your-websites-image-uploader-using-filestack\">A Simple Way to Build a Progress Bar for Your Website’s Image Uploader Using Filestack</a></h2>\n          <p><img src=\"https://cdn.hackernoon.com/images/0sm1KIKmbZhu9AD2GAr4cKywoN43-ng139i1.jpeg\" alt=\"\" /> </p>\n          <br />\n          <p>By <a href=\"https://hackernoon.com/u/filestack\">@filestack</a> [ 7 Min read ] Let’s walk through how to build one manually, and then I’ll show you why we ensured you would never have to. <a href=\"https://hackernoon.com/a-simple-way-to-build-a-progress-bar-for-your-websites-image-uploader-using-filestack\">Read More.</a></p>\n        \n          <h2><a href=\"https://hackernoon.com/how-an-nyc-based-university-boosted-backup-reliability-while-slashing-costs\">How an NYC-Based University Boosted Backup Reliability While Slashing Costs​</a></h2>\n          <p><img src=\"https://cdn.hackernoon.com/images/hQ098u52DzPm2Y4UITQcQXtLRAk2-ml039lt.png\" alt=\"\" /> </p>\n          <br />\n          <p>By <a href=\"https://hackernoon.com/u/n2w\">@n2w</a> [ 4 Min read ] Learn how N2W supports St. Johns University, which educates more than 20,000 students and employs over 1,400 staff, using a hybrid environment. <a href=\"https://hackernoon.com/how-an-nyc-based-university-boosted-backup-reliability-while-slashing-costs\">Read More.</a></p>\n        \n          <h2><a href=\"https://hackernoon.com/from-chatbots-to-guardians-of-data-how-bchat-harnesses-ai-for-secure-messaging\">From Chatbots to Guardians of Data: How BChat Harnesses AI for Secure Messaging</a></h2>\n          <p><img src=\"https://cdn.hackernoon.com/images/PWiKbaVxohZ8PidtkLYzFcnG9Qw2-n2121kz.jpeg\" alt=\"\" /> </p>\n          <br />\n          <p>By <a href=\"https://hackernoon.com/u/beldexcoin\">@beldexcoin</a> [ 5 Min read ] AI is often associated with collecting personal data but what if AI helped protect user data? Read to know how BeldexAI protects your data on BChat.  <a href=\"https://hackernoon.com/from-chatbots-to-guardians-of-data-how-bchat-harnesses-ai-for-secure-messaging\">Read More.</a></p>\n        \n              \n        <br />\n        <p>🧑‍💻 What happened in your world this week?</p>\n        <p>\n          It's been said that\n          <a href=\"https://hackernoon.com/developers-the-why-and-how-to-writing-technical-articles-54e824789ef6\">writing can help consolidate technical knowledge</a>,\n          <a href=\"https://hackernoon.com/how-can-non-writers-become-effective-bloggers-1pq32wd\">establish credibility</a>,\n          <a href=\"https://hackernoon.com/how-can-non-writers-become-effective-bloggers-1pq32wd\"> and contribute to emerging community standards</a>.\n          Feeling stuck? We got you covered ⬇️⬇️⬇️\n        </p>\n        <br />\n        <p>\n          <a href=\"https://app.hackernoon.com/mobile/lZx3fmlPdlPJpVBIdble\">ANSWER THESE GREATEST INTERVIEW QUESTIONS OF ALL TIME</a>\n        </p>\n        <br />\n        <p>We hope you enjoy this worth of free reading material. Feel free to forward this email to a nerdy friend who'll love you for it.See you on Planet Internet! With love, \n The HackerNoon Team ✌️</p>\n        <br />\n        <p><img src=\"https://cdn.hackernoon.com/images/the-hackernoon-newsletter-footer.png\" alt=\"\" /></p>\n      \n            ",
          "content:encodedSnippet": "How are you, hacker?\n🪐 What’s happening in tech today, August 3, 2025?\n HackerNoon Newsletter\n          brings the HackerNoon \n          homepage\n          straight to your inbox.\n          On this day,\n          \n            Radio Shack Announced TRS-80 Computer in 1977,  Mozilla Corporation was founded in 2005,  Christopher Columbus set sail in 1492, \n          \n          and  we present you with these top quality stories. \n          \n            From \n        AI Agents Are Growing Up - And They Need Zero-Trust Parenting\n       to \n        Turn a Regular Wallet into a Smart Account with EIP 7702 ,\n       let’s dive right in.\n          \n        \nImmutable Backups: Everything You Need To Know To Protect Your Cloud\n \nBy @n2w [ 6 Min read ] Learn how immutable backups prevent ransomware, ensure data integrity, and meet compliance needs with secure, tamper-proof cloud data protection. Read More.\nAI Agents Are Growing Up - And They Need Zero-Trust Parenting\n \nBy @arjun-subedi [ 8 Min read ] AI is evolving fast, but security isn’t keeping up. Discover why zero-trust architecture is critical for safe, scalable AI agent deployment. Read More.\nA Human-centred Framework for Designing Complex AI Solutions for Strategic Decision-making\n \nBy @v3d [ 7 Min read ] The practical framework helps designers, data scientists, and engineers find common ground, aligning the voice and needs of users with the design of AI systems Read More.\nTurn a Regular Wallet into a Smart Account with EIP 7702 \n \nBy @hacker39947670 [ 13 Min read ] Learn how EIP-7702 enables smart wallet features for existing Ethereum accounts. Complete developer guide with code examples. Read More.\n9 Things Hollywood Gets Wrong About Hacking\n \nBy @moonlock [ 11 Min read ] Movie hacking ≠ reality: Real cyberattacks rely on phishing, not fast code. Moonlock, MacPaw’s cybersecurity division, reveals how films get it wrong. Read More.\nA Simple Way to Build a Progress Bar for Your Website’s Image Uploader Using Filestack\n \nBy @filestack [ 7 Min read ] Let’s walk through how to build one manually, and then I’ll show you why we ensured you would never have to. Read More.\nHow an NYC-Based University Boosted Backup Reliability While Slashing Costs​\n \nBy @n2w [ 4 Min read ] Learn how N2W supports St. Johns University, which educates more than 20,000 students and employs over 1,400 staff, using a hybrid environment. Read More.\nFrom Chatbots to Guardians of Data: How BChat Harnesses AI for Secure Messaging\n \nBy @beldexcoin [ 5 Min read ] AI is often associated with collecting personal data but what if AI helped protect user data? Read to know how BeldexAI protects your data on BChat.  Read More.\n🧑‍💻 What happened in your world this week?\nwriting can help consolidate technical knowledge,\n          establish credibility,\n           and contribute to emerging community standards.\n          Feeling stuck? We got you covered ⬇️⬇️⬇️\n        \nANSWER THESE GREATEST INTERVIEW QUESTIONS OF ALL TIME\n        \nWe hope you enjoy this worth of free reading material. Feel free to forward this email to a nerdy friend who'll love you for it.See you on Planet Internet! With love, \n The HackerNoon Team ✌️",
          "dc:creator": "Noonification",
          "guid": "https://hackernoon.com/8-3-2025-newsletter?source=rss",
          "categories": [
            "hackernoon-newsletter",
            "noonification",
            "latest-tect-stories",
            "immutable-backups",
            "ai-agent",
            "ai-design",
            "web3-ux",
            "cybersecurity",
            "filestack",
            "st.-john's-university-backup",
            "ai"
          ],
          "isoDate": "2025-08-03T16:04:11.000Z"
        }
      },
      {
        "json": {
          "creator": "Sergey Drymchenko",
          "title": "Mobile AI with ONNX Runtime: How to Build Real-Time Noise Suppression That Works",
          "link": "https://hackernoon.com/mobile-ai-with-onnx-runtime-how-to-build-real-time-noise-suppression-that-works?source=rss",
          "pubDate": "Sun, 03 Aug 2025 16:03:09 GMT",
          "content:encoded": "<p>Your phone is more powerful than a desktop computer from five years ago. The latest flagship Android devices pack neural processing units, multi-core CPUs that would make 2019 laptops jealous, and RAM configurations that seemed impossible just a few years back. So why does it feel like we're barely scratching the surface of what's possible with AI on mobile?</p>\n<p>Sure, you can now even run quantized versions of Llama and DeepSeek models locally on your device. But let's be honest - those conversations still feel clunky, slow, and nowhere near the seamless experience users expect from their apps. The hype around on-device conversational AI is real, but the practical reality? We're not quite there yet.</p>\n<p>Here's where most developers miss the opportunity: conversational AI isn't the only game in town. While everyone's chasing the next ChatGPT clone, there's a massive untapped potential in specialized AI applications that actually work brilliantly on mobile hardware <em>right now</em>.</p>\n<p>Take noise suppression. Your users are constantly battling background noise during calls, recordings, and voice messages. Wind, traffic, crying babies, barking dogs - it's an endless war against audio chaos. But what if your app could eliminate that noise in real-time, locally, without sending a single byte to the cloud?</p>\n<p>This isn't science fiction. It's happening today, and any Android developer can implement it. The tools are mature, the performance is there, and your users will immediately notice the difference.</p>\n<h2 id=\"onnxruntimeyourgatewaytomobileai\"><strong>ONNX Runtime: Your Gateway to Mobile AI</strong></h2>\n<p>The mobile AI landscape is fragmented. PyTorch dominates research, TensorFlow rules production, and countless specialized frameworks emerge for specific use cases. For Android developers, this creates a painful choice: commit to one ecosystem or maintain separate pipelines for different models.</p>\n<p>After evaluating mobile AI frameworks, we chose ONNX Runtime for several compelling reasons that directly impact Android development.</p>\n<p><strong>Wider Compatibility Across Android Versions</strong></p>\n<p>Unlike Google's LiteRT (formerly TensorFlow Lite), which mandates a minimum SDK level of 31 (Android 12), ONNX Runtime comfortably supports Android API levels as low as 24 (or even 21, if you are a magician). Our project’s minimum supported version was API 28, making ONNX Runtime the clear choice to reach a broader audience without excluding millions of active users on Android 10 and earlier devices.</p>\n<p><strong>Seamless Cross-Framework Integration</strong></p>\n<p>ONNX Runtime’s greatest strength lies in its framework-agnostic nature. Whether your AI models originate from PyTorch, TensorFlow, or even traditional ML libraries like scikit-learn, exporting models to ONNX allows uniform deployment across Android, iOS, desktops, and cloud environments. This flexibility significantly simplifies maintenance, enabling a unified pipeline rather than juggling multiple framework-specific tools.</p>\n<p><strong>Lightweight and Modular Deployment</strong></p>\n<p>Integration with ONNX Runtime is straightforward. With a compact Maven AAR (around 5–7 MB for CPU builds), the library integrates cleanly into your existing Android app without introducing unnecessary dependencies like Google Play Services or requesting additional user permissions. This streamlined deployment keeps your app lean, performant, and secure.</p>\n<p><strong>Proven Real-Time Performance</strong></p>\n<p>ONNX Runtime is battle-tested in demanding real-time scenarios. Audio-processing models, such as noise suppression or speech enhancement, consistently deliver inference speeds under 4 ms per audio frame on standard mobile hardware - comfortably within real-time performance requirements. Our team leveraged this exact capability for reliable, low-latency noise suppression.</p>\n<p>Ultimately, ONNX Runtime provided our team not just convenience, but strategic advantage - allowing us to maintain compatibility, performance, and simplicity without compromises. If your project demands accessible, performant, and scalable mobile AI, ONNX Runtime could very well be your optimal choice.</p>\n<h2 id=\"integrationplansettinguponnxruntime\"><strong>Integration Plan: Setting Up ONNX Runtime</strong></h2>\n<p>The default ONNX Runtime package weighs in at a hefty 27MB. For a mobile app, that's not just bloat - it's a user acquisition killer. Research shows that for every 6MB increase in APK size, install conversion rates drop by 1% (I should note that the study is not the newest one, and concerns mainly not the most developed countries, but still, it is worth considering)</p>\n<p>The solution? A custom minimal build that strips your deployment down to exactly what you need. Our DTLN noise suppression implementation clocks in at just 7.1MB - a 70% size reduction that keeps your app lean and your users happy.</p>\n<p>ONNX Runtime's architecture is modular by design. The full package includes execution providers for GPU acceleration (NNAPI, Vulkan), dozens of operators you'll never use, and compatibility layers for edge cases that don't apply to your specific model. By building only what you need, you eliminate this overhead entirely.</p>\n<h3 id=\"step1convertyourmodelstoortformat\"><strong>Step 1: Convert Your Models to ORT Format</strong></h3>\n<p>Before building, convert your ONNX models to ORT format. This optimized format removes unused graph nodes and operator definitions, further reducing your final binary size.</p>\n<p>\\</p>\n<pre><code class=\"javascript language-javascript\">python -m onnxruntime.tools.convert_onnx_models_to_ort &lt;onnx model file or dir&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;--target_platform {arm,amd64}\n</code></pre>\n<h3 id=\"step2createoperatorconfiguration\"><strong>Step 2: Create Operator Configuration</strong></h3>\n<p>After converting all the necessary models, configuration files with the necessary operators that will be required for the minimal build of ONNX will also be generated.</p>\n<p>When using several models, combine all the configuration files into one.</p>\n<p>The final file will look something like this:</p>\n<p>\\</p>\n<pre><code class=\"javascript language-javascript\"># Generated from model/s:\nai.onnx;1;Transpose\nai.onnx;6;Sigmoid\nai.onnx;7;Add,LSTM\nai.onnx;9;MatMul\nai.onnx;11;Concat,Slice,Squeeze,Unsqueeze\nai.onnx;1;Transpose\nai.onnx;5;Reshape\n//other operators\n</code></pre>\n<p><strong>Step 3: Execute Custom Build</strong></p>\n<p>With your operator configuration ready, build ONNX Runtime from source with minimal dependencies:</p>\n<p>\\</p>\n<pre><code class=\"bash language-bash\">./build.sh --android \\\n  --android_sdk_path ~/Library/Android/sdk \\\n  --android_ndk_path ~/Library/Android/sdk/ndk/28.0.12674087 \\\n  --android_abi arm64-v8a \\\n  --android_api 24 \\\n  --minimal_build \\\n  --include_ops_by_config path/to/required_operators.config \\\n  --build_java \\\n  --config=Rel\n</code></pre>\n<ul>\n<li>--minimal_build: Excludes unnecessary execution providers and operators</li>\n<li>--include<em>ops</em>by_config: Includes only operators specified in your config file</li>\n<li>--android_abi armeabi-v7a: Targets ARM32 for maximum device compatibility</li>\n<li>--android_api 24: Maintains compatibility with Android 7.0+</li>\n</ul>\n<p>If you also want to support old devices, repeat step 3 with –android_abi armeabi-v7a and them merge both resulting aar files with following script:</p>\n<p>\\</p>\n<pre><code class=\"bash language-bash\">#!/usr/bin/env sh\n\n# Clean up from previous runs, if any\nrm -rf merge-tmp\nmkdir -p merge-tmp\ncd merge-tmp\n\necho \"Unzipping each ABI-specific AAR...\"\nmkdir a64\nunzip ../onnxruntime-arm64-v8a.aar -d a64\n\nmkdir a32\nunzip ../onnxruntime-armeabi-v7a.aar -d a32\n\necho \"Preparing universal base from arm64 AAR...\"\nmkdir universal\ncp -r a64/* universal\n\nrm -rf universal/jni\nmkdir -p universal/jni\n\n\necho \"Merging native libs from each architecture...\"\nmkdir -p universal/jni/arm64-v8a\ncp a64/jni/arm64-v8a/*.so universal/jni/arm64-v8a\n\nmkdir -p universal/jni/armeabi-v7a\ncp a32/jni/armeabi-v7a/*.so universal/jni/armeabi-v7a\n\n\n# Re-zip contents of 'universal' to create a new AAR\necho \"Creating universal AAR...\"\ncd universal\nzip -r onnxruntime-universal.aar ./*\n\necho \"Done! The merged AAR is at:\"\necho \"$(pwd)/onnxruntime-universal.aar\"\n</code></pre>\n<p>The minimal build approach transforms ONNX Runtime from a deployment liability into a strategic advantage. Your users get the full AI capability without the bloat, and your app maintains the lean profile that modern mobile development demands.</p>\n<p>Next, let's see this optimized runtime in action with real-time DTLN noise suppression.</p>\n<h3 id=\"whyaudioprocessingshowcasesaivalue\">Why Audio Processing Showcases AI Value</h3>\n<p>Audio processing is the perfect introduction to mobile AI - delivering immediate, tangible value while your competitors wrestle with bloated language models that drain batteries and require constant internet connections.</p>\n<p><strong>The Daily Audio War Your Users Are Fighting</strong></p>\n<p>Sarah records voice messages while walking through a busy street. Between honking taxis, construction noise, and subway rumbles, she re-records messages three times before giving up and typing instead.</p>\n<p>Marcus joins client calls from his home office, which doubles as his toddler's playroom. Every presentation becomes a cycle of \"mute, unmute, apologize for the crying.\"</p>\n<p>Elena creates YouTube content in her apartment but spends hours in post-production cleaning up neighbor noise, traffic, and air conditioning hum.</p>\n<p>These aren't edge cases - they're the reality of modern mobile computing where everyone expects professional results from consumer hardware in chaotic environments.</p>\n<p><strong>Why Noise Suppression Creates Instant \"Wow\" Moments</strong></p>\n<p>Audio quality improvements trigger immediate emotional responses. Unlike other AI applications requiring explanation, noise suppression provides instant gratification users can perceive within seconds. Play someone their own voice - crystal clear - after removing background noise, and watch their reaction. They don't need to understand LSTM networks; they just know their audio sounds professional.</p>\n<p>The beauty of audio processing as an AI showcase lies in universality. Everyone understands good audio, everyone has experienced bad audio, and everyone immediately recognizes improvement when noise disappears. You're not asking users to trust your AI - you're proving its value in the most direct way possible.</p>\n<h2 id=\"buildingaproductionreadydemorealtimenoisesuppression\">Building a Production-Ready Demo: Real-Time Noise Suppression</h2>\n<p>Now, let's build a sample project that demonstrates the practical power of ONNX Runtime on Android. Rather than a basic \"hello world\" example, we'll create something close to production quality - a real-time noise suppression demonstration where users can record audio in noisy environments and experience the striking difference between their original recording and the AI-cleaned version.</p>\n<p><strong>You can find a complete sample here, on my Github: <strong><a href=\"https://github.com/linreal/android-onnx-showcase\">https://github.com/linreal/android-onnx-showcase</a></strong>.</strong></p>\n<p><strong>Models, used in sample are from <strong><a href=\"https://github.com/breizhn/DTLN\">https://github.com/breizhn/DTLN</a></strong></strong></p>\n<h2 id=\"quickimplementationoverview\">Quick Implementation Overview</h2>\n<p>Before diving into DTLN's dual-path architecture, let's establish how the pieces fit together. The beauty of this implementation lies in its clean separation of concerns - each component has a single responsibility, making the system both testable and maintainable.</p>\n<h3 id=\"thecorecomponents\">The Core Components</h3>\n<p>At the heart of our noise suppression pipeline sit three key interfaces that work together:</p>\n<p>\\</p>\n<pre><code class=\"bash language-bash\">interface NoiseSuppressor {\n    suspend fun initialize()\n    fun processChunk(audioChunk: FloatArray): FloatArray\n    fun release()\n}\n\ninterface AudioRecorder {\n    suspend fun startRecording(): Flow&lt;ShortArray&gt;\n    suspend fun stopRecording()\n}\n\ninterface ConcurrentAudioProcessor {\n    suspend fun startProcessing(\n        suppressor: NoiseSuppressor,\n        rawOutputFile: File,\n        processedOutputFile: File\n    )\n    suspend fun stopProcessing(): ProcessingResult\n}\n</code></pre>\n<p>The NoiseSuppressor encapsulates all ONNX Runtime complexity behind a simple interface. Feed it audio chunks, get back denoised audio. The stateful nature of DTLN is completely hidden - the implementation maintains LSTM states internally between calls.</p>\n<p><strong>Data Flow Architecture</strong></p>\n<p>\\</p>\n<pre><code class=\"bash language-bash\">AudioRecorder → Flow&lt;ShortArray&gt; → ConcurrentAudioProcessor → NoiseSuppressor → Processed Audio Files\n</code></pre>\n<p>\\\nThe ConcurrentAudioProcessor orchestrates the entire pipeline. It subscribes to the audio recorder's Flow, converts audio formats, processes chunks through the noise suppressor, and writes both original and processed audio to files simultaneously.</p>\n<p>\\</p>\n<pre><code class=\"bash language-bash\">rawAudioRecorder.startRecording().collect { audioChunk -&gt;\n    // Convert format for processing\n    val floatChunk = AudioConversionUtils.shortArrayToFloatArray(audioChunk)\n\n    // Process through DTLN\n    val processedChunk = suppressor.processChunk(floatChunk)\n\n    // Save both versions concurrently\n    launch { rawFileWriter.writeAudioData(floatChunk) }\n    launch { processedFileWriter.writeAudioData(processedChunk) }\n}\n</code></pre>\n<h3 id=\"whythisarchitectureworks\">Why This Architecture Works</h3>\n<p><strong>Reactive Processing:</strong> The Flow-based design ensures your UI remains responsive. Audio processing happens on background threads while the main thread handles user interactions.</p>\n<p><strong>Format Isolation:</strong> Each component works with its preferred audio format. <code>AudioRecorder</code> produces ShortArray (16-bit PCM), while <code>NoiseSuppressor</code> expects FloatArray (normalized samples). Conversion happens at the boundary.</p>\n<p><strong>Error Boundaries:</strong> If ONNX initialization fails, only the NoiseSuppressor component is affected. The audio recorder and file writers continue functioning, ensuring graceful degradation.</p>\n<p><strong>Resource Management:</strong> Each component manages its own resources. The <code>ConcurrentAudioProcessor</code> coordinates lifecycle events but doesn't own the underlying implementations.</p>\n<p>This modular approach means you can swap out the DTLN implementation for any other ONNX model, replace the audio recorder with a file-based source, or modify the output format without touching other components. The architecture scales from proof-of-concept to production deployment.</p>\n<p>Next, we'll explore the DTLN architecture that makes this magic happen.</p>\n<h3 id=\"understandingdtlnarchitecture\">Understanding DTLN Architecture</h3>\n<p>Traditional noise suppression approaches face a fundamental tradeoff. Frequency-domain methods excel at removing stationary noise (air conditioning, fan hum) but struggle with dynamic sounds like speech or music bleeding through. Time-domain approaches handle complex, changing signals well but often introduce artifacts or fail with consistent background noise.</p>\n<p>DTLN sidesteps this limitation entirely through its dual-path architecture:</p>\n<p><strong>Stage 1: Frequency Domain Processing</strong> The first model operates in the frequency domain, analyzing the spectral characteristics of your audio. It generates a suppression mask that identifies which frequency components contain noise versus speech. This stage excels at removing stationary background noise - the steady hum of air conditioning, traffic, or office chatter.</p>\n<p>\\</p>\n<pre><code class=\"bash language-bash\">// Stage 1: Frequency domain mask estimation\n\nval (magnitude, phase) = fftProcessor.forward(inBuffer)\nval outMask = model1.run(mapOf(\"input_2\" to magnitudeTensor, \"input_3\" to lstmState))\nfor (i in magnitude.indices) {\n    magnitude[i] *= outMask[i] // Apply suppression mask\n}\n</code></pre>\n<p><strong>Stage 2: Time Domain Refinement</strong> The masked frequency-domain signal gets converted back to the time domain, then fed into a second model that operates directly on the audio waveform. This stage catches what the frequency analysis missed - handling dynamic noise patterns, preserving speech naturalness, and cleaning up any artifacts from the first stage.</p>\n<p>\\</p>\n<pre><code class=\"bash language-bash\">// Stage 2: Time domain refinement\n\nval estimatedBlock = fftProcessor.inverse(magnitude, phase)\nval finalBlock = model2.run(mapOf(\"input_4\" to estimatedTensor, \"input_5\" to lstmState))\n</code></pre>\n<h3 id=\"themobilefirstdesignphilosophy\">The Mobile-First Design Philosophy</h3>\n<p>DTLN's architecture reflects years of practical mobile AI deployment experience. Every design decision prioritizes real-world constraints over academic benchmarks.</p>\n<p><strong>Chunk-Based Processing</strong> The model processes audio in 512-sample chunks (32ms at 16kHz), striking the optimal balance between latency and context. This chunk size is small enough for real-time processing but large enough to provide meaningful temporal context for the LSTM networks.</p>\n<p>\\</p>\n<pre><code class=\"bash language-bash\">companion object {\n    private const val BLOCK_LEN = 512  // 32ms chunks\n    private const val BLOCK_SHIFT = 128  // 75% overlap for smooth processing\n}\n</code></pre>\n<p><strong>Stateful LSTM Networks</strong> Both models use LSTM (Long Short-Term Memory) networks that maintain internal state between chunks. This temporal memory allows the model to distinguish between speech and noise based on context, not just instantaneous audio characteristics.</p>\n<p>\\</p>\n<pre><code class=\"bash language-bash\">class NoiseSuppressorImpl {\n    // These tensors maintain LSTM state between processing calls\n    private var input3Tensor: OnnxTensor? = null  // Model 1 LSTM state\n    private var input5Tensor: OnnxTensor? = null  // Model 2 LSTM state\n\n    fun processChunk(audioChunk: FloatArray): FloatArray {\n        // State automatically carries forward to next chunk\n        val result1 = model1.run(mapOf(\"input_3\" to input3Tensor))\n        input3Tensor?.close()\n        input3Tensor = result1[1] as OnnxTensor  // Update state\n\n        // State continuity ensures smooth, artifact-free processing\n    }\n}\n</code></pre>\n<h3 id=\"performancecharacteristicsthatmatter\">Performance Characteristics That Matter</h3>\n<p>Understanding DTLN's architecture helps predict its behavior in your application. These performance characteristics directly impact user experience:</p>\n<p><strong>Latency Profile</strong></p>\n<ul>\n<li>Algorithmic Delay: 32ms (one chunk processing time)</li>\n<li>Inference Time: 3-4ms per chunk on mid-range Android hardware</li>\n<li>Total Latency: ~35ms end-to-end (imperceptible for most use cases)</li>\n</ul>\n<p><strong>Resource Usage</strong></p>\n<ul>\n<li>Memory Footprint: ~28MB during active processing</li>\n<li>CPU Usage: 12-18% on typical mid-range device</li>\n<li>Battery Impact: Negligible for typical recording sessions</li>\n</ul>\n<p>These characteristics make DTLN particularly well-suited for mobile applications where users expect immediate results without sacrificing device performance or battery life.</p>\n<h3 id=\"onnxruntimeintegrationstrategy\">ONNX Runtime Integration Strategy</h3>\n<p>Getting ONNX Runtime working on Android isn't just about adding a dependency to your build.gradle. The difference between a proof-of-concept that crashes under load and a production-ready implementation lies in the session configuration, memory management, and resource allocation strategy.</p>\n<p>As we already prepared a minimal runtime build, it’s time to look into what lies next.</p>\n<p><strong>Session Configuration for Mobile Reality</strong></p>\n<p>The default ONNX Runtime session configuration assumes you're running on a server with abundant resources. Mobile devices operate under entirely different constraints: limited memory, thermal throttling, and users who expect apps to remain responsive during AI processing.</p>\n<p>\\</p>\n<pre><code class=\"bash language-bash\">private val sessionOptions = OrtSession.SessionOptions().apply {\n    setIntraOpNumThreads(numThreads.coerceIn(1, 4))\n    setInterOpNumThreads(numThreads)\n    setMemoryPatternOptimization(true)\n    setOptimizationLevel(OrtSession.SessionOptions.OptLevel.ALL_OPT)\n    setExecutionMode(OrtSession.SessionOptions.ExecutionMode.SEQUENTIAL)\n}\n</code></pre>\n<p>Your first instinct might be to use all available CPU cores for maximum performance. Resist this urge. Mobile devices prioritize battery life over raw computational speed, and Android's thermal management will throttle aggressive CPU usage within seconds.</p>\n<p>The sweet spot for real-time audio processing sits between 2-4 threads, determined by your device's core count:</p>\n<p>\\</p>\n<pre><code class=\"bash language-bash\">private val numThreads = Runtime.getRuntime().availableProcessors().coerceIn(1, 4)\n</code></pre>\n<p>This configuration delivers 95% of maximum performance while consuming 60% less battery than an unrestricted thread pool. Your users notice the efficiency gains more than the minor latency difference.</p>\n<p><code>setMemoryPatternOptimization(true)</code> activates ONNX Runtime's most impactful mobile optimization. This setting analyzes your model's memory access patterns during the first few inference calls, then pre-allocates memory pools to minimize garbage collection pressure during real-time processing.</p>\n<p>\\</p>\n<pre><code class=\"bash language-bash\">setExecutionMode(OrtSession.SessionOptions.ExecutionMode.SEQUENTIAL)\n</code></pre>\n<p>Sequential execution might seem counterintuitive when parallel processing offers higher throughput. However, real-time audio processing demands predictable latency over peak performance. Parallel execution creates latency spikes when thread synchronization occurs - precisely what you want to avoid during live audio processing.</p>\n<p>Sequential execution delivers consistent 3-4ms inference times, while parallel mode ranges from 2-8ms with unpredictable spikes. Users perceive consistency as quality.</p>\n<p><strong>Memory Pre-allocation: The Performance Multiplier</strong></p>\n<p>The most critical optimization for mobile ONNX Runtime applications involves pre-allocating tensors that get reused across inference calls. Creating tensors during inference triggers memory allocations that accumulate into significant performance bottlenecks.</p>\n<p>\\</p>\n<pre><code class=\"bash language-bash\">// Pre-allocate tensors during initialization\ninput3Tensor = createZeroTensor(INP_SHAPE_2)  // Model 1 LSTM state\ninput5Tensor = createZeroTensor(INP_SHAPE_2)  // Model 2 LSTM state\n\nprivate fun createZeroTensor(shape: LongArray): OnnxTensor {\n    val env = requireNotNull(env) { \"ONNX Environment not initialized\" }\n    val size = shape.reduce { acc, i -&gt; acc * i }.toInt()\n    return OnnxTensor.createTensor(env, FloatBuffer.allocate(size), shape)\n}\n</code></pre>\n<p><strong>Garbage Collection Pressure Reduction</strong> - Creating tensors during inference generates objects that must be garbage collected. Pre-allocation moves this cost to initialization time, keeping inference paths allocation-free.</p>\n<p><strong>Memory Fragmentation Prevention</strong> - Repeated tensor creation fragments heap memory, leading to unexpected allocation failures. Pre-allocated tensors maintain consistent memory layout.</p>\n<p><strong>Latency Consistency</strong> - Allocation costs are unpredictable and can introduce latency spikes during real-time processing. Pre-allocation ensures consistent inference timing.</p>\n<p>These integration strategies transform ONNX Runtime from a research tool into a production-ready component. The configuration choices, memory management patterns, and error handling approaches directly impact user experience in ways that become apparent only under real-world usage conditions.</p>\n<p>You can look into <strong><a href=\"https://github.com/linreal/android-onnx-showcase/blob/main/app/src/main/java/gos/denver/onnxshowcase/audio/impl/NoiseSuppressorImpl.kt\">https://github.com/linreal/android-onnx-showcase/blob/main/app/src/main/java/gos/denver/onnxshowcase/audio/impl/NoiseSuppressorImpl.kt</a></strong> for a full source code.</p>\n<h2 id=\"conclusionaiascompetitiveadvantage\">Conclusion: AI as Competitive Advantage</h2>\n<p>The mobile AI landscape is experiencing a fundamental shift. While competitors chase resource-hungry language models and cloud-dependent solutions, there's a massive opportunity in specialized, on-device AI that delivers immediate value to users.</p>\n<h3 id=\"keytakeawaysforandroiddevelopers\"><strong>Key Takeaways for Android Developers</strong></h3>\n<p><strong>On-device AI is production-ready today. T</strong>he combination of ONNX Runtime's optimization capabilities and purpose-built models like DTLN delivers performance that matches or exceeds cloud solutions while eliminating latency and connectivity requirements. Your users get instant results, and you get a feature that works everywhere - from subway tunnels to airplane mode.</p>\n<p><strong>APK size optimization transforms deployment strategy.</strong> Our minimal ONNX Runtime build reduced library size by 70% without sacrificing functionality. This isn't just about storage - it directly impacts user acquisition. When AI features add 7MB instead of 27MB to your app, the cost-benefit equation shifts dramatically in your favor.</p>\n<p><strong>User experience trumps algorithmic sophistication.</strong> DTLN isn't the most advanced noise suppression model available, but it strikes the perfect balance between quality, performance, and resource consumption for mobile deployment. Users don't care about model architecture - they care about crystal-clear audio in noisy environments.</p>\n<p>Apps implementing on-device AI gain three competitive advantages: Privacy by Design (no sensitive data leaves the device), Offline Reliability (consistent experience regardless of network conditions), and Cost Structure Benefits (no cloud inference costs or operational expenses that scale with usage).</p>\n<h3 id=\"nextstepsandexploration\"><strong>Next Steps and Exploration</strong></h3>\n<p>The techniques demonstrated here extend far beyond noise suppression. ONNX Runtime enables practical deployment of models for audio processing, computer vision, natural language tasks, and sensor fusion applications.</p>\n<p>The complete implementation is available on GitHub: <strong><a href=\"https://github.com/linreal/android-onnx-showcase\">android-onnx-showcase</a></strong>. Use it as a foundation for your own AI-powered features.</p>\n<p>Your Android app deserves AI that enhances user experience without compromising performance, privacy, or reliability. ONNX Runtime makes this vision achievable today. The tools are ready, the performance is proven - time to build something amazing.</p>\n<hr />\n<p><em>Found this implementation useful? Star the <strong><a href=\"https://github.com/linreal/android-onnx-showcase\">GitHub repository</a></strong> and share your results. The mobile AI community grows stronger when we share practical knowledge.</em></p>\n<p><em>Follow me for more deep-dives into production-ready mobile AI implementations that your users will actually notice and appreciate.</em> \\n </p>",
          "content:encodedSnippet": "Your phone is more powerful than a desktop computer from five years ago. The latest flagship Android devices pack neural processing units, multi-core CPUs that would make 2019 laptops jealous, and RAM configurations that seemed impossible just a few years back. So why does it feel like we're barely scratching the surface of what's possible with AI on mobile?\nSure, you can now even run quantized versions of Llama and DeepSeek models locally on your device. But let's be honest - those conversations still feel clunky, slow, and nowhere near the seamless experience users expect from their apps. The hype around on-device conversational AI is real, but the practical reality? We're not quite there yet.\nHere's where most developers miss the opportunity: conversational AI isn't the only game in town. While everyone's chasing the next ChatGPT clone, there's a massive untapped potential in specialized AI applications that actually work brilliantly on mobile hardware right now.\nTake noise suppression. Your users are constantly battling background noise during calls, recordings, and voice messages. Wind, traffic, crying babies, barking dogs - it's an endless war against audio chaos. But what if your app could eliminate that noise in real-time, locally, without sending a single byte to the cloud?\nThis isn't science fiction. It's happening today, and any Android developer can implement it. The tools are mature, the performance is there, and your users will immediately notice the difference.\nONNX Runtime: Your Gateway to Mobile AI\nThe mobile AI landscape is fragmented. PyTorch dominates research, TensorFlow rules production, and countless specialized frameworks emerge for specific use cases. For Android developers, this creates a painful choice: commit to one ecosystem or maintain separate pipelines for different models.\nAfter evaluating mobile AI frameworks, we chose ONNX Runtime for several compelling reasons that directly impact Android development.\nWider Compatibility Across Android Versions\nUnlike Google's LiteRT (formerly TensorFlow Lite), which mandates a minimum SDK level of 31 (Android 12), ONNX Runtime comfortably supports Android API levels as low as 24 (or even 21, if you are a magician). Our project’s minimum supported version was API 28, making ONNX Runtime the clear choice to reach a broader audience without excluding millions of active users on Android 10 and earlier devices.\nSeamless Cross-Framework Integration\nONNX Runtime’s greatest strength lies in its framework-agnostic nature. Whether your AI models originate from PyTorch, TensorFlow, or even traditional ML libraries like scikit-learn, exporting models to ONNX allows uniform deployment across Android, iOS, desktops, and cloud environments. This flexibility significantly simplifies maintenance, enabling a unified pipeline rather than juggling multiple framework-specific tools.\nLightweight and Modular Deployment\nIntegration with ONNX Runtime is straightforward. With a compact Maven AAR (around 5–7 MB for CPU builds), the library integrates cleanly into your existing Android app without introducing unnecessary dependencies like Google Play Services or requesting additional user permissions. This streamlined deployment keeps your app lean, performant, and secure.\nProven Real-Time Performance\nONNX Runtime is battle-tested in demanding real-time scenarios. Audio-processing models, such as noise suppression or speech enhancement, consistently deliver inference speeds under 4 ms per audio frame on standard mobile hardware - comfortably within real-time performance requirements. Our team leveraged this exact capability for reliable, low-latency noise suppression.\nUltimately, ONNX Runtime provided our team not just convenience, but strategic advantage - allowing us to maintain compatibility, performance, and simplicity without compromises. If your project demands accessible, performant, and scalable mobile AI, ONNX Runtime could very well be your optimal choice.\nIntegration Plan: Setting Up ONNX Runtime\nThe default ONNX Runtime package weighs in at a hefty 27MB. For a mobile app, that's not just bloat - it's a user acquisition killer. Research shows that for every 6MB increase in APK size, install conversion rates drop by 1% (I should note that the study is not the newest one, and concerns mainly not the most developed countries, but still, it is worth considering)\nThe solution? A custom minimal build that strips your deployment down to exactly what you need. Our DTLN noise suppression implementation clocks in at just 7.1MB - a 70% size reduction that keeps your app lean and your users happy.\nONNX Runtime's architecture is modular by design. The full package includes execution providers for GPU acceleration (NNAPI, Vulkan), dozens of operators you'll never use, and compatibility layers for edge cases that don't apply to your specific model. By building only what you need, you eliminate this overhead entirely.\nStep 1: Convert Your Models to ORT Format\nBefore building, convert your ONNX models to ORT format. This optimized format removes unused graph nodes and operator definitions, further reducing your final binary size.\n\\\npython -m onnxruntime.tools.convert_onnx_models_to_ort <onnx model file or dir> &nbsp;&nbsp;&nbsp;--target_platform {arm,amd64}\n\nStep 2: Create Operator Configuration\nAfter converting all the necessary models, configuration files with the necessary operators that will be required for the minimal build of ONNX will also be generated.\nWhen using several models, combine all the configuration files into one.\nThe final file will look something like this:\n\\\n# Generated from model/s:\nai.onnx;1;Transpose\nai.onnx;6;Sigmoid\nai.onnx;7;Add,LSTM\nai.onnx;9;MatMul\nai.onnx;11;Concat,Slice,Squeeze,Unsqueeze\nai.onnx;1;Transpose\nai.onnx;5;Reshape\n//other operators\n\nStep 3: Execute Custom Build\nWith your operator configuration ready, build ONNX Runtime from source with minimal dependencies:\n\\\n./build.sh --android \\\n  --android_sdk_path ~/Library/Android/sdk \\\n  --android_ndk_path ~/Library/Android/sdk/ndk/28.0.12674087 \\\n  --android_abi arm64-v8a \\\n  --android_api 24 \\\n  --minimal_build \\\n  --include_ops_by_config path/to/required_operators.config \\\n  --build_java \\\n  --config=Rel\n\n--minimal_build: Excludes unnecessary execution providers and operators\n--includeopsby_config: Includes only operators specified in your config file\n--android_abi armeabi-v7a: Targets ARM32 for maximum device compatibility\n--android_api 24: Maintains compatibility with Android 7.0+\nIf you also want to support old devices, repeat step 3 with –android_abi armeabi-v7a and them merge both resulting aar files with following script:\n\\\n#!/usr/bin/env sh\n\n# Clean up from previous runs, if any\nrm -rf merge-tmp\nmkdir -p merge-tmp\ncd merge-tmp\n\necho \"Unzipping each ABI-specific AAR...\"\nmkdir a64\nunzip ../onnxruntime-arm64-v8a.aar -d a64\n\nmkdir a32\nunzip ../onnxruntime-armeabi-v7a.aar -d a32\n\necho \"Preparing universal base from arm64 AAR...\"\nmkdir universal\ncp -r a64/* universal\n\nrm -rf universal/jni\nmkdir -p universal/jni\n\n\necho \"Merging native libs from each architecture...\"\nmkdir -p universal/jni/arm64-v8a\ncp a64/jni/arm64-v8a/*.so universal/jni/arm64-v8a\n\nmkdir -p universal/jni/armeabi-v7a\ncp a32/jni/armeabi-v7a/*.so universal/jni/armeabi-v7a\n\n\n# Re-zip contents of 'universal' to create a new AAR\necho \"Creating universal AAR...\"\ncd universal\nzip -r onnxruntime-universal.aar ./*\n\necho \"Done! The merged AAR is at:\"\necho \"$(pwd)/onnxruntime-universal.aar\"\n\nThe minimal build approach transforms ONNX Runtime from a deployment liability into a strategic advantage. Your users get the full AI capability without the bloat, and your app maintains the lean profile that modern mobile development demands.\nNext, let's see this optimized runtime in action with real-time DTLN noise suppression.\nWhy Audio Processing Showcases AI Value\nAudio processing is the perfect introduction to mobile AI - delivering immediate, tangible value while your competitors wrestle with bloated language models that drain batteries and require constant internet connections.\nThe Daily Audio War Your Users Are Fighting\nSarah records voice messages while walking through a busy street. Between honking taxis, construction noise, and subway rumbles, she re-records messages three times before giving up and typing instead.\nMarcus joins client calls from his home office, which doubles as his toddler's playroom. Every presentation becomes a cycle of \"mute, unmute, apologize for the crying.\"\nElena creates YouTube content in her apartment but spends hours in post-production cleaning up neighbor noise, traffic, and air conditioning hum.\nThese aren't edge cases - they're the reality of modern mobile computing where everyone expects professional results from consumer hardware in chaotic environments.\nWhy Noise Suppression Creates Instant \"Wow\" Moments\nAudio quality improvements trigger immediate emotional responses. Unlike other AI applications requiring explanation, noise suppression provides instant gratification users can perceive within seconds. Play someone their own voice - crystal clear - after removing background noise, and watch their reaction. They don't need to understand LSTM networks; they just know their audio sounds professional.\nThe beauty of audio processing as an AI showcase lies in universality. Everyone understands good audio, everyone has experienced bad audio, and everyone immediately recognizes improvement when noise disappears. You're not asking users to trust your AI - you're proving its value in the most direct way possible.\nBuilding a Production-Ready Demo: Real-Time Noise Suppression\nNow, let's build a sample project that demonstrates the practical power of ONNX Runtime on Android. Rather than a basic \"hello world\" example, we'll create something close to production quality - a real-time noise suppression demonstration where users can record audio in noisy environments and experience the striking difference between their original recording and the AI-cleaned version.\nYou can find a complete sample here, on my Github: https://github.com/linreal/android-onnx-showcase.\nModels, used in sample are from https://github.com/breizhn/DTLN\nQuick Implementation Overview\nBefore diving into DTLN's dual-path architecture, let's establish how the pieces fit together. The beauty of this implementation lies in its clean separation of concerns - each component has a single responsibility, making the system both testable and maintainable.\nThe Core Components\nAt the heart of our noise suppression pipeline sit three key interfaces that work together:\n\\\ninterface NoiseSuppressor {\n    suspend fun initialize()\n    fun processChunk(audioChunk: FloatArray): FloatArray\n    fun release()\n}\n\ninterface AudioRecorder {\n    suspend fun startRecording(): Flow<ShortArray>\n    suspend fun stopRecording()\n}\n\ninterface ConcurrentAudioProcessor {\n    suspend fun startProcessing(\n        suppressor: NoiseSuppressor,\n        rawOutputFile: File,\n        processedOutputFile: File\n    )\n    suspend fun stopProcessing(): ProcessingResult\n}\n\nThe NoiseSuppressor encapsulates all ONNX Runtime complexity behind a simple interface. Feed it audio chunks, get back denoised audio. The stateful nature of DTLN is completely hidden - the implementation maintains LSTM states internally between calls.\nData Flow Architecture\n\\\nAudioRecorder → Flow<ShortArray> → ConcurrentAudioProcessor → NoiseSuppressor → Processed Audio Files\n\n\\\nThe ConcurrentAudioProcessor orchestrates the entire pipeline. It subscribes to the audio recorder's Flow, converts audio formats, processes chunks through the noise suppressor, and writes both original and processed audio to files simultaneously.\n\\\nrawAudioRecorder.startRecording().collect { audioChunk ->\n    // Convert format for processing\n    val floatChunk = AudioConversionUtils.shortArrayToFloatArray(audioChunk)\n\n    // Process through DTLN\n    val processedChunk = suppressor.processChunk(floatChunk)\n\n    // Save both versions concurrently\n    launch { rawFileWriter.writeAudioData(floatChunk) }\n    launch { processedFileWriter.writeAudioData(processedChunk) }\n}\n\nWhy This Architecture Works\nReactive Processing: The Flow-based design ensures your UI remains responsive. Audio processing happens on background threads while the main thread handles user interactions.\nFormat Isolation: Each component works with its preferred audio format. AudioRecorder produces ShortArray (16-bit PCM), while NoiseSuppressor expects FloatArray (normalized samples). Conversion happens at the boundary.\nError Boundaries: If ONNX initialization fails, only the NoiseSuppressor component is affected. The audio recorder and file writers continue functioning, ensuring graceful degradation.\nResource Management: Each component manages its own resources. The ConcurrentAudioProcessor coordinates lifecycle events but doesn't own the underlying implementations.\nThis modular approach means you can swap out the DTLN implementation for any other ONNX model, replace the audio recorder with a file-based source, or modify the output format without touching other components. The architecture scales from proof-of-concept to production deployment.\nNext, we'll explore the DTLN architecture that makes this magic happen.\nUnderstanding DTLN Architecture\nTraditional noise suppression approaches face a fundamental tradeoff. Frequency-domain methods excel at removing stationary noise (air conditioning, fan hum) but struggle with dynamic sounds like speech or music bleeding through. Time-domain approaches handle complex, changing signals well but often introduce artifacts or fail with consistent background noise.\nDTLN sidesteps this limitation entirely through its dual-path architecture:\nStage 1: Frequency Domain Processing The first model operates in the frequency domain, analyzing the spectral characteristics of your audio. It generates a suppression mask that identifies which frequency components contain noise versus speech. This stage excels at removing stationary background noise - the steady hum of air conditioning, traffic, or office chatter.\n\\\n// Stage 1: Frequency domain mask estimation\n\nval (magnitude, phase) = fftProcessor.forward(inBuffer)\nval outMask = model1.run(mapOf(\"input_2\" to magnitudeTensor, \"input_3\" to lstmState))\nfor (i in magnitude.indices) {\n    magnitude[i] *= outMask[i] // Apply suppression mask\n}\n\nStage 2: Time Domain Refinement The masked frequency-domain signal gets converted back to the time domain, then fed into a second model that operates directly on the audio waveform. This stage catches what the frequency analysis missed - handling dynamic noise patterns, preserving speech naturalness, and cleaning up any artifacts from the first stage.\n\\\n// Stage 2: Time domain refinement\n\nval estimatedBlock = fftProcessor.inverse(magnitude, phase)\nval finalBlock = model2.run(mapOf(\"input_4\" to estimatedTensor, \"input_5\" to lstmState))\n\nThe Mobile-First Design Philosophy\nDTLN's architecture reflects years of practical mobile AI deployment experience. Every design decision prioritizes real-world constraints over academic benchmarks.\nChunk-Based Processing The model processes audio in 512-sample chunks (32ms at 16kHz), striking the optimal balance between latency and context. This chunk size is small enough for real-time processing but large enough to provide meaningful temporal context for the LSTM networks.\n\\\ncompanion object {\n    private const val BLOCK_LEN = 512  // 32ms chunks\n    private const val BLOCK_SHIFT = 128  // 75% overlap for smooth processing\n}\n\nStateful LSTM Networks Both models use LSTM (Long Short-Term Memory) networks that maintain internal state between chunks. This temporal memory allows the model to distinguish between speech and noise based on context, not just instantaneous audio characteristics.\n\\\nclass NoiseSuppressorImpl {\n    // These tensors maintain LSTM state between processing calls\n    private var input3Tensor: OnnxTensor? = null  // Model 1 LSTM state\n    private var input5Tensor: OnnxTensor? = null  // Model 2 LSTM state\n\n    fun processChunk(audioChunk: FloatArray): FloatArray {\n        // State automatically carries forward to next chunk\n        val result1 = model1.run(mapOf(\"input_3\" to input3Tensor))\n        input3Tensor?.close()\n        input3Tensor = result1[1] as OnnxTensor  // Update state\n\n        // State continuity ensures smooth, artifact-free processing\n    }\n}\n\nPerformance Characteristics That Matter\nUnderstanding DTLN's architecture helps predict its behavior in your application. These performance characteristics directly impact user experience:\nLatency Profile\nAlgorithmic Delay: 32ms (one chunk processing time)\nInference Time: 3-4ms per chunk on mid-range Android hardware\nTotal Latency: ~35ms end-to-end (imperceptible for most use cases)\nResource Usage\nMemory Footprint: ~28MB during active processing\nCPU Usage: 12-18% on typical mid-range device\nBattery Impact: Negligible for typical recording sessions\nThese characteristics make DTLN particularly well-suited for mobile applications where users expect immediate results without sacrificing device performance or battery life.\nONNX Runtime Integration Strategy\nGetting ONNX Runtime working on Android isn't just about adding a dependency to your build.gradle. The difference between a proof-of-concept that crashes under load and a production-ready implementation lies in the session configuration, memory management, and resource allocation strategy.\nAs we already prepared a minimal runtime build, it’s time to look into what lies next.\nSession Configuration for Mobile Reality\nThe default ONNX Runtime session configuration assumes you're running on a server with abundant resources. Mobile devices operate under entirely different constraints: limited memory, thermal throttling, and users who expect apps to remain responsive during AI processing.\n\\\nprivate val sessionOptions = OrtSession.SessionOptions().apply {\n    setIntraOpNumThreads(numThreads.coerceIn(1, 4))\n    setInterOpNumThreads(numThreads)\n    setMemoryPatternOptimization(true)\n    setOptimizationLevel(OrtSession.SessionOptions.OptLevel.ALL_OPT)\n    setExecutionMode(OrtSession.SessionOptions.ExecutionMode.SEQUENTIAL)\n}\n\nYour first instinct might be to use all available CPU cores for maximum performance. Resist this urge. Mobile devices prioritize battery life over raw computational speed, and Android's thermal management will throttle aggressive CPU usage within seconds.\nThe sweet spot for real-time audio processing sits between 2-4 threads, determined by your device's core count:\n\\\nprivate val numThreads = Runtime.getRuntime().availableProcessors().coerceIn(1, 4)\n\nThis configuration delivers 95% of maximum performance while consuming 60% less battery than an unrestricted thread pool. Your users notice the efficiency gains more than the minor latency difference.\nsetMemoryPatternOptimization(true) activates ONNX Runtime's most impactful mobile optimization. This setting analyzes your model's memory access patterns during the first few inference calls, then pre-allocates memory pools to minimize garbage collection pressure during real-time processing.\n\\\nsetExecutionMode(OrtSession.SessionOptions.ExecutionMode.SEQUENTIAL)\n\nSequential execution might seem counterintuitive when parallel processing offers higher throughput. However, real-time audio processing demands predictable latency over peak performance. Parallel execution creates latency spikes when thread synchronization occurs - precisely what you want to avoid during live audio processing.\nSequential execution delivers consistent 3-4ms inference times, while parallel mode ranges from 2-8ms with unpredictable spikes. Users perceive consistency as quality.\nMemory Pre-allocation: The Performance Multiplier\nThe most critical optimization for mobile ONNX Runtime applications involves pre-allocating tensors that get reused across inference calls. Creating tensors during inference triggers memory allocations that accumulate into significant performance bottlenecks.\n\\\n// Pre-allocate tensors during initialization\ninput3Tensor = createZeroTensor(INP_SHAPE_2)  // Model 1 LSTM state\ninput5Tensor = createZeroTensor(INP_SHAPE_2)  // Model 2 LSTM state\n\nprivate fun createZeroTensor(shape: LongArray): OnnxTensor {\n    val env = requireNotNull(env) { \"ONNX Environment not initialized\" }\n    val size = shape.reduce { acc, i -> acc * i }.toInt()\n    return OnnxTensor.createTensor(env, FloatBuffer.allocate(size), shape)\n}\n\nGarbage Collection Pressure Reduction - Creating tensors during inference generates objects that must be garbage collected. Pre-allocation moves this cost to initialization time, keeping inference paths allocation-free.\nMemory Fragmentation Prevention - Repeated tensor creation fragments heap memory, leading to unexpected allocation failures. Pre-allocated tensors maintain consistent memory layout.\nLatency Consistency - Allocation costs are unpredictable and can introduce latency spikes during real-time processing. Pre-allocation ensures consistent inference timing.\nThese integration strategies transform ONNX Runtime from a research tool into a production-ready component. The configuration choices, memory management patterns, and error handling approaches directly impact user experience in ways that become apparent only under real-world usage conditions.\nYou can look into https://github.com/linreal/android-onnx-showcase/blob/main/app/src/main/java/gos/denver/onnxshowcase/audio/impl/NoiseSuppressorImpl.kt for a full source code.\nConclusion: AI as Competitive Advantage\nThe mobile AI landscape is experiencing a fundamental shift. While competitors chase resource-hungry language models and cloud-dependent solutions, there's a massive opportunity in specialized, on-device AI that delivers immediate value to users.\nKey Takeaways for Android Developers\nOn-device AI is production-ready today. The combination of ONNX Runtime's optimization capabilities and purpose-built models like DTLN delivers performance that matches or exceeds cloud solutions while eliminating latency and connectivity requirements. Your users get instant results, and you get a feature that works everywhere - from subway tunnels to airplane mode.\nAPK size optimization transforms deployment strategy. Our minimal ONNX Runtime build reduced library size by 70% without sacrificing functionality. This isn't just about storage - it directly impacts user acquisition. When AI features add 7MB instead of 27MB to your app, the cost-benefit equation shifts dramatically in your favor.\nUser experience trumps algorithmic sophistication. DTLN isn't the most advanced noise suppression model available, but it strikes the perfect balance between quality, performance, and resource consumption for mobile deployment. Users don't care about model architecture - they care about crystal-clear audio in noisy environments.\nApps implementing on-device AI gain three competitive advantages: Privacy by Design (no sensitive data leaves the device), Offline Reliability (consistent experience regardless of network conditions), and Cost Structure Benefits (no cloud inference costs or operational expenses that scale with usage).\nNext Steps and Exploration\nThe techniques demonstrated here extend far beyond noise suppression. ONNX Runtime enables practical deployment of models for audio processing, computer vision, natural language tasks, and sensor fusion applications.\nThe complete implementation is available on GitHub: android-onnx-showcase. Use it as a foundation for your own AI-powered features.\nYour Android app deserves AI that enhances user experience without compromising performance, privacy, or reliability. ONNX Runtime makes this vision achievable today. The tools are ready, the performance is proven - time to build something amazing.\nFound this implementation useful? Star the GitHub repository and share your results. The mobile AI community grows stronger when we share practical knowledge.\nFollow me for more deep-dives into production-ready mobile AI implementations that your users will actually notice and appreciate. \\n",
          "dc:creator": "Sergey Drymchenko",
          "content": "Build real-time AI noise suppression for Android with ONNX Runtime. Complete tutorial with working code, performance tips, and 70% APK size reduction.",
          "contentSnippet": "Build real-time AI noise suppression for Android with ONNX Runtime. Complete tutorial with working code, performance tips, and 70% APK size reduction.",
          "guid": "https://hackernoon.com/mobile-ai-with-onnx-runtime-how-to-build-real-time-noise-suppression-that-works?source=rss",
          "categories": [
            "mobile-ai",
            "onnx-runtime",
            "on-device-ai",
            "mobile-ai-performance",
            "android-ai-sdk",
            "dtln-noise-reduction",
            "lightweight-ai-deployment",
            "onnx-runtime-android"
          ],
          "isoDate": "2025-08-03T16:03:09.000Z"
        }
      },
      {
        "json": {
          "creator": "Kaspar Tiri",
          "title": "The Real Reason Most Indie Games Flop (It Has Nothing To Do With Gameplay)",
          "link": "https://hackernoon.com/the-real-reason-most-indie-games-flop-it-has-nothing-to-do-with-gameplay?source=rss",
          "pubDate": "Sun, 03 Aug 2025 15:50:07 GMT",
          "content:encoded": "<h3 id=\"highqualitygamesaregettinglost\"><strong>High-Quality Games Are Getting Lost</strong></h3>\n<p>In the past few years, the gaming industry has seen a tidal wave of investment. Tens of billions of dollars have flowed into studios and publishers—more than ten times the historical average. The result is exactly what you’d expect: <strong>an explosion of high-quality content.</strong></p>\n<p>From 2019 to 2023, the number of games released on Steam nearly doubled, reaching over <strong><a href=\"https://steamdb.info/stats/releases/\">14,500 new games</a></strong>&nbsp;per year. Meanwhile, the App Store and Google Play are flooded with over a thousand apps published every day, offering players more choice than ever. Those distribution channels have become saturated.</p>\n<p>Despite the surge in funding and quality, most games are quietly slipping through the cracks. I meet founders all the time whose launch strategy is no deeper than: <em>“We’re making a great game and putting it up on Steam Early Access.”</em>That’s not a go-to-market strategy—that’s wishful thinking. \\n </p>\n<h3 id=\"weveseenthisstorybefore\">We’ve Seen This Story Before</h3>\n<p>In the early 2000s and throughout the 2010s, Hollywood studios kept doubling down on blockbuster content—fund content, release in theaters, repeat. The assumption was that the better the content, the better the outcome. Then <a href=\"https://hackernoon.com/company/netflix\">Netflix</a> changed the game. They didn’t just create shows. They changed how audiences discovered and consumed content. It was a new distribution model: personalized, frictionless, on-demand access to content, delivered over the internet, bypassing movie theaters entirely. Today, nearly every major player from Disney to HBO follows that same model. Content still matters, but distribution is what changed the industry.</p>\n<p>The same happened in music. Record labels used to control everything through their artist rosters. But <a href=\"https://hackernoon.com/company/spotify\">Spotify</a>, <a href=\"https://hackernoon.com/company/youtube\">YouTube</a>, and later <a href=\"https://hackernoon.com/company/tiktok\">TikTok</a> shifted the power. They didn’t make music—they just made it easier to access and share. Today, artists break through because of those platforms. Labels that once owned the pipeline now find themselves negotiating with it.</p>\n<p>Gaming is following the same arc. Incredible content, saturated channels, and a growing realization that discovery—not quality—is the real bottleneck. \\n </p>\n<h3 id=\"distributionisthebottleneck\"><strong>Distribution Is the Bottleneck</strong></h3>\n<p>We’re not short on great games. We’re short on new ways to make people care.</p>\n<p>Steam saw more than 40 games launched a day in 2023. Mobile app stores are even more saturated, with over 1,000 apps published daily. Discovery hasn’t kept up with the flood of content. It’s been overwhelmed by it.</p>\n<p>Steam has added curators, tags, and algorithmic feeds, but most releases still sink within days. Mobile stores are worse—prime real estate is dominated by paid ads, and organic discovery is nearly nonexistent. There’s simply too much content, not enough visibility, and no efficient way to rise above the noise <strong>unless you pay your way to the front.</strong></p>\n<p>This saturation is not just a discovery problem—it’s an economic one.</p>\n<p>Apple’s ATT rollout in 2021 disrupted mobile user acquisition overnight. <strong><a href=\"https://www.konvoy.vc/newsletters/mobile-gaming-post-idfa-deprecation\">Over 80%</a></strong> of iPhone users became invisible to targeted ads, breaking the model that many mobile studios relied on to find and convert high-value players. CPI costs jumped <strong><a href=\"https://www.adexchanger.com/mobile/ua-for-game-developers-is-an-entirely-different-animal-in-the-post-att-era/\">nearly 90%</a></strong>. ROAS dropped. What once worked no longer does.</p>\n<p>At the same time, most games don’t make money. But it’s not always because the games are bad—it’s because they’re invisible. On Steam, <strong><a href=\"https://gameworldobserver.com/2023/10/06/steam-stats-41k-games-last-3-years-half-made-500-or-less\">67% of games</a></strong> have earned less than $5,000 in lifetime revenue—and more than half never crossed $1,000. The average player sticks to four games a year. On mobile, the top 1% of games account for over 90% of downloads. Nearly 60% of apps on the App Store <strong>don’t even have a single review.</strong></p>\n<p>There’s no middle class. Big-budget games and breakout hits get all the attention. Everyone else fights for scraps. The end result is the “rich get richer.”</p>\n<p>Indies can’t afford to brute-force their way into visibility. They can’t outspend or outmarket incumbents. And yet most studios still rely on the same tired playbook: launch on Steam, pay the platform tax, hope the algorithm works. That’s not a strategy. It’s a gamble (tho, once in a blue moon, the algorithm favors an indie and it breaks out).</p>\n<p>Distribution is not a side task—it’s the real product challenge. And it’s the one thing this industry hasn’t meaningfully rethought.</p>\n<p>\\</p>\n<h3 id=\"theshifthasalreadystarted\">The Shift Has Already Started</h3>\n<p>Some companies aren’t waiting for better distribution. They’re building it.</p>\n<p>Epic didn’t just launch a hit game—they turned Fortnite into a platform. With UEFN (Unreal Editor for Fortnite), developers can now build games inside Fortnite using AAA tools, publish instantly, and tap into a built-in audience of millions. Discovery and monetization are integrated. The friction is gone.</p>\n<p>Roblox took it even further. It’s a closed-loop system where content and distribution live in the same place. Creators build games, users discover them, and both sides benefit. What makes Roblox especially interesting right now is this: <strong>distribution is ahead of content</strong>. The platform has reach. It just doesn’t have enough standout experiences. For developers, that’s an opportunity to succeed not by out-marketing the competition, but simply by building something better.</p>\n<p>Other players are entering the space from the edges. YouTube is embedding games directly into its platform. Discord lets users play inside servers. Netflix now offers games alongside its shows. Even Telegram supports native games through mini-apps. All of these are experiments in rethinking where and how games are discovered.</p>\n<p>And then there’s the web.</p>\n<p>The open web is becoming viable again—not just for casual games, but for real, session-based experiences. There’s no platform tax. No gatekeepers. No approval queues. A single build can reach anyone with a browser. For developers, that’s freedom. For players, it’s one click away.</p>\n<p>We’re starting to see early signs of this shift. <strong><a href=\"https://www.reddit.com/r/IndieGaming/comments/124znci/our_first_gameplay_reveal_trailer_for_bapbap_a/\">BAPBAP</a></strong>&nbsp;built an early fanbase in 2023 through a web version before launching on Steam, fueling thousands of installs on day one. <strong><a href=\"https://en.wikipedia.org/wiki/GDEV?utm_source=chatgpt.com\">Hero Wars</a></strong>&nbsp;took the same path years earlier—starting on the web, then expanding to mobile, where it surpassed <a href=\"https://www.pocketgamer.biz/hero-wars-alliance-celebrates-15-billion-in-revenue/?utm_source=chatgpt.com\">150 million installs and $1.5 billion in revenue.</a></p>\n<p>But most developers are still funneling their games into the same overcrowded storefronts—fighting over the same algorithms, the same paid installs, and the same limited real estate. It’s time to shift that energy. Instead of competing in the same narrow lanes, the opportunity is to explore new ones. Go where users already are. Build for the platforms that actually enable discovery. Let distribution shape your strategy—not follow it.</p>\n<p>The future won’t be defined by who builds the best-looking game. It will be defined by who rethinks the path to finding it.</p>",
          "content:encodedSnippet": "High-Quality Games Are Getting Lost\nIn the past few years, the gaming industry has seen a tidal wave of investment. Tens of billions of dollars have flowed into studios and publishers—more than ten times the historical average. The result is exactly what you’d expect: an explosion of high-quality content.\nFrom 2019 to 2023, the number of games released on Steam nearly doubled, reaching over 14,500 new games per year. Meanwhile, the App Store and Google Play are flooded with over a thousand apps published every day, offering players more choice than ever. Those distribution channels have become saturated.\nDespite the surge in funding and quality, most games are quietly slipping through the cracks. I meet founders all the time whose launch strategy is no deeper than: “We’re making a great game and putting it up on Steam Early Access.”That’s not a go-to-market strategy—that’s wishful thinking. \\n \nWe’ve Seen This Story Before\nIn the early 2000s and throughout the 2010s, Hollywood studios kept doubling down on blockbuster content—fund content, release in theaters, repeat. The assumption was that the better the content, the better the outcome. Then Netflix changed the game. They didn’t just create shows. They changed how audiences discovered and consumed content. It was a new distribution model: personalized, frictionless, on-demand access to content, delivered over the internet, bypassing movie theaters entirely. Today, nearly every major player from Disney to HBO follows that same model. Content still matters, but distribution is what changed the industry.\nThe same happened in music. Record labels used to control everything through their artist rosters. But Spotify, YouTube, and later TikTok shifted the power. They didn’t make music—they just made it easier to access and share. Today, artists break through because of those platforms. Labels that once owned the pipeline now find themselves negotiating with it.\nGaming is following the same arc. Incredible content, saturated channels, and a growing realization that discovery—not quality—is the real bottleneck. \\n \nDistribution Is the Bottleneck\nWe’re not short on great games. We’re short on new ways to make people care.\nSteam saw more than 40 games launched a day in 2023. Mobile app stores are even more saturated, with over 1,000 apps published daily. Discovery hasn’t kept up with the flood of content. It’s been overwhelmed by it.\nSteam has added curators, tags, and algorithmic feeds, but most releases still sink within days. Mobile stores are worse—prime real estate is dominated by paid ads, and organic discovery is nearly nonexistent. There’s simply too much content, not enough visibility, and no efficient way to rise above the noise unless you pay your way to the front.\nThis saturation is not just a discovery problem—it’s an economic one.\nApple’s ATT rollout in 2021 disrupted mobile user acquisition overnight. Over 80% of iPhone users became invisible to targeted ads, breaking the model that many mobile studios relied on to find and convert high-value players. CPI costs jumped nearly 90%. ROAS dropped. What once worked no longer does.\nAt the same time, most games don’t make money. But it’s not always because the games are bad—it’s because they’re invisible. On Steam, 67% of games have earned less than $5,000 in lifetime revenue—and more than half never crossed $1,000. The average player sticks to four games a year. On mobile, the top 1% of games account for over 90% of downloads. Nearly 60% of apps on the App Store don’t even have a single review.\nThere’s no middle class. Big-budget games and breakout hits get all the attention. Everyone else fights for scraps. The end result is the “rich get richer.”\nIndies can’t afford to brute-force their way into visibility. They can’t outspend or outmarket incumbents. And yet most studios still rely on the same tired playbook: launch on Steam, pay the platform tax, hope the algorithm works. That’s not a strategy. It’s a gamble (tho, once in a blue moon, the algorithm favors an indie and it breaks out).\nDistribution is not a side task—it’s the real product challenge. And it’s the one thing this industry hasn’t meaningfully rethought.\n\\\nThe Shift Has Already Started\nSome companies aren’t waiting for better distribution. They’re building it.\nEpic didn’t just launch a hit game—they turned Fortnite into a platform. With UEFN (Unreal Editor for Fortnite), developers can now build games inside Fortnite using AAA tools, publish instantly, and tap into a built-in audience of millions. Discovery and monetization are integrated. The friction is gone.\nRoblox took it even further. It’s a closed-loop system where content and distribution live in the same place. Creators build games, users discover them, and both sides benefit. What makes Roblox especially interesting right now is this: distribution is ahead of content. The platform has reach. It just doesn’t have enough standout experiences. For developers, that’s an opportunity to succeed not by out-marketing the competition, but simply by building something better.\nOther players are entering the space from the edges. YouTube is embedding games directly into its platform. Discord lets users play inside servers. Netflix now offers games alongside its shows. Even Telegram supports native games through mini-apps. All of these are experiments in rethinking where and how games are discovered.\nAnd then there’s the web.\nThe open web is becoming viable again—not just for casual games, but for real, session-based experiences. There’s no platform tax. No gatekeepers. No approval queues. A single build can reach anyone with a browser. For developers, that’s freedom. For players, it’s one click away.\nWe’re starting to see early signs of this shift. BAPBAP built an early fanbase in 2023 through a web version before launching on Steam, fueling thousands of installs on day one. Hero Wars took the same path years earlier—starting on the web, then expanding to mobile, where it surpassed 150 million installs and $1.5 billion in revenue.\nBut most developers are still funneling their games into the same overcrowded storefronts—fighting over the same algorithms, the same paid installs, and the same limited real estate. It’s time to shift that energy. Instead of competing in the same narrow lanes, the opportunity is to explore new ones. Go where users already are. Build for the platforms that actually enable discovery. Let distribution shape your strategy—not follow it.\nThe future won’t be defined by who builds the best-looking game. It will be defined by who rethinks the path to finding it.",
          "dc:creator": "Kaspar Tiri",
          "content": "Despite a boom in high-quality game development, most titles go unnoticed due to oversaturated platforms and outdated launch strategies. This article draws parallels with film and music to highlight how discovery—not content—is the industry’s true bottleneck. It advocates for new distribution models, from Fortnite’s UEFN and Roblox to embedded platforms like YouTube and Te",
          "contentSnippet": "Despite a boom in high-quality game development, most titles go unnoticed due to oversaturated platforms and outdated launch strategies. This article draws parallels with film and music to highlight how discovery—not content—is the industry’s true bottleneck. It advocates for new distribution models, from Fortnite’s UEFN and Roblox to embedded platforms like YouTube and Te",
          "guid": "https://hackernoon.com/the-real-reason-most-indie-games-flop-it-has-nothing-to-do-with-gameplay?source=rss",
          "categories": [
            "gaming",
            "game-discovery",
            "indie-game-marketing",
            "mobile-game-visibility",
            "game-development",
            "game-distribution-strategy",
            "app-store-visibility-hacks",
            "game-launch-strategy-2025"
          ],
          "isoDate": "2025-08-03T15:50:07.000Z"
        }
      },
      {
        "json": {
          "creator": "Arun Goyal",
          "title": "10 Ways AI Is Shaping the Future of Mobile App Development",
          "link": "https://hackernoon.com/10-ways-ai-is-shaping-the-future-of-mobile-app-development?source=rss",
          "pubDate": "Sun, 03 Aug 2025 15:29:15 GMT",
          "content:encoded": "<p>Artificial Intelligence (AI) in mobile apps was synonymous with chatbots for an extended period. Ask a question and get an answer to the extent of that on many users. This perception would have been long outdated by 2025. Today, AI is not a mere feature; it is fast becoming the invisible force that shapes how an app is built, how it unfolds upon its release, and the way it interacts with users at a very intimate level.&nbsp;</p>\n<p>Walking this path, mobile app development is getting changed, and AI is leading it. Even though conversational AI still holds important roles, developers and businesses have begun utilizing machine learning, predictive analytics, computer vision, natural language processing, and generative AI to their fullest capacity to produce intelligent and adaptive experiences, many of which latter thought to be from the far future.</p>\n<p>What does this mean for the current mobile app development scenario? Transitioning from static apps to those learning, adapting, and anticipating is the forecasted step. Let's further know how well AI is reshaping mobile app development services way beyond the virtual assistant zone.</p>\n<h2 id=\"top10waysaiistransformingmobileappdevelopmentin2025\"><strong>Top 10 Ways AI Is Transforming Mobile App Development in 2025</strong></h2>\n<p>AI is driving a massive shift in mobile app development changing how apps interact, adapt, and perform. From personalization to predictive design, here are the top ten ways AI is revolutionizing the mobile experience:</p>\n<h3 id=\"personalizedexperiencesatscale\"><strong>Personalized Experiences at Scale</strong></h3>\n<p>Some of the most visible changes in the AI field are the enhancement of user-oriented experiences. Earlier, the apps had the very same layout, content, and function for all users. Now, AI helps apps observe user behaviour, learn from these observations, and adapt their content and interface accordingly. Behind the scenes, AI goes on to analyze it all to provide every user with a very special session just for them.</p>\n<p>This level of personalization has become a core expectation, prompting every mobile app development company to incorporate such features. Whether it's a cross platform mobile app development project or a native solution, the need to create contextual user experiences is paramount.</p>\n<h3 id=\"intelligentsearchanddiscovery\"><strong>Intelligent Search and Discovery</strong></h3>\n<p>Another major shift has been the interaction facet of search within apps. Conventional search functions depended significantly on exact keywords, often discouraging users from locating what they wanted. AI radically enhanced this experience to make search more intelligent and conversational. Natural Language Processing (NLP) enables users with the ability to ask questions or make search queries using off-the-cuff language, and AI looks at the underlying intention of the words.</p>\n<p>In modern applications, the integration of an intelligent layer is standard practice among companies specializing in custom mobile app development services.</p>\n<h3 id=\"predictivecapabilitiesandanticipatorydesign\"><strong>Predictive Capabilities and Anticipatory Design</strong></h3>\n<p>One compelling ability of AI is prediction. AI can analyze patterns in user behavior and come up with what a user may want to see next, and offer it before the user asks for it. The anticipatory design, as people today commonly know it, makes the app truly clever by putting up suggestions, reminders, or shortcuts that really resonate with the user's habits.</p>\n<h3 id=\"aiindesignanddevelopmentnbsp\"><strong>AI in Design and Development</strong>&nbsp;</h3>\n<p>AI is influencing not only how apps work but also how they are created. Mobile app development, which embodies long design cycles and manual testing, is now aided and accelerated by AI in each step. There are now AI-aided tools that help designers create wireframes or mockups based on simple sketches or text prompts.</p>\n<p>Hence, repetitive tasks will require very little time and thus allow teams to invest more in creativity and strategy. This transformation is reshaping enterprise mobile app development, helping larger organizations deploy sophisticated solutions faster and with higher quality assurance.</p>\n<h3 id=\"smarterapptestingandmaintenance\"><strong>Smarter App Testing and Maintenance</strong></h3>\n<p>AI finds another key use case in quality assurance. Traditional methods are unable to keep pace with short deployment cycles and constant upgrades. AI-based test frameworks simulate user behavior or find edge cases and even predict where the bugs are most likely to appear based on prior data. Besides that, AI is doing wonders post-launch by monitoring app performance. It records crashes, wanders into behavioral analysis, detects anomalies, and blows the whistle when it stumbles upon deviations from the normal.</p>\n<h3 id=\"multimodalinteractionwithai\"><strong>Multimodal Interaction with AI</strong></h3>\n<p>Furthermore, this has been extended and pushed towards sensory interaction, particularly in voice, image, and gesture recognition. Making apps more inclusive and user-friendly, especially for those who use experimental hands-free or visual inputs. AI in voice recognition enables users to interact with apps to initiate commands and have them respond through speech, giving ways of interface new fluid and human feeling.&nbsp;</p>\n<p>Computer vision aids in the identification of faces by the app, scanning QR codes, or physically identifying objects via the smartphone camera. Today, users don't just want to know what is meant by mobile application development; they demand smarter, intuitive apps that understand them deeply.</p>\n<h3 id=\"securityandfrauddetection\"><strong>Security and Fraud Detection</strong></h3>\n<p>Security is another area where AI technologies have taken a giant leap. Older computer security models deal with threats of the past, whereas the cyber-threats of today are an altogether different animal. Using AI-based models, these computers now analyze millions of interactions occurring among interconnected devices to detect suspicious activity, irregular login patterns, or even data theft.&nbsp;</p>\n<p>Such apps now use AI to watch transactions for fraudulent behavior before any harm is done to users. The biometric security system, whether it be facial recognition or fingerprint scanning, is an AI-enabled gateway to an easy and secure authentication method.</p>\n<h3 id=\"riseofgenerativeaiinmobileapps\"><strong>Rise of Generative AI in Mobile Apps</strong></h3>\n<p>In the last year, generative AI has emerged as one of the most thrilling areas in the app development world. Tools such as GPT-4 and DALL·E of OpenAI have opened a new avenue for users to generate text, images, music, and videos, with a mere handful of commands. Mobile applications are using this technology to create generative spaces for creators to work in.&nbsp;</p>\n<p>From AI photo editing, avatar generation, to story ideation, to productivity apps, users have become accustomed to AI either assisting or potentially co-creating content with them.</p>\n<h3 id=\"fromreactivetoadaptiveapps\"><strong>From Reactive to Adaptive Apps</strong></h3>\n<p>One of the most revolutionary and disruptive changes is from reactive to adaptive app experiences. Traditional apps respond to user input. This is where AI-enabled apps excel they can learn behaviors from their human users, changing the interface, suggesting actions, and even dynamically reprogramming their workflows. For instance, depending on whether a user's mood is detected from voice tone or facial expression, a mental wellness app may choose to deliver a particular set of suggestive activities.</p>\n<h3 id=\"accessibilityandinclusivitythroughai\"><strong>Accessibility and Inclusivity Through AI</strong></h3>\n<p>AI has emerged as an enabler to infuse accessibility into mobile app creation, thereby catering to a variety of user needs. These days, apps offer a wide range of capabilities, including real-time conversion between text and speech, and vice versa. AI translations and UI variations that meet the needs of visually impaired users. Thus, by breaking down the barriers of language, cognition, and physicality it necessitates that technology assist everyone, irrespective of ability or creed.</p>\n<h2 id=\"thechallengesahead\"><strong>The Challenges Ahead</strong></h2>\n<p>Integrating AI into mobile app development services is challenging when it comes to ensuring data privacy, model accuracy, algorithmic bias, and development budgets. Trust is key from the user's perspective. They have to be transparent about the collection and use of data, conform to global privacy laws, continuously monitor, and update the model to avoid unintended consequences.&nbsp;</p>\n<p>Despite all these problems, the benefits of AI are significant enough to overpower any challenge. If applied properly, AI can help developers build smarter, faster, and safer mobile apps.</p>\n<h2 id=\"closingthoughtsfuturereadywithai\"><strong>Closing Thoughts: Future-Ready with AI</strong></h2>\n<p>Mobile app development would become intelligent even in the manner of their behavior, way of their imagination, and way of their construction. It means we are during those moments when AI chips on the device will make processing real-time but safer and efficient; emotion recognition and zero-UI interfaces will set new limits; and then AI will be analyzed as a collaborator instead of a tool.&nbsp;</p>\n<p>For developers, the latest technologies must be mastered with data-first thinking. Businesses must do the innovation, invest in more innovative experiences, and keep the user as a priority.</p>\n<p>Whether it’s for startups or enterprises, those looking for the best mobile app development company need to focus on long-term value, where AI meets user-centric design. As AI becomes the backbone of digital evolution, the future of cross platform mobile app development and beyond is undeniably innovative, intuitive, and transformational.</p>\n<p>\\n </p>",
          "content:encodedSnippet": "Artificial Intelligence (AI) in mobile apps was synonymous with chatbots for an extended period. Ask a question and get an answer to the extent of that on many users. This perception would have been long outdated by 2025. Today, AI is not a mere feature; it is fast becoming the invisible force that shapes how an app is built, how it unfolds upon its release, and the way it interacts with users at a very intimate level. \nWalking this path, mobile app development is getting changed, and AI is leading it. Even though conversational AI still holds important roles, developers and businesses have begun utilizing machine learning, predictive analytics, computer vision, natural language processing, and generative AI to their fullest capacity to produce intelligent and adaptive experiences, many of which latter thought to be from the far future.\nWhat does this mean for the current mobile app development scenario? Transitioning from static apps to those learning, adapting, and anticipating is the forecasted step. Let's further know how well AI is reshaping mobile app development services way beyond the virtual assistant zone.\nTop 10 Ways AI Is Transforming Mobile App Development in 2025\nAI is driving a massive shift in mobile app development changing how apps interact, adapt, and perform. From personalization to predictive design, here are the top ten ways AI is revolutionizing the mobile experience:\nPersonalized Experiences at Scale\nSome of the most visible changes in the AI field are the enhancement of user-oriented experiences. Earlier, the apps had the very same layout, content, and function for all users. Now, AI helps apps observe user behaviour, learn from these observations, and adapt their content and interface accordingly. Behind the scenes, AI goes on to analyze it all to provide every user with a very special session just for them.\nThis level of personalization has become a core expectation, prompting every mobile app development company to incorporate such features. Whether it's a cross platform mobile app development project or a native solution, the need to create contextual user experiences is paramount.\nIntelligent Search and Discovery\nAnother major shift has been the interaction facet of search within apps. Conventional search functions depended significantly on exact keywords, often discouraging users from locating what they wanted. AI radically enhanced this experience to make search more intelligent and conversational. Natural Language Processing (NLP) enables users with the ability to ask questions or make search queries using off-the-cuff language, and AI looks at the underlying intention of the words.\nIn modern applications, the integration of an intelligent layer is standard practice among companies specializing in custom mobile app development services.\nPredictive Capabilities and Anticipatory Design\nOne compelling ability of AI is prediction. AI can analyze patterns in user behavior and come up with what a user may want to see next, and offer it before the user asks for it. The anticipatory design, as people today commonly know it, makes the app truly clever by putting up suggestions, reminders, or shortcuts that really resonate with the user's habits.\nAI in Design and Development \nAI is influencing not only how apps work but also how they are created. Mobile app development, which embodies long design cycles and manual testing, is now aided and accelerated by AI in each step. There are now AI-aided tools that help designers create wireframes or mockups based on simple sketches or text prompts.\nHence, repetitive tasks will require very little time and thus allow teams to invest more in creativity and strategy. This transformation is reshaping enterprise mobile app development, helping larger organizations deploy sophisticated solutions faster and with higher quality assurance.\nSmarter App Testing and Maintenance\nAI finds another key use case in quality assurance. Traditional methods are unable to keep pace with short deployment cycles and constant upgrades. AI-based test frameworks simulate user behavior or find edge cases and even predict where the bugs are most likely to appear based on prior data. Besides that, AI is doing wonders post-launch by monitoring app performance. It records crashes, wanders into behavioral analysis, detects anomalies, and blows the whistle when it stumbles upon deviations from the normal.\nMultimodal Interaction with AI\nFurthermore, this has been extended and pushed towards sensory interaction, particularly in voice, image, and gesture recognition. Making apps more inclusive and user-friendly, especially for those who use experimental hands-free or visual inputs. AI in voice recognition enables users to interact with apps to initiate commands and have them respond through speech, giving ways of interface new fluid and human feeling. \nComputer vision aids in the identification of faces by the app, scanning QR codes, or physically identifying objects via the smartphone camera. Today, users don't just want to know what is meant by mobile application development; they demand smarter, intuitive apps that understand them deeply.\nSecurity and Fraud Detection\nSecurity is another area where AI technologies have taken a giant leap. Older computer security models deal with threats of the past, whereas the cyber-threats of today are an altogether different animal. Using AI-based models, these computers now analyze millions of interactions occurring among interconnected devices to detect suspicious activity, irregular login patterns, or even data theft. \nSuch apps now use AI to watch transactions for fraudulent behavior before any harm is done to users. The biometric security system, whether it be facial recognition or fingerprint scanning, is an AI-enabled gateway to an easy and secure authentication method.\nRise of Generative AI in Mobile Apps\nIn the last year, generative AI has emerged as one of the most thrilling areas in the app development world. Tools such as GPT-4 and DALL·E of OpenAI have opened a new avenue for users to generate text, images, music, and videos, with a mere handful of commands. Mobile applications are using this technology to create generative spaces for creators to work in. \nFrom AI photo editing, avatar generation, to story ideation, to productivity apps, users have become accustomed to AI either assisting or potentially co-creating content with them.\nFrom Reactive to Adaptive Apps\nOne of the most revolutionary and disruptive changes is from reactive to adaptive app experiences. Traditional apps respond to user input. This is where AI-enabled apps excel they can learn behaviors from their human users, changing the interface, suggesting actions, and even dynamically reprogramming their workflows. For instance, depending on whether a user's mood is detected from voice tone or facial expression, a mental wellness app may choose to deliver a particular set of suggestive activities.\nAccessibility and Inclusivity Through AI\nAI has emerged as an enabler to infuse accessibility into mobile app creation, thereby catering to a variety of user needs. These days, apps offer a wide range of capabilities, including real-time conversion between text and speech, and vice versa. AI translations and UI variations that meet the needs of visually impaired users. Thus, by breaking down the barriers of language, cognition, and physicality it necessitates that technology assist everyone, irrespective of ability or creed.\nThe Challenges Ahead\nIntegrating AI into mobile app development services is challenging when it comes to ensuring data privacy, model accuracy, algorithmic bias, and development budgets. Trust is key from the user's perspective. They have to be transparent about the collection and use of data, conform to global privacy laws, continuously monitor, and update the model to avoid unintended consequences. \nDespite all these problems, the benefits of AI are significant enough to overpower any challenge. If applied properly, AI can help developers build smarter, faster, and safer mobile apps.\nClosing Thoughts: Future-Ready with AI\nMobile app development would become intelligent even in the manner of their behavior, way of their imagination, and way of their construction. It means we are during those moments when AI chips on the device will make processing real-time but safer and efficient; emotion recognition and zero-UI interfaces will set new limits; and then AI will be analyzed as a collaborator instead of a tool. \nFor developers, the latest technologies must be mastered with data-first thinking. Businesses must do the innovation, invest in more innovative experiences, and keep the user as a priority.\nWhether it’s for startups or enterprises, those looking for the best mobile app development company need to focus on long-term value, where AI meets user-centric design. As AI becomes the backbone of digital evolution, the future of cross platform mobile app development and beyond is undeniably innovative, intuitive, and transformational.\n\\n",
          "dc:creator": "Arun Goyal",
          "content": "\nAI is no longer just a feature in mobile apps—it’s becoming the engine behind how they’re designed, built, and experienced. This article explores ten groundbreaking ways artificial intelligence is transforming mobile app development in 2025—from hyper-personalized UX and predictive design to generative tools, adaptive interfaces, enhanced security, and inclusive features. With NLP, computer vision, and machine learning at the core, modern apps are becoming smarter, safer, and more intuitive—marking a pivotal shift from reactive utilities to adaptive digital companions.",
          "contentSnippet": "AI is no longer just a feature in mobile apps—it’s becoming the engine behind how they’re designed, built, and experienced. This article explores ten groundbreaking ways artificial intelligence is transforming mobile app development in 2025—from hyper-personalized UX and predictive design to generative tools, adaptive interfaces, enhanced security, and inclusive features. With NLP, computer vision, and machine learning at the core, modern apps are becoming smarter, safer, and more intuitive—marking a pivotal shift from reactive utilities to adaptive digital companions.",
          "guid": "https://hackernoon.com/10-ways-ai-is-shaping-the-future-of-mobile-app-development?source=rss",
          "categories": [
            "ai-mobile-app-development",
            "mobile-app-development",
            "ai-trends",
            "predictive-mobile-ux",
            "generative-ai-apps",
            "cross-platform-ai-apps",
            "custom-app-development",
            "good-company"
          ],
          "isoDate": "2025-08-03T15:29:15.000Z"
        }
      },
      {
        "json": {
          "creator": "Pair Programming AI Agent",
          "title": "Solving Coding Puzzles: The Evolution of Programmer Assistance Tools",
          "link": "https://hackernoon.com/solving-coding-puzzles-the-evolution-of-programmer-assistance-tools?source=rss",
          "pubDate": "Sun, 03 Aug 2025 15:15:06 GMT",
          "content:encoded": "<h2 id=\"tableoflinks\">Table of Links</h2>\n<p><a href=\"https://hackernoon.com/preview/MlSqFDkgc8wyYNhcTQUS\">Abstract and 1 Introduction</a></p>\n<p><a href=\"https://hackernoon.com/preview/8dpQgkvMbLYJAljrV7Vf\">2. Prior conceptualisations of intelligent assistance for programmers</a> </p>\n<p><a href=\"https://hackernoon.com/preview/Fbh4JJB153JBpm3kLCxV\">3. A brief overview of large language models for code generation</a> </p>\n<p><a href=\"https://hackernoon.com/preview/HmlrCOxDGvgs92HVCJ2K\">4. Commercial programming tools that use large language models</a> </p>\n<p><a href=\"https://hackernoon.com/preview/LfBQwyQ4BSGJwpgYltOg\">5. Reliability, safety, and security implications of code-generating AI models</a> </p>\n<p><a href=\"https://hackernoon.com/preview/CygvKtzl4ehOH2JMjzSJ\">6. Usability and design studies of AI-assisted programming</a> </p>\n<p><a href=\"http://hackernoon.com/preview/avzRmaZuB6kTScIGgBXb\">7. Experience reports and 7.1. Writing effective prompts is hard</a></p>\n<p><a href=\"http://hackernoon.com/preview/trg3lvQVoL7t14dCFdHw\">7.2. The activity of programming shifts towards checking and unfamiliar debugging</a></p>\n<p><a href=\"https://hackernoon.com/preview/Y6BbJahplhYZlxdqdCFp\">7.3. These tools are useful for boilerplate and code reuse</a></p>\n<p>8. The inadequacy of existing metaphors for AI-assisted programming </p>\n<p><a href=\"https://hackernoon.com/preview/vWx560H10HWi8ZHXooSN\">8.1. AI assistance as search</a> </p>\n<p><a href=\"https://hackernoon.com/preview/7aqW8wQKjdANYySTv4HT\">8.2. AI assistance as compilation</a> </p>\n<p><a href=\"http://hackernoon.com/preview/dt4WL0IqtGFKwYXl8xcM\">8.3. AI assistance as pair programming</a> </p>\n<p><a href=\"https://hackernoon.com/preview/y6sPtr5BxC8m3FKl3sPe\">8.4. A distinct way of programming</a> </p>\n<p><a href=\"http://hackernoon.com/preview/cFluWTtWEw5cYM79in5t\">9. Issues with application to end-user programming</a> </p>\n<p><a href=\"http://hackernoon.com/preview/yXSCL6V4pdtdts6ABfM6\">9.1. Issue 1: Intent specification, problem decomposition and computational thinking</a></p>\n<p><a href=\"https://hackernoon.com/preview/E4BSkXJzfI4viO9ZlSiq\">9.2. Issue 2: Code correctness, quality and (over)confidence</a> </p>\n<p><a href=\"https://hackernoon.com/preview/bnqPT5z9RjUqofcdLHgu\">9.3. Issue 3: Code comprehension and maintenance</a> </p>\n<p><a href=\"http://hackernoon.com/preview/BakiKXXyiC7EliqZuaEi\">9.4. Issue 4: Consequences of automation in end-user programming</a> </p>\n<p><a href=\"http://hackernoon.com/preview/KUolRiHRR6l2EibKExUJ\">9.5. Issue 5: No code, and the dilemma of the direct answer</a> </p>\n<p><a href=\"http://hackernoon.com/preview/4zcamJIgNx2iZo9jpBY5\">10. Conclusion</a> </p>\n<p><a href=\"https://hackernoon.com/preview/tJyNpGmyfTQHlfAqjVVC\">A. Experience report sources</a> </p>\n<p><a href=\"https://hackernoon.com/preview/DfXa3jYCd5LYy3NDyv6c\">References</a></p>\n<h2 id=\"2priorconceptualisationsofintelligentassistanceforprogrammers\">2. Prior conceptualisations of intelligent assistance for programmers</h2>\n<p>What counts as ‘intelligent assistance’ can be the subject of some debate. Do we select only features that are driven by technologies that the artificial intelligence research community (itself undefined) would recognise as artificial intelligence? Do we include those that use expert-coded heuristics? Systems that make inferences a human might disagree with, or those with the potential for error? Mixed-initiative systems (Horvitz, 1999)? Or those that make the user feel intelligent, assisted, or empowered? While this debate is beyond the scope of this paper, we feel that to properly contextualise the qualitative difference made by large language models, a broad and inclusive approach to the term ‘intelligence’ is required.</p>\n<p>\\\nEnd-user programming has long been home to inferential, or intelligent assistance. The strategy of direct manipulation (Shneiderman &amp; Norwood, 1993) is highly successful for certain types of limited, albeit useful, computational tasks, where the interface being used (“what you see”, e.g., a text editor or an image editor) to develop an information artefact can represent closely the artefact being developed (“what you get”, e.g., a text document or an image). However, this strategy cannot be straightforwardly applied to programs. Programs notate multiple possible paths of execution simultaneously, and they define “behaviour to occur at some future time” (Blackwell, 2002b). Rendering multiple futures in the present is a core problem of live programming research (Tanimoto, 2013), which aims to externalise programs as they are edited (Basman et al., 2016).</p>\n<p>\\\nThe need to bridge the abstraction gap between direct manipulation and multiple paths of execution led to the invention of programming by demonstration (PBD) (Kurlander et al., 1993; Lieberman, 2001; Myers, 1992). A form of inferential assistance, PBD allows end-user programmers to make concrete demonstrations of desired behaviour that are generalised into executable programs. Despite their promise, PBD systems have not achieved widespread success as end-user programming tools, although their idea survives in vestigial form as various “macro recording” tools, and the approach is seeing a resurgence with the growing commercialisation of “robotic process automation”.</p>\n<p>\\\nProgramming language design has long been concerned with shifting the burden of intelligence between programmer, program, compiler, and user. Programming language compilers, in translating between high-level languages and machine code, are a kind of intelligent assistance for programmers. The declarative language Prolog aspired to bring a kind of intelligence, where the programmer would only be responsible for specifying (“declaring”) what to compute, but not how to compute it; that responsibility was left to the interpreter. At the same time, the language was designed with intelligent applications in mind. Indeed, it found widespread use within artificial intelligence and computational linguistics research (Colmerauer &amp; Roussel, 1996; Rouchy, 2006).</p>\n<p>\\\nFormal verification tools use a specification language, such as Hoare triples (Hoare, 1969), and writing such specifications can be considered programming at a ‘higher’ level of abstraction. Program synthesis, in particular synthesis through refinement, aims at intelligently transforming these rules into executable and correct code. However, the term “program synthesis” is also used more broadly, and programs can be synthesised from other sources than higher-level specifications. Concretely, program synthesis by example, or simply programming by example (PBE), facilitates the generation of executable code from input-output examples. An example of successfully commercialised PBE is Excel’s Flash Fill (Gulwani, 2011), which synthesises string transformations in spreadsheets from a small number of examples.</p>\n<p>\\\nThe Cognitive Dimensions framework (T. R. Green, 1989; T. Green &amp; Blackwell, 1998) identifies three categories of programming activity: authoring, transcription, and modification. Modern programmer assistance encompasses each of these. For example, program synthesis tools transform the direct authoring of code into the (arguably easier) authoring of examples. Intelligent code completions (Marasoiu et al., 2015) support the direct authoring of code. Intelligent support for reuse, such as smart code copy/paste (Allamanis &amp; Brockschmidt, 2017) support transcription, and refactoring tools (Hermans et al., 2015) support modification. Researchers have investigated inferential support for navigating source code (Henley &amp; Fleming, 2014), debugging (J. Williams et al., 2020), and selectively undoing code changes (Yoon &amp; Myers, 2015). Additionally, intelligent tools can also support learning (Cao et al., 2015).</p>\n<p>\\\nAllamanis et al. (2018) review work at the intersection of machine learning, programming languages, and software engineering. They seek to adapt methods first developed for natural language, such as language models, to source code. The emergence of large bodies of open source code, sometimes called “big code”, enabled this research area. Language models are sensitive to lexical features like names, code formatting, and order of methods, while traditional tools like compilers or code verifiers are not. Through the “naturalness hypothesis”, which claims that “software is a form of human communication; software corpora have similar statistical properties to natural language corpora; the authors claim that these properties can be exploited to build better software engineering tools.” Some support for this hypothesis comes from research that used n-gram models to build a code completion engine for Java that outperformed Eclipse’s completion feature (Hindle et al., 2012, 2016). This approach can underpin recommender systems (such as code autocompletion), debuggers, code analysers (such as type checkers (Raychev et al., 2015)), and code synthesizers. We can expect the recent expansion in capability of language models, discussed next, to magnify the effectiveness of these applications.</p>\n<p>\\</p>\n<p>:::info\n<strong>Authors:</strong></p>\n<p>(1) Advait Sarkar, Microsoft Research, University of Cambridge (advait@microsoft.com);</p>\n<p>(2) Andrew D. Gordon, Microsoft Research, University of Edinburgh (adg@microsoft.com);</p>\n<p>(3) Carina Negreanu, Microsoft Research (cnegreanu@microsoft.com);</p>\n<p>(4) Christian Poelitz, Microsoft Research (cpoelitz@microsoft.com);</p>\n<p>(5) Sruti Srinivasa Ragavan, Microsoft Research (a-srutis@microsoft.com);</p>\n<p>(6) Ben Zorn, Microsoft Research (ben.zorn@microsoft.com).</p>\n<p>:::</p>\n<hr />\n<p>:::info\nThis paper is <strong><a href=\"https://arxiv.org/abs/2208.06213\">available on arxiv</a></strong> under CC BY-NC-ND 4.0 DEED license.</p>\n<p>:::</p>\n<p>\\</p>",
          "content:encodedSnippet": "Table of Links\nAbstract and 1 Introduction\n2. Prior conceptualisations of intelligent assistance for programmers \n3. A brief overview of large language models for code generation \n4. Commercial programming tools that use large language models \n5. Reliability, safety, and security implications of code-generating AI models \n6. Usability and design studies of AI-assisted programming \n7. Experience reports and 7.1. Writing effective prompts is hard\n7.2. The activity of programming shifts towards checking and unfamiliar debugging\n7.3. These tools are useful for boilerplate and code reuse\n8. The inadequacy of existing metaphors for AI-assisted programming \n8.1. AI assistance as search \n8.2. AI assistance as compilation \n8.3. AI assistance as pair programming \n8.4. A distinct way of programming \n9. Issues with application to end-user programming \n9.1. Issue 1: Intent specification, problem decomposition and computational thinking\n9.2. Issue 2: Code correctness, quality and (over)confidence \n9.3. Issue 3: Code comprehension and maintenance \n9.4. Issue 4: Consequences of automation in end-user programming \n9.5. Issue 5: No code, and the dilemma of the direct answer \n10. Conclusion \nA. Experience report sources \nReferences\n2. Prior conceptualisations of intelligent assistance for programmers\nWhat counts as ‘intelligent assistance’ can be the subject of some debate. Do we select only features that are driven by technologies that the artificial intelligence research community (itself undefined) would recognise as artificial intelligence? Do we include those that use expert-coded heuristics? Systems that make inferences a human might disagree with, or those with the potential for error? Mixed-initiative systems (Horvitz, 1999)? Or those that make the user feel intelligent, assisted, or empowered? While this debate is beyond the scope of this paper, we feel that to properly contextualise the qualitative difference made by large language models, a broad and inclusive approach to the term ‘intelligence’ is required.\n\\\nEnd-user programming has long been home to inferential, or intelligent assistance. The strategy of direct manipulation (Shneiderman & Norwood, 1993) is highly successful for certain types of limited, albeit useful, computational tasks, where the interface being used (“what you see”, e.g., a text editor or an image editor) to develop an information artefact can represent closely the artefact being developed (“what you get”, e.g., a text document or an image). However, this strategy cannot be straightforwardly applied to programs. Programs notate multiple possible paths of execution simultaneously, and they define “behaviour to occur at some future time” (Blackwell, 2002b). Rendering multiple futures in the present is a core problem of live programming research (Tanimoto, 2013), which aims to externalise programs as they are edited (Basman et al., 2016).\n\\\nThe need to bridge the abstraction gap between direct manipulation and multiple paths of execution led to the invention of programming by demonstration (PBD) (Kurlander et al., 1993; Lieberman, 2001; Myers, 1992). A form of inferential assistance, PBD allows end-user programmers to make concrete demonstrations of desired behaviour that are generalised into executable programs. Despite their promise, PBD systems have not achieved widespread success as end-user programming tools, although their idea survives in vestigial form as various “macro recording” tools, and the approach is seeing a resurgence with the growing commercialisation of “robotic process automation”.\n\\\nProgramming language design has long been concerned with shifting the burden of intelligence between programmer, program, compiler, and user. Programming language compilers, in translating between high-level languages and machine code, are a kind of intelligent assistance for programmers. The declarative language Prolog aspired to bring a kind of intelligence, where the programmer would only be responsible for specifying (“declaring”) what to compute, but not how to compute it; that responsibility was left to the interpreter. At the same time, the language was designed with intelligent applications in mind. Indeed, it found widespread use within artificial intelligence and computational linguistics research (Colmerauer & Roussel, 1996; Rouchy, 2006).\n\\\nFormal verification tools use a specification language, such as Hoare triples (Hoare, 1969), and writing such specifications can be considered programming at a ‘higher’ level of abstraction. Program synthesis, in particular synthesis through refinement, aims at intelligently transforming these rules into executable and correct code. However, the term “program synthesis” is also used more broadly, and programs can be synthesised from other sources than higher-level specifications. Concretely, program synthesis by example, or simply programming by example (PBE), facilitates the generation of executable code from input-output examples. An example of successfully commercialised PBE is Excel’s Flash Fill (Gulwani, 2011), which synthesises string transformations in spreadsheets from a small number of examples.\n\\\nThe Cognitive Dimensions framework (T. R. Green, 1989; T. Green & Blackwell, 1998) identifies three categories of programming activity: authoring, transcription, and modification. Modern programmer assistance encompasses each of these. For example, program synthesis tools transform the direct authoring of code into the (arguably easier) authoring of examples. Intelligent code completions (Marasoiu et al., 2015) support the direct authoring of code. Intelligent support for reuse, such as smart code copy/paste (Allamanis & Brockschmidt, 2017) support transcription, and refactoring tools (Hermans et al., 2015) support modification. Researchers have investigated inferential support for navigating source code (Henley & Fleming, 2014), debugging (J. Williams et al., 2020), and selectively undoing code changes (Yoon & Myers, 2015). Additionally, intelligent tools can also support learning (Cao et al., 2015).\n\\\nAllamanis et al. (2018) review work at the intersection of machine learning, programming languages, and software engineering. They seek to adapt methods first developed for natural language, such as language models, to source code. The emergence of large bodies of open source code, sometimes called “big code”, enabled this research area. Language models are sensitive to lexical features like names, code formatting, and order of methods, while traditional tools like compilers or code verifiers are not. Through the “naturalness hypothesis”, which claims that “software is a form of human communication; software corpora have similar statistical properties to natural language corpora; the authors claim that these properties can be exploited to build better software engineering tools.” Some support for this hypothesis comes from research that used n-gram models to build a code completion engine for Java that outperformed Eclipse’s completion feature (Hindle et al., 2012, 2016). This approach can underpin recommender systems (such as code autocompletion), debuggers, code analysers (such as type checkers (Raychev et al., 2015)), and code synthesizers. We can expect the recent expansion in capability of language models, discussed next, to magnify the effectiveness of these applications.\n\\\n:::info\nAuthors:\n(1) Advait Sarkar, Microsoft Research, University of Cambridge (advait@microsoft.com);\n(2) Andrew D. Gordon, Microsoft Research, University of Edinburgh (adg@microsoft.com);\n(3) Carina Negreanu, Microsoft Research (cnegreanu@microsoft.com);\n(4) Christian Poelitz, Microsoft Research (cpoelitz@microsoft.com);\n(5) Sruti Srinivasa Ragavan, Microsoft Research (a-srutis@microsoft.com);\n(6) Ben Zorn, Microsoft Research (ben.zorn@microsoft.com).\n:::\n:::info\nThis paper is available on arxiv under CC BY-NC-ND 4.0 DEED license.\n:::\n\\",
          "dc:creator": "Pair Programming AI Agent",
          "content": "From simplifying tasks with direct manipulation to generating code from examples, tracing how intelligent tools have always helped programmers tackle complex puzzles and bridge the gap between ideas and executable code.",
          "contentSnippet": "From simplifying tasks with direct manipulation to generating code from examples, tracing how intelligent tools have always helped programmers tackle complex puzzles and bridge the gap between ideas and executable code.",
          "guid": "https://hackernoon.com/solving-coding-puzzles-the-evolution-of-programmer-assistance-tools?source=rss",
          "categories": [
            "large-language-models",
            "ai-assisted-programming",
            "github-copilot",
            "code-generation",
            "programmer-assistance",
            "end-user-programming",
            "usability-studies",
            "inferential-assistance"
          ],
          "isoDate": "2025-08-03T15:15:06.000Z"
        }
      },
      {
        "json": {
          "creator": "Georgy Starikov",
          "title": "The Hidden Cost of Performance: How High-Load Specialization Warps Engineering Intuition",
          "link": "https://hackernoon.com/the-hidden-cost-of-performance-how-high-load-specialization-warps-engineering-intuition?source=rss",
          "pubDate": "Sun, 03 Aug 2025 15:09:29 GMT",
          "content:encoded": "<p>In high-performance software engineering, it’s easy to become so focused on optimization that you lose sight of broader business needs. This article shares lessons from my 20+ years building real-time, high-load systems across finance, telecom, and advertising. I explain how engineering intuition—shaped by edge-case systems—can become a liability when applied blindly. The goal: help engineering teams, managers, and even non-technical leaders understand when performance matters, and when it doesn’t.</p>\n<p>The world of high-load, low-latency systems is a crucible of engineering disciplines. It distills software down to its most brutal essence: cycles, bytes, wire time. It teaches you to think like a CPU, to treat L1 cache behavior as gospel, and to view allocations with suspicion. It sharpens your instincts for system limits and exposes any architectural indecision under fire at 200,000 RPS. Like all specializations, it also distorts your lens.</p>\n<p>In this piece, I want to reflect on the cost of repeatedly optimizing for edge cases. Specifically, how the deeply internalized mindset from building ultra-performant, latency-sensitive systems can become a limiting factor when engineers work in more elastic, less deterministic business domains.</p>\n<h3 id=\"whereintuitionbegins\"><strong>Where Intuition Begins</strong></h3>\n<p>I started my journey in real-time systems, where timing guarantees are absolute. Like brakes in a car, the system simply cannot be late. Over time, I transitioned into web systems where elasticity and geo-distribution took precedence over millisecond determinism. In banking, consistency and security overtook performance. Then, in adtech, I encountered the most complex compromise yet: soft real-time expectations (under 100ms), low cost per request, and architectural elasticity, all under high traffic conditions.</p>\n<p>This varied experience taught me that an engineer must think vertically, understanding the entire system from business goals to infrastructure. However, it also exposed the trap many fall into: carrying over instincts honed in one domain into another, without adapting them.</p>\n<h3 id=\"latencyasreflex\"><strong>Latency as Reflex</strong></h3>\n<p>In high-load systems with latency constraints, your thinking changes. You focus not on modularity or reusability, but on minimizing processing. The logic is data-centric: don’t transform the data. Shape your logic to fit the data. Don’t pass structures between microservices. Instead, keep them where they are and compute directly. Don’t copy—compute in place.</p>\n<p>These habits are powerful. But the engineer must also understand the variability of input data, the business flow that justifies it, and the degree of correctness required. And they must know when such reflexes start working against the business.</p>\n<h3 id=\"pathologicaloptimizationingeneralsystems\"><strong>Pathological Optimization in General Systems</strong></h3>\n<p>An engineer who grew up working on high-load systems often assumes the bottleneck is always latency. But most systems are not bound by that constraint. Over the years, I’ve seen engineers apply data-centric programming, sharded databases and even custom databases, to CRUD backends. The performance gain was marginal; the complexity cost was vast.</p>\n<p>One example: while working at MTS and AdNow, we optimized the DSP backend to hit 200k RPS. The temptation was to optimize everything. We learned to isolate the high-performance core and treat admin panels, user dashboards, and analytics with simpler tools like Postgres and standard libraries. Not every component needed to live at the edge.</p>\n<h3 id=\"whenexperiencebecomesbias\"><strong>When Experience Becomes Bias</strong></h3>\n<p>Engineers carry the weight of their successes. For example, I avoided sharding if it was possible to do the processing on a single server, albeit with a significantly expanded RAM volume (for example, up to 4TB), and this often gave excellent results both in the cost of maintenance and in development - it is much easier to write code when all the data is in your memory than to work with sharded data. In such cases, we scaled vertically, adding RAM.</p>\n<p>However, this same intuition can become counterproductive in systems where horizontal scale is natural and cheap. Intuition must be regularly retrained. A 10-core server may outperform a 40-core box unless NUMA topology and mutex contention are addressed. You must consider switches (Cut-Through vs. Store-and-Forward), storage behavior (95th percentile latency), and data access patterns.</p>\n<p>The mature engineer’s mindset is not \"What is the best possible system?\" but \"What does the business need, and how can we get there with minimum future pain?\"</p>\n<h3 id=\"debuggabilityvsefficiency\"><strong>Debuggability vs. Efficiency</strong></h3>\n<p>Another anti-pattern from high-performance thinking: sacrificing observability for CPU savings. In one system, we replaced JSON logging with binary formats to reduce overhead. It worked—3% CPU saved. But the trade-off? Incident response slowed, human debugging suffered, and onboarding became a challenge.</p>\n<p>In ultra-constrained systems like SCADA (which I worked on early in my career), this trade-off is acceptable. But in most cloud-native systems, human time trumps compute time. Engineers should always ask: “Who’s going to debug this at 3 a.m.?”</p>\n<h3 id=\"culturaldriftinengineeringteams\"><strong>Cultural Drift in Engineering Teams</strong></h3>\n<p>I’ve seen high-performance specialists bring over habits that don’t scale organizationally: rewriting libraries, resisting abstractions, and insisting on building from scratch. I’ve been guilty of it too, creating \"hot\" functions in x86-64 assembler and using directly the processor's SIMD commands (AVX-512), even when using the Go language. These systems work brilliantly, but only in the hands of their authors. By the way, assembler is very conveniently integrated into Go, but, as practice has shown, few people know it.</p>\n<p>Today, as a manager, I emphasize that business tasks must come first. If business requires creating a system with extreme performance characteristics, then we must remember that this will require a stellar team and vice versa, if a standard system is required, then it is not worth using solutions that are difficult to support and develop, but should focus on schemes and architecture that are understandable to the mass developer, which can be mastered by a mid-level developer in two weeks.</p>\n<p>I also caution against microservices sprawl. Teams eager to optimize development workflows may inadvertently turn a tight data-centric pipeline into a network of chatty, latency-laden services. Even Amazon Prime Video teams have returned from microservices to monoliths in such contexts.</p>\n<h3 id=\"unlearningthehabitofoptimization\"><strong>Unlearning the Habit of Optimization</strong></h3>\n<p>The hardest thing for performance-oriented engineers to learn is when not to optimize. When building the MTS platform, we had parts of the system that were hot paths and others that were barely used. Initially, the urge was to use the same tooling across all components. But it’s a trap. CRUD services don’t need to scale like your bidding engine. Choose the right tool, even if that means sacrificing uniformity.</p>\n<p>Similarly, early in my career, when developing code to perform a fast inverse Fourier transform, I wrote a highly optimized assembler code that outperformed GCC by 30%. But six months later, the processors changed, and my code optimized for prefetch pipelines began to perform worse than the compiler-generated one. That’s the real cost of low-level perfection: it rarely lasts. Performance tuning should be reserved for business-critical paths.</p>\n<h3 id=\"lifecyclecostofoptimization\"><strong>Lifecycle Cost of Optimization</strong></h3>\n<p>What often gets overlooked is the total lifecycle cost of early optimization. An efficient algorithm or exotic data layout may save compute time today, but if it slows down onboarding, complicates testability, or becomes a barrier to architectural evolution, then the system is effectively accruing technical debt disguised as technical brilliance. I’ve seen projects where an engineer’s initial low-level perfection became a tax the team paid for years—refactoring was too risky, and new hires avoided touching critical modules. Mature systems require performance that evolves with the business, not just code that’s clever in the moment. The question we should always ask is: “Can this optimization survive team growth and domain shifts over 3–5 years?”</p>\n<h3 id=\"learningtoletgo\"><strong>Learning to Let Go</strong></h3>\n<p>In our CTR/VTR predictor, we send updates in real time. But for the segment coverage calculator in the UI, we switched to batch processing. The latency of updating the data in the UI has increased, but the complexity of support and development has decreased significantly without any impact on the business goal.</p>\n<p>The wisdom is not in knowing how to optimize, but in knowing when the business doesn’t need it. Premature optimization is only “evil” when it’s misaligned with business maturity. If you're targeting 200k RPS on a core, yes—start sharp. But if it's 200k RPS on a cluster, and you can shard data processing (e.g. distribute requests across nodes), then act iteratively, start with inefficient but working code, and plan refactoring to achieve lower server load. And how to use the \"extra\" hardware freed up after optimization has never been a problem.</p>\n<h3 id=\"matureengineersunderstandtradeoffs\"><strong>Mature Engineers Understand Trade-offs</strong></h3>\n<p>The most balanced engineers I’ve worked with understand the entire vertical, from business requirements to infrastructure tuning. They know when to use Apache Ignite and when Postgres is enough. They make performance decisions only where bottlenecks align with business outcomes.</p>\n<p>Such engineers avoid optimization addiction. They favor maintainability. They are patient with temporary solutions and confident that the roadmap allows for future improvements. That confidence, along with technical range, is what I consider “technical maturity.”</p>\n<h3 id=\"leadingselforganizingteamswithoutoverengineering\"><strong>Leading Self-Organizing Teams Without Overengineering</strong></h3>\n<p>Left unchecked, high-performance teams often over-abstract. To prevent that, I encourage cross-functional ownership—engineers who think like analysts, testers, and product managers. I advocate for teams that talk openly, document and justify the architectural decisions (ADR), and include domain experts in the loop. You cannot succeed with brilliant engineers alone. You need people from the market.</p>\n<p>Also, I’ve seen over-specialization derail early-stage teams. For new systems, buy experienced teams or foundational platforms. Don’t reinvent everything. Starting from scratch without market-ready expertise often leads to failure, unless backed by large investments.</p>\n<h3 id=\"finalthoughts\"><strong>Final Thoughts</strong></h3>\n<p>I don’t regret specializing in high-load systems. It shaped how I think. But I’ve also seen how these instincts, left unchecked, can limit engineers in broader domains. We must relearn general software engineering just as athletes must relearn walking after years of sprinting.</p>\n<p>Your best skill can become your biggest bias. And your greatest strength, when balanced, is what makes you a truly versatile engineer.</p>\n<p>If you’re a product leader, founder, or manager: don’t ask your engineers to over-optimize from the start. Let them build clear, maintainable systems that can scale later if needed. High performance has its place—but business alignment always comes first. </p>",
          "content:encodedSnippet": "In high-performance software engineering, it’s easy to become so focused on optimization that you lose sight of broader business needs. This article shares lessons from my 20+ years building real-time, high-load systems across finance, telecom, and advertising. I explain how engineering intuition—shaped by edge-case systems—can become a liability when applied blindly. The goal: help engineering teams, managers, and even non-technical leaders understand when performance matters, and when it doesn’t.\nThe world of high-load, low-latency systems is a crucible of engineering disciplines. It distills software down to its most brutal essence: cycles, bytes, wire time. It teaches you to think like a CPU, to treat L1 cache behavior as gospel, and to view allocations with suspicion. It sharpens your instincts for system limits and exposes any architectural indecision under fire at 200,000 RPS. Like all specializations, it also distorts your lens.\nIn this piece, I want to reflect on the cost of repeatedly optimizing for edge cases. Specifically, how the deeply internalized mindset from building ultra-performant, latency-sensitive systems can become a limiting factor when engineers work in more elastic, less deterministic business domains.\nWhere Intuition Begins\nI started my journey in real-time systems, where timing guarantees are absolute. Like brakes in a car, the system simply cannot be late. Over time, I transitioned into web systems where elasticity and geo-distribution took precedence over millisecond determinism. In banking, consistency and security overtook performance. Then, in adtech, I encountered the most complex compromise yet: soft real-time expectations (under 100ms), low cost per request, and architectural elasticity, all under high traffic conditions.\nThis varied experience taught me that an engineer must think vertically, understanding the entire system from business goals to infrastructure. However, it also exposed the trap many fall into: carrying over instincts honed in one domain into another, without adapting them.\nLatency as Reflex\nIn high-load systems with latency constraints, your thinking changes. You focus not on modularity or reusability, but on minimizing processing. The logic is data-centric: don’t transform the data. Shape your logic to fit the data. Don’t pass structures between microservices. Instead, keep them where they are and compute directly. Don’t copy—compute in place.\nThese habits are powerful. But the engineer must also understand the variability of input data, the business flow that justifies it, and the degree of correctness required. And they must know when such reflexes start working against the business.\nPathological Optimization in General Systems\nAn engineer who grew up working on high-load systems often assumes the bottleneck is always latency. But most systems are not bound by that constraint. Over the years, I’ve seen engineers apply data-centric programming, sharded databases and even custom databases, to CRUD backends. The performance gain was marginal; the complexity cost was vast.\nOne example: while working at MTS and AdNow, we optimized the DSP backend to hit 200k RPS. The temptation was to optimize everything. We learned to isolate the high-performance core and treat admin panels, user dashboards, and analytics with simpler tools like Postgres and standard libraries. Not every component needed to live at the edge.\nWhen Experience Becomes Bias\nEngineers carry the weight of their successes. For example, I avoided sharding if it was possible to do the processing on a single server, albeit with a significantly expanded RAM volume (for example, up to 4TB), and this often gave excellent results both in the cost of maintenance and in development - it is much easier to write code when all the data is in your memory than to work with sharded data. In such cases, we scaled vertically, adding RAM.\nHowever, this same intuition can become counterproductive in systems where horizontal scale is natural and cheap. Intuition must be regularly retrained. A 10-core server may outperform a 40-core box unless NUMA topology and mutex contention are addressed. You must consider switches (Cut-Through vs. Store-and-Forward), storage behavior (95th percentile latency), and data access patterns.\nThe mature engineer’s mindset is not \"What is the best possible system?\" but \"What does the business need, and how can we get there with minimum future pain?\"\nDebuggability vs. Efficiency\nAnother anti-pattern from high-performance thinking: sacrificing observability for CPU savings. In one system, we replaced JSON logging with binary formats to reduce overhead. It worked—3% CPU saved. But the trade-off? Incident response slowed, human debugging suffered, and onboarding became a challenge.\nIn ultra-constrained systems like SCADA (which I worked on early in my career), this trade-off is acceptable. But in most cloud-native systems, human time trumps compute time. Engineers should always ask: “Who’s going to debug this at 3 a.m.?”\nCultural Drift in Engineering Teams\nI’ve seen high-performance specialists bring over habits that don’t scale organizationally: rewriting libraries, resisting abstractions, and insisting on building from scratch. I’ve been guilty of it too, creating \"hot\" functions in x86-64 assembler and using directly the processor's SIMD commands (AVX-512), even when using the Go language. These systems work brilliantly, but only in the hands of their authors. By the way, assembler is very conveniently integrated into Go, but, as practice has shown, few people know it.\nToday, as a manager, I emphasize that business tasks must come first. If business requires creating a system with extreme performance characteristics, then we must remember that this will require a stellar team and vice versa, if a standard system is required, then it is not worth using solutions that are difficult to support and develop, but should focus on schemes and architecture that are understandable to the mass developer, which can be mastered by a mid-level developer in two weeks.\nI also caution against microservices sprawl. Teams eager to optimize development workflows may inadvertently turn a tight data-centric pipeline into a network of chatty, latency-laden services. Even Amazon Prime Video teams have returned from microservices to monoliths in such contexts.\nUnlearning the Habit of Optimization\nThe hardest thing for performance-oriented engineers to learn is when not to optimize. When building the MTS platform, we had parts of the system that were hot paths and others that were barely used. Initially, the urge was to use the same tooling across all components. But it’s a trap. CRUD services don’t need to scale like your bidding engine. Choose the right tool, even if that means sacrificing uniformity.\nSimilarly, early in my career, when developing code to perform a fast inverse Fourier transform, I wrote a highly optimized assembler code that outperformed GCC by 30%. But six months later, the processors changed, and my code optimized for prefetch pipelines began to perform worse than the compiler-generated one. That’s the real cost of low-level perfection: it rarely lasts. Performance tuning should be reserved for business-critical paths.\nLifecycle Cost of Optimization\nWhat often gets overlooked is the total lifecycle cost of early optimization. An efficient algorithm or exotic data layout may save compute time today, but if it slows down onboarding, complicates testability, or becomes a barrier to architectural evolution, then the system is effectively accruing technical debt disguised as technical brilliance. I’ve seen projects where an engineer’s initial low-level perfection became a tax the team paid for years—refactoring was too risky, and new hires avoided touching critical modules. Mature systems require performance that evolves with the business, not just code that’s clever in the moment. The question we should always ask is: “Can this optimization survive team growth and domain shifts over 3–5 years?”\nLearning to Let Go\nIn our CTR/VTR predictor, we send updates in real time. But for the segment coverage calculator in the UI, we switched to batch processing. The latency of updating the data in the UI has increased, but the complexity of support and development has decreased significantly without any impact on the business goal.\nThe wisdom is not in knowing how to optimize, but in knowing when the business doesn’t need it. Premature optimization is only “evil” when it’s misaligned with business maturity. If you're targeting 200k RPS on a core, yes—start sharp. But if it's 200k RPS on a cluster, and you can shard data processing (e.g. distribute requests across nodes), then act iteratively, start with inefficient but working code, and plan refactoring to achieve lower server load. And how to use the \"extra\" hardware freed up after optimization has never been a problem.\nMature Engineers Understand Trade-offs\nThe most balanced engineers I’ve worked with understand the entire vertical, from business requirements to infrastructure tuning. They know when to use Apache Ignite and when Postgres is enough. They make performance decisions only where bottlenecks align with business outcomes.\nSuch engineers avoid optimization addiction. They favor maintainability. They are patient with temporary solutions and confident that the roadmap allows for future improvements. That confidence, along with technical range, is what I consider “technical maturity.”\nLeading Self-Organizing Teams Without Overengineering\nLeft unchecked, high-performance teams often over-abstract. To prevent that, I encourage cross-functional ownership—engineers who think like analysts, testers, and product managers. I advocate for teams that talk openly, document and justify the architectural decisions (ADR), and include domain experts in the loop. You cannot succeed with brilliant engineers alone. You need people from the market.\nAlso, I’ve seen over-specialization derail early-stage teams. For new systems, buy experienced teams or foundational platforms. Don’t reinvent everything. Starting from scratch without market-ready expertise often leads to failure, unless backed by large investments.\nFinal Thoughts\nI don’t regret specializing in high-load systems. It shaped how I think. But I’ve also seen how these instincts, left unchecked, can limit engineers in broader domains. We must relearn general software engineering just as athletes must relearn walking after years of sprinting.\nYour best skill can become your biggest bias. And your greatest strength, when balanced, is what makes you a truly versatile engineer.\nIf you’re a product leader, founder, or manager: don’t ask your engineers to over-optimize from the start. Let them build clear, maintainable systems that can scale later if needed. High performance has its place—but business alignment always comes first.",
          "dc:creator": "Georgy Starikov",
          "content": "Georgy Starikov, a software engineering manager at NVIDIA, shares how deep specialization in high-load, low-latency systems can distort engineering intuition. While performance tuning is essential in critical systems, applying those habits blindly to general business applications often leads to complexity and inefficiency. He emphasizes aligning engineering decisions with business goals, choosing simplicity and maintainability over premature optimization, and recognizing when performance isn't the priority. The key takeaway: mature engineers know when not to optimize.",
          "contentSnippet": "Georgy Starikov, a software engineering manager at NVIDIA, shares how deep specialization in high-load, low-latency systems can distort engineering intuition. While performance tuning is essential in critical systems, applying those habits blindly to general business applications often leads to complexity and inefficiency. He emphasizes aligning engineering decisions with business goals, choosing simplicity and maintainability over premature optimization, and recognizing when performance isn't the priority. The key takeaway: mature engineers know when not to optimize.",
          "guid": "https://hackernoon.com/the-hidden-cost-of-performance-how-high-load-specialization-warps-engineering-intuition?source=rss",
          "categories": [
            "engineering-teams",
            "system-design",
            "performance-optimization",
            "tech-leadership",
            "high-load-systems",
            "crud-backend-scaling",
            "software-architecture",
            "software-engineering"
          ],
          "isoDate": "2025-08-03T15:09:29.000Z"
        }
      },
      {
        "json": {
          "creator": "Pair Programming AI Agent",
          "title": "Can Anyone Code Now? Exploring AI Help for Non-Programmers",
          "link": "https://hackernoon.com/can-anyone-code-now-exploring-ai-help-for-non-programmers?source=rss",
          "pubDate": "Sun, 03 Aug 2025 15:00:04 GMT",
          "content:encoded": "<h2 id=\"tableoflinks\">Table of Links</h2>\n<p><a href=\"https://hackernoon.com/preview/MlSqFDkgc8wyYNhcTQUS\">Abstract and 1 Introduction</a></p>\n<p><a href=\"https://hackernoon.com/preview/8dpQgkvMbLYJAljrV7Vf\">2. Prior conceptualisations of intelligent assistance for programmers</a></p>\n<p><a href=\"https://hackernoon.com/preview/Fbh4JJB153JBpm3kLCxV\">3. A brief overview of large language models for code generation</a></p>\n<p><a href=\"https://hackernoon.com/preview/HmlrCOxDGvgs92HVCJ2K\">4. Commercial programming tools that use large language models</a></p>\n<p><a href=\"https://hackernoon.com/preview/LfBQwyQ4BSGJwpgYltOg\">5. Reliability, safety, and security implications of code-generating AI models</a></p>\n<p><a href=\"https://hackernoon.com/preview/CygvKtzl4ehOH2JMjzSJ\">6. Usability and design studies of AI-assisted programming</a></p>\n<p><a href=\"http://hackernoon.com/preview/avzRmaZuB6kTScIGgBXb\">7. Experience reports and 7.1. Writing effective prompts is hard</a></p>\n<p><a href=\"http://hackernoon.com/preview/trg3lvQVoL7t14dCFdHw\">7.2. The activity of programming shifts towards checking and unfamiliar debugging</a></p>\n<p><a href=\"https://hackernoon.com/preview/Y6BbJahplhYZlxdqdCFp\">7.3. These tools are useful for boilerplate and code reuse</a></p>\n<p>8. The inadequacy of existing metaphors for AI-assisted programming</p>\n<p><a href=\"https://hackernoon.com/preview/vWx560H10HWi8ZHXooSN\">8.1. AI assistance as search</a></p>\n<p><a href=\"https://hackernoon.com/preview/7aqW8wQKjdANYySTv4HT\">8.2. AI assistance as compilation</a></p>\n<p><a href=\"http://hackernoon.com/preview/dt4WL0IqtGFKwYXl8xcM\">8.3. AI assistance as pair programming</a></p>\n<p><a href=\"https://hackernoon.com/preview/y6sPtr5BxC8m3FKl3sPe\">8.4. A distinct way of programming</a></p>\n<p><a href=\"http://hackernoon.com/preview/cFluWTtWEw5cYM79in5t\">9. Issues with application to end-user programming</a></p>\n<p><a href=\"http://hackernoon.com/preview/yXSCL6V4pdtdts6ABfM6\">9.1. Issue 1: Intent specification, problem decomposition and computational thinking</a></p>\n<p><a href=\"https://hackernoon.com/preview/E4BSkXJzfI4viO9ZlSiq\">9.2. Issue 2: Code correctness, quality and (over)confidence</a></p>\n<p><a href=\"https://hackernoon.com/preview/bnqPT5z9RjUqofcdLHgu\">9.3. Issue 3: Code comprehension and maintenance</a></p>\n<p><a href=\"http://hackernoon.com/preview/BakiKXXyiC7EliqZuaEi\">9.4. Issue 4: Consequences of automation in end-user programming</a></p>\n<p><a href=\"http://hackernoon.com/preview/KUolRiHRR6l2EibKExUJ\">9.5. Issue 5: No code, and the dilemma of the direct answer</a></p>\n<p><a href=\"http://hackernoon.com/preview/4zcamJIgNx2iZo9jpBY5\">10. Conclusion</a></p>\n<p><a href=\"https://hackernoon.com/preview/tJyNpGmyfTQHlfAqjVVC\">A. Experience report sources</a></p>\n<p><a href=\"https://hackernoon.com/preview/DfXa3jYCd5LYy3NDyv6c\">References</a></p>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/fWZa4tUiBGemnqQfBGgCPf9594N2-8q833y4.png\" alt=\"Figure 1 – Code generation using the GitHub Copilot editor extension. The portion highlighted in blue has been generated by the model. Left: a function body, generated based on a textual description in a comment. Right: a set of generated test cases. Source: copilot.github.com\" /></p>\n<h2 id=\"abstract\">Abstract</h2>\n<p>Large language models, such as OpenAI’s codex and Deepmind’s AlphaCode, can generate code to solve a variety of problems expressed in natural language. This technology has already been commercialised in at least one widely-used programming editor extension: GitHub Copilot.</p>\n<p>\\\nIn this paper, we explore how programming with large language models (LLM-assisted programming) is similar to, and differs from, prior conceptualisations of programmer assistance. We draw upon publicly available experience reports of LLM-assisted programming, as well as prior usability and design studies. We find that while LLM-assisted programming shares some properties of compilation, pair programming, and programming via search and reuse, there are fundamental differences both in the technical possibilities as well as the practical experience. Thus, LLM-assisted programming ought to be viewed as a new way of programming with its own distinct properties and challenges.</p>\n<p>\\\nFinally, we draw upon observations from a user study in which non-expert end user programmers use LLM-assisted tools for solving data tasks in spreadsheets. We discuss the issues that might arise, and open research challenges, in applying large language models to end-user programming, particularly with users who have little or no programming expertise.</p>\n<h3 id=\"1introduction\">1. Introduction</h3>\n<p>Inferential assistance for programmers has manifested in various forms, such as programming by demonstration, declarative programming languages, and program synthesis (Section 2). Large language models such as GPT mark a quantitative and qualitative step-change in the automatic generation of code and natural language text. This can be attributed to cumulative innovations of vector-space word embeddings, the transformer architecture, large text corpora, and pre-trained language models (Section 3).</p>\n<p>\\\nThese models have been commercialised in the form of APIs such as OpenAI Codex, or as programmerfacing tools such as GitHub Copilot and Tabnine. These tools function as a sort of advanced autocomplete, able to synthesize multiple lines of code based on a prompt within the code editor, which may be natural language (e.g., a comment), code (e.g., a function signature) or an ad-hoc mixture. The capabilities of such tools go well beyond traditional syntax-directed autocomplete, and include the ability to synthesize entire function bodies, write test cases, and complete repetitive patterns (Section 4). These tools have reliability, safety, and security implications (Section 5).</p>\n<p>\\\nPrior lab-based and telemetric research on the usability of such tools finds that developers generally appreciate the capabilities of these tools and find them to be a positive asset to the development experience, despite no strong effects on task completion times or correctness. Core usability issues include the challenge of correctly framing prompts as well as the effort required to check and debug generated code (Section 6).</p>\n<p>\\\nLongitudinal experience reports of developers support some of the lab-based findings, while contradicting others. The challenges of correctly framing prompts and the efforts of debugging also appear here. However, there are many reports that these tools do in fact strongly reduce task time (i.e., speed up the development process) (Section 7).</p>\n<p>\\\nProgramming with large language models invites comparison to related ways of programming, such as search, compilation, and pair programming. While there are indeed similarities with each of these, the empirical reports of the experience of such tools also show crucial differences. Search, compilation, and pair programming are thus found to be inadequate metaphors for the nature of LLM-assisted programming; it is a distinct way of programming with its own unique blend of properties (Section 8).</p>\n<p>\\\nWhile LLM-assisted programming is currently geared towards expert programmers, arguably the greatest beneficiaries of their abilities will be non-expert end-user programmers. Nonetheless, there are issues with their direct application in end-user programming scenarios. Through a study of LLM-assisted end-user programming in spreadsheets, we uncover issues in intent specification, code correctness, comprehension, LLM tuning, and end-user behaviour, and motivate the need for further study in this area (Section 9).</p>\n<p>\\</p>\n<p>:::info\nThis paper is <strong><a href=\"https://arxiv.org/abs/2208.06213\">available on arxiv</a></strong> under CC BY-NC-ND 4.0 DEED license.</p>\n<p>:::</p>\n<p>:::info\n<strong>Authors:</strong></p>\n<p>(1) Advait Sarkar, Microsoft Research, University of Cambridge (advait@microsoft.com);</p>\n<p>(2) Andrew D. Gordon, Microsoft Research, University of Edinburgh (adg@microsoft.com);</p>\n<p>(3) Carina Negreanu, Microsoft Research (cnegreanu@microsoft.com);</p>\n<p>(4) Christian Poelitz, Microsoft Research (cpoelitz@microsoft.com);</p>\n<p>(5) Sruti Srinivasa Ragavan, Microsoft Research (a-srutis@microsoft.com);</p>\n<p>(6) Ben Zorn, Microsoft Research (ben.zorn@microsoft.com).</p>\n<p>:::</p>\n<p>\\</p>",
          "content:encodedSnippet": "Table of Links\nAbstract and 1 Introduction\n2. Prior conceptualisations of intelligent assistance for programmers\n3. A brief overview of large language models for code generation\n4. Commercial programming tools that use large language models\n5. Reliability, safety, and security implications of code-generating AI models\n6. Usability and design studies of AI-assisted programming\n7. Experience reports and 7.1. Writing effective prompts is hard\n7.2. The activity of programming shifts towards checking and unfamiliar debugging\n7.3. These tools are useful for boilerplate and code reuse\n8. The inadequacy of existing metaphors for AI-assisted programming\n8.1. AI assistance as search\n8.2. AI assistance as compilation\n8.3. AI assistance as pair programming\n8.4. A distinct way of programming\n9. Issues with application to end-user programming\n9.1. Issue 1: Intent specification, problem decomposition and computational thinking\n9.2. Issue 2: Code correctness, quality and (over)confidence\n9.3. Issue 3: Code comprehension and maintenance\n9.4. Issue 4: Consequences of automation in end-user programming\n9.5. Issue 5: No code, and the dilemma of the direct answer\n10. Conclusion\nA. Experience report sources\nReferences\n\\\n \nAbstract\nLarge language models, such as OpenAI’s codex and Deepmind’s AlphaCode, can generate code to solve a variety of problems expressed in natural language. This technology has already been commercialised in at least one widely-used programming editor extension: GitHub Copilot.\n\\\nIn this paper, we explore how programming with large language models (LLM-assisted programming) is similar to, and differs from, prior conceptualisations of programmer assistance. We draw upon publicly available experience reports of LLM-assisted programming, as well as prior usability and design studies. We find that while LLM-assisted programming shares some properties of compilation, pair programming, and programming via search and reuse, there are fundamental differences both in the technical possibilities as well as the practical experience. Thus, LLM-assisted programming ought to be viewed as a new way of programming with its own distinct properties and challenges.\n\\\nFinally, we draw upon observations from a user study in which non-expert end user programmers use LLM-assisted tools for solving data tasks in spreadsheets. We discuss the issues that might arise, and open research challenges, in applying large language models to end-user programming, particularly with users who have little or no programming expertise.\n1. Introduction\nInferential assistance for programmers has manifested in various forms, such as programming by demonstration, declarative programming languages, and program synthesis (Section 2). Large language models such as GPT mark a quantitative and qualitative step-change in the automatic generation of code and natural language text. This can be attributed to cumulative innovations of vector-space word embeddings, the transformer architecture, large text corpora, and pre-trained language models (Section 3).\n\\\nThese models have been commercialised in the form of APIs such as OpenAI Codex, or as programmerfacing tools such as GitHub Copilot and Tabnine. These tools function as a sort of advanced autocomplete, able to synthesize multiple lines of code based on a prompt within the code editor, which may be natural language (e.g., a comment), code (e.g., a function signature) or an ad-hoc mixture. The capabilities of such tools go well beyond traditional syntax-directed autocomplete, and include the ability to synthesize entire function bodies, write test cases, and complete repetitive patterns (Section 4). These tools have reliability, safety, and security implications (Section 5).\n\\\nPrior lab-based and telemetric research on the usability of such tools finds that developers generally appreciate the capabilities of these tools and find them to be a positive asset to the development experience, despite no strong effects on task completion times or correctness. Core usability issues include the challenge of correctly framing prompts as well as the effort required to check and debug generated code (Section 6).\n\\\nLongitudinal experience reports of developers support some of the lab-based findings, while contradicting others. The challenges of correctly framing prompts and the efforts of debugging also appear here. However, there are many reports that these tools do in fact strongly reduce task time (i.e., speed up the development process) (Section 7).\n\\\nProgramming with large language models invites comparison to related ways of programming, such as search, compilation, and pair programming. While there are indeed similarities with each of these, the empirical reports of the experience of such tools also show crucial differences. Search, compilation, and pair programming are thus found to be inadequate metaphors for the nature of LLM-assisted programming; it is a distinct way of programming with its own unique blend of properties (Section 8).\n\\\nWhile LLM-assisted programming is currently geared towards expert programmers, arguably the greatest beneficiaries of their abilities will be non-expert end-user programmers. Nonetheless, there are issues with their direct application in end-user programming scenarios. Through a study of LLM-assisted end-user programming in spreadsheets, we uncover issues in intent specification, code correctness, comprehension, LLM tuning, and end-user behaviour, and motivate the need for further study in this area (Section 9).\n\\\n:::info\nThis paper is available on arxiv under CC BY-NC-ND 4.0 DEED license.\n:::\n:::info\nAuthors:\n(1) Advait Sarkar, Microsoft Research, University of Cambridge (advait@microsoft.com);\n(2) Andrew D. Gordon, Microsoft Research, University of Edinburgh (adg@microsoft.com);\n(3) Carina Negreanu, Microsoft Research (cnegreanu@microsoft.com);\n(4) Christian Poelitz, Microsoft Research (cpoelitz@microsoft.com);\n(5) Sruti Srinivasa Ragavan, Microsoft Research (a-srutis@microsoft.com);\n(6) Ben Zorn, Microsoft Research (ben.zorn@microsoft.com).\n:::\n\\",
          "dc:creator": "Pair Programming AI Agent",
          "content": "Come see how coding is changing with AI language models. Sharing real-world stories and studies showing just how different—and awesome—it is to program with these new tools now.",
          "contentSnippet": "Come see how coding is changing with AI language models. Sharing real-world stories and studies showing just how different—and awesome—it is to program with these new tools now.",
          "guid": "https://hackernoon.com/can-anyone-code-now-exploring-ai-help-for-non-programmers?source=rss",
          "categories": [
            "large-language-models",
            "ai-assisted-programming",
            "github-copilot",
            "code-generation",
            "programmer-assistance",
            "end-user-programming",
            "usability-studies",
            "inferential-assistance"
          ],
          "isoDate": "2025-08-03T15:00:04.000Z"
        }
      },
      {
        "json": {
          "creator": "Khamisi Hamisi",
          "title": "Europe’s Data Vision: Dataspaces for Zero-Trust AI Infrastructure",
          "link": "https://hackernoon.com/europes-data-vision-dataspaces-for-zero-trust-ai-infrastructure?source=rss",
          "pubDate": "Sun, 03 Aug 2025 12:15:08 GMT",
          "content:encoded": "<p>As AI systems scale across sectors like healthcare, manufacturing, and finance, Europe faces a critical challenge: how to orchestrate AI securely across privacy, regulatory, and organizational boundaries.</p>\n<p>\\\nThis case study explores a pioneering Huberta project that embraces zero-trust architecture, metadata-first orchestration, and mathematical compliance via PDEs.</p>\n<p>\\\nAt the heart of this initiative lies a breakthrough: policy-aware orchestration through partial differential equations, allowing AI to run only when privacy, intent, and law align.</p>\n<p>\\\nUpstaff provided specialized <a href=\"https://upstaff.com/blog/artificial-intelligence-machine-learning-engineer-ai-ml/become-a-machine-learning-engineer-your-guide/\">AI engineers</a> who tackled the core challenges of federated orchestration, zero-trust metadata, and explainable infrastructure at scale.</p>\n<p>\\\nThis article provides insights into a European data infrastructure project focused on creating a policy-aware, zero-trust system for federated AI.</p>\n<p>\\\nThe initiative aims to revolutionize data infrastructure by replacing centralized data systems with a decentralized, privacy-preserving framework.</p>\n<p>\\\nIt uses partial differential equations (PDEs) to enforce compliance (e.g., GDPR, EU AI Act) and manage data access for secure multi-party collaboration without raw data exchange.</p>\n<p>\\\n<strong>What we will cover:</strong></p>\n<p>\\</p>\n<ul>\n<li>Zero-Trust Metadata and Dataspaces</li>\n<li>Zero-Trust AI Orchestration Across Privacy and Policy Boundaries</li>\n<li>System Architecture Overview</li>\n<li>Engineering Stack &amp; Capabilities</li>\n<li>Cloud Infrastructure Capability Matrix (AWS-focused)</li>\n<li>Engineering the Backbone of Federated AI</li>\n<li>Results So Far</li>\n<li>Lessons Learned &amp; Engineering Insights</li>\n<li>Why This Matters: The Next Wave of AI Infrastructure</li>\n<li>Conclusion: Engineering Trustworthy AI at Scale</li>\n</ul>\n<h2 id=\"dataspace\"><strong>Dataspace</strong></h2>\n<p>A dataspace is a federated network designed for secure, <a href=\"https://upstaff.com/blog/blockchain-web-3-0/depin-decentralized-physical-infrastructure-networks/\">decentralized data exchange</a>. It allows organizations to maintain control over their data while enabling interoperability across different platforms and industries.</p>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/2bL8Ve2IGiP0vEziDpWY80JjirD2-xu02fq2.jpeg\" alt=\"\" /></p>\n<p>\\\nDataspace enables trusted data sharing in a way that preserves the data sovereignty of participants based on a standard governance framework.</p>\n<p>\\</p>\n<ul>\n<li>Dataspaces are pivotal in sectors like mobility, healthcare, logistics, and smart cities, where data integration is essential for innovation and efficiency.</li>\n<li>Dataspaces can be purpose- or sector-specific, or cross-sectoral.</li>\n</ul>\n<h2 id=\"zerotrustmetadataanddataspaces\"><strong>Zero-Trust Metadata and Dataspaces</strong></h2>\n<p>As Europe advances toward a digitally sovereign future, the way we handle data is undergoing a fundamental shift.</p>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/2bL8Ve2IGiP0vEziDpWY80JjirD2-kg12feu.jpeg\" alt=\"\" /></p>\n<p>\\\n\\\nTraditional architectures such as centralized data lakes, post-hoc compliance checks, and monolithic workflows are no longer sufficient. Emerging standards, like the EU AI Act and GDPR, demand real-time governance, privacy-preserving design, and explainability by default.</p>\n<p>\\\nAt the frontier of this transformation is a groundbreaking project. Its mission is to reimagine data infrastructure as a policy-aware, zero-trust system built not from pipelines, but from mathematics.</p>\n<p>\\\nAt the core of this system are partial differential equations (PDEs) that regulate resource access, data movement, and AI behavior through boundary conditions.</p>\n<p>\\\nThis paradigm allows multi-party collaboration without raw data exchange, high-performance computing (HPC) on demand, with minimal energy footprint, and compliance encoded directly into the infrastructure.</p>\n<h3 id=\"howpdeorchestratedinfrastructurediffersfromconventionalsystems\"><strong>How PDE-Orchestrated Infrastructure Differs From Conventional Systems</strong></h3>\n<p>| Feauture | Conventional Cloud AI | PDE-Orchestrated Zero-Trust AI |\n|----|----|----|\n| Data Movement | Centralized | Local-only |\n| Policy Compliance | Post-hoc | By-construction |\n| Resource Usage | Persistent | Ephemeral |\n| Governance | Manual | Embedded in PDEs |\n| Traceability | Limited | DAG + Policy-bound |</p>\n<h2 id=\"zerotrustaiorchestrationacrossprivacyandpolicyboundaries\"><strong>Zero-Trust AI Orchestration Across Privacy and Policy Boundaries</strong></h2>\n<p>The project's vision is radical: create a framework where data never moves, but value does.</p>\n<p>\\\nRather than collecting data into central repositories, each participant in the system, whether in healthcare, manufacturing, or public services, retains full control of their data.</p>\n<p>\\\nA dynamic knowledge graph holds metadata, ontologies, and processing “recipes.” Computation is triggered by PDEs that enforce policy gates (GDPR, ISO, GAMP) as mathematical constraints.</p>\n<p>\\\nWhen certain boundary conditions are met, e.g., a spike in demand or anomaly detection, a short-lived HPC cluster spins up, computes locally, and vanishes.</p>\n<p>\\\nBut to make this vision real, the team needed engineers with a rare mix of skills:</p>\n<p>\\</p>\n<ul>\n<li>Privacy-preserving machine learning</li>\n<li>Federated AI</li>\n<li>Knowledge graph integration</li>\n<li>Explainable DAG orchestration</li>\n<li>Semantic modeling and metadata processing</li>\n</ul>\n<p>\\\nAt the heart of the system lies a governance PDE, where each term in the equation maps to a constraint:</p>\n<p>\\</p>\n<ul>\n<li>∂u/∂t + ∇·(α(u)∇u) = f(x, t)- represents AI execution across time and space.</li>\n<li>∂u/∂t — latency or response time</li>\n<li>α(u) — policy gating/access weights</li>\n<li>f(x, t) — triggers like demand spike or anomaly</li>\n<li>Boundary terms = regulatory or domain-specific constraints, GDPR compliance, semantic gates, and user intent.</li>\n</ul>\n<p>\\\nIf the PDE has no solution, computation is halted. This turns policy from a rule to a hard condition of execution. “If you can’t solve the PDE, you can’t run the task.” This is proactive compliance by construction.</p>\n<h2 id=\"systemarchitectureoverview\"><strong>System Architecture Overview</strong></h2>\n<ul>\n<li><p><strong>Local Data Silos</strong>: Hospitals, factories, and labs retain full control of raw data. Nothing is centralized.</p>\n<p>\\</p></li>\n<li><p><strong>Policy Gate</strong>: Applies GDPR, AI Act, and internal policies at the metadata boundary. Invalid flows are filtered before orchestration.</p>\n<p>\\</p></li>\n<li><p><strong>PDE Engine</strong>: The core of the system. It solves boundary-condition equations where each constraint represents a legal, semantic, or resource constraint.</p>\n<p>\\</p></li>\n</ul>\n<p>Examples:</p>\n<p>\\</p>\n<ol>\n<li>A GDPR clause becomes an unsolvable boundary if data leaves its origin.</li>\n<li>A compute budget becomes a conditional activation.</li>\n</ol>\n<p>\\</p>\n<ul>\n<li><p><strong>Knowledge Graph:</strong> Stores semantic mappings, policy clauses, domain taxonomies, and orchestration “recipes.” This separates logic from data — enabling fast, ontology-driven decisions.</p>\n<p>\\</p></li>\n<li><p><strong>Ephemeral HPC Clusters:</strong> Resources are spun up only when a PDE solution exists — when policy, readiness, and workload match.</p>\n<p>\\\nThese may include:</p>\n<p>\\</p></li>\n</ul>\n<ol>\n<li>Classification models</li>\n<li>Anomaly detectors</li>\n<li>Simulation workloads</li>\n<li>Federated training</li>\n</ol>\n<p>\\</p>\n<ul>\n<li><strong>DAG Traceability</strong>: Each operation logs its origin: which policy triggered it, which resource was allocated, and which boundary condition was met.</li>\n</ul>\n<h2 id=\"engineeringstackcapabilities\"><strong>Engineering Stack & Capabilities</strong></h2>\n<p>| Domain | Contribution | Tools and Methods |\n|----|----|----|\n| Federated AI | Built vertical &amp; horizontal pipelines | PySyft, Flower, OpenMined, custom secure aggregation protocols |\n| Semantic Modeling | Ontology→PDE mapping | RDF/OWL, Protégé, SPARQL, Neo4j, GraphQL |\n| Metadata-First Design | Graph-driven orchestration | GraphQL, custom DAG wrappers, Apache Airflow, Argo Workflows, Prefect, Temporal |\n| Explainability &amp; Auditing | Traceable execution lineage | DAG visualizers, metadata provenance tracing, JSON-LD, OpenPolicyAgent logs |\n| PDE Compliance Runtime | Mathematical constraint solver | SciPy, JAX, TensorFlow PDE, PyTorch autograd, custom symbolic solvers |\n| Infrastructure Engineering | Deployed resilient, policy-aware federated systems across cloud-native and hybrid environments | Amazon Web Services |</p>\n<p>\\</p>\n<h2 id=\"cloudinfrastructurecapabilitymatrixawsfocused\"><strong>Cloud Infrastructure Capability Matrix (AWS-Focused)</strong></h2>\n<p>\\</p>\n<p>| Category | AWS Services Listed | Notes |\n|----|----|----|\n| Compute &amp; Containerization | ECS, EKS, EC2, Fargate, Lambda | All AWS-native |\n| Networking &amp; Security | VPC, PrivateLink, IAM, Security Groups, KMS, Secrets Manager | AWS-specific |\n| Storage | S3, EFS, FSx | AWS storage services |\n| Serverless Pipelines | Step Functions, EventBridge, DynamoDB Streams | AWS-native serverless tools |\n| Data Layer | Neptune, RDS, Aurora, Glue, Athena | All are AWS-managed data services |\n| Monitoring &amp; Observability | CloudWatch, X-Ray, OpenTelemetry | FirOpenTelemetry is a cross-cloud; two are AWS |\n| Compliance Enforcement | Macie, GuardDuty, Config | All AWS-native compliance/security tools |</p>\n<h2 id=\"engineeringthebackboneoffederatedai\"><strong>Engineering the Backbone of Federated AI</strong></h2>\n<p>Among others, Federated AI also allows them to significantly reduce the amount of data they transfer. In fact, some projects managed to reduce their data transfer burden by more than 99% compared to a centralized training model.</p>\n<p>\\\nThis is important because moving very large datasets contributes to higher costs, lower performance, and decreased energy efficiency.</p>\n<p>\\\nThere are two main approaches to federated AI:</p>\n<p>\\</p>\n<ul>\n<li><p><strong>Horizontal federated AI</strong>: pulls model weights from the same types of data in every site</p>\n<p>\\</p></li>\n<li><p><strong>Vertical federated AI:</strong> pulls model weights from different types of data in different sites</p>\n<p>\\</p></li>\n</ul>\n<p>AI engineers contributed to several mission-critical domains:</p>\n<p>\\</p>\n<ul>\n<li><p><strong>Multi-head AI pipelines</strong></p>\n<p>Asynchronous pipelines for classification, anomaly detection, and schema interpretation, all integrated into a dynamic metadata fabric.</p>\n<p>\\</p></li>\n<li><p><strong>Semantic-aware orchestration</strong></p>\n<p>Knowledge graph outputs to PDE boundary inputs, ensuring compute only runs when policies, semantics, and capacity align.</p>\n<p>\\</p></li>\n<li><p><strong>Zero-trust federation logic</strong></p>\n<p>AI workflows to operate without ever touching raw data—only abstracted metadata fragments.</p>\n<p>\\</p></li>\n<li><p><strong>Audit-ready explainability</strong></p>\n<p>Directed acyclic graphs (DAGs) trace each decision back to a semantic label or policy clause, aligning with upcoming EU AI Act requirements.</p></li>\n</ul>\n<p>\\\nBehind some of the engineering challenges in this initiative is a team of specialized AI engineers from Upstaff, who could contribute to policy-aware AI infrastructure across domains as sensitive as healthcare and industrial manufacturing.</p>\n<h2 id=\"resultssofar\"><strong>Results So Far</strong></h2>\n<p>Though still in active development, the project has made several breakthroughs:</p>\n<p>\\</p>\n<ul>\n<li>A working alpha prototype of the PDE aggregator with sub-second concurrency response.</li>\n<li>Real-time metadata ingestion and anomaly classification through AI modules.</li>\n<li>Federated learning simulations operating under policy constraints.</li>\n<li>Traceable, explainable orchestration flows through self-documenting DAGs.</li>\n</ul>\n<h2 id=\"lessonslearnedengineeringinsights\"><strong>Lessons Learned & Engineering Insights</strong></h2>\n<ul>\n<li>Math over policies wins: Executable PDEs &gt; static rules</li>\n<li>Metadata is infrastructure: Ontologies replaced scripts</li>\n<li>Compliance must be first-class: Not a feature—an execution condition</li>\n<li>No-code ≠ Low-trust: Engineers must deeply understand the domain and legal semantics</li>\n</ul>\n<h2 id=\"whythismattersthenextwaveofaiinfrastructure\"><strong>Why This Matters: The Next Wave of AI Infrastructure</strong></h2>\n<h2 id=\"\"> </h2>\n<p><img src=\"https://cdn.hackernoon.com/images/2bL8Ve2IGiP0vEziDpWY80JjirD2-yn22fs8.jpeg\" alt=\"\" /></p>\n<p>\\\nThe technical architecture being developed in this project isn’t niche. It’s a preview of where AI and data engineering are headed:</p>\n<p>\\</p>\n<ul>\n<li>Federated AI in finance and healthcare</li>\n<li>Semantic interoperability across ESG supply chains</li>\n<li>Ephemeral HPC for energy-efficient computing</li>\n<li>Mathematical governance over data flows</li>\n</ul>\n<h2 id=\"conclusionengineeringtrustworthyaiatscale\"><strong>Conclusion: Engineering Trustworthy AI at Scale</strong></h2>\n<p>Real-world AI lives at the intersection of regulation, infrastructure, ethics, and performance. This initiative is a bold attempt to build a system where all those concerns are solved mathematically, structurally, and scalably.</p>\n<p>\\\nCompliance isn’t a document; it’s a boundary condition. And orchestration isn’t a workflow; it’s an equation.</p>",
          "content:encodedSnippet": "As AI systems scale across sectors like healthcare, manufacturing, and finance, Europe faces a critical challenge: how to orchestrate AI securely across privacy, regulatory, and organizational boundaries.\n\\\nThis case study explores a pioneering Huberta project that embraces zero-trust architecture, metadata-first orchestration, and mathematical compliance via PDEs.\n\\\nAt the heart of this initiative lies a breakthrough: policy-aware orchestration through partial differential equations, allowing AI to run only when privacy, intent, and law align.\n\\\nUpstaff provided specialized AI engineers who tackled the core challenges of federated orchestration, zero-trust metadata, and explainable infrastructure at scale.\n\\\nThis article provides insights into a European data infrastructure project focused on creating a policy-aware, zero-trust system for federated AI.\n\\\nThe initiative aims to revolutionize data infrastructure by replacing centralized data systems with a decentralized, privacy-preserving framework.\n\\\nIt uses partial differential equations (PDEs) to enforce compliance (e.g., GDPR, EU AI Act) and manage data access for secure multi-party collaboration without raw data exchange.\n\\\nWhat we will cover:\n\\\n\nZero-Trust Metadata and Dataspaces\nZero-Trust AI Orchestration Across Privacy and Policy Boundaries\nSystem Architecture Overview\nEngineering Stack & Capabilities\nCloud Infrastructure Capability Matrix (AWS-focused)\nEngineering the Backbone of Federated AI\nResults So Far\nLessons Learned & Engineering Insights\nWhy This Matters: The Next Wave of AI Infrastructure\nConclusion: Engineering Trustworthy AI at Scale\nDataspace\nA dataspace is a federated network designed for secure, decentralized data exchange. It allows organizations to maintain control over their data while enabling interoperability across different platforms and industries.\n\\\n \n\\\nDataspace enables trusted data sharing in a way that preserves the data sovereignty of participants based on a standard governance framework.\n\\\n\nDataspaces are pivotal in sectors like mobility, healthcare, logistics, and smart cities, where data integration is essential for innovation and efficiency.\nDataspaces can be purpose- or sector-specific, or cross-sectoral.\nZero-Trust Metadata and Dataspaces\nAs Europe advances toward a digitally sovereign future, the way we handle data is undergoing a fundamental shift.\n\\\n \n\\\n\\\nTraditional architectures such as centralized data lakes, post-hoc compliance checks, and monolithic workflows are no longer sufficient. Emerging standards, like the EU AI Act and GDPR, demand real-time governance, privacy-preserving design, and explainability by default.\n\\\nAt the frontier of this transformation is a groundbreaking project. Its mission is to reimagine data infrastructure as a policy-aware, zero-trust system built not from pipelines, but from mathematics.\n\\\nAt the core of this system are partial differential equations (PDEs) that regulate resource access, data movement, and AI behavior through boundary conditions.\n\\\nThis paradigm allows multi-party collaboration without raw data exchange, high-performance computing (HPC) on demand, with minimal energy footprint, and compliance encoded directly into the infrastructure.\nHow PDE-Orchestrated Infrastructure Differs From Conventional Systems\n| Feauture | Conventional Cloud AI | PDE-Orchestrated Zero-Trust AI |\n|----|----|----|\n| Data Movement | Centralized | Local-only |\n| Policy Compliance | Post-hoc | By-construction |\n| Resource Usage | Persistent | Ephemeral |\n| Governance | Manual | Embedded in PDEs |\n| Traceability | Limited | DAG + Policy-bound |\nZero-Trust AI Orchestration Across Privacy and Policy Boundaries\nThe project's vision is radical: create a framework where data never moves, but value does.\n\\\nRather than collecting data into central repositories, each participant in the system, whether in healthcare, manufacturing, or public services, retains full control of their data.\n\\\nA dynamic knowledge graph holds metadata, ontologies, and processing “recipes.” Computation is triggered by PDEs that enforce policy gates (GDPR, ISO, GAMP) as mathematical constraints.\n\\\nWhen certain boundary conditions are met, e.g., a spike in demand or anomaly detection, a short-lived HPC cluster spins up, computes locally, and vanishes.\n\\\nBut to make this vision real, the team needed engineers with a rare mix of skills:\n\\\n\nPrivacy-preserving machine learning\nFederated AI\nKnowledge graph integration\nExplainable DAG orchestration\nSemantic modeling and metadata processing\n\\\nAt the heart of the system lies a governance PDE, where each term in the equation maps to a constraint:\n\\\n\n∂u/∂t + ∇·(α(u)∇u) = f(x, t)- represents AI execution across time and space.\n∂u/∂t — latency or response time\nα(u) — policy gating/access weights\nf(x, t) — triggers like demand spike or anomaly\nBoundary terms = regulatory or domain-specific constraints, GDPR compliance, semantic gates, and user intent.\n\\\nIf the PDE has no solution, computation is halted. This turns policy from a rule to a hard condition of execution. “If you can’t solve the PDE, you can’t run the task.” This is proactive compliance by construction.\nSystem Architecture Overview\nLocal Data Silos: Hospitals, factories, and labs retain full control of raw data. Nothing is centralized.\n\\\nPolicy Gate: Applies GDPR, AI Act, and internal policies at the metadata boundary. Invalid flows are filtered before orchestration.\n\\\nPDE Engine: The core of the system. It solves boundary-condition equations where each constraint represents a legal, semantic, or resource constraint.\n\\\nExamples:\n\\\n\nA GDPR clause becomes an unsolvable boundary if data leaves its origin.\nA compute budget becomes a conditional activation.\n\\\n\n\nKnowledge Graph: Stores semantic mappings, policy clauses, domain taxonomies, and orchestration “recipes.” This separates logic from data — enabling fast, ontology-driven decisions.\n\\\nEphemeral HPC Clusters: Resources are spun up only when a PDE solution exists — when policy, readiness, and workload match.\n\\\nThese may include:\n\\\nClassification models\nAnomaly detectors\nSimulation workloads\nFederated training\n\\\n\nDAG Traceability: Each operation logs its origin: which policy triggered it, which resource was allocated, and which boundary condition was met.\nEngineering Stack & Capabilities\n| Domain | Contribution | Tools and Methods |\n|----|----|----|\n| Federated AI | Built vertical & horizontal pipelines | PySyft, Flower, OpenMined, custom secure aggregation protocols |\n| Semantic Modeling | Ontology→PDE mapping | RDF/OWL, Protégé, SPARQL, Neo4j, GraphQL |\n| Metadata-First Design | Graph-driven orchestration | GraphQL, custom DAG wrappers, Apache Airflow, Argo Workflows, Prefect, Temporal |\n| Explainability & Auditing | Traceable execution lineage | DAG visualizers, metadata provenance tracing, JSON-LD, OpenPolicyAgent logs |\n| PDE Compliance Runtime | Mathematical constraint solver | SciPy, JAX, TensorFlow PDE, PyTorch autograd, custom symbolic solvers |\n| Infrastructure Engineering | Deployed resilient, policy-aware federated systems across cloud-native and hybrid environments | Amazon Web Services |\n\\\nCloud Infrastructure Capability Matrix (AWS-Focused)\n\\\n| Category | AWS Services Listed | Notes |\n|----|----|----|\n| Compute & Containerization | ECS, EKS, EC2, Fargate, Lambda | All AWS-native |\n| Networking & Security | VPC, PrivateLink, IAM, Security Groups, KMS, Secrets Manager | AWS-specific |\n| Storage | S3, EFS, FSx | AWS storage services |\n| Serverless Pipelines | Step Functions, EventBridge, DynamoDB Streams | AWS-native serverless tools |\n| Data Layer | Neptune, RDS, Aurora, Glue, Athena | All are AWS-managed data services |\n| Monitoring & Observability | CloudWatch, X-Ray, OpenTelemetry | FirOpenTelemetry is a cross-cloud; two are AWS |\n| Compliance Enforcement | Macie, GuardDuty, Config | All AWS-native compliance/security tools |\nEngineering the Backbone of Federated AI\nAmong others, Federated AI also allows them to significantly reduce the amount of data they transfer. In fact, some projects managed to reduce their data transfer burden by more than 99% compared to a centralized training model.\n\\\nThis is important because moving very large datasets contributes to higher costs, lower performance, and decreased energy efficiency.\n\\\nThere are two main approaches to federated AI:\n\\\n\n\nHorizontal federated AI: pulls model weights from the same types of data in every site\n\\\nVertical federated AI: pulls model weights from different types of data in different sites\n\\\nAI engineers contributed to several mission-critical domains:\n\\\n\n\nMulti-head AI pipelines\nAsynchronous pipelines for classification, anomaly detection, and schema interpretation, all integrated into a dynamic metadata fabric.\n\\\nSemantic-aware orchestration\nKnowledge graph outputs to PDE boundary inputs, ensuring compute only runs when policies, semantics, and capacity align.\n\\\nZero-trust federation logic\nAI workflows to operate without ever touching raw data—only abstracted metadata fragments.\n\\\nAudit-ready explainability\nDirected acyclic graphs (DAGs) trace each decision back to a semantic label or policy clause, aligning with upcoming EU AI Act requirements.\n\n\n\\\nBehind some of the engineering challenges in this initiative is a team of specialized AI engineers from Upstaff, who could contribute to policy-aware AI infrastructure across domains as sensitive as healthcare and industrial manufacturing.\nResults So Far\nThough still in active development, the project has made several breakthroughs:\n\\\n\nA working alpha prototype of the PDE aggregator with sub-second concurrency response.\nReal-time metadata ingestion and anomaly classification through AI modules.\nFederated learning simulations operating under policy constraints.\nTraceable, explainable orchestration flows through self-documenting DAGs.\nLessons Learned & Engineering Insights\nMath over policies wins: Executable PDEs > static rules\nMetadata is infrastructure: Ontologies replaced scripts\nCompliance must be first-class: Not a feature—an execution condition\nNo-code ≠ Low-trust: Engineers must deeply understand the domain and legal semantics\nWhy This Matters: The Next Wave of AI Infrastructure\n \n\n\\\nThe technical architecture being developed in this project isn’t niche. It’s a preview of where AI and data engineering are headed:\n\\\n\nFederated AI in finance and healthcare\nSemantic interoperability across ESG supply chains\nEphemeral HPC for energy-efficient computing\nMathematical governance over data flows\nConclusion: Engineering Trustworthy AI at Scale\nReal-world AI lives at the intersection of regulation, infrastructure, ethics, and performance. This initiative is a bold attempt to build a system where all those concerns are solved mathematically, structurally, and scalably.\n\\\nCompliance isn’t a document; it’s a boundary condition. And orchestration isn’t a workflow; it’s an equation.",
          "dc:creator": "Khamisi Hamisi",
          "content": "This article provides insights into a European data infrastructure project focused on creating a policy-aware, zero-trust system for federated AI. The initiative aims to revolutionize data infrastructure by replacing centralized data systems with a decentralized, privacy-preserving framework. It uses partial differential equations (PDEs) to enforce compliance and manage data access for secure multi-party collaboration without raw data exchange.",
          "contentSnippet": "This article provides insights into a European data infrastructure project focused on creating a policy-aware, zero-trust system for federated AI. The initiative aims to revolutionize data infrastructure by replacing centralized data systems with a decentralized, privacy-preserving framework. It uses partial differential equations (PDEs) to enforce compliance and manage data access for secure multi-party collaboration without raw data exchange.",
          "guid": "https://hackernoon.com/europes-data-vision-dataspaces-for-zero-trust-ai-infrastructure?source=rss",
          "categories": [
            "ai-infrastructure",
            "zero-trust-ai",
            "pde",
            "zero-trust",
            "federated-ai",
            "zero-trust-metadata",
            "what-is-federated-ai",
            "europe-data-vision"
          ],
          "isoDate": "2025-08-03T12:15:08.000Z"
        }
      },
      {
        "json": {
          "creator": "Go [Technical Documentation]",
          "title": "Reproducible Go Toolchains: What You Need to Know",
          "link": "https://hackernoon.com/reproducible-go-toolchains-what-you-need-to-know?source=rss",
          "pubDate": "Sun, 03 Aug 2025 12:00:07 GMT",
          "content:encoded": "<p>One of the key benefits of open-source software is that anyone can read the source code and inspect what it does. And yet most software, even open-source software, is downloaded in the form of compiled binaries, which are much more difficult to inspect. If an attacker wanted to run a <a href=\"https://cloud.google.com/software-supply-chain-security/docs/attack-vectors\">supply chain attack</a> on an open-source project, the least visible way would be to replace the binaries being served while leaving the source code unmodified.</p>\n<p>\\\nThe best way to address this kind of attack is to make open-source software builds <em>reproducible</em>, meaning that a build that starts with the same sources produces the same outputs every time it runs. That way, anyone can verify that posted binaries are free of hidden changes by building from authentic sources and checking that the rebuilt binaries are bit-for-bit identical to the posted binaries. That approach proves the binaries have no backdoors or other changes not present in the source code, without having to disassemble or look inside them at all. Since anyone can verify the binaries, independent groups can easily detect and report supply chain attacks.</p>\n<p>\\\nAs supply chain security becomes more important, so do reproducible builds, because they provide a simple way to verify the posted binaries for open-source projects.</p>\n<p>\\\nGo 1.21.0 is the first Go toolchain with perfectly reproducible builds. Earlier toolchains were possible to reproduce, but only with significant effort, and probably no one did: they just trusted that the binaries posted on <a href=\"/dl/\">go.dev/dl</a> were the correct ones. Now it’s easy to “trust but verify.”</p>\n<p>\\\nThis post explains what goes into making builds reproducible, examines the many changes we had to make to Go to make Go toolchains reproducible, and then demonstrates one of the benefits of reproducibility by verifying the Ubuntu package for Go 1.21.0.</p>\n<h2 id=\"makingabuildreproducible\">Making a Build Reproducible</h2>\n<p>Computers are generally deterministic, so you might think all builds would be equally reproducible. That’s only true from a certain point of view. Let’s call a piece of information a <em>relevant input</em> when the output of a build can change depending on that input. A build is reproducible if it can be repeated with all the same relevant inputs. Unfortunately, lots of build tools turn out to incorporate inputs that we would usually not realize are relevant and that might be difficult to recreate or provide as input. Let’s call an input an <em>unintentional input</em> when it turns out to be relevant but we didn’t mean it to be.</p>\n<p>\\\nThe most common unintentional input in build systems is the current time. If a build writes an executable to disk, the file system records the current time as the executable’s modification time. If the build then packages that file using a tool like “tar” or “zip”, the modification time is written into the archive. We certainly didn’t want our build to change based on the current time, but it does. So the current time turns out to be an unintentional input to the build. Worse, most programs don’t let you provide the current time as an input, so there is no way to repeat this build. To fix this, we might set the time stamps on created files to Unix time 0 or to a specific time read from one of the build’s source files. That way, the current time is no longer a relevant input to the build.</p>\n<p>\\\nCommon relevant inputs to a build include:</p>\n<ul>\n<li>the specific version of the source code to build;</li>\n<li>the specific versions of dependencies that will be included in the build;</li>\n<li>the operating system running the build, which may affect path names in the resulting binaries;</li>\n<li>the architecture of the CPU on the build system, which may affect which optimizations the compiler uses or the layout of certain data structures;</li>\n<li>the compiler version being used, as well as compiler options passed to it, which affect how the code is compiled;</li>\n<li>the name of the directory containing the source code, which may appear in debug information;</li>\n<li>the user name, group name, uid, and gid of the account running the build, which may appear in file metadata in an archive;</li>\n<li>and many more.</li>\n</ul>\n<p>\\\nTo have a reproducible build, every relevant input must be configurable in the build, and then the binaries must be posted alongside an explicit configuration listing every relevant input. If you’ve done that, you have a reproducible build. Congratulations!</p>\n<p>\\\nWe’re not done, though. If the binaries can only be reproduced if you first find a computer with the right architecture, install a specific operating system version, compiler version, put the source code in the right directory, set your user identity correctly, and so on, that may be too much work in practice for anyone to bother.</p>\n<p>\\\nWe want builds to be not just reproducible but <em>easy to reproduce</em>. To do that, we need to identify relevant inputs and then, instead of documenting them, eliminate them. The build obviously has to depend on the source code being built, but everything else can be eliminated. When a build’s only relevant input is its source code, let’s call that <em>perfectly reproducible</em>.</p>\n<h2 id=\"perfectlyreproduciblebuildsforgo\">Perfectly Reproducible Builds for Go</h2>\n<p>As of Go 1.21, the Go toolchain is perfectly reproducible: its only relevant input is the source code for that build. We can build a specific toolchain (say, Go for Linux/x86-64) on a Linux/x86-64 host, or a Windows/ARM64 host, or a FreeBSD/386 host, or any other host that supports Go, and we can use any Go bootstrap compiler, including bootstrapping all the way back to Go 1.4’s C implementation, and we can vary any other details. None of that changes the toolchains that are built. If we start with the same toolchain source code, we will get the exact same toolchain binaries out.</p>\n<p>\\\nThis perfect reproducibility is the culmination of efforts dating back originally to Go 1.10, although most of the effort was concentrated in Go 1.20 and Go 1.21. This section highlights some of the most interesting relevant inputs that we eliminated.</p>\n<h3 id=\"reproducibilityingo110\">Reproducibility in Go 1.10</h3>\n<p>Go 1.10 introduced a content-aware build cache that decides whether targets are up-to-date based on a fingerprint of the build inputs instead of file modification times. Because the toolchain itself is one of those build inputs, and because Go is written in Go, the <a href=\"/s/go15bootstrap\">bootstrap process</a> would only converge if the toolchain build on a single machine was reproducible. The overall toolchain build looks like this:</p>\n<p><img src=\"https://cdn.hackernoon.com/images/eQHzh6rz7ETBHLjs0KzCl1Dooqp2-7r03a8v.jpeg\" alt=\"\" /></p>\n<p>\\\nWe start by building the sources for the current Go toolchain using an earlier Go version, the bootstrap toolchain (Go 1.10 used Go 1.4, written in C; Go 1.21 uses Go 1.17). That produces “toolchain1”, which we use to build everything again, producing “toolchain2”, which we use to build everything again, producing “toolchain3”.</p>\n<p>\\\nToolchain1 and toolchain2 have been built from the same sources but with different Go implementations (compilers and libraries), so their binaries are certain to be different. However, if both Go implementations are non-buggy, correct implementations, toolchain1 and toolchain2 should behave exactly the same. In particular, when presented with the Go 1.X sources, toolchain1’s output (toolchain2) and toolchain2’s output (toolchain3) should be identical, meaning toolchain2 and toolchain3 should be identical.</p>\n<p>\\\nAt least, that’s the idea. Making that true in practice required removing a couple unintentional inputs:</p>\n<p><strong>Randomness.</strong> Map iteration and running work in multiple goroutines serialized with locks both introduce randomness in the order that results may be generated. This randomness can make the toolchain produce one of several different possible outputs each time it runs. To make the build reproducible, we had to find each of these and sort the relevant list of items before using it to generate output.</p>\n<p>\\\n<strong>Bootstrap Libraries.</strong> Any library used by the compiler that can choose from multiple different correct outputs might change its output from one Go version to the next. If that library output change causes a compiler output change, then toolchain1 and toolchain2 will not be semantically identical, and toolchain2 and toolchain3 will not be bit-for-bit identical.</p>\n<p>\\\nThe canonical example is the <code>sort</code> package, which can place elements that compare equal in <a href=\"/blog/compat#output\">any order it likes</a>. A register allocator might sort to prioritize commonly used variables, and the linker sorts symbols in the data section by size. To completely eliminate any effect from the sorting algorithm, the comparison function used must never report two distinct elements as equal. In practice, this invariant turned out to be too onerous to impose on every use of sort in the toolchain, so instead we arranged to copy the Go 1.X <code>sort</code> package into the source tree that is presented to the bootstrap compiler. That way, the compiler uses the same sort algorithm when using the bootstrap toolchain as it does when built with itself.</p>\n<p>\\\nAnother package we had to copy was <code>compress/zlib</code>, because the linker writes compressed debug information, and optimizations to compression libraries can change the exact output. Over time, we’ve <a href=\"https://go.googlesource.com/go/+/go1.21.0/src/cmd/dist/buildtool.go#55\">added other packages to that list too</a>. This approach has the added benefit of allowing the Go 1.X compiler to use new APIs added to those packages immediately, at the cost that those packages must be written to compile with older versions of Go.</p>\n<h3 id=\"reproducibilityingo120\">Reproducibility in Go 1.20</h3>\n<p>Work on Go 1.20 prepared for both easy reproducible builds and <a href=\"toolchain\">toolchain management</a> by removing two more relevant inputs from the toolchain build.</p>\n<p>\\\n<strong>Host C toolchain.</strong> Some Go packages, most notably <code>net</code>, default to <a href=\"cgo\">using </a><code>cgo</code> on most operating systems. In some cases, such as macOS and Windows, invoking system DLLs using <code>cgo</code> is the only reliable way to resolve host names. When we use <code>cgo</code>, though, we invoke the host C toolchain (meaning a specific C compiler and C library), and different toolchains have different compilation algorithms and library code, producing different outputs. The build graph for a <code>cgo</code> package looks like:</p>\n<p><img src=\"https://cdn.hackernoon.com/images/eQHzh6rz7ETBHLjs0KzCl1Dooqp2-ej13a0g.jpeg\" alt=\"\" /></p>\n<p>\\\nThe host C toolchain is therefore a relevant input to the pre-compiled <code>net.a</code> that ships with the toolchain. For Go 1.20, we decided to fix this by removing <code>net.a</code> from the toolchain. That is, Go 1.20 stopped shipping pre-compiled packages to seed the build cache with. Now, the first time a program uses package <code>net</code>, the Go toolchain compiles it using the local system’s C toolchain and caches that result. </p>\n<p>\\\nIn addition to removing a relevant input from toolchain builds and making toolchain downloads smaller, not shipping pre-compiled packages also makes toolchain downloads more portable. If we build package <code>net</code> on one system with one C toolchain and then compile other parts of the program on a different system with a different C toolchain, in general there is no guarantee that the two parts can be linked together.</p>\n<p>\\\nOne reason we shipped the pre-compiled <code>net</code> package in the first place was to allow building programs that used package net even on systems without a C toolchain installed. If there’s no pre-compiled package, what happens on those systems? The answer varies by operating system, but in all cases we arranged for the Go toolchain to continue to work well for building pure Go programs without a host C toolchain.</p>\n<p>\\</p>\n<ul>\n<li>On macOS, we rewrote package net using the underlying mechanisms that cgo would use, without any actual C code. This avoids invoking the host C toolchain but still emits a binary that refers to the required system DLLs. This approach is only possible because every Mac has the same dynamic libraries installed. Making the non-cgo macOS package net use the system DLLs also meant that cross-compiled macOS executables now use the system DLLs for network access, resolving a long-standing feature request.</li>\n</ul>\n<p>\\</p>\n<ul>\n<li>On Windows, package net already made direct use of DLLs without C code, so nothing needed to be changed.</li>\n</ul>\n<p>\\</p>\n<ul>\n<li>On Unix systems, we cannot assume a specific DLL interface to network code, but the pure Go version works fine for systems that use typical IP and DNS setups. Also, it is much easier to install a C toolchain on Unix systems than it is on macOS and especially Windows. We changed the <code>go</code> command to enable or disable <code>cgo</code> automatically based on whether the system has a C toolchain installed. Unix systems without a C toolchain fall back to the pure Go version of package net, and in the rare cases where that’s not good enough, they can install a C toolchain.</li>\n</ul>\n<p>\\\nHaving dropped the pre-compiled packages, the only part of the Go toolchain that still depended on the host C toolchain was binaries built using package net, specifically the <code>go</code> command. With the macOS improvements, it was now viable to build those commands with <code>cgo</code> disabled, completely removing the host C toolchain as an input, but we left that final step for Go 1.21.</p>\n<p>\\\n<strong>Host dynamic linker.</strong> When programs use <code>cgo</code> on a system using dynamically linked C libraries, the resulting binaries contain the path to the system’s dynamic linker, something like <code>/lib64/ld-linux-x86-64.so.2</code>. If the path is wrong, the binaries don’t run. Typically each operating system/architecture combination has a single correct answer for this path. Unfortunately, musl-based Linuxes like Alpine Linux use a different dynamic linker than glibc-based Linuxes like Ubuntu. To make Go run at all on Alpine Linux, in Go bootstrap process looked like this:</p>\n<p><img src=\"https://cdn.hackernoon.com/images/eQHzh6rz7ETBHLjs0KzCl1Dooqp2-4k23atf.jpeg\" alt=\"\" /></p>\n<p>\\\nThe bootstrap program cmd/dist inspected the local system’s dynamic linker and wrote that value into a new source file compiled along with the rest of the linker sources, effectively hard-coding that default into the linker itself. Then when the linker built a program from a set of compiled packages, it used that default. The result is that a Go toolchain built on Alpine is different from a toolchain built on Ubuntu: the host configuration is a relevant input to the toolchain build. This is a reproducibility problem but also a portability problem: a Go toolchain built on Alpine doesn’t build working binaries or even run on Ubuntu, and vice versa.</p>\n<p>\\\nFor Go 1.20, we took a step toward fixing the reproducibility problem by changing the linker to consult the host configuration when it is running, instead of having a default hard-coded at toolchain build time:</p>\n<p><img src=\"https://cdn.hackernoon.com/images/eQHzh6rz7ETBHLjs0KzCl1Dooqp2-u033a9y.jpeg\" alt=\"\" /></p>\n<p>\\\nThis fixed the portability of the linker binary on Alpine Linux, although not the overall toolchain, since the <code>go</code> command still used package <code>net</code> and therefore <code>cgo</code> and therefore had a dynamic linker reference in its own binary. Just as in the previous section, compiling the <code>go</code> command without <code>cgo</code> enabled would fix this, but we left that change for Go 1.21. (We didn’t feel there was enough time left in the Go 1.20 cycle to test such that change properly.)</p>\n<h3 id=\"reproducibilityingo121\">Reproducibility in Go 1.21</h3>\n<p>For Go 1.21, the goal of perfect reproducibility was in sight, and we took care of the remaining, mostly small, relevant inputs that remained.</p>\n<p>\\\n<strong>Host C toolchain and dynamic linker.</strong> As discussed above, Go 1.20 took important steps toward removing the host C toolchain and dynamic linker as relevant inputs. Go 1.21 completed the removal of these relevant inputs by building the toolchain with <code>cgo</code> disabled. This improved portability of the toolchain too: Go 1.21 is the first Go release where the standard Go toolchain runs unmodified on Alpine Linux systems.</p>\n<p>\\\nRemoving these relevant inputs made it possible to cross-compile a Go toolchain from a different system without any loss in functionality. That in turn improved the supply chain security of the Go toolchain: we can now build Go toolchains for all target systems using a trusted Linux/x86-64 system, instead of needing to arrange a separate trusted system for each target. As a result, Go 1.21 is the first release to include posted binaries for all systems at <a href=\"/dl/\">go.dev/dl/</a>.</p>\n<p>\\\n<strong>Source directory.</strong> Go programs include full paths in the runtime and debugging metadata, so that when a program crashes or is run in a debugger, stack traces include the full path to the source file, not just the name of the file in an unspecified directory. Unfortunately, including the full path makes the directory where the source code is stored a relevant input to the build. To fix this, Go 1.21 changed the release toolchain builds to install commands like the compiler using <code>go install -trimpath</code>, which replaces the source directory with the module path of the code. If a released compiler crashes, the stack trace will print paths like <code>cmd/compile/main.go</code> instead of <code>/home/user/go/src/cmd/compile/main.go</code>. </p>\n<p>\\\nSince the full paths would refer to a directory on a different machine anyway, this rewrite is no loss. On the other hand, for non-release builds, we keep the full path, so that when developers working on the compiler itself cause it to crash, IDEs and other tools reading those crashes can easily find the correct source file.</p>\n<p>\\\n<strong>Host operating system.</strong> Paths on Windows systems are backslash-separated, like <code>cmd\\compile\\main.go</code>. Other systems use forward slashes, like <code>cmd/compile/main.go</code>. Although earlier versions of Go had normalized most of these paths to use forward slashes, one inconsistency had crept back in, causing slightly different toolchain builds on Windows. We found and fixed the bug.</p>\n<p>\\\n<strong>Host architecture.</strong> Go runs on a variety of ARM systems and can emit code using a software library for floating-point math (SWFP) or using hardware floating-point instructions (HWFP). Toolchains defaulting to one mode or the other will necessarily differ. Like we saw with the dynamic linker earlier, the Go bootstrap process inspected the build system to make sure that the resulting toolchain worked on that system. For historical reasons, the rule was “assume SWFP unless the build is running on an ARM system with floating-point hardware”, with cross-compiled toolchains assuming SWFP. </p>\n<p>\\\nThe vast majority of ARM systems today do have floating-point hardware, so this introduced an unnecessary difference between natively compiled and cross-compiled toolchains, and as a further wrinkle, Windows ARM builds always assumed HWFP, making the decision operating system-dependent. We changed the rule to be “assume HWFP unless the build is running on an ARM system without floating-point hardware”. This way, cross-compilation and builds on modern ARM systems produce identical toolchains.</p>\n<p>\\\n<strong>Packaging logic.</strong> All the code to create the actual toolchain archives we post for download lived in a separate Git repository, golang.org/x/build, and the exact details of how archives get packaged does change over time. If you wanted to reproduce those archives, you needed to have the right version of that repository. We removed this relevant input by moving the code to package the archives into the main Go source tree, as <code>cmd/distpack</code>. As of Go 1.21, if you have the sources for a given version of Go, you also have the sources for packaging the archives. The golang.org/x/build repository is no longer a relevant input.</p>\n<p>\\\n<strong>User IDs.</strong> The tar archives we posted for download were built from a distribution written to the file system, and using <code>tar.FileInfoHeader</code> copies the user and group IDs from the file system into the tar file, making the user running the build a relevant input. We changed the archiving code to clear these.</p>\n<p>\\\n<strong>Current time.</strong> Like with user IDs, the tar and zip archives we posted for download had been built by copying the file system modification times into the archives, making the current time a relevant input. We could have cleared the time, but we thought it would look surprising and possibly even break some tools to use the Unix or MS-DOS zero time. Instead, we changed the go/VERSION file stored in the repository to add the time associated with that version:</p>\n<pre><code>$ cat go1.21.0/VERSION\ngo1.21.0\ntime 2023-08-04T20:14:06Z\n$\n</code></pre>\n<p>The packagers now copy the time from the VERSION file when writing files to archives, instead of copying the local file’s modification times.</p>\n<p>\\\n<strong>Cryptographic signing keys.</strong> The Go toolchain for macOS won’t run on end-user systems unless we sign the binaries with an Apple-approved signing key. We use an internal system to get them signed with Google’s signing key, and obviously we cannot share that secret key in order to allow others to reproduce the signed binaries. Instead, we wrote a verifier that can check whether two binaries are identical except for their signatures.</p>\n<p>\\\n<strong>OS-specific packagers.</strong> We use the Xcode tools <code>pkgbuild</code> and <code>productbuild</code> to create the downloadable macOS PKG installer, and we use WiX to create the downloadable Windows MSI installer. We don’t want verifiers to need the same exact versions of those tools, so we took the same approach as for the cryptographic signing keys, writing a verifier that can look inside the packages and check that the toolchain files are exactly as expected.</p>\n<h2 id=\"verifyingthegotoolchains\">Verifying the Go Toolchains</h2>\n<p>It’s not enough to make Go toolchains reproducible once. We want to make sure they stay reproducible, and we want to make sure others can reproduce them easily.</p>\n<p>\\\nTo keep ourselves honest, we now build all Go distributions on both a trusted Linux/x86-64 system and a Windows/x86-64 system. Except for the architecture, the two systems have almost nothing in common. The two systems must produce bit-for-bit identical archives or else we do not proceed with the release.</p>\n<p>\\\nTo allow others to verify that we’re honest, we’ve written and published a verifier, <code>golang.org/x/build/cmd/gorebuild</code>. That program will start with the source code in our Git repository and rebuild the current Go versions, checking that they match the archives posted on <a href=\"/dl/\">go.dev/dl</a>. Most archives are required to match bit-for-bit. As mentioned above, there are three exceptions where a more relaxed check is used:</p>\n<p>\\</p>\n<ul>\n<li>The macOS tar.gz file is expected to differ, but then the verifier compares the contents inside. The rebuilt and posted copies must contain the same files, and all the files must match exactly, except for executable binaries. Executable binaries must match exactly after stripping code signatures.</li>\n</ul>\n<p>\\</p>\n<ul>\n<li>The macOS PKG installer is not rebuilt. Instead, the verifier reads the files inside the PKG installer and checks that they match the macOS tar.gz exactly, again after code signature stripping. In the long term, the PKG creation is trivial enough that it could potentially be added to cmd/distpack, but the verifier would still have to parse the PKG file to run the signature-ignoring code executable comparison.</li>\n</ul>\n<p>\\</p>\n<ul>\n<li>The Windows MSI installer is not rebuilt. Instead, the verifier invokes the Linux program <code>msiextract</code> to extract the files inside and check that they match the rebuilt Windows zip file exactly. In the long term, perhaps the MSI creation could be added to cmd/distpack, and then the verifier could use a bit-for-bit MSI comparison.</li>\n</ul>\n<p>\\\nWe run <code>gorebuild</code> nightly, posting the results at <a href=\"/rebuild\">go.dev/rebuild</a>, and of course anyone else can run it too.</p>\n<h2 id=\"verifyingubuntusgotoolchain\">Verifying Ubuntu’s Go Toolchain</h2>\n<p>The Go toolchain’s easily reproducible builds should mean that the binaries in the toolchains posted on go.dev match the binaries included in other packaging systems, even when those packagers build from source. Even if the packagers have compiled with different configurations or other changes, the easily reproducible builds should still make it easy to reproduce their binaries. To demonstrate this, let’s reproduce the Ubuntu <code>golang-1.21</code> package version <code>1.21.0-1</code> for Linux/x86-64.</p>\n<p>\\\nTo start, we need to download and extract the Ubuntu packages, which are <a href=\"https://linux.die.net/man/1/ar\">ar(1) archives</a> containing zstd-compressed tar archives:</p>\n<pre><code>$ mkdir deb\n$ cd deb\n$ curl -LO http://mirrors.kernel.org/ubuntu/pool/main/g/golang-1.21/golang-1.21-src_1.21.0-1_all.deb\n$ ar xv golang-1.21-src_1.21.0-1_all.deb\nx - debian-binary\nx - control.tar.zst\nx - data.tar.zst\n$ unzstd &lt; data.tar.zst | tar xv\n...\nx ./usr/share/go-1.21/src/archive/tar/common.go\nx ./usr/share/go-1.21/src/archive/tar/example_test.go\nx ./usr/share/go-1.21/src/archive/tar/format.go\nx ./usr/share/go-1.21/src/archive/tar/fuzz_test.go\n...\n$\n</code></pre>\n<p>\\\nThat was the source archive. Now the amd64 binary archive:</p>\n<pre><code>$ rm -f debian-binary *.zst\n$ curl -LO http://mirrors.kernel.org/ubuntu/pool/main/g/golang-1.21/golang-1.21-go_1.21.0-1_amd64.deb\n$ ar xv golang-1.21-src_1.21.0-1_all.deb\nx - debian-binary\nx - control.tar.zst\nx - data.tar.zst\n$ unzstd &lt; data.tar.zst | tar xv | grep -v '/$'\n...\nx ./usr/lib/go-1.21/bin/go\nx ./usr/lib/go-1.21/bin/gofmt\nx ./usr/lib/go-1.21/go.env\nx ./usr/lib/go-1.21/pkg/tool/linux_amd64/addr2line\nx ./usr/lib/go-1.21/pkg/tool/linux_amd64/asm\nx ./usr/lib/go-1.21/pkg/tool/linux_amd64/buildid\n...\n$\n</code></pre>\n<p>\\\nUbuntu splits the normal Go tree into two halves, in /usr/share/go-1.21 and /usr/lib/go-1.21. Let’s put them back together:</p>\n<pre><code>$ mkdir go-ubuntu\n$ cp -R usr/share/go-1.21/* usr/lib/go-1.21/* go-ubuntu\ncp: cannot overwrite directory go-ubuntu/api with non-directory usr/lib/go-1.21/api\ncp: cannot overwrite directory go-ubuntu/misc with non-directory usr/lib/go-1.21/misc\ncp: cannot overwrite directory go-ubuntu/pkg/include with non-directory usr/lib/go-1.21/pkg/include\ncp: cannot overwrite directory go-ubuntu/src with non-directory usr/lib/go-1.21/src\ncp: cannot overwrite directory go-ubuntu/test with non-directory usr/lib/go-1.21/test\n$\n</code></pre>\n<p>\\\nThe errors are complaining about copying symlinks, which we can ignore.</p>\n<p>\\\nNow we need to download and extract the upstream Go sources:</p>\n<pre><code>$ curl -LO https://go.googlesource.com/go/+archive/refs/tags/go1.21.0.tar.gz\n$ mkdir go-clean\n$ cd go-clean\n$ curl -L https://go.googlesource.com/go/+archive/refs/tags/go1.21.0.tar.gz | tar xzv\n...\nx src/archive/tar/common.go\nx src/archive/tar/example_test.go\nx src/archive/tar/format.go\nx src/archive/tar/fuzz_test.go\n...\n$\n</code></pre>\n<p>\\\nTo skip some trial and error, it turns out that Ubuntu builds Go with <code>GO386=softfloat</code>, which forces the use of software floating point when compiling for 32-bit x86, and strips (removes symbol tables from) the resulting ELF binaries. Let’s start with a <code>GO386=softfloat</code> build:</p>\n<pre><code>$ cd src\n$ GOOS=linux GO386=softfloat ./make.bash -distpack\nBuilding Go cmd/dist using /Users/rsc/sdk/go1.17.13. (go1.17.13 darwin/amd64)\nBuilding Go toolchain1 using /Users/rsc/sdk/go1.17.13.\nBuilding Go bootstrap cmd/go (go_bootstrap) using Go toolchain1.\nBuilding Go toolchain2 using go_bootstrap and Go toolchain1.\nBuilding Go toolchain3 using go_bootstrap and Go toolchain2.\nBuilding commands for host, darwin/amd64.\nBuilding packages and commands for target, linux/amd64.\nPackaging archives for linux/amd64.\ndistpack: 818d46ede85682dd go1.21.0.src.tar.gz\ndistpack: 4fcd8651d084a03d go1.21.0.linux-amd64.tar.gz\ndistpack: eab8ed80024f444f v0.0.1-go1.21.0.linux-amd64.zip\ndistpack: 58528cce1848ddf4 v0.0.1-go1.21.0.linux-amd64.mod\ndistpack: d8da1f27296edea4 v0.0.1-go1.21.0.linux-amd64.info\n---\nInstalled Go for linux/amd64 in /Users/rsc/deb/go-clean\nInstalled commands in /Users/rsc/deb/go-clean/bin\n*** You need to add /Users/rsc/deb/go-clean/bin to your PATH.\n$\n</code></pre>\n<p>\\\nThat left the standard package in <code>pkg/distpack/go1.21.0.linux-amd64.tar.gz</code>. Let’s unpack it and strip the binaries to match Ubuntu:</p>\n<pre><code>$ cd ../..\n$ tar xzvf go-clean/pkg/distpack/go1.21.0.linux-amd64.tar.gz\nx go/CONTRIBUTING.md\nx go/LICENSE\nx go/PATENTS\nx go/README.md\nx go/SECURITY.md\nx go/VERSION\n...\n$ elfstrip go/bin/* go/pkg/tool/linux_amd64/*\n$\n</code></pre>\n<p>\\\nNow we can diff the Go toolchain we’ve created on our Mac with the Go toolchain that Ubuntu ships:</p>\n<pre><code>$ diff -r go go-ubuntu\nOnly in go: CONTRIBUTING.md\nOnly in go: LICENSE\nOnly in go: PATENTS\nOnly in go: README.md\nOnly in go: SECURITY.md\nOnly in go: codereview.cfg\nOnly in go: doc\nOnly in go: lib\nBinary files go/misc/chrome/gophertool/gopher.png and go-ubuntu/misc/chrome/gophertool/gopher.png differ\nOnly in go-ubuntu/pkg/tool/linux_amd64: dist\nOnly in go-ubuntu/pkg/tool/linux_amd64: distpack\nOnly in go/src: all.rc\nOnly in go/src: clean.rc\nOnly in go/src: make.rc\nOnly in go/src: run.rc\ndiff -r go/src/syscall/mksyscall.pl go-ubuntu/src/syscall/mksyscall.pl\n1c1\n&lt; #!/usr/bin/env perl\n---\n&gt; #! /usr/bin/perl\n...\n$\n</code></pre>\n<p>We’ve successfully reproduced the Ubuntu package’s executables and identified the complete set of changes that remain:</p>\n<ul>\n<li>Various metadata and supporting files have been deleted.</li>\n</ul>\n<p>\\</p>\n<ul>\n<li>The <code>gopher.png</code> file has been modified. On closer inspection the two are identical except for an embedded timestamp that Ubuntu has updated. Perhaps Ubuntu’s packaging scripts recompressed the png with a tool that rewrites the timestamp even when it cannot improve on the existing compression.</li>\n</ul>\n<p>\\</p>\n<ul>\n<li>The binaries <code>dist</code> and <code>distpack</code>, which are built during bootstrap but not included in standard archives, have been included in the Ubuntu package.</li>\n</ul>\n<p>\\</p>\n<ul>\n<li>The Plan 9 build scripts (<code>*.rc</code>) have been deleted, although the Windows build scripts (<code>*.bat</code>) remain.</li>\n</ul>\n<p>\\</p>\n<ul>\n<li><code>mksyscall.pl</code> and seven other Perl scripts not shown have had their headers changed.</li>\n</ul>\n<p>\\\nNote in particular that we’ve reconstructed the toolchain binaries bit-for-bit: they do not show up in the diff at all. That is, we proved that the Ubuntu Go binaries correspond exactly to the upstream Go sources.</p>\n<p>\\\nEven better, we proved this without using any Ubuntu software at all: these commands were run on a Mac, and <code>unzstd</code> and <code>elfstrip</code> are short Go programs. A sophisticated attacker might insert malicious code into an Ubuntu package by changing the package-creation tools. If they did, reproducing the Go Ubuntu package from clean sources using those malicious tools would still produce bit-for-bit identical copies of the malicious packages. </p>\n<p>\\\nThis attack would be invisible to that kind of rebuild, much like <a href=\"https://dl.acm.org/doi/10.1145/358198.358210\">Ken Thompson’s compiler attack</a>. Verifying the Ubuntu packages using no Ubuntu software at all is a much stronger check. Go’s perfectly reproducible builds, which don’t depend on unindented details like the host operating system, host architecture, and host C toolchain, are what make this stronger check possible.</p>\n<p>\\\n(As an aside for the historical record, Ken Thompson told me once that his attack was in fact detected, because the compiler build stopped being reproducible. It had a bug: a string constant in the backdoor added to the compiler was imperfectly handled and grew by a single NUL byte each time the compiler compiled itself. Eventually someone noticed the non-reproducible build and tried to find the cause by compiling to assembly. The compiler’s backdoor did not reproduce itself into assembly output at all, so assembling that output removed the backdoor.)</p>\n<h2 id=\"conclusion\">Conclusion</h2>\n<p>Reproducible builds are an important tool for strengthening the open-source supply chain. Frameworks like <a href=\"https://slsa.dev/\">SLSA</a> focus on provenance and a software chain of custody that can be used to inform decisions about trust. Reproducible builds complement that approach by providing a way to verify that the trust is well-placed.</p>\n<p>\\\nPerfect reproducibility (when the source files are the build’s only relevant input) is only possible for programs that build themselves, like compiler toolchains. It is a lofty but worthwhile goal precisely because self-hosting compiler toolchains are otherwise quite difficult to verify. Go’s perfect reproducibility means that, assuming packagers don’t modify the source code, every repackaging of Go 1.21.0 for Linux/x86-64 (substitute your favorite system) in any form should be distributing exactly the same binaries, even when they all build from source. We’ve seen that this is not quite true for Ubuntu Linux, but perfect reproducibility still lets us reproduce the Ubuntu packaging using a very different, non-Ubuntu system.</p>\n<p>\\\nIdeally all open source software distributed in binary form would have easy-to-reproduce builds. In practice, as we’ve seen in this post, it is very easy for unintended inputs to leak into builds. For Go programs that don’t need <code>cgo</code>, a reproducible build is as simple as compiling with <code>CGO_ENABLED=0 go build -trimpath</code>. Disabling <code>cgo</code> removes the host C toolchain as a relevant input, and <code>-trimpath</code> removes the current directory. If your program does need <code>cgo</code>, you need to arrange for a specific host C toolchain version before running <code>go build</code>, such as by running the build in a specific virtual machine or container image.</p>\n<p>\\\nMoving beyond Go, the <a href=\"https://reproducible-builds.org/\">Reproducible Builds</a> project aims to improve reproducibility of all open source and is a good starting point for more information about making your own software builds reproducible.</p>\n<hr />\n<p><em>Russ Cox</em></p>\n<p>\\\n<em>Photo by <a href=\"https://unsplash.com/@a_pudov?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash\">Alex Pudov</a> on <a href=\"https://unsplash.com/photos/a-close-up-of-a-chain-with-a-blurry-background-cmrcu5Gb9ko?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash\">Unsplash</a></em></p>\n<p>\\\n<em>This article is available on&nbsp;<strong><a href=\"https://go.dev/blog/rebuild\">The Go Blog</a></strong>&nbsp;under a CC BY 4.0 DEED license.</em></p>",
          "content:encodedSnippet": "One of the key benefits of open-source software is that anyone can read the source code and inspect what it does. And yet most software, even open-source software, is downloaded in the form of compiled binaries, which are much more difficult to inspect. If an attacker wanted to run a supply chain attack on an open-source project, the least visible way would be to replace the binaries being served while leaving the source code unmodified.\n\\\nThe best way to address this kind of attack is to make open-source software builds reproducible, meaning that a build that starts with the same sources produces the same outputs every time it runs. That way, anyone can verify that posted binaries are free of hidden changes by building from authentic sources and checking that the rebuilt binaries are bit-for-bit identical to the posted binaries. That approach proves the binaries have no backdoors or other changes not present in the source code, without having to disassemble or look inside them at all. Since anyone can verify the binaries, independent groups can easily detect and report supply chain attacks.\n\\\nAs supply chain security becomes more important, so do reproducible builds, because they provide a simple way to verify the posted binaries for open-source projects.\n\\\nGo 1.21.0 is the first Go toolchain with perfectly reproducible builds. Earlier toolchains were possible to reproduce, but only with significant effort, and probably no one did: they just trusted that the binaries posted on go.dev/dl were the correct ones. Now it’s easy to “trust but verify.”\n\\\nThis post explains what goes into making builds reproducible, examines the many changes we had to make to Go to make Go toolchains reproducible, and then demonstrates one of the benefits of reproducibility by verifying the Ubuntu package for Go 1.21.0.\nMaking a Build Reproducible\nComputers are generally deterministic, so you might think all builds would be equally reproducible. That’s only true from a certain point of view. Let’s call a piece of information a relevant input when the output of a build can change depending on that input. A build is reproducible if it can be repeated with all the same relevant inputs. Unfortunately, lots of build tools turn out to incorporate inputs that we would usually not realize are relevant and that might be difficult to recreate or provide as input. Let’s call an input an unintentional input when it turns out to be relevant but we didn’t mean it to be.\n\\\nThe most common unintentional input in build systems is the current time. If a build writes an executable to disk, the file system records the current time as the executable’s modification time. If the build then packages that file using a tool like “tar” or “zip”, the modification time is written into the archive. We certainly didn’t want our build to change based on the current time, but it does. So the current time turns out to be an unintentional input to the build. Worse, most programs don’t let you provide the current time as an input, so there is no way to repeat this build. To fix this, we might set the time stamps on created files to Unix time 0 or to a specific time read from one of the build’s source files. That way, the current time is no longer a relevant input to the build.\n\\\nCommon relevant inputs to a build include:\nthe specific version of the source code to build;\nthe specific versions of dependencies that will be included in the build;\nthe operating system running the build, which may affect path names in the resulting binaries;\nthe architecture of the CPU on the build system, which may affect which optimizations the compiler uses or the layout of certain data structures;\nthe compiler version being used, as well as compiler options passed to it, which affect how the code is compiled;\nthe name of the directory containing the source code, which may appear in debug information;\nthe user name, group name, uid, and gid of the account running the build, which may appear in file metadata in an archive;\nand many more.\n\\\nTo have a reproducible build, every relevant input must be configurable in the build, and then the binaries must be posted alongside an explicit configuration listing every relevant input. If you’ve done that, you have a reproducible build. Congratulations!\n\\\nWe’re not done, though. If the binaries can only be reproduced if you first find a computer with the right architecture, install a specific operating system version, compiler version, put the source code in the right directory, set your user identity correctly, and so on, that may be too much work in practice for anyone to bother.\n\\\nWe want builds to be not just reproducible but easy to reproduce. To do that, we need to identify relevant inputs and then, instead of documenting them, eliminate them. The build obviously has to depend on the source code being built, but everything else can be eliminated. When a build’s only relevant input is its source code, let’s call that perfectly reproducible.\nPerfectly Reproducible Builds for Go\nAs of Go 1.21, the Go toolchain is perfectly reproducible: its only relevant input is the source code for that build. We can build a specific toolchain (say, Go for Linux/x86-64) on a Linux/x86-64 host, or a Windows/ARM64 host, or a FreeBSD/386 host, or any other host that supports Go, and we can use any Go bootstrap compiler, including bootstrapping all the way back to Go 1.4’s C implementation, and we can vary any other details. None of that changes the toolchains that are built. If we start with the same toolchain source code, we will get the exact same toolchain binaries out.\n\\\nThis perfect reproducibility is the culmination of efforts dating back originally to Go 1.10, although most of the effort was concentrated in Go 1.20 and Go 1.21. This section highlights some of the most interesting relevant inputs that we eliminated.\nReproducibility in Go 1.10\nGo 1.10 introduced a content-aware build cache that decides whether targets are up-to-date based on a fingerprint of the build inputs instead of file modification times. Because the toolchain itself is one of those build inputs, and because Go is written in Go, the bootstrap process would only converge if the toolchain build on a single machine was reproducible. The overall toolchain build looks like this:\n\n\\\nWe start by building the sources for the current Go toolchain using an earlier Go version, the bootstrap toolchain (Go 1.10 used Go 1.4, written in C; Go 1.21 uses Go 1.17). That produces “toolchain1”, which we use to build everything again, producing “toolchain2”, which we use to build everything again, producing “toolchain3”.\n\\\nToolchain1 and toolchain2 have been built from the same sources but with different Go implementations (compilers and libraries), so their binaries are certain to be different. However, if both Go implementations are non-buggy, correct implementations, toolchain1 and toolchain2 should behave exactly the same. In particular, when presented with the Go 1.X sources, toolchain1’s output (toolchain2) and toolchain2’s output (toolchain3) should be identical, meaning toolchain2 and toolchain3 should be identical.\n\\\nAt least, that’s the idea. Making that true in practice required removing a couple unintentional inputs:\nRandomness. Map iteration and running work in multiple goroutines serialized with locks both introduce randomness in the order that results may be generated. This randomness can make the toolchain produce one of several different possible outputs each time it runs. To make the build reproducible, we had to find each of these and sort the relevant list of items before using it to generate output.\n\\\nBootstrap Libraries. Any library used by the compiler that can choose from multiple different correct outputs might change its output from one Go version to the next. If that library output change causes a compiler output change, then toolchain1 and toolchain2 will not be semantically identical, and toolchain2 and toolchain3 will not be bit-for-bit identical.\n\\\nThe canonical example is the sort package, which can place elements that compare equal in any order it likes. A register allocator might sort to prioritize commonly used variables, and the linker sorts symbols in the data section by size. To completely eliminate any effect from the sorting algorithm, the comparison function used must never report two distinct elements as equal. In practice, this invariant turned out to be too onerous to impose on every use of sort in the toolchain, so instead we arranged to copy the Go 1.X sort package into the source tree that is presented to the bootstrap compiler. That way, the compiler uses the same sort algorithm when using the bootstrap toolchain as it does when built with itself.\n\\\nAnother package we had to copy was compress/zlib, because the linker writes compressed debug information, and optimizations to compression libraries can change the exact output. Over time, we’ve added other packages to that list too. This approach has the added benefit of allowing the Go 1.X compiler to use new APIs added to those packages immediately, at the cost that those packages must be written to compile with older versions of Go.\nReproducibility in Go 1.20\nWork on Go 1.20 prepared for both easy reproducible builds and toolchain management by removing two more relevant inputs from the toolchain build.\n\\\nHost C toolchain. Some Go packages, most notably net, default to using cgo on most operating systems. In some cases, such as macOS and Windows, invoking system DLLs using cgo is the only reliable way to resolve host names. When we use cgo, though, we invoke the host C toolchain (meaning a specific C compiler and C library), and different toolchains have different compilation algorithms and library code, producing different outputs. The build graph for a cgo package looks like:\n\n\\\nThe host C toolchain is therefore a relevant input to the pre-compiled net.a that ships with the toolchain. For Go 1.20, we decided to fix this by removing net.a from the toolchain. That is, Go 1.20 stopped shipping pre-compiled packages to seed the build cache with. Now, the first time a program uses package net, the Go toolchain compiles it using the local system’s C toolchain and caches that result. \n\\\nIn addition to removing a relevant input from toolchain builds and making toolchain downloads smaller, not shipping pre-compiled packages also makes toolchain downloads more portable. If we build package net on one system with one C toolchain and then compile other parts of the program on a different system with a different C toolchain, in general there is no guarantee that the two parts can be linked together.\n\\\nOne reason we shipped the pre-compiled net package in the first place was to allow building programs that used package net even on systems without a C toolchain installed. If there’s no pre-compiled package, what happens on those systems? The answer varies by operating system, but in all cases we arranged for the Go toolchain to continue to work well for building pure Go programs without a host C toolchain.\n\\\n\nOn macOS, we rewrote package net using the underlying mechanisms that cgo would use, without any actual C code. This avoids invoking the host C toolchain but still emits a binary that refers to the required system DLLs. This approach is only possible because every Mac has the same dynamic libraries installed. Making the non-cgo macOS package net use the system DLLs also meant that cross-compiled macOS executables now use the system DLLs for network access, resolving a long-standing feature request.\n\\\n\nOn Windows, package net already made direct use of DLLs without C code, so nothing needed to be changed.\n\\\n\nOn Unix systems, we cannot assume a specific DLL interface to network code, but the pure Go version works fine for systems that use typical IP and DNS setups. Also, it is much easier to install a C toolchain on Unix systems than it is on macOS and especially Windows. We changed the go command to enable or disable cgo automatically based on whether the system has a C toolchain installed. Unix systems without a C toolchain fall back to the pure Go version of package net, and in the rare cases where that’s not good enough, they can install a C toolchain.\n\\\nHaving dropped the pre-compiled packages, the only part of the Go toolchain that still depended on the host C toolchain was binaries built using package net, specifically the go command. With the macOS improvements, it was now viable to build those commands with cgo disabled, completely removing the host C toolchain as an input, but we left that final step for Go 1.21.\n\\\nHost dynamic linker. When programs use cgo on a system using dynamically linked C libraries, the resulting binaries contain the path to the system’s dynamic linker, something like /lib64/ld-linux-x86-64.so.2. If the path is wrong, the binaries don’t run. Typically each operating system/architecture combination has a single correct answer for this path. Unfortunately, musl-based Linuxes like Alpine Linux use a different dynamic linker than glibc-based Linuxes like Ubuntu. To make Go run at all on Alpine Linux, in Go bootstrap process looked like this:\n\n\\\nThe bootstrap program cmd/dist inspected the local system’s dynamic linker and wrote that value into a new source file compiled along with the rest of the linker sources, effectively hard-coding that default into the linker itself. Then when the linker built a program from a set of compiled packages, it used that default. The result is that a Go toolchain built on Alpine is different from a toolchain built on Ubuntu: the host configuration is a relevant input to the toolchain build. This is a reproducibility problem but also a portability problem: a Go toolchain built on Alpine doesn’t build working binaries or even run on Ubuntu, and vice versa.\n\\\nFor Go 1.20, we took a step toward fixing the reproducibility problem by changing the linker to consult the host configuration when it is running, instead of having a default hard-coded at toolchain build time:\n\n\\\nThis fixed the portability of the linker binary on Alpine Linux, although not the overall toolchain, since the go command still used package net and therefore cgo and therefore had a dynamic linker reference in its own binary. Just as in the previous section, compiling the go command without cgo enabled would fix this, but we left that change for Go 1.21. (We didn’t feel there was enough time left in the Go 1.20 cycle to test such that change properly.)\nReproducibility in Go 1.21\nFor Go 1.21, the goal of perfect reproducibility was in sight, and we took care of the remaining, mostly small, relevant inputs that remained.\n\\\nHost C toolchain and dynamic linker. As discussed above, Go 1.20 took important steps toward removing the host C toolchain and dynamic linker as relevant inputs. Go 1.21 completed the removal of these relevant inputs by building the toolchain with cgo disabled. This improved portability of the toolchain too: Go 1.21 is the first Go release where the standard Go toolchain runs unmodified on Alpine Linux systems.\n\\\nRemoving these relevant inputs made it possible to cross-compile a Go toolchain from a different system without any loss in functionality. That in turn improved the supply chain security of the Go toolchain: we can now build Go toolchains for all target systems using a trusted Linux/x86-64 system, instead of needing to arrange a separate trusted system for each target. As a result, Go 1.21 is the first release to include posted binaries for all systems at go.dev/dl/.\n\\\nSource directory. Go programs include full paths in the runtime and debugging metadata, so that when a program crashes or is run in a debugger, stack traces include the full path to the source file, not just the name of the file in an unspecified directory. Unfortunately, including the full path makes the directory where the source code is stored a relevant input to the build. To fix this, Go 1.21 changed the release toolchain builds to install commands like the compiler using go install -trimpath, which replaces the source directory with the module path of the code. If a released compiler crashes, the stack trace will print paths like cmd/compile/main.go instead of /home/user/go/src/cmd/compile/main.go. \n\\\nSince the full paths would refer to a directory on a different machine anyway, this rewrite is no loss. On the other hand, for non-release builds, we keep the full path, so that when developers working on the compiler itself cause it to crash, IDEs and other tools reading those crashes can easily find the correct source file.\n\\\nHost operating system. Paths on Windows systems are backslash-separated, like cmd\\compile\\main.go. Other systems use forward slashes, like cmd/compile/main.go. Although earlier versions of Go had normalized most of these paths to use forward slashes, one inconsistency had crept back in, causing slightly different toolchain builds on Windows. We found and fixed the bug.\n\\\nHost architecture. Go runs on a variety of ARM systems and can emit code using a software library for floating-point math (SWFP) or using hardware floating-point instructions (HWFP). Toolchains defaulting to one mode or the other will necessarily differ. Like we saw with the dynamic linker earlier, the Go bootstrap process inspected the build system to make sure that the resulting toolchain worked on that system. For historical reasons, the rule was “assume SWFP unless the build is running on an ARM system with floating-point hardware”, with cross-compiled toolchains assuming SWFP. \n\\\nThe vast majority of ARM systems today do have floating-point hardware, so this introduced an unnecessary difference between natively compiled and cross-compiled toolchains, and as a further wrinkle, Windows ARM builds always assumed HWFP, making the decision operating system-dependent. We changed the rule to be “assume HWFP unless the build is running on an ARM system without floating-point hardware”. This way, cross-compilation and builds on modern ARM systems produce identical toolchains.\n\\\nPackaging logic. All the code to create the actual toolchain archives we post for download lived in a separate Git repository, golang.org/x/build, and the exact details of how archives get packaged does change over time. If you wanted to reproduce those archives, you needed to have the right version of that repository. We removed this relevant input by moving the code to package the archives into the main Go source tree, as cmd/distpack. As of Go 1.21, if you have the sources for a given version of Go, you also have the sources for packaging the archives. The golang.org/x/build repository is no longer a relevant input.\n\\\nUser IDs. The tar archives we posted for download were built from a distribution written to the file system, and using tar.FileInfoHeader copies the user and group IDs from the file system into the tar file, making the user running the build a relevant input. We changed the archiving code to clear these.\n\\\nCurrent time. Like with user IDs, the tar and zip archives we posted for download had been built by copying the file system modification times into the archives, making the current time a relevant input. We could have cleared the time, but we thought it would look surprising and possibly even break some tools to use the Unix or MS-DOS zero time. Instead, we changed the go/VERSION file stored in the repository to add the time associated with that version:\n$ cat go1.21.0/VERSION\ngo1.21.0\ntime 2023-08-04T20:14:06Z\n$\n\nThe packagers now copy the time from the VERSION file when writing files to archives, instead of copying the local file’s modification times.\n\\\nCryptographic signing keys. The Go toolchain for macOS won’t run on end-user systems unless we sign the binaries with an Apple-approved signing key. We use an internal system to get them signed with Google’s signing key, and obviously we cannot share that secret key in order to allow others to reproduce the signed binaries. Instead, we wrote a verifier that can check whether two binaries are identical except for their signatures.\n\\\nOS-specific packagers. We use the Xcode tools pkgbuild and productbuild to create the downloadable macOS PKG installer, and we use WiX to create the downloadable Windows MSI installer. We don’t want verifiers to need the same exact versions of those tools, so we took the same approach as for the cryptographic signing keys, writing a verifier that can look inside the packages and check that the toolchain files are exactly as expected.\nVerifying the Go Toolchains\nIt’s not enough to make Go toolchains reproducible once. We want to make sure they stay reproducible, and we want to make sure others can reproduce them easily.\n\\\nTo keep ourselves honest, we now build all Go distributions on both a trusted Linux/x86-64 system and a Windows/x86-64 system. Except for the architecture, the two systems have almost nothing in common. The two systems must produce bit-for-bit identical archives or else we do not proceed with the release.\n\\\nTo allow others to verify that we’re honest, we’ve written and published a verifier, golang.org/x/build/cmd/gorebuild. That program will start with the source code in our Git repository and rebuild the current Go versions, checking that they match the archives posted on go.dev/dl. Most archives are required to match bit-for-bit. As mentioned above, there are three exceptions where a more relaxed check is used:\n\\\n\nThe macOS tar.gz file is expected to differ, but then the verifier compares the contents inside. The rebuilt and posted copies must contain the same files, and all the files must match exactly, except for executable binaries. Executable binaries must match exactly after stripping code signatures.\n\\\n\nThe macOS PKG installer is not rebuilt. Instead, the verifier reads the files inside the PKG installer and checks that they match the macOS tar.gz exactly, again after code signature stripping. In the long term, the PKG creation is trivial enough that it could potentially be added to cmd/distpack, but the verifier would still have to parse the PKG file to run the signature-ignoring code executable comparison.\n\\\n\nThe Windows MSI installer is not rebuilt. Instead, the verifier invokes the Linux program msiextract to extract the files inside and check that they match the rebuilt Windows zip file exactly. In the long term, perhaps the MSI creation could be added to cmd/distpack, and then the verifier could use a bit-for-bit MSI comparison.\n\\\nWe run gorebuild nightly, posting the results at go.dev/rebuild, and of course anyone else can run it too.\nVerifying Ubuntu’s Go Toolchain\nThe Go toolchain’s easily reproducible builds should mean that the binaries in the toolchains posted on go.dev match the binaries included in other packaging systems, even when those packagers build from source. Even if the packagers have compiled with different configurations or other changes, the easily reproducible builds should still make it easy to reproduce their binaries. To demonstrate this, let’s reproduce the Ubuntu golang-1.21 package version 1.21.0-1 for Linux/x86-64.\n\\\nTo start, we need to download and extract the Ubuntu packages, which are ar(1) archives containing zstd-compressed tar archives:\n$ mkdir deb\n$ cd deb\n$ curl -LO http://mirrors.kernel.org/ubuntu/pool/main/g/golang-1.21/golang-1.21-src_1.21.0-1_all.deb\n$ ar xv golang-1.21-src_1.21.0-1_all.deb\nx - debian-binary\nx - control.tar.zst\nx - data.tar.zst\n$ unzstd < data.tar.zst | tar xv\n...\nx ./usr/share/go-1.21/src/archive/tar/common.go\nx ./usr/share/go-1.21/src/archive/tar/example_test.go\nx ./usr/share/go-1.21/src/archive/tar/format.go\nx ./usr/share/go-1.21/src/archive/tar/fuzz_test.go\n...\n$\n\n\\\nThat was the source archive. Now the amd64 binary archive:\n$ rm -f debian-binary *.zst\n$ curl -LO http://mirrors.kernel.org/ubuntu/pool/main/g/golang-1.21/golang-1.21-go_1.21.0-1_amd64.deb\n$ ar xv golang-1.21-src_1.21.0-1_all.deb\nx - debian-binary\nx - control.tar.zst\nx - data.tar.zst\n$ unzstd < data.tar.zst | tar xv | grep -v '/$'\n...\nx ./usr/lib/go-1.21/bin/go\nx ./usr/lib/go-1.21/bin/gofmt\nx ./usr/lib/go-1.21/go.env\nx ./usr/lib/go-1.21/pkg/tool/linux_amd64/addr2line\nx ./usr/lib/go-1.21/pkg/tool/linux_amd64/asm\nx ./usr/lib/go-1.21/pkg/tool/linux_amd64/buildid\n...\n$\n\n\\\nUbuntu splits the normal Go tree into two halves, in /usr/share/go-1.21 and /usr/lib/go-1.21. Let’s put them back together:\n$ mkdir go-ubuntu\n$ cp -R usr/share/go-1.21/* usr/lib/go-1.21/* go-ubuntu\ncp: cannot overwrite directory go-ubuntu/api with non-directory usr/lib/go-1.21/api\ncp: cannot overwrite directory go-ubuntu/misc with non-directory usr/lib/go-1.21/misc\ncp: cannot overwrite directory go-ubuntu/pkg/include with non-directory usr/lib/go-1.21/pkg/include\ncp: cannot overwrite directory go-ubuntu/src with non-directory usr/lib/go-1.21/src\ncp: cannot overwrite directory go-ubuntu/test with non-directory usr/lib/go-1.21/test\n$\n\n\\\nThe errors are complaining about copying symlinks, which we can ignore.\n\\\nNow we need to download and extract the upstream Go sources:\n$ curl -LO https://go.googlesource.com/go/+archive/refs/tags/go1.21.0.tar.gz\n$ mkdir go-clean\n$ cd go-clean\n$ curl -L https://go.googlesource.com/go/+archive/refs/tags/go1.21.0.tar.gz | tar xzv\n...\nx src/archive/tar/common.go\nx src/archive/tar/example_test.go\nx src/archive/tar/format.go\nx src/archive/tar/fuzz_test.go\n...\n$\n\n\\\nTo skip some trial and error, it turns out that Ubuntu builds Go with GO386=softfloat, which forces the use of software floating point when compiling for 32-bit x86, and strips (removes symbol tables from) the resulting ELF binaries. Let’s start with a GO386=softfloat build:\n$ cd src\n$ GOOS=linux GO386=softfloat ./make.bash -distpack\nBuilding Go cmd/dist using /Users/rsc/sdk/go1.17.13. (go1.17.13 darwin/amd64)\nBuilding Go toolchain1 using /Users/rsc/sdk/go1.17.13.\nBuilding Go bootstrap cmd/go (go_bootstrap) using Go toolchain1.\nBuilding Go toolchain2 using go_bootstrap and Go toolchain1.\nBuilding Go toolchain3 using go_bootstrap and Go toolchain2.\nBuilding commands for host, darwin/amd64.\nBuilding packages and commands for target, linux/amd64.\nPackaging archives for linux/amd64.\ndistpack: 818d46ede85682dd go1.21.0.src.tar.gz\ndistpack: 4fcd8651d084a03d go1.21.0.linux-amd64.tar.gz\ndistpack: eab8ed80024f444f v0.0.1-go1.21.0.linux-amd64.zip\ndistpack: 58528cce1848ddf4 v0.0.1-go1.21.0.linux-amd64.mod\ndistpack: d8da1f27296edea4 v0.0.1-go1.21.0.linux-amd64.info\n---\nInstalled Go for linux/amd64 in /Users/rsc/deb/go-clean\nInstalled commands in /Users/rsc/deb/go-clean/bin\n*** You need to add /Users/rsc/deb/go-clean/bin to your PATH.\n$\n\n\\\nThat left the standard package in pkg/distpack/go1.21.0.linux-amd64.tar.gz. Let’s unpack it and strip the binaries to match Ubuntu:\n$ cd ../..\n$ tar xzvf go-clean/pkg/distpack/go1.21.0.linux-amd64.tar.gz\nx go/CONTRIBUTING.md\nx go/LICENSE\nx go/PATENTS\nx go/README.md\nx go/SECURITY.md\nx go/VERSION\n...\n$ elfstrip go/bin/* go/pkg/tool/linux_amd64/*\n$\n\n\\\nNow we can diff the Go toolchain we’ve created on our Mac with the Go toolchain that Ubuntu ships:\n$ diff -r go go-ubuntu\nOnly in go: CONTRIBUTING.md\nOnly in go: LICENSE\nOnly in go: PATENTS\nOnly in go: README.md\nOnly in go: SECURITY.md\nOnly in go: codereview.cfg\nOnly in go: doc\nOnly in go: lib\nBinary files go/misc/chrome/gophertool/gopher.png and go-ubuntu/misc/chrome/gophertool/gopher.png differ\nOnly in go-ubuntu/pkg/tool/linux_amd64: dist\nOnly in go-ubuntu/pkg/tool/linux_amd64: distpack\nOnly in go/src: all.rc\nOnly in go/src: clean.rc\nOnly in go/src: make.rc\nOnly in go/src: run.rc\ndiff -r go/src/syscall/mksyscall.pl go-ubuntu/src/syscall/mksyscall.pl\n1c1\n< #!/usr/bin/env perl\n---\n> #! /usr/bin/perl\n...\n$\n\nWe’ve successfully reproduced the Ubuntu package’s executables and identified the complete set of changes that remain:\nVarious metadata and supporting files have been deleted.\n\\\n\nThe gopher.png file has been modified. On closer inspection the two are identical except for an embedded timestamp that Ubuntu has updated. Perhaps Ubuntu’s packaging scripts recompressed the png with a tool that rewrites the timestamp even when it cannot improve on the existing compression.\n\\\n\nThe binaries dist and distpack, which are built during bootstrap but not included in standard archives, have been included in the Ubuntu package.\n\\\n\nThe Plan 9 build scripts (*.rc) have been deleted, although the Windows build scripts (*.bat) remain.\n\\\n\nmksyscall.pl and seven other Perl scripts not shown have had their headers changed.\n\\\nNote in particular that we’ve reconstructed the toolchain binaries bit-for-bit: they do not show up in the diff at all. That is, we proved that the Ubuntu Go binaries correspond exactly to the upstream Go sources.\n\\\nEven better, we proved this without using any Ubuntu software at all: these commands were run on a Mac, and unzstd and elfstrip are short Go programs. A sophisticated attacker might insert malicious code into an Ubuntu package by changing the package-creation tools. If they did, reproducing the Go Ubuntu package from clean sources using those malicious tools would still produce bit-for-bit identical copies of the malicious packages. \n\\\nThis attack would be invisible to that kind of rebuild, much like Ken Thompson’s compiler attack. Verifying the Ubuntu packages using no Ubuntu software at all is a much stronger check. Go’s perfectly reproducible builds, which don’t depend on unindented details like the host operating system, host architecture, and host C toolchain, are what make this stronger check possible.\n\\\n(As an aside for the historical record, Ken Thompson told me once that his attack was in fact detected, because the compiler build stopped being reproducible. It had a bug: a string constant in the backdoor added to the compiler was imperfectly handled and grew by a single NUL byte each time the compiler compiled itself. Eventually someone noticed the non-reproducible build and tried to find the cause by compiling to assembly. The compiler’s backdoor did not reproduce itself into assembly output at all, so assembling that output removed the backdoor.)\nConclusion\nReproducible builds are an important tool for strengthening the open-source supply chain. Frameworks like SLSA focus on provenance and a software chain of custody that can be used to inform decisions about trust. Reproducible builds complement that approach by providing a way to verify that the trust is well-placed.\n\\\nPerfect reproducibility (when the source files are the build’s only relevant input) is only possible for programs that build themselves, like compiler toolchains. It is a lofty but worthwhile goal precisely because self-hosting compiler toolchains are otherwise quite difficult to verify. Go’s perfect reproducibility means that, assuming packagers don’t modify the source code, every repackaging of Go 1.21.0 for Linux/x86-64 (substitute your favorite system) in any form should be distributing exactly the same binaries, even when they all build from source. We’ve seen that this is not quite true for Ubuntu Linux, but perfect reproducibility still lets us reproduce the Ubuntu packaging using a very different, non-Ubuntu system.\n\\\nIdeally all open source software distributed in binary form would have easy-to-reproduce builds. In practice, as we’ve seen in this post, it is very easy for unintended inputs to leak into builds. For Go programs that don’t need cgo, a reproducible build is as simple as compiling with CGO_ENABLED=0 go build -trimpath. Disabling cgo removes the host C toolchain as a relevant input, and -trimpath removes the current directory. If your program does need cgo, you need to arrange for a specific host C toolchain version before running go build, such as by running the build in a specific virtual machine or container image.\n\\\nMoving beyond Go, the Reproducible Builds project aims to improve reproducibility of all open source and is a good starting point for more information about making your own software builds reproducible.\nRuss Cox\n\\\nPhoto by Alex Pudov on Unsplash\n\\\nThis article is available on The Go Blog under a CC BY 4.0 DEED license.",
          "dc:creator": "Go [Technical Documentation]",
          "content": "This post explains what goes into making builds reproducible, and then demonstrates one of the benefits of reproducibility by verifying the Ubuntu package for Go 1.21.0.",
          "contentSnippet": "This post explains what goes into making builds reproducible, and then demonstrates one of the benefits of reproducibility by verifying the Ubuntu package for Go 1.21.0.",
          "guid": "https://hackernoon.com/reproducible-go-toolchains-what-you-need-to-know?source=rss",
          "categories": [
            "go",
            "golang",
            "go-toolchains",
            "what-are-go-tool-chains",
            "reproducible-builds",
            "reproducibility-in-go",
            "hackernoon-top-story",
            "host-dynamic-linker"
          ],
          "isoDate": "2025-08-03T12:00:07.000Z"
        }
      },
      {
        "json": {
          "creator": "Techbeat",
          "title": "The TechBeat: Here's The Exact Indie-Hacking Vibe-Coding Setup I Use as a Middle-Aged Product Manager (8/3/2025)",
          "link": "https://hackernoon.com/8-3-2025-techbeat?source=rss",
          "pubDate": "Sun, 03 Aug 2025 06:10:52 GMT",
          "content:encoded": "<p>How are you, hacker? \n 🪐<strong>Want to know what's trending right now?:</strong>\n <a href=\"https://hackernoon.com/homepage-has-a-new-baby\">The Techbeat by HackerNoon </a> has got you covered with fresh content from our trending stories of the day! Set email preference <a href=\"https://app.hackernoon.com/profile/email-settings\">here</a>.\n ## <strong><a href=\"https://hackernoon.com/immutable-backups-everything-you-need-to-know-to-protect-your-cloud\">Immutable Backups: Everything You Need To Know To Protect Your Cloud</a></strong> <img src=\"https://cdn.hackernoon.com/images/hQ098u52DzPm2Y4UITQcQXtLRAk2-by039c5.png\" alt=\"\" />\n By <a href=\"https://hackernoon.com/u/n2w\">@n2w</a> [ 6 Min read ] \n Learn how immutable backups prevent ransomware, ensure data integrity, and meet compliance needs with secure, tamper-proof cloud data protection. <a href=\"https://hackernoon.com/immutable-backups-everything-you-need-to-know-to-protect-your-cloud\">Read More.</a></p>\n<h2 id=\"selectiveprivacyhowbelnetssplittunnelingbalancesspeedandsecurityhttpshackernooncomselectiveprivacyhowbelnetssplittunnelingbalancesspeedandsecurityhttpscdnhackernooncomimagespwikbavxohz8pidtklyzfcng9qw2fa03n5pjpeg\"><strong><a href=\"https://hackernoon.com/selective-privacy-how-belnets-split-tunneling-balances-speed-and-security\">Selective Privacy: How BelNet’s Split Tunneling Balances Speed and Security</a></strong> <img src=\"https://cdn.hackernoon.com/images/PWiKbaVxohZ8PidtkLYzFcnG9Qw2-fa03n5p.jpeg\" alt=\"\" /></h2>\n<p>By <a href=\"https://hackernoon.com/u/beldexcoin\">@beldexcoin</a> [ 4 Min read ] \n BelNet introduces split tunneling for faster, more private browsing—select which data is encrypted, and enjoy speed without compromising confidentiality. <a href=\"https://hackernoon.com/selective-privacy-how-belnets-split-tunneling-balances-speed-and-security\">Read More.</a></p>\n<h2 id=\"howtripadvisordeliversrealtimepersonalizationatscalewithmlhttpshackernooncomhowtripadvisordeliversrealtimepersonalizationatscalewithmlhttpscdnhackernooncomimagesinxbrjris6m1kdhuwcynhiiurxm190039ujjpeg\"><strong><a href=\"https://hackernoon.com/how-tripadvisor-delivers-real-time-personalization-at-scale-with-ml\">How Tripadvisor Delivers Real-Time Personalization at Scale with ML</a></strong> <img src=\"https://cdn.hackernoon.com/images/InxBRjRIs6M1kdhuWcyNHiiUrxm1-90039uj.jpeg\" alt=\"\" /></h2>\n<p>By <a href=\"https://hackernoon.com/u/scylladb\">@scylladb</a> [ 2 Min read ] \n Tripadvisor uses ML and ScyllaDB on AWS to deliver real-time personalization at massive scale with millisecond latency and advanced data architecture. <a href=\"https://hackernoon.com/how-tripadvisor-delivers-real-time-personalization-at-scale-with-ml\">Read More.</a></p>\n<h2 id=\"herestheexactindiehackingvibecodingsetupiuseasamiddleagedproductmanagerhttpshackernooncomherestheexactindiehackingvibecodingsetupiuseasamiddleagedproductmanagerhttpscdnhackernooncomimagesklbs1aomwbuziv9xhjj0ns36cty1ot02tpdjpeg\"><strong><a href=\"https://hackernoon.com/heres-the-exact-indie-hacking-vibe-coding-setup-i-use-as-a-middle-aged-product-manager\">Here's The Exact Indie-Hacking Vibe-Coding Setup I Use as a Middle-Aged Product Manager</a></strong> <img src=\"https://cdn.hackernoon.com/images/KLbs1aomwbUZiV9XHjj0nS36CTy1-ot02tpd.jpeg\" alt=\"\" /></h2>\n<p>By <a href=\"https://hackernoon.com/u/ivankuznetsov\">@ivankuznetsov</a> [ 7 Min read ] \n Middle-aged PM shares his AI-powered vibe-coding setup after restarting dev journey to beat burnout.  <a href=\"https://hackernoon.com/heres-the-exact-indie-hacking-vibe-coding-setup-i-use-as-a-middle-aged-product-manager\">Read More.</a></p>\n<h2 id=\"dataprivacychallengesinopenmcparchitectureshttpshackernooncomdataprivacychallengesinopenmcparchitectureshttpscdnhackernooncomimagesbtjpboajojhszer7saivzoylpfn1xu02zempng\"><strong><a href=\"https://hackernoon.com/data-privacy-challenges-in-open-mcp-architectures\">Data Privacy Challenges in Open MCP Architectures</a></strong> <img src=\"https://cdn.hackernoon.com/images/BtjpboAJojhsZer7SAIVzOYlpFn1-xu02zem.png\" alt=\"\" /></h2>\n<p>By <a href=\"https://hackernoon.com/u/mayankc\">@mayankc</a> [ 29 Min read ] \n MCP lets AI access tools in real time—but also expands risks. This guide explores its security pitfalls and best practices for safe deployment. <a href=\"https://hackernoon.com/data-privacy-challenges-in-open-mcp-architectures\">Read More.</a></p>\n<h2 id=\"turnaregularwalletintoasmartaccountwitheip7702httpshackernooncomturnaregularwalletintoasmartaccountwitheip7702httpscdnhackernooncomimagesj4okdrdzfyh3zwxi47hcwrilvg12ws03uidpng\"><strong><a href=\"https://hackernoon.com/turn-a-regular-wallet-into-a-smart-account-with-eip-7702\">Turn a Regular Wallet into a Smart Account with EIP 7702 </a></strong> <img src=\"https://cdn.hackernoon.com/images/J4oKDrDzfYh3ZwXi47hCWrIlVg12-ws03uid.png\" alt=\"\" /></h2>\n<p>By <a href=\"https://hackernoon.com/u/hacker39947670\">@hacker39947670</a> [ 13 Min read ] \n Learn how EIP-7702 enables smart wallet features for existing Ethereum accounts. Complete developer guide with code examples. <a href=\"https://hackernoon.com/turn-a-regular-wallet-into-a-smart-account-with-eip-7702\">Read More.</a></p>\n<h2 id=\"multibankioceozaktaherontheevolutionofmultiassetbrokerageandrwatokenizationhttpshackernooncommultibankioceozaktaherontheevolutionofmultiassetbrokerageandrwatokenizationhttpscdnhackernooncomimagesxewesokkism0pgjq4dyeehqofjj2im0257awebp\"><strong><a href=\"https://hackernoon.com/multibankio-ceo-zak-taher-on-the-evolution-of-multi-asset-brokerage-and-rwa-tokenization\">MultiBank.io CEO Zak Taher On The Evolution Of Multi-Asset Brokerage And RWA Tokenization</a></strong> <img src=\"https://cdn.hackernoon.com/images/XEwEsoKKiSM0pGjq4dyeehqOfjj2-im0257a.webp\" alt=\"\" /></h2>\n<p>By <a href=\"https://hackernoon.com/u/penworth\">@penworth</a> [ 4 Min read ] \n Zak Taher has spent over 2 decades in the industry guiding teams and businesses through transformation, volatility, and innovation. <a href=\"https://hackernoon.com/multibankio-ceo-zak-taher-on-the-evolution-of-multi-asset-brokerage-and-rwa-tokenization\">Read More.</a></p>\n<h2 id=\"downsideliquidityahypothesisonshortpoolsforevmhttpshackernooncomdownsideliquidityahypothesisonshortpoolsforevmhttpscdnhackernooncomimageslokbjqeefqrue8qf8ehzspop2hp20v03l8ppng\"><strong><a href=\"https://hackernoon.com/downside-liquidity-a-hypothesis-on-short-pools-for-evm\">Downside Liquidity: A Hypothesis on Short Pools for EVM</a></strong> <img src=\"https://cdn.hackernoon.com/images/lokbjQEefQRUe8qF8EHzsPop2hP2-0v03l8p.png\" alt=\"\" /></h2>\n<p>By <a href=\"https://hackernoon.com/u/iamshvetsov\">@iamshvetsov</a> [ 5 Min read ] \n In this article, I’ve shared a hypothesis about a short liquidity pool and proposed a basic implementation in Solidity for the Ethereum blockchain. <a href=\"https://hackernoon.com/downside-liquidity-a-hypothesis-on-short-pools-for-evm\">Read More.</a></p>\n<h2 id=\"whydevelopersneedmobilefirsterrortrackingandhowwebuiltithttpshackernooncomwhydevelopersneedmobilefirsterrortrackingandhowwebuiltithttpscdnhackernooncomimagesxknl896ovrf59ohsvzeniqj23hp22d03avqpng\"><strong><a href=\"https://hackernoon.com/why-developers-need-mobile-first-error-tracking-and-how-we-built-it\">Why Developers Need Mobile-First Error Tracking (And How We Built It)</a></strong> <img src=\"https://cdn.hackernoon.com/images/Xknl896oVrf59ohsvzEnIqj23hP2-2d03avq.png\" alt=\"\" /></h2>\n<p>By <a href=\"https://hackernoon.com/u/danzabrotski\">@danzabrotski</a> [ 7 Min read ] \n Mobile-first app monitoring that frees developers from desktop-bound error tracking. Real-time phone notifications, AI integration roadmap, and startup benefits <a href=\"https://hackernoon.com/why-developers-need-mobile-first-error-tracking-and-how-we-built-it\">Read More.</a></p>\n<h2 id=\"stopbelievingtheagenthypethenumbersdontliehttpshackernooncomstopbelievingtheagenthypethenumbersdontliehttpscdnhackernooncomimages0pq9nxdlb7aj68mnqwgr9620nx32mj236tnpng\"><strong><a href=\"https://hackernoon.com/stop-believing-the-agent-hypethe-numbers-dont-lie\">Stop Believing the Agent Hype—The Numbers Don’t Lie</a></strong> <img src=\"https://cdn.hackernoon.com/images/0pq9nXdlB7aJ68MnqWgr9620nx32-mj236tn.png\" alt=\"\" /></h2>\n<p>By <a href=\"https://hackernoon.com/u/ukanwat\">@ukanwat</a> [ 7 Min read ] \n Here's why the current hype around autonomous agents is mathematically impossible and what actually works in production. <a href=\"https://hackernoon.com/stop-believing-the-agent-hypethe-numbers-dont-lie\">Read More.</a></p>\n<h2 id=\"thisopensourcetoolcanspinupentirewebsitesfromasingleprompthttpshackernooncomthisopensourcetoolcanspinupentirewebsitesfromasingleprompthttpscdnhackernooncomimagesfqksrpuzfmmjzrsg6qhgjdywibu1ad03a1upng\"><strong><a href=\"https://hackernoon.com/this-open-source-tool-can-spin-up-entire-websites-from-a-single-prompt\">This Open Source Tool Can Spin Up Entire Websites from a Single Prompt</a></strong> <img src=\"https://cdn.hackernoon.com/images/FQKsrPUzFMMjzRsg6QHgjdyWIBu1-ad03a1u.png\" alt=\"\" /></h2>\n<p>By <a href=\"https://hackernoon.com/u/bolshiyanov\">@bolshiyanov</a> [ 52 Min read ] \n Your collaborative AI assistant to design, iterate, and scale full-stack applications for the web. <a href=\"https://hackernoon.com/this-open-source-tool-can-spin-up-entire-websites-from-a-single-prompt\">Read More.</a></p>\n<h2 id=\"theeasiestwaytodetectencodeandsearchfacesusingaihttpshackernooncomtheeasiestwaytodetectencodeandsearchfacesusingaihttpscdnhackernooncomimagesdkjgv1jzzizlbtfgkk4nrc3it7m2zof39srpng\"><strong><a href=\"https://hackernoon.com/the-easiest-way-to-detect-encode-and-search-faces-using-ai\">The Easiest Way to Detect, Encode, and Search Faces Using AI</a></strong> <img src=\"https://cdn.hackernoon.com/images/dkjgV1JZZIZLBTFGKK4nRc3It7M2-zof39sr.png\" alt=\"\" /></h2>\n<p>By <a href=\"https://hackernoon.com/u/badmonster0\">@badmonster0</a> [ 5 Min read ] \n  Learn how to build a scalable face recognition pipeline with CocoIndex—from detecting faces to running real-time similarity searches in a vector database. <a href=\"https://hackernoon.com/the-easiest-way-to-detect-encode-and-search-faces-using-ai\">Read More.</a></p>\n<h2 id=\"maccstealertakesonamos\">**[Mac.c Stealer Takes on AMOS:</h2>\n<p>A New Rival Shakes Up the macOS Infostealer Market](https://hackernoon.com/macc-stealer-takes-on-amos-a-new-rival-shakes-up-the-macos-infostealer-market)** <img src=\"https://cdn.hackernoon.com/images/l7noBCUFwmcERrcGKL5jHUS0UcV2-be03ld8.png\" alt=\"\" />\n By <a href=\"https://hackernoon.com/u/moonlock\">@moonlock</a> [ 8 Min read ] \n Moonlock analysed Mac.c stealer, a new rival to AMOS. Learn its tactics, code reuse, and \"building in public\" strategy. <a href=\"https://hackernoon.com/macc-stealer-takes-on-amos-a-new-rival-shakes-up-the-macos-infostealer-market\">Read More.</a></p>\n<h2 id=\"dogecointargetsd050butlittlepepesd85mpresalestealsthespotlighthttpshackernooncomdogecointargetsd050butlittlepepesd85mpresalestealsthespotlighthttpscdnhackernooncomimagesinxbrjris6m1kdhuwcynhiiurxm16q0391tpng\"><strong><a href=\"https://hackernoon.com/dogecoin-targets-$050-but-little-pepes-$85m-presale-steals-the-spotlight\">Dogecoin Targets $0.50, But Little Pepe’s $8.5M Presale Steals the Spotlight</a></strong> <img src=\"https://cdn.hackernoon.com/images/InxBRjRIs6M1kdhuWcyNHiiUrxm1-6q0391t.png\" alt=\"\" /></h2>\n<p>By <a href=\"https://hackernoon.com/u/kashvipandey\">@kashvipandey</a> [ 4 Min read ] \n Dogecoin eyes $0.50, but Little Pepe (LILPEPE) is surging with a $8.5M presale and its own Pepe Chain, positioning as the next big meme coin ecosystem. <a href=\"https://hackernoon.com/dogecoin-targets-$050-but-little-pepes-$85m-presale-steals-the-spotlight\">Read More.</a></p>\n<h2 id=\"towardholisticevaluationofllmsintegratinghumanfeedbackwithtraditionalmetricshttpshackernooncomtowardholisticevaluationofllmsintegratinghumanfeedbackwithtraditionalmetricshttpscdnhackernooncomimages5wpkgv75aonqktjlafw2yqmk9yd29i139m7png\"><strong><a href=\"https://hackernoon.com/toward-holistic-evaluation-of-llms-integrating-human-feedback-with-traditional-metrics\">Toward Holistic Evaluation of LLMs: Integrating Human Feedback with Traditional Metrics</a></strong> <img src=\"https://cdn.hackernoon.com/images/5wpKgV75aONqkTJlafw2yQmK9yd2-9i139m7.png\" alt=\"\" /></h2>\n<p>By <a href=\"https://hackernoon.com/u/nileshbh\">@nileshbh</a> [ 16 Min read ] \n A deep dive into why LLMs need both metrics and human feedback for real-world accuracy, ethics, and performance. <a href=\"https://hackernoon.com/toward-holistic-evaluation-of-llms-integrating-human-feedback-with-traditional-metrics\">Read More.</a></p>\n<h2 id=\"yourebuildingaiagentswronghereshowtofixthatwithaachttpshackernooncomyourebuildingaiagentswronghereshowtofixthatwithaachttpscdnhackernooncomimageskkgjo9l6i5hbluxp8d37sd3t8tl2in13b2hjpeg\"><strong><a href=\"https://hackernoon.com/youre-building-ai-agents-wrong-heres-how-to-fix-that-with-aac\">You’re Building AI Agents Wrong. Here’s How to Fix That with AAC</a></strong> <img src=\"https://cdn.hackernoon.com/images/KKgJo9L6i5hBlUxP8D37SD3t8tl2-in13b2h.jpeg\" alt=\"\" /></h2>\n<p>By <a href=\"https://hackernoon.com/u/maxnechaev\">@maxnechaev</a> [ 10 Min read ] \n Fragile, chaotic AI agents are everywhere. AAC is a simple yet powerful architecture that brings structure, scalability, and reliability to your agent systems. <a href=\"https://hackernoon.com/youre-building-ai-agents-wrong-heres-how-to-fix-that-with-aac\">Read More.</a></p>\n<h2 id=\"howisetupacowriehoneypottocapturerealsshattackshttpshackernooncomhowisetupacowriehoneypottocapturerealsshattackshttpscdnhackernooncomimagesocisomom6sg3siejqlp1gwmonse2c80332lpng\"><strong><a href=\"https://hackernoon.com/how-i-set-up-a-cowrie-honeypot-to-capture-real-ssh-attacks\">How I Set Up a Cowrie Honeypot to Capture Real SSH Attacks</a></strong> <img src=\"https://cdn.hackernoon.com/images/OciSOMOm6Sg3siEjQlp1GWmOnSE2-c80332l.png\" alt=\"\" /></h2>\n<p>By <a href=\"https://hackernoon.com/u/authenticpeach\">@authenticpeach</a> [ 10 Min read ] \n Simulate real-world SSH attacks with Cowrie, log attacker behavior, and analyze tactics using MITRE ATT&amp;CK in this hands-on honeypot project. <a href=\"https://hackernoon.com/how-i-set-up-a-cowrie-honeypot-to-capture-real-ssh-attacks\">Read More.</a></p>\n<h2 id=\"bitcoinminingcouldmakeourelectricitygridssmarterhttpshackernooncombitcoinminingcouldmakeourelectricitygridssmarterhttpscdnhackernooncomimagesehuyzrllaubgargtd43keixtots2vc03e8vjpeg\"><strong><a href=\"https://hackernoon.com/bitcoin-mining-could-make-our-electricity-grids-smarter\">Bitcoin Mining Could Make Our Electricity Grids Smarter</a></strong> <img src=\"https://cdn.hackernoon.com/images/EHUYZRLLAUbgArGtd43kEIxTOTS2-vc03e8v.jpeg\" alt=\"\" /></h2>\n<p>By <a href=\"https://hackernoon.com/u/maken8\">@maken8</a> [ 6 Min read ] \n In this article, my co-author and I explore how Bitcoin would revolutionize the same electricity network it is backed by. <a href=\"https://hackernoon.com/bitcoin-mining-could-make-our-electricity-grids-smarter\">Read More.</a></p>\n<h2 id=\"metasaibossjustcalledllmssimplistichereswhathesbuildinginsteadhttpshackernooncommetasaibossjustcalledllmssimplistichereswhathesbuildinginsteadhttpscdnhackernooncomimagesin6h2uigxkapyohz6k4n9srfgsw13o039fepng\"><strong><a href=\"https://hackernoon.com/metas-ai-boss-just-called-llms-simplistic-heres-what-hes-building-instead\">Meta’s AI Boss Just Called LLMs ‘Simplistic’ — Here’s What He’s Building Instead</a></strong> <img src=\"https://cdn.hackernoon.com/images/iN6H2UigxKapyOHZ6k4N9srFgsw1-3o039fe.png\" alt=\"\" /></h2>\n<p>By <a href=\"https://hackernoon.com/u/hacker-Antho\">@hacker-Antho</a> [ 8 Min read ] \n Yann LeCun, Chief AI Scientist at Meta, discusses the future of AI.  <a href=\"https://hackernoon.com/metas-ai-boss-just-called-llms-simplistic-heres-what-hes-building-instead\">Read More.</a></p>\n<h2 id=\"theartofagreatrollouthttpshackernooncomtheartofagreatrollouthttpscdnhackernooncomimageseiqyf9kpzbykdo2yaxl3qdnct3c3jl53a00png\"><strong><a href=\"https://hackernoon.com/the-art-of-a-great-rollout\">The Art of a Great Rollout</a></strong> <img src=\"https://cdn.hackernoon.com/images/eiqyF9kpzBYkDO2YaXl3qdncT3C3-jl53a00.png\" alt=\"\" /></h2>\n<p>By <a href=\"https://hackernoon.com/u/sidosera\">@sidosera</a> [ 4 Min read ] \n We live in the era of high-frequency software deployments, where mass-market software products update several times a day, sometimes delivering hundreds or even <a href=\"https://hackernoon.com/the-art-of-a-great-rollout\">Read More.</a> \n 🧑‍💻 What happened in your world this week? It's been said that <a href=\"https://hackernoon.com/developers-the-why-and-how-to-writing-technical-articles-54e824789ef6\">writing can help consolidate technical knowledge</a>, <a href=\"https://hackernoon.com/how-can-non-writers-become-effective-bloggers-1pq32wd\">establish credibility</a>,<a href=\"https://hackernoon.com/how-can-non-writers-become-effective-bloggers-1pq32wd\"> and contribute to emerging community standards</a>. Feeling stuck? We got you covered ⬇️⬇️⬇️\n <a href=\"https://app.hackernoon.com/mobile/lZx3fmlPdlPJpVBIdble\">ANSWER THESE GREATEST INTERVIEW QUESTIONS OF ALL TIME</a>\n We hope you enjoy this worth of free reading material. Feel free to forward this email to a nerdy friend who'll love you for it.\n See you on Planet Internet! With love, \n The HackerNoon Team ✌️\n <img src=\"https://cdn.hackernoon.com/images/ezgif.com-gif-maker%20(44).gif\" alt=\"\" /></p>",
          "content:encodedSnippet": "How are you, hacker? \n 🪐Want to know what's trending right now?:\n The Techbeat by HackerNoon  has got you covered with fresh content from our trending stories of the day! Set email preference here.\n ## Immutable Backups: Everything You Need To Know To Protect Your Cloud \n By @n2w [ 6 Min read ] \n Learn how immutable backups prevent ransomware, ensure data integrity, and meet compliance needs with secure, tamper-proof cloud data protection. Read More.\nSelective Privacy: How BelNet’s Split Tunneling Balances Speed and Security \nBy @beldexcoin [ 4 Min read ] \n BelNet introduces split tunneling for faster, more private browsing—select which data is encrypted, and enjoy speed without compromising confidentiality. Read More.\nHow Tripadvisor Delivers Real-Time Personalization at Scale with ML \nBy @scylladb [ 2 Min read ] \n Tripadvisor uses ML and ScyllaDB on AWS to deliver real-time personalization at massive scale with millisecond latency and advanced data architecture. Read More.\nHere's The Exact Indie-Hacking Vibe-Coding Setup I Use as a Middle-Aged Product Manager \nBy @ivankuznetsov [ 7 Min read ] \n Middle-aged PM shares his AI-powered vibe-coding setup after restarting dev journey to beat burnout.  Read More.\nData Privacy Challenges in Open MCP Architectures \nBy @mayankc [ 29 Min read ] \n MCP lets AI access tools in real time—but also expands risks. This guide explores its security pitfalls and best practices for safe deployment. Read More.\nTurn a Regular Wallet into a Smart Account with EIP 7702  \nBy @hacker39947670 [ 13 Min read ] \n Learn how EIP-7702 enables smart wallet features for existing Ethereum accounts. Complete developer guide with code examples. Read More.\nMultiBank.io CEO Zak Taher On The Evolution Of Multi-Asset Brokerage And RWA Tokenization \nBy @penworth [ 4 Min read ] \n Zak Taher has spent over 2 decades in the industry guiding teams and businesses through transformation, volatility, and innovation. Read More.\nDownside Liquidity: A Hypothesis on Short Pools for EVM \nBy @iamshvetsov [ 5 Min read ] \n In this article, I’ve shared a hypothesis about a short liquidity pool and proposed a basic implementation in Solidity for the Ethereum blockchain. Read More.\nWhy Developers Need Mobile-First Error Tracking (And How We Built It) \nBy @danzabrotski [ 7 Min read ] \n Mobile-first app monitoring that frees developers from desktop-bound error tracking. Real-time phone notifications, AI integration roadmap, and startup benefits Read More.\nStop Believing the Agent Hype—The Numbers Don’t Lie \nBy @ukanwat [ 7 Min read ] \n Here's why the current hype around autonomous agents is mathematically impossible and what actually works in production. Read More.\nThis Open Source Tool Can Spin Up Entire Websites from a Single Prompt \nBy @bolshiyanov [ 52 Min read ] \n Your collaborative AI assistant to design, iterate, and scale full-stack applications for the web. Read More.\nThe Easiest Way to Detect, Encode, and Search Faces Using AI \nBy @badmonster0 [ 5 Min read ] \n  Learn how to build a scalable face recognition pipeline with CocoIndex—from detecting faces to running real-time similarity searches in a vector database. Read More.\n**[Mac.c Stealer Takes on AMOS:\nA New Rival Shakes Up the macOS Infostealer Market](https://hackernoon.com/macc-stealer-takes-on-amos-a-new-rival-shakes-up-the-macos-infostealer-market)** \n By @moonlock [ 8 Min read ] \n Moonlock analysed Mac.c stealer, a new rival to AMOS. Learn its tactics, code reuse, and \"building in public\" strategy. Read More.\nDogecoin Targets $0.50, But Little Pepe’s $8.5M Presale Steals the Spotlight \nBy @kashvipandey [ 4 Min read ] \n Dogecoin eyes $0.50, but Little Pepe (LILPEPE) is surging with a $8.5M presale and its own Pepe Chain, positioning as the next big meme coin ecosystem. Read More.\nToward Holistic Evaluation of LLMs: Integrating Human Feedback with Traditional Metrics \nBy @nileshbh [ 16 Min read ] \n A deep dive into why LLMs need both metrics and human feedback for real-world accuracy, ethics, and performance. Read More.\nYou’re Building AI Agents Wrong. Here’s How to Fix That with AAC \nBy @maxnechaev [ 10 Min read ] \n Fragile, chaotic AI agents are everywhere. AAC is a simple yet powerful architecture that brings structure, scalability, and reliability to your agent systems. Read More.\nHow I Set Up a Cowrie Honeypot to Capture Real SSH Attacks \nBy @authenticpeach [ 10 Min read ] \n Simulate real-world SSH attacks with Cowrie, log attacker behavior, and analyze tactics using MITRE ATT&CK in this hands-on honeypot project. Read More.\nBitcoin Mining Could Make Our Electricity Grids Smarter \nBy @maken8 [ 6 Min read ] \n In this article, my co-author and I explore how Bitcoin would revolutionize the same electricity network it is backed by. Read More.\nMeta’s AI Boss Just Called LLMs ‘Simplistic’ — Here’s What He’s Building Instead \nBy @hacker-Antho [ 8 Min read ] \n Yann LeCun, Chief AI Scientist at Meta, discusses the future of AI.  Read More.\nThe Art of a Great Rollout \nBy @sidosera [ 4 Min read ] \n We live in the era of high-frequency software deployments, where mass-market software products update several times a day, sometimes delivering hundreds or even Read More. \n 🧑‍💻 What happened in your world this week? It's been said that writing can help consolidate technical knowledge, establish credibility, and contribute to emerging community standards. Feeling stuck? We got you covered ⬇️⬇️⬇️\n ANSWER THESE GREATEST INTERVIEW QUESTIONS OF ALL TIME\n We hope you enjoy this worth of free reading material. Feel free to forward this email to a nerdy friend who'll love you for it.\n See you on Planet Internet! With love, \n The HackerNoon Team ✌️",
          "dc:creator": "Techbeat",
          "guid": "https://hackernoon.com/8-3-2025-techbeat?source=rss",
          "categories": [
            "tech-beat",
            "hackernoon-newsletter",
            "latest-tect-stories",
            "technology",
            "creativity"
          ],
          "isoDate": "2025-08-03T06:10:52.000Z"
        }
      },
      {
        "json": {
          "creator": "BTCWire",
          "title": "Pepeto Price Forecast 2025: Can This $0.000000144 Meme Coin Outrun Dogecoin, Shiba Inu, And Ethereum",
          "link": "https://hackernoon.com/pepeto-price-forecast-2025-can-this-$0000000144-meme-coin-outrun-dogecoin-shiba-inu-and-ethereum?source=rss",
          "pubDate": "Sat, 02 Aug 2025 20:26:38 GMT",
          "content:encoded": "<p>Dogecoin stands its ground. Shiba Inu is charging forward. Ethereum keeps pulling in heavy institutional cash. But quietly, in its own lane, Pepeto is gaining serious ground.</p>\n<p>Priced at just $0.000000144, Pepeto’s presale has already raked in over $5.8M, with $6M now in clear view. That kind of early buzz doesn’t spark without investors spotting real promise.</p>\n<p>Here’s why Pepeto is turning heads.</p>\n<h3 id=\"dogecoinvspepetoprovenplayervsrisingstar\">Dogecoin vs. Pepeto: Proven Player vs. Rising Star</h3>\n<p>Dogecoin has held steady this month, trading between $0.2163 and $0.2477, nudging up against resistance at $0.2477. Analysts project a climb to $0.2608 by late August, with a 2025 range of $0.220 to $0.320—offering a tidy 40–45% gain.</p>\n<p>It’s solid, but Pepeto plays a different game. Starting at $0.000000144, even a modest jump to $0.000005 in 2025 could deliver a jaw-dropping 34x return. No wild bets needed.</p>\n<p>Dogecoin has its legacy. Pepeto has its launchpad.</p>\n<h3 id=\"shibainuvspepetomomentumvsfirstmoveredge\">Shiba Inu vs. Pepeto: Momentum vs. First-Mover Edge</h3>\n<p>Shiba Inu has been electric. In July, it leaped from $0.0000117 to $0.0000160 before settling around $0.0000128–$0.0000130. Whales grabbed 1.81 trillion SHIB mid-month, and net inflows skyrocketed over 25,000% soon after.</p>\n<p>The hype is real, but SHIB’s growth is now measured. Pepeto, still in presale, offers the kind of early-stage opportunity Shiba Inu left behind years ago. It’s the difference between a coin with limited upside and one yet to hit major exchanges.</p>\n<h3 id=\"ethereumvspepetobedrockvsbreakout\">Ethereum vs. Pepeto: Bedrock vs. Breakout</h3>\n<p>Ethereum is the market’s foundation. From $2,403 earlier this year to $3,800 now, it’s testing resistance at $3,840–$3,940. With ETF inflows surpassing $1.5B, ETH is the darling of big money.</p>\n<p>But Ethereum’s gains are gradual, not explosive. Pepeto, still in its infancy, has untapped potential. A controlled climb to $0.000005–$0.000007 could easily outpace ETH’s expected returns by a wide margin.</p>\n<h3 id=\"pepetoethandshib2025pricereturnsnapshot\">PEPETO, ETH, and SHIB 2025 Price Return Snapshot</h3>\n<p>| Asset | Current Price ($) | Realistic Target ($) | Multiplier (x) | $10,000 Investment ($) |\n|----|----|----|----|----|\n| Pepeto | 0.000000144 | 0.000005 | 34.7 | 347,222.22 |\n| Dogecoin | 0.2190 | 0.320 | 1.46 | 14,600.00 |\n| Shiba Inu | 0.0000128 | 0.000030 | 2.34 | 23,400.00 |\n| Ethereum | 3,800 | 5,500 | 1.44 | 14,400.00 |</p>\n<p>\\n These numbers aren’t pipe dreams—they’re rooted in market trends and positioning.</p>\n<h3 id=\"pepetomorethanamemecoin\">Pepeto: More Than a Meme Coin</h3>\n<p>Most meme coins live and die by social media buzz—tweets, pumps, and viral moments. Pepeto is built differently.</p>\n<p>It’s not just a token; it’s an ecosystem. Pepeto’s exchange offers zero-fee trading for meme coins, creating a trader-friendly hub. Its cross-chain bridge solves liquidity fragmentation, linking meme coins across networks.</p>\n<p>And then there’s staking, with annual yields exceeding 255%. This isn’t about chasing quick flips—it’s about rewarding loyalty. Over 32 trillion PEPETO tokens are already staked, a clear sign of early believer confidence.</p>\n<h3 id=\"apresalethatspickingupspeed\">A Presale That’s Picking Up Speed</h3>\n<p>Presales are a trust test. Investors scan for warning signs and watch for staying power. Pepeto is passing with flying colors.</p>\n<p>At $0.000000144, it’s still affordable, but the $6M goal is almost here. This is the sweet spot before major listings erase the early-buyer advantage.</p>\n<p>Its staking model adds reliability, distributing 32,015,981.73 PEPETO per ETH block for two years. That’s a steady reward stream tied to the token’s rise.</p>\n<p><img src=\"https://cdn.hackernoon.com/images/FS1PiuQb1sWxoW2ESuJpZswu0xk2-rl036q7.jpeg\" alt=\"\" /></p>\n<h2 id=\"thetokenomicsfuelingpepeto\">The Tokenomics Fueling Pepeto</h2>\n<p>Pepeto’s tokenomics strike a smart balance. From a 420 trillion token supply, 30% goes to the presale, ensuring early investors get a fair shot. Another 30% powers staking, offering over 255% yearly rewards, with 32 trillion tokens already committed.</p>\n<p>Marketing claims 20% to boost Pepeto’s visibility. Liquidity gets 12.5% to ensure smooth trading post-launch. The final 7.5% funds development, driving enhancements to the exchange and bridge.</p>\n<p>This structure keeps the project strong, rewards holders, and fuels growth while ensuring market stability.</p>\n<p>Joining Pepeto is a breeze. Set up a wallet—Metamask for desktop or Best Wallet for mobile. Fund it with ETH, USDT, BNB, or a card. Connect, pick your PEPETO amount, and buy. Stake right away to earn rewards during the presale. Visit <strong><a href=\"https://pepeto.io/\">https://pepeto.io/</a></strong>&nbsp; to get started!</p>\n<h2 id=\"bottomline\">Bottom Line</h2>\n<p>Dogecoin has its diehards. Shiba Inu has its whale army. Ethereum has institutional muscle. But Pepeto has what they lack: a $0.000000144 entry point and real-world utility.</p>\n<p>With nearly $6M raised, Pepeto is poised at the starting gate of what could be a blockbuster 2025.</p>\n<p>For more information about PEPETO, visit the links below:</p>\n<p>Website:&nbsp;<strong><a href=\"https://pepeto.io/\">https://pepeto.io</a></strong><a href=\"https://pepeto.io/\"> \\n </a>Whitepaper:&nbsp;<strong>[https://pepeto.io/assets/documents/whitepaper.pdf?v2=true></strong><a href=\"https://pepeto.io/assets/documents/whitepaper.pdf?v2=true\"> \\n </a>Telegram:&nbsp;<strong>[https://t.me/pepeto_channel></strong><a href=\"https://t.me/pepeto_channel\"> \\n </a>Instagram:&nbsp;<strong>[https://www.instagram.com/pepetocoin/></strong><a href=\"https://www.instagram.com/pepetocoin/\"> \\n </a>Twitter/X:&nbsp;<strong><a href=\"https://x.com/Pepetocoin\">https://x.com/Pepetocoin</a></strong></p>\n<p>:::tip\nThis story was published as a press release by Btcwire under HackerNoon’s Business Blogging&nbsp;<strong><a href=\"https://business.hackernoon.com/business-blogging?ref=hackernoon.com\">Program</a></strong>.</p>\n<p>:::</p>\n<p>\\</p>",
          "content:encodedSnippet": "Dogecoin stands its ground. Shiba Inu is charging forward. Ethereum keeps pulling in heavy institutional cash. But quietly, in its own lane, Pepeto is gaining serious ground.\nPriced at just $0.000000144, Pepeto’s presale has already raked in over $5.8M, with $6M now in clear view. That kind of early buzz doesn’t spark without investors spotting real promise.\nHere’s why Pepeto is turning heads.\nDogecoin vs. Pepeto: Proven Player vs. Rising Star\nDogecoin has held steady this month, trading between $0.2163 and $0.2477, nudging up against resistance at $0.2477. Analysts project a climb to $0.2608 by late August, with a 2025 range of $0.220 to $0.320—offering a tidy 40–45% gain.\nIt’s solid, but Pepeto plays a different game. Starting at $0.000000144, even a modest jump to $0.000005 in 2025 could deliver a jaw-dropping 34x return. No wild bets needed.\nDogecoin has its legacy. Pepeto has its launchpad.\nShiba Inu vs. Pepeto: Momentum vs. First-Mover Edge\nShiba Inu has been electric. In July, it leaped from $0.0000117 to $0.0000160 before settling around $0.0000128–$0.0000130. Whales grabbed 1.81 trillion SHIB mid-month, and net inflows skyrocketed over 25,000% soon after.\nThe hype is real, but SHIB’s growth is now measured. Pepeto, still in presale, offers the kind of early-stage opportunity Shiba Inu left behind years ago. It’s the difference between a coin with limited upside and one yet to hit major exchanges.\nEthereum vs. Pepeto: Bedrock vs. Breakout\nEthereum is the market’s foundation. From $2,403 earlier this year to $3,800 now, it’s testing resistance at $3,840–$3,940. With ETF inflows surpassing $1.5B, ETH is the darling of big money.\nBut Ethereum’s gains are gradual, not explosive. Pepeto, still in its infancy, has untapped potential. A controlled climb to $0.000005–$0.000007 could easily outpace ETH’s expected returns by a wide margin.\nPEPETO, ETH, and SHIB 2025 Price Return Snapshot\n| Asset | Current Price ($) | Realistic Target ($) | Multiplier (x) | $10,000 Investment ($) |\n|----|----|----|----|----|\n| Pepeto | 0.000000144 | 0.000005 | 34.7 | 347,222.22 |\n| Dogecoin | 0.2190 | 0.320 | 1.46 | 14,600.00 |\n| Shiba Inu | 0.0000128 | 0.000030 | 2.34 | 23,400.00 |\n| Ethereum | 3,800 | 5,500 | 1.44 | 14,400.00 |\n\\n These numbers aren’t pipe dreams—they’re rooted in market trends and positioning.\nPepeto: More Than a Meme Coin\nMost meme coins live and die by social media buzz—tweets, pumps, and viral moments. Pepeto is built differently.\nIt’s not just a token; it’s an ecosystem. Pepeto’s exchange offers zero-fee trading for meme coins, creating a trader-friendly hub. Its cross-chain bridge solves liquidity fragmentation, linking meme coins across networks.\nAnd then there’s staking, with annual yields exceeding 255%. This isn’t about chasing quick flips—it’s about rewarding loyalty. Over 32 trillion PEPETO tokens are already staked, a clear sign of early believer confidence.\nA Presale That’s Picking Up Speed\nPresales are a trust test. Investors scan for warning signs and watch for staying power. Pepeto is passing with flying colors.\nAt $0.000000144, it’s still affordable, but the $6M goal is almost here. This is the sweet spot before major listings erase the early-buyer advantage.\nIts staking model adds reliability, distributing 32,015,981.73 PEPETO per ETH block for two years. That’s a steady reward stream tied to the token’s rise.\n\nThe Tokenomics Fueling Pepeto\nPepeto’s tokenomics strike a smart balance. From a 420 trillion token supply, 30% goes to the presale, ensuring early investors get a fair shot. Another 30% powers staking, offering over 255% yearly rewards, with 32 trillion tokens already committed.\nMarketing claims 20% to boost Pepeto’s visibility. Liquidity gets 12.5% to ensure smooth trading post-launch. The final 7.5% funds development, driving enhancements to the exchange and bridge.\nThis structure keeps the project strong, rewards holders, and fuels growth while ensuring market stability.\nJoining Pepeto is a breeze. Set up a wallet—Metamask for desktop or Best Wallet for mobile. Fund it with ETH, USDT, BNB, or a card. Connect, pick your PEPETO amount, and buy. Stake right away to earn rewards during the presale. Visit https://pepeto.io/  to get started!\nBottom Line\nDogecoin has its diehards. Shiba Inu has its whale army. Ethereum has institutional muscle. But Pepeto has what they lack: a $0.000000144 entry point and real-world utility.\nWith nearly $6M raised, Pepeto is poised at the starting gate of what could be a blockbuster 2025.\nFor more information about PEPETO, visit the links below:\nWebsite: https://pepeto.io \\n Whitepaper: [https://pepeto.io/assets/documents/whitepaper.pdf?v2=true> \\n Telegram: [https://t.me/pepeto_channel> \\n Instagram: [https://www.instagram.com/pepetocoin/> \\n Twitter/X: https://x.com/Pepetocoin\n:::tip\nThis story was published as a press release by Btcwire under HackerNoon’s Business Blogging Program.\n:::\n\\",
          "dc:creator": "BTCWire",
          "content": "Pepeto is a new, low-cost token that could offer a 34x return in 2025. It's already raked in over $5.8M and has $6M in the bank. Pepeto is still in presale, but has the kind of early-stage opportunity Shiba Inu left behind.",
          "contentSnippet": "Pepeto is a new, low-cost token that could offer a 34x return in 2025. It's already raked in over $5.8M and has $6M in the bank. Pepeto is still in presale, but has the kind of early-stage opportunity Shiba Inu left behind.",
          "guid": "https://hackernoon.com/pepeto-price-forecast-2025-can-this-$0000000144-meme-coin-outrun-dogecoin-shiba-inu-and-ethereum?source=rss",
          "categories": [
            "web3",
            "pepeto",
            "chainwire",
            "press-release",
            "pepeto-announcement",
            "blockchain-development",
            "crypto-trading",
            "good-company"
          ],
          "isoDate": "2025-08-02T20:26:38.000Z"
        }
      },
      {
        "json": {
          "title": "Here's How You Can Build Your Own Markdown Parser: Part 2 - How to Read File From the Command Line",
          "link": "https://hackernoon.com/heres-how-you-can-build-your-own-markdown-parser-part-2-how-to-read-file-from-the-command-line?source=rss",
          "pubDate": "Sat, 02 Aug 2025 19:00:05 GMT",
          "content:encoded": "<p>In this post, we will implement a command-line interface that’ll accept a markdown file as a command-line argument, read its content, and print the entire content of the file in the terminal.</p>\n<p>\\\nAfter doing this, we will be well on our way to start implementing parsing basic texts, headers, lists, and so on.</p>\n<p>\\\nI’ll explain all the code in detail, and in the end, I’ll give you the entire code so that you can try without any issues.</p>\n<h2 id=\"requiredmodules\">Required Modules</h2>\n<p>There are two modules that we need to use:</p>\n<ul>\n<li><p><code>std::env</code> - we need <code>env</code> module for interacting with the environment the program is currently running in. Now, we use it here to access the command-line arguments passed to our program.</p></li>\n<li><p><code>std::fs</code> - we need <code>fs</code> for file operations like reading from and writing to files.</p>\n<p>use std::env; use std::fs;</p></li>\n</ul>\n<h2 id=\"gettingthemarkdownfilefromthecommandline\">Getting the markdown file from the command line.</h2>\n<p>After getting the required modules, we can start working on getting the markdown file from the command line argument. From now on, we will write every line of code inside the main function.</p>\n<pre><code>let args: Vec&lt;String&gt; = env::args().collect();\n</code></pre>\n<p>\\\nLet’s understand what this line does.</p>\n<ul>\n<li><code>env::args()</code> - This function returns an iterator of the arguments provided in the command line to the program.</li>\n<li><code>collect()</code> - Then we are using the collect() method to consume the iterator and collect all the items from that iterator into a collection.</li>\n<li><code>Vec&lt;String&gt;</code> - To store all the items from the iterator, we are using the Vector collection that stores elements of type <code>String</code>. We gave the variable name of this <code>Vec&lt;String&gt;</code> as <code>args</code>. So, this <code>args</code> is holding all the items from that command line iterator.</li>\n</ul>\n<p>\\\nNow, let’s handle the case where the user either knowingly or unknowingly skips giving the markdown file in the command line argument. In this case, we need to ask the user to provide a markdown file.</p>\n<pre><code>if args.len() &lt; 2 {\n        println!(\"Please provide a markdown file\");\n        return;\n}\n</code></pre>\n<p>\\\nHere, we are saying if the number of commands is less than 2, then print a statement asking the user to provide a markdown file and then return from the program.</p>\n<blockquote>\n  <p>[!Note] Number of Arguments In command line, the first argument is the program’s name. We need another argument that’ll represent the filename. Hence, we need the length of the <code>args</code> to be at least 2.</p>\n</blockquote>\n<h2 id=\"readingthefileandprintingitscontent\">Reading the file and printing its content.</h2>\n<p>Now, let’s store the filename that we got from the command line argument.</p>\n<pre><code>let filename = &amp;args[1];\n</code></pre>\n<p>\\\nWe are creating a variable <code>filename</code> and storing the filename from the 2nd command-line argument.</p>\n<p>\\\nNow, let’s start reading the raw content of the file and print the entire content as it is.</p>\n<pre><code>println!(\"Attempting to read file: {}\", filename);\nlet content = fs::read_to_string(filename).expect(\"Something went wrong reading the file\");\nprintln!(\"File content:\\n{}\", content);\n</code></pre>\n<ul>\n<li>First, we are just printing a logging statement to know that we are attempting to read the file.</li>\n<li><code>fs::read_to_string(filename)</code> - This function comes from the <code>fs</code> module that reads the entire content of the file specified by the filename.</li>\n<li>Then, we are storing the entire content in the <code>content</code> variable and finally printing out the entire content on the console.</li>\n</ul>\n<p>\\\nBefore explaining the <code>expect()</code> method, let’s understand a specific data type in Rust.</p>\n<h2 id=\"resultinrust\"><code>Result</code> in Rust</h2>\n<p>In Rust, the way we handle operations that might fail is by using <code>Result</code> type. It’s an enum with two variants:</p>\n<pre><code>enum Result&lt;T, E&gt; {\n    Ok(T),    // Success - contains the value of type T\n    Err(E),   // Error - contains the error of type E\n}\n</code></pre>\n<p>\\\nNow, let’s get back to the <code>fs::read_to_string()</code> function. If you look in the docs, it returns a <code>Result</code> type, and for a success case, it returns a <code>String</code> type, and for a failure case, it returns a <code>std::io::Error</code> type.</p>\n<p>\\\nNow, let’s connect this with the <code>expect()</code> method.</p>\n<p>\\\nThis <code>expect()</code> method is a shortcut that says:</p>\n<ul>\n<li>if <code>fs::read_to_string()</code> works fine and returns <code>Ok(string)</code>, then return the string value.</li>\n<li>if <code>fs::read_to_string()</code> doesn’t work, then crash the program with the custom error message (“Something went wrong reading the file”).</li>\n</ul>\n<h2 id=\"testingtheprogram\">Testing the Program</h2>\n<p>To test, let’s create a <code>test.md</code> file in the root of the project and put some random markdown text.</p>\n<pre><code># this is a header\n- this is a list\nthis is a normal text\n</code></pre>\n<p>\\\nNow, open your terminal from your project directory and type the command:</p>\n<pre><code>cargo run -- test.md\n</code></pre>\n<p>\\\nIt’ll compile and execute the code and give you the following output.</p>\n<p><img src=\"https://cdn.hackernoon.com/images/ucQGpuYfFBfK3PrUUxfQVqx1slZ2-is037n7.jpeg\" alt=\"reading raw content from markdown file\" /></p>\n<p>This output shows that we can successfully get the markdown file’s content and print its raw data. In the next post, we will start to learn about parsing.</p>\n<h2 id=\"completesourcecode\">Complete Source Code</h2>\n<pre><code>use std::env;\nuse std::fs;\n\nfn main() {\n    let args: Vec&lt;String&gt; = env::args().collect();\n\n    if args.len() &lt; 2 {\n        println!(\"Please provide a markdown file\");\n        return;\n    }\n\n    let filename = &amp;args[1];\n\n    println!(\"Attempting to read file: {}\", filename);\n\n    let content = fs::read_to_string(filename).expect(\"Something went wrong reading the file\");\n\n    println!(\"File content:\\n{}\", content);\n}\n</code></pre>\n<h2 id=\"conclusion\">Conclusion</h2>\n<p>In this post, we understood how to interact with the command line and also read the markdown file from the command line argument. We also understood basic error handling using <code>Result</code> where we know things might go wrong, and we made sure that our program can handle that.</p>\n<p>\\\nNow, we understand reading and printing all the markdown file content. From the next post, we are slowly going to implement our parsing algorithm step by step and cover basic text, headers, lists, and other things one by one. I’m really excited for the next post; I hope you are excited too. See you soon.</p>\n<p>\\</p>",
          "content:encodedSnippet": "In this post, we will implement a command-line interface that’ll accept a markdown file as a command-line argument, read its content, and print the entire content of the file in the terminal.\n\\\nAfter doing this, we will be well on our way to start implementing parsing basic texts, headers, lists, and so on.\n\\\nI’ll explain all the code in detail, and in the end, I’ll give you the entire code so that you can try without any issues.\nRequired Modules\nThere are two modules that we need to use:\nstd::env - we need env module for interacting with the environment the program is currently running in. Now, we use it here to access the command-line arguments passed to our program.\n\n\nstd::fs - we need fs for file operations like reading from and writing to files.\nuse std::env; use std::fs;\n\n\nGetting the markdown file from the command line.\nAfter getting the required modules, we can start working on getting the markdown file from the command line argument. From now on, we will write every line of code inside the main function.\nlet args: Vec<String> = env::args().collect();\n\n\\\nLet’s understand what this line does.\nenv::args() - This function returns an iterator of the arguments provided in the command line to the program.\ncollect() - Then we are using the collect() method to consume the iterator and collect all the items from that iterator into a collection.\nVec<String> - To store all the items from the iterator, we are using the Vector collection that stores elements of type String. We gave the variable name of this Vec<String> as args. So, this args is holding all the items from that command line iterator.\n\\\nNow, let’s handle the case where the user either knowingly or unknowingly skips giving the markdown file in the command line argument. In this case, we need to ask the user to provide a markdown file.\nif args.len() < 2 {\n        println!(\"Please provide a markdown file\");\n        return;\n}\n\n\\\nHere, we are saying if the number of commands is less than 2, then print a statement asking the user to provide a markdown file and then return from the program.\n[!Note] Number of Arguments In command line, the first argument is the program’s name. We need another argument that’ll represent the filename. Hence, we need the length of the args to be at least 2.\nReading the file and printing its content.\nNow, let’s store the filename that we got from the command line argument.\nlet filename = &args[1];\n\n\\\nWe are creating a variable filename and storing the filename from the 2nd command-line argument.\n\\\nNow, let’s start reading the raw content of the file and print the entire content as it is.\nprintln!(\"Attempting to read file: {}\", filename);\nlet content = fs::read_to_string(filename).expect(\"Something went wrong reading the file\");\nprintln!(\"File content:\\n{}\", content);\n\nFirst, we are just printing a logging statement to know that we are attempting to read the file.\nfs::read_to_string(filename) - This function comes from the fs module that reads the entire content of the file specified by the filename.\nThen, we are storing the entire content in the content variable and finally printing out the entire content on the console.\n\\\nBefore explaining the expect() method, let’s understand a specific data type in Rust.\nResult in Rust\nIn Rust, the way we handle operations that might fail is by using Result type. It’s an enum with two variants:\nenum Result<T, E> {\n    Ok(T),    // Success - contains the value of type T\n    Err(E),   // Error - contains the error of type E\n}\n\n\\\nNow, let’s get back to the fs::read_to_string() function. If you look in the docs, it returns a Result type, and for a success case, it returns a String type, and for a failure case, it returns a std::io::Error type.\n\\\nNow, let’s connect this with the expect() method.\n\\\nThis expect() method is a shortcut that says:\nif fs::read_to_string() works fine and returns Ok(string), then return the string value.\nif fs::read_to_string() doesn’t work, then crash the program with the custom error message (“Something went wrong reading the file”).\nTesting the Program\nTo test, let’s create a test.md file in the root of the project and put some random markdown text.\n# this is a header\n- this is a list\nthis is a normal text\n\n\\\nNow, open your terminal from your project directory and type the command:\ncargo run -- test.md\n\n\\\nIt’ll compile and execute the code and give you the following output.\n\nThis output shows that we can successfully get the markdown file’s content and print its raw data. In the next post, we will start to learn about parsing.\nComplete Source Code\nuse std::env;\nuse std::fs;\n\nfn main() {\n    let args: Vec<String> = env::args().collect();\n\n    if args.len() < 2 {\n        println!(\"Please provide a markdown file\");\n        return;\n    }\n\n    let filename = &args[1];\n\n    println!(\"Attempting to read file: {}\", filename);\n\n    let content = fs::read_to_string(filename).expect(\"Something went wrong reading the file\");\n\n    println!(\"File content:\\n{}\", content);\n}\n\nConclusion\nIn this post, we understood how to interact with the command line and also read the markdown file from the command line argument. We also understood basic error handling using Result where we know things might go wrong, and we made sure that our program can handle that.\n\\\nNow, we understand reading and printing all the markdown file content. From the next post, we are slowly going to implement our parsing algorithm step by step and cover basic text, headers, lists, and other things one by one. I’m really excited for the next post; I hope you are excited too. See you soon.\n\\",
          "content": "In this post, we will implement a command-line interface that’ll accept a markdown file as an argument. We will then read its content and print the entire content of the file in the terminal. After doing this we will be well on our way to start implementing parsing basic texts, headers, lists, and so on.",
          "contentSnippet": "In this post, we will implement a command-line interface that’ll accept a markdown file as an argument. We will then read its content and print the entire content of the file in the terminal. After doing this we will be well on our way to start implementing parsing basic texts, headers, lists, and so on.",
          "guid": "https://hackernoon.com/heres-how-you-can-build-your-own-markdown-parser-part-2-how-to-read-file-from-the-command-line?source=rss",
          "categories": [
            "rust",
            "markdown",
            "parser",
            "command-line",
            "rust-tutorial",
            "rustlang",
            "learn-rust",
            "hackernoon-top-story"
          ],
          "isoDate": "2025-08-02T19:00:05.000Z"
        }
      },
      {
        "json": {
          "creator": "Ryan Daws",
          "title": "Deep Cogito v2: Open-source AI that hones its reasoning skills",
          "link": "https://www.artificialintelligence-news.com/news/deep-cogito-v2-open-source-ai-hones-its-reasoning-skills/",
          "pubDate": "Fri, 01 Aug 2025 14:11:47 +0000",
          "content:encoded": "\n<p><a href=\"https://www.deepcogito.com/\" target=\"_blank\" rel=\"noreferrer noopener\">Deep Cogito</a> has released Cogito v2, a new family of open-source AI models that sharpen their own reasoning skills.</p>\n\n\n\n<p>Released under an open-source licence, the new Cogito v2 lineup includes four hybrid reasoning AI models: two mid-sized at 70B and 109B parameters, and two large-scale versions at 405B and 671B.&nbsp;</p>\n\n\n\n<p>The largest, a 671B Mixture-of-Experts (MoE) model, is already being touted as one of the most powerful open-source AIs in the world. The company reports that it competes with the latest from DeepSeek and is closing the gap on proprietary systems like O3 and Claude 4 Opus.</p>\n\n\n\n<p>But the real story isn&#8217;t just about size or power; it&#8217;s about a fundamental shift in how the AI learns. Instead of just &#8216;thinking&#8217; longer at inference time to find an answer, Cogito v2 is designed to internalise its own reasoning processes.</p>\n\n\n\n<p>This internalised reasoning is achieved through a technique called Iterated Distillation and Amplification (IDA), which distils the discoveries from a search back into the model&#8217;s core parameters. The goal is to build a stronger &#8216;intuition&#8217;, allowing the model to anticipate the outcome of its own reasoning without having to perform the entire search.</p>\n\n\n\n<p>Because the open-source AI models have a better “gut feeling” for the right approach, their reasoning chains are 60% shorter than those of rivals like Deepseek R1.</p>\n\n\n\n<p>This efficiency extends to the budget. Deep Cogito says that it developed all its models – from experiments to final training – for a combined total of less than $3.5 million. Still a large sum likely for you or I, but miniscule compared to the spending of many of the leading AI labs.</p>\n\n\n\n<p>The flagship 671B model received special attention, trained not only to improve its final answers but to refine the thinking process itself. This approach discourages the model from “meandering” and rewards a more direct path to the solution. The performance data suggests it works, with Deep Cogito’s open-source AI model matching or exceeding the latest DeepSeek versions on key benchmarks while being close to proprietary alternatives:</p>\n\n\n\n<figure class=\"wp-block-image aligncenter size-full\"><img fetchpriority=\"high\" decoding=\"async\" width=\"828\" height=\"466\" src=\"https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/cogito-v2-preview-671b-moe-ai-model-artificial-intelligence-reasoning-open-source-development-skills-benchmark.jpg\" alt=\"Benchmark comparison of the flagship open-source Deep Cogito v2 671B AI reasoning model against Deepseek and OpenAI o3 and Anthropic Claude models.\" class=\"wp-image-107275\" srcset=\"https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/cogito-v2-preview-671b-moe-ai-model-artificial-intelligence-reasoning-open-source-development-skills-benchmark.jpg 828w, https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/cogito-v2-preview-671b-moe-ai-model-artificial-intelligence-reasoning-open-source-development-skills-benchmark-300x169.jpg 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/cogito-v2-preview-671b-moe-ai-model-artificial-intelligence-reasoning-open-source-development-skills-benchmark-768x432.jpg 768w\" sizes=\"(max-width: 828px) 100vw, 828px\" /></figure>\n\n\n\n<p>Perhaps one of the most surprising outcomes is the models&#8217; ability to reason about images; a skill they were never explicitly trained for.</p>\n\n\n\n<p>The team shared an example of this reasoning where Deep Cogito’s open-source AI model compared two images of a duck and a lion, demonstrating a deep thinking process about their habitats, colours, and composition purely through transfer learning. Deep Cogito believes this emergent property could be a powerful way to bootstrap training data for future multimodal reasoning systems.</p>\n\n\n\n<p>Looking ahead, the Deep Cogito team plans to &#8220;hill climb on the gains of iterative self-improvement&#8221; in its quest to build superintelligence. They have restated their commitment that all AI models they create will be open-source.</p>\n\n\n\n<p><strong>See also: </strong><a href=\"https://www.artificialintelligence-news.com/news/leak-openai-open-source-ai-model-release-imminent/\"><strong>Leak suggests OpenAI’s open-source AI model release is imminent</strong></a></p>\n\n\n\n<figure class=\"wp-block-image aligncenter size-full is-resized\"><a href=\"https://www.ai-expo.net/\"><img decoding=\"async\" width=\"728\" height=\"90\" src=\"https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png\" alt=\"\" class=\"wp-image-11874\" style=\"width:800px;height:auto\" srcset=\"https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w\" sizes=\"(max-width: 728px) 100vw, 728px\" /></a></figure>\n\n\n\n<p><strong>Want to learn more about AI and big data from industry leaders?</strong> Check out<a href=\"https://www.ai-expo.net/\"> AI &amp; Big Data Expo</a> taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including <a href=\"https://intelligentautomation-conference.com/northamerica/\">Intelligent Automation Conference</a>, <a href=\"https://www.blockchain-expo.com/\">BlockX</a>,<a href=\"https://digitaltransformation-week.com/\"> Digital Transformation Week</a>, and <a href=\"https://www.cybersecuritycloudexpo.com/\">Cyber Security &amp; Cloud Expo</a>.</p>\n\n\n\n<p>Explore other upcoming enterprise technology events and webinars powered by TechForge <a href=\"https://techforge.pub/events/\">here</a>.</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/deep-cogito-v2-open-source-ai-hones-its-reasoning-skills/\">Deep Cogito v2: Open-source AI that hones its reasoning skills</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
          "content:encodedSnippet": "Deep Cogito has released Cogito v2, a new family of open-source AI models that sharpen their own reasoning skills.\nReleased under an open-source licence, the new Cogito v2 lineup includes four hybrid reasoning AI models: two mid-sized at 70B and 109B parameters, and two large-scale versions at 405B and 671B. \nThe largest, a 671B Mixture-of-Experts (MoE) model, is already being touted as one of the most powerful open-source AIs in the world. The company reports that it competes with the latest from DeepSeek and is closing the gap on proprietary systems like O3 and Claude 4 Opus.\nBut the real story isn’t just about size or power; it’s about a fundamental shift in how the AI learns. Instead of just ‘thinking’ longer at inference time to find an answer, Cogito v2 is designed to internalise its own reasoning processes.\nThis internalised reasoning is achieved through a technique called Iterated Distillation and Amplification (IDA), which distils the discoveries from a search back into the model’s core parameters. The goal is to build a stronger ‘intuition’, allowing the model to anticipate the outcome of its own reasoning without having to perform the entire search.\nBecause the open-source AI models have a better “gut feeling” for the right approach, their reasoning chains are 60% shorter than those of rivals like Deepseek R1.\nThis efficiency extends to the budget. Deep Cogito says that it developed all its models – from experiments to final training – for a combined total of less than $3.5 million. Still a large sum likely for you or I, but miniscule compared to the spending of many of the leading AI labs.\nThe flagship 671B model received special attention, trained not only to improve its final answers but to refine the thinking process itself. This approach discourages the model from “meandering” and rewards a more direct path to the solution. The performance data suggests it works, with Deep Cogito’s open-source AI model matching or exceeding the latest DeepSeek versions on key benchmarks while being close to proprietary alternatives:\n\n\n\n\nPerhaps one of the most surprising outcomes is the models’ ability to reason about images; a skill they were never explicitly trained for.\nThe team shared an example of this reasoning where Deep Cogito’s open-source AI model compared two images of a duck and a lion, demonstrating a deep thinking process about their habitats, colours, and composition purely through transfer learning. Deep Cogito believes this emergent property could be a powerful way to bootstrap training data for future multimodal reasoning systems.\nLooking ahead, the Deep Cogito team plans to “hill climb on the gains of iterative self-improvement” in its quest to build superintelligence. They have restated their commitment that all AI models they create will be open-source.\nSee also: Leak suggests OpenAI’s open-source AI model release is imminent\n\n\n\n\nWant to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security & Cloud Expo.\nExplore other upcoming enterprise technology events and webinars powered by TechForge here.\nThe post Deep Cogito v2: Open-source AI that hones its reasoning skills appeared first on AI News.",
          "dc:creator": "Ryan Daws",
          "content": "<p>Deep Cogito has released Cogito v2, a new family of open-source AI models that sharpen their own reasoning skills. Released under an open-source licence, the new Cogito v2 lineup includes four hybrid reasoning AI models: two mid-sized at 70B and 109B parameters, and two large-scale versions at 405B and 671B.&#160; The largest, a 671B Mixture-of-Experts [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/deep-cogito-v2-open-source-ai-hones-its-reasoning-skills/\">Deep Cogito v2: Open-source AI that hones its reasoning skills</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
          "contentSnippet": "Deep Cogito has released Cogito v2, a new family of open-source AI models that sharpen their own reasoning skills. Released under an open-source licence, the new Cogito v2 lineup includes four hybrid reasoning AI models: two mid-sized at 70B and 109B parameters, and two large-scale versions at 405B and 671B.  The largest, a 671B Mixture-of-Experts […]\nThe post Deep Cogito v2: Open-source AI that hones its reasoning skills appeared first on AI News.",
          "guid": "https://www.artificialintelligence-news.com/?p=107273",
          "categories": [
            "Artificial Intelligence",
            "Companies",
            "Development",
            "new_Open-Source & Democratised AI",
            "new_Reinforcement Learning",
            "ai",
            "artificial intelligence",
            "benchmarks",
            "deep cogito",
            "development",
            "models",
            "open-source",
            "reasoning"
          ],
          "isoDate": "2025-08-01T14:11:47.000Z"
        }
      },
      {
        "json": {
          "creator": "Ryan Daws",
          "title": "Leak suggests OpenAI’s open-source AI model release is imminent",
          "link": "https://www.artificialintelligence-news.com/news/leak-openai-open-source-ai-model-release-imminent/",
          "pubDate": "Fri, 01 Aug 2025 12:03:44 +0000",
          "content:encoded": "\n<p>A leak suggests that OpenAI is about to launch a powerful new open-source AI model, potentially within hours.</p>\n\n\n\n<p>The evidence comes from a trail of digital breadcrumbs, eagerly pored over by developers. At the centre of it all are screenshots showing a series of model repositories with names like yofo-deepcurrent/gpt-oss-120b and yofo-wildflower/gpt-oss-20b. The repos have since been deleted, but <a href=\"https://huggingface.co/yofo-riverbend\" target=\"_blank\" rel=\"noreferrer noopener\">the accounts</a> feature OpenAI team members.</p>\n\n\n\n<p>That gpt-oss tag is the real smoking gun, seemingly a clear signpost for ‘GPT Open Source Software’. For a company that has increasingly guarded its top-tier models, this would be somewhat of a return to its roots. The fact that we are seeing multiple versions, with different codenames and sizes, suggests a well-planned family of models are about to make their debut.</p>\n\n\n\n<figure class=\"wp-block-image size-large\"><img decoding=\"async\" width=\"679\" height=\"1024\" src=\"https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/openai-open-source-ai-model-open-source-artificial-intelligence-leak-gpt-679x1024.jpeg\" alt=\"Screenshot of alleged leaked repos for OpenAI's open-source AI model that is set for imminent launch.\" class=\"wp-image-107267\" srcset=\"https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/openai-open-source-ai-model-open-source-artificial-intelligence-leak-gpt-679x1024.jpeg 679w, https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/openai-open-source-ai-model-open-source-artificial-intelligence-leak-gpt-199x300.jpeg 199w, https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/openai-open-source-ai-model-open-source-artificial-intelligence-leak-gpt-768x1159.jpeg 768w, https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/openai-open-source-ai-model-open-source-artificial-intelligence-leak-gpt-1018x1536.jpeg 1018w, https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/openai-open-source-ai-model-open-source-artificial-intelligence-leak-gpt.jpeg 1036w\" sizes=\"(max-width: 679px) 100vw, 679px\" /></figure>\n\n\n\n<p>Thanks to a leaked configuration file, we can even peek under the bonnet of the suspected 120 billion parameter version.</p>\n\n\n\n<p>The model appears to be built on a Mixture of Experts, or MoE, architecture. Think of it less like a single, monolithic brain trying to know everything, and more like a board of 128 specialist advisors. When a query comes in, the system intelligently selects the four best experts for the job. This gives the model the vast knowledge of its huge parameter count, but the speed and agility of a much smaller system, as only a fraction of it is working at any one time.</p>\n\n\n\n<p>This design puts OpenAI’s open-source AI model squarely in competition with the darlings of the scene, like Mistral AI&#8217;s Mixtral and Meta&#8217;s Llama family.</p>\n\n\n\n<p>And the specs don&#8217;t stop there. OpenAI’s open-source AI model appears to boast a huge vocabulary, which should make it more efficient with a wider range of languages, and uses Sliding Window Attention to handle long streams of text without breaking a sweat. In practice, this all points to a model that is both powerful and practical to run.</p>\n\n\n\n<p>So, why would OpenAI make such a move now? For years, the company has faced gentle jabs and outright criticism for straying from its more open beginnings. Launching a powerful gpt-oss would be a massive charm offensive aimed directly at the developers and researchers who felt left behind.</p>\n\n\n\n<p>Of course, it’s also a shrewd competitive play. Meta and Mistral have shown how a thriving open-source ecosystem can drive innovation. By dropping a powerful open-source AI model like this appears to be into the mix, OpenAI isn&#8217;t just joining the race; it’s attempting to redefine the track.</p>\n\n\n\n<p>Until we get the official word from OpenAI, this is all still, technically, rumour. But it’s a rumour with substance, backed by code and configuration files.</p>\n\n\n\n<p>The launch of a high-performance, 120-billion-parameter open-source MoE model from the most famous name in AI would be nothing short of a landmark event, and it appears to be imminent.</p>\n\n\n\n<p><em>(Photo by <a href=\"https://unsplash.com/@maria_shalabaieva?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash\" target=\"_blank\" rel=\"noreferrer noopener\">Mariia Shalabaieva</a>)</em></p>\n\n\n\n<p><strong>See also: </strong><a href=\"https://www.artificialintelligence-news.com/news/zuckerberg-outlines-meta-ai-vision-personal-superintelligence/\"><strong>Zuckerberg outlines Meta’s AI vision for ‘personal superintelligence’</strong></a></p>\n\n\n\n<figure class=\"wp-block-image size-full is-resized\"><a href=\"https://www.ai-expo.net/\"><img decoding=\"async\" width=\"728\" height=\"90\" src=\"https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png\" alt=\"\" class=\"wp-image-11874\" style=\"width:800px;height:auto\" srcset=\"https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w\" sizes=\"(max-width: 728px) 100vw, 728px\" /></a></figure>\n\n\n\n<p><strong>Want to learn more about AI and big data from industry leaders?</strong> Check out<a href=\"https://www.ai-expo.net/\"> AI &amp; Big Data Expo</a> taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including <a href=\"https://intelligentautomation-conference.com/northamerica/\">Intelligent Automation Conference</a>, <a href=\"https://www.blockchain-expo.com/\">BlockX</a>,<a href=\"https://digitaltransformation-week.com/\"> Digital Transformation Week</a>, and <a href=\"https://www.cybersecuritycloudexpo.com/\">Cyber Security &amp; Cloud Expo</a>.</p>\n\n\n\n<p>Explore other upcoming enterprise technology events and webinars powered by TechForge <a href=\"https://techforge.pub/events/\">here</a>.</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/leak-openai-open-source-ai-model-release-imminent/\">Leak suggests OpenAI’s open-source AI model release is imminent</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
          "content:encodedSnippet": "A leak suggests that OpenAI is about to launch a powerful new open-source AI model, potentially within hours.\nThe evidence comes from a trail of digital breadcrumbs, eagerly pored over by developers. At the centre of it all are screenshots showing a series of model repositories with names like yofo-deepcurrent/gpt-oss-120b and yofo-wildflower/gpt-oss-20b. The repos have since been deleted, but the accounts feature OpenAI team members.\nThat gpt-oss tag is the real smoking gun, seemingly a clear signpost for ‘GPT Open Source Software’. For a company that has increasingly guarded its top-tier models, this would be somewhat of a return to its roots. The fact that we are seeing multiple versions, with different codenames and sizes, suggests a well-planned family of models are about to make their debut.\n\n\n\n\nThanks to a leaked configuration file, we can even peek under the bonnet of the suspected 120 billion parameter version.\nThe model appears to be built on a Mixture of Experts, or MoE, architecture. Think of it less like a single, monolithic brain trying to know everything, and more like a board of 128 specialist advisors. When a query comes in, the system intelligently selects the four best experts for the job. This gives the model the vast knowledge of its huge parameter count, but the speed and agility of a much smaller system, as only a fraction of it is working at any one time.\nThis design puts OpenAI’s open-source AI model squarely in competition with the darlings of the scene, like Mistral AI’s Mixtral and Meta’s Llama family.\nAnd the specs don’t stop there. OpenAI’s open-source AI model appears to boast a huge vocabulary, which should make it more efficient with a wider range of languages, and uses Sliding Window Attention to handle long streams of text without breaking a sweat. In practice, this all points to a model that is both powerful and practical to run.\nSo, why would OpenAI make such a move now? For years, the company has faced gentle jabs and outright criticism for straying from its more open beginnings. Launching a powerful gpt-oss would be a massive charm offensive aimed directly at the developers and researchers who felt left behind.\nOf course, it’s also a shrewd competitive play. Meta and Mistral have shown how a thriving open-source ecosystem can drive innovation. By dropping a powerful open-source AI model like this appears to be into the mix, OpenAI isn’t just joining the race; it’s attempting to redefine the track.\nUntil we get the official word from OpenAI, this is all still, technically, rumour. But it’s a rumour with substance, backed by code and configuration files.\nThe launch of a high-performance, 120-billion-parameter open-source MoE model from the most famous name in AI would be nothing short of a landmark event, and it appears to be imminent.\n(Photo by Mariia Shalabaieva)\nSee also: Zuckerberg outlines Meta’s AI vision for ‘personal superintelligence’\n\n\n\n\nWant to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security & Cloud Expo.\nExplore other upcoming enterprise technology events and webinars powered by TechForge here.\nThe post Leak suggests OpenAI’s open-source AI model release is imminent appeared first on AI News.",
          "dc:creator": "Ryan Daws",
          "content": "<p>A leak suggests that OpenAI is about to launch a powerful new open-source AI model, potentially within hours. The evidence comes from a trail of digital breadcrumbs, eagerly pored over by developers. At the centre of it all are screenshots showing a series of model repositories with names like yofo-deepcurrent/gpt-oss-120b and yofo-wildflower/gpt-oss-20b. The repos have [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/leak-openai-open-source-ai-model-release-imminent/\">Leak suggests OpenAI’s open-source AI model release is imminent</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
          "contentSnippet": "A leak suggests that OpenAI is about to launch a powerful new open-source AI model, potentially within hours. The evidence comes from a trail of digital breadcrumbs, eagerly pored over by developers. At the centre of it all are screenshots showing a series of model repositories with names like yofo-deepcurrent/gpt-oss-120b and yofo-wildflower/gpt-oss-20b. The repos have […]\nThe post Leak suggests OpenAI’s open-source AI model release is imminent appeared first on AI News.",
          "guid": "https://www.artificialintelligence-news.com/?p=107266",
          "categories": [
            "Artificial Intelligence",
            "Companies",
            "Development",
            "ai",
            "artificial intelligence",
            "development",
            "gpt",
            "open-source",
            "openai"
          ],
          "isoDate": "2025-08-01T12:03:44.000Z"
        }
      },
      {
        "json": {
          "creator": "Ryan Daws",
          "title": "Shah Muhammad, Sweco: How AI is building the future of our cities",
          "link": "https://www.artificialintelligence-news.com/news/shah-muhammad-sweco-how-ai-is-building-future-of-our-cities/",
          "pubDate": "Thu, 31 Jul 2025 16:44:13 +0000",
          "content:encoded": "\n<p>Shah Muhammad, who leads AI Innovation at the design and engineering firm <a href=\"https://www.sweco.co.uk/\">Sweco</a>, offers his insights into how AI is building the cities of the future.</p>\n\n\n\n<p>Ever been stuck in traffic and thought, &#8220;Surely, there’s a better way to design this city?&#8221; Or walked past a giant new building and wondered if it would be an energy-guzzling monster?</p>\n\n\n\n<p>For decades, building our towns and cities has been a slow, complicated process, often relying on educated guesswork. But what if we could give city planners superpowers? What if they could test-drive a dozen different futures before a single shovel hits the ground?</p>\n\n\n\n<p>That’s exactly what’s starting to happen. And the secret ingredient is AI.</p>\n\n\n\n<figure class=\"wp-block-image alignleft size-full is-resized\"><img loading=\"lazy\" decoding=\"async\" width=\"683\" height=\"683\" src=\"https://www.artificialintelligence-news.com/wp-content/uploads/2025/07/shah-muhammad-sweco-group-ai.jpeg\" alt=\"Headshot of Shah Muhammad, who leads AI Innovation at the design and engineering firm Sweco, and has given his insights on how AI is building the future of our cities.\" class=\"wp-image-107259\" style=\"width:136px;height:auto\" srcset=\"https://www.artificialintelligence-news.com/wp-content/uploads/2025/07/shah-muhammad-sweco-group-ai.jpeg 683w, https://www.artificialintelligence-news.com/wp-content/uploads/2025/07/shah-muhammad-sweco-group-ai-300x300.jpeg 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2025/07/shah-muhammad-sweco-group-ai-150x150.jpeg 150w\" sizes=\"(max-width: 683px) 100vw, 683px\" /></figure>\n\n\n\n<p>&#8220;AI is revolutionising urban design and infrastructure planning at Sweco by optimising processes, enhancing decision-making, and improving sustainability outcomes,&#8221; Shah explains. &#8220;It allows us to analyse vast amounts of data, simulate various scenarios, and create more efficient and resilient urban environments.&#8221;</p>\n\n\n\n<p>Shah is saying that AI gives his team the ability to ask the big questions that will impact people’s lives when designing the cities of the future: &#8220;What’s the smartest way to build this neighbourhood to cut down on traffic jams and pollution? How can we design a building that stays cool in a heatwave without huge electricity bills?&#8221; The AI can run the numbers on thousands of possibilities to find the best path forward.</p>\n\n\n\n<p>Of course, the real world is messy. It’s not a neat and tidy computer simulation. It’s full of unpredictable weather, unexpected delays, and the beautiful chaos of human life. This is the number one headache.</p>\n\n\n\n<p>&#8220;The biggest challenge in applying data-driven models to physical environments is the complexity and variability of real-world conditions,&#8221; Shah says. &#8220;Ensuring that models accurately represent these conditions and can adapt to changing conditions is crucial.&#8221;</p>\n\n\n\n<p>So, how do they deal with that? They start with the basics. They get their house in order. Before they even think about AI, they make sure the information it learns from is rock-solid and trustworthy.</p>\n\n\n\n<p>&#8220;To ensure data quality and interoperability across projects, we implement rigorous data governance practices, standardise data formats, and use interoperable software tools,&#8221; he says.</p>\n\n\n\n<p>That might sound a bit technical, but think of it this way: they’re making sure everyone on the team is singing from the same hymn sheet. When all the different software tools can talk to each other and everyone trusts the information, the AI can do its job properly. It &#8220;enables seamless data exchange and collaboration among different teams and stakeholders.&#8221;</p>\n\n\n\n<p>But of all the things AI can do, this next part might be the most hopeful when using it to design future cities. It shows that this technology can have a real heart.</p>\n\n\n\n<p>&#8220;There are many projects where AI has made a measurable impact on sustainability, making it hard to single out one,&#8221; he reflects. &#8220;However, if I were to choose, I would highlight a project where AI was used to preserve biodiversity by identifying endangered species and providing this information to researchers.&#8221;</p>\n\n\n\n<p>In this scenario, technology is giving nature a voice in the planning meeting. It’s like the AI raising its hand and saying, &#8220;Hang on, let&#8217;s be careful here, there’s a family of rare birds living in this area.&#8221; It allows us to build with respect for the world around us.</p>\n\n\n\n<p>So, what&#8217;s the next chapter? According to Shah, it’s about turning that crystal ball into a real-time guide.&nbsp;</p>\n\n\n\n<p>&#8220;According to me, the biggest opportunity for AI in the AEC sector lies in predictive analytics and automation,&#8221; Shah explains. “By anticipating future trends, identifying potential issues early, and automating routine tasks, AI can greatly enhance efficiency, reduce costs, and improve the overall quality of projects.&#8221;</p>\n\n\n\n<p>This could mean safer bridges, roads that need fewer repairs, and less disruption to our lives. It means freeing up talented people from the boring tasks to focus on building the cities of the future that are more in tune with the people who call them home.</p>\n\n\n\n<p><em>Shah Muhammad is speaking at </em><a href=\"https://www.ai-expo.net/europe/\"><em>AI &amp; Big Data Expo Europe</em></a><em> in Amsterdam on 24-25 September 2025 where he will be hosting a presentation on ‘Leveraging Generative and Agentic AI for Intelligent Process Automation’. Find out more about the event and how to attend </em><a href=\"https://www.ai-expo.net/europe/\"><em>here</em></a><em>.</em></p>\n\n\n\n<p><strong>See also: </strong><a href=\"https://www.artificialintelligence-news.com/news/zuckerberg-outlines-meta-ai-vision-personal-superintelligence/\"><strong>Zuckerberg outlines Meta’s AI vision for ‘personal superintelligence’</strong></a></p>\n\n\n\n<figure class=\"wp-block-image size-full is-resized\"><a href=\"https://www.ai-expo.net/\"><img decoding=\"async\" width=\"728\" height=\"90\" src=\"https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png\" alt=\"\" class=\"wp-image-11874\" style=\"width:800px;height:auto\" srcset=\"https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w\" sizes=\"(max-width: 728px) 100vw, 728px\" /></a></figure>\n\n\n\n<p><strong>Want to learn more about AI and big data from industry leaders?</strong> Check out<a href=\"https://www.ai-expo.net/\"> AI &amp; Big Data Expo</a> taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including <a href=\"https://intelligentautomation-conference.com/northamerica/\">Intelligent Automation Conference</a>, <a href=\"https://www.blockchain-expo.com/\">BlockX</a>,<a href=\"https://digitaltransformation-week.com/\"> Digital Transformation Week</a>, and <a href=\"https://www.cybersecuritycloudexpo.com/\">Cyber Security &amp; Cloud Expo</a>.</p>\n\n\n\n<p>Explore other upcoming enterprise technology events and webinars powered by TechForge <a href=\"https://techforge.pub/events/\">here</a>.</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/shah-muhammad-sweco-how-ai-is-building-future-of-our-cities/\">Shah Muhammad, Sweco: How AI is building the future of our cities</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
          "content:encodedSnippet": "Shah Muhammad, who leads AI Innovation at the design and engineering firm Sweco, offers his insights into how AI is building the cities of the future.\nEver been stuck in traffic and thought, “Surely, there’s a better way to design this city?” Or walked past a giant new building and wondered if it would be an energy-guzzling monster?\nFor decades, building our towns and cities has been a slow, complicated process, often relying on educated guesswork. But what if we could give city planners superpowers? What if they could test-drive a dozen different futures before a single shovel hits the ground?\nThat’s exactly what’s starting to happen. And the secret ingredient is AI.\n\n\n\n\n“AI is revolutionising urban design and infrastructure planning at Sweco by optimising processes, enhancing decision-making, and improving sustainability outcomes,” Shah explains. “It allows us to analyse vast amounts of data, simulate various scenarios, and create more efficient and resilient urban environments.”\nShah is saying that AI gives his team the ability to ask the big questions that will impact people’s lives when designing the cities of the future: “What’s the smartest way to build this neighbourhood to cut down on traffic jams and pollution? How can we design a building that stays cool in a heatwave without huge electricity bills?” The AI can run the numbers on thousands of possibilities to find the best path forward.\nOf course, the real world is messy. It’s not a neat and tidy computer simulation. It’s full of unpredictable weather, unexpected delays, and the beautiful chaos of human life. This is the number one headache.\n“The biggest challenge in applying data-driven models to physical environments is the complexity and variability of real-world conditions,” Shah says. “Ensuring that models accurately represent these conditions and can adapt to changing conditions is crucial.”\nSo, how do they deal with that? They start with the basics. They get their house in order. Before they even think about AI, they make sure the information it learns from is rock-solid and trustworthy.\n“To ensure data quality and interoperability across projects, we implement rigorous data governance practices, standardise data formats, and use interoperable software tools,” he says.\nThat might sound a bit technical, but think of it this way: they’re making sure everyone on the team is singing from the same hymn sheet. When all the different software tools can talk to each other and everyone trusts the information, the AI can do its job properly. It “enables seamless data exchange and collaboration among different teams and stakeholders.”\nBut of all the things AI can do, this next part might be the most hopeful when using it to design future cities. It shows that this technology can have a real heart.\n“There are many projects where AI has made a measurable impact on sustainability, making it hard to single out one,” he reflects. “However, if I were to choose, I would highlight a project where AI was used to preserve biodiversity by identifying endangered species and providing this information to researchers.”\nIn this scenario, technology is giving nature a voice in the planning meeting. It’s like the AI raising its hand and saying, “Hang on, let’s be careful here, there’s a family of rare birds living in this area.” It allows us to build with respect for the world around us.\nSo, what’s the next chapter? According to Shah, it’s about turning that crystal ball into a real-time guide. \n“According to me, the biggest opportunity for AI in the AEC sector lies in predictive analytics and automation,” Shah explains. “By anticipating future trends, identifying potential issues early, and automating routine tasks, AI can greatly enhance efficiency, reduce costs, and improve the overall quality of projects.”\nThis could mean safer bridges, roads that need fewer repairs, and less disruption to our lives. It means freeing up talented people from the boring tasks to focus on building the cities of the future that are more in tune with the people who call them home.\nShah Muhammad is speaking at AI & Big Data Expo Europe in Amsterdam on 24-25 September 2025 where he will be hosting a presentation on ‘Leveraging Generative and Agentic AI for Intelligent Process Automation’. Find out more about the event and how to attend here.\nSee also: Zuckerberg outlines Meta’s AI vision for ‘personal superintelligence’\n\n\n\n\nWant to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security & Cloud Expo.\nExplore other upcoming enterprise technology events and webinars powered by TechForge here.\nThe post Shah Muhammad, Sweco: How AI is building the future of our cities appeared first on AI News.",
          "dc:creator": "Ryan Daws",
          "content": "<p>Shah Muhammad, who leads AI Innovation at the design and engineering firm Sweco, offers his insights into how AI is building the cities of the future. Ever been stuck in traffic and thought, &#8220;Surely, there’s a better way to design this city?&#8221; Or walked past a giant new building and wondered if it would be [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/shah-muhammad-sweco-how-ai-is-building-future-of-our-cities/\">Shah Muhammad, Sweco: How AI is building the future of our cities</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
          "contentSnippet": "Shah Muhammad, who leads AI Innovation at the design and engineering firm Sweco, offers his insights into how AI is building the cities of the future. Ever been stuck in traffic and thought, “Surely, there’s a better way to design this city?” Or walked past a giant new building and wondered if it would be […]\nThe post Shah Muhammad, Sweco: How AI is building the future of our cities appeared first on AI News.",
          "guid": "https://www.artificialintelligence-news.com/?p=107258",
          "categories": [
            "AI & Big Data Expo",
            "Applications",
            "Artificial Intelligence",
            "Enterprise",
            "Industries",
            "new_AI in Action",
            "new_Features",
            "new_Interviews",
            "Real Estate",
            "ai",
            "ai & big data expo",
            "artificial intelligence",
            "sustainability",
            "sweco",
            "urban design"
          ],
          "isoDate": "2025-07-31T16:44:13.000Z"
        }
      },
      {
        "json": {
          "creator": "Sally Giles",
          "title": "24/7 compliance monitoring: The AI advantage in data protection",
          "link": "https://www.artificialintelligence-news.com/news/24-7-compliance-monitoring-the-ai-advantage-in-data-protection/",
          "pubDate": "Thu, 31 Jul 2025 12:16:03 +0000",
          "content:encoded": "\n<p>Data protection compliance has evolved from a periodic checklist exercise to a continuous responsibility. With cyber threats emerging and regulatory requirements becoming increasingly stringent, organisations can&#8217;t afford to rely on manual compliance monitoring approaches. The advent of artificial intelligence has transformed the challenge, offering capabilities for continuous oversight and real-time protection of sensitive data.</p>\n\n\n\n<div style=\"height:20px\" aria-hidden=\"true\" class=\"wp-block-spacer\"></div>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-the-evolution-of-compliance-monitoring\">The evolution of compliance monitoring</h3>\n\n\n\n<p>Traditional compliance monitoring is characterised by annual assessments and reactive responses to incidents. While this approach is sufficient for simpler regulatory environments, it falls short in addressing the complexities of modern data protection. The<a href=\"https://gdpr-info.eu/\"> General Data Protection Regulation (GDPR),</a> the Data Protection Act 2018, and emerging frameworks like the Digital Services Act demand compliance and demonstrable, ongoing adherence to data handling protocols.</p>\n\n\n\n<p>The shift to continuous monitoring represents a change in how organisations approach compliance. Rather than periodic snapshots of compliance status, businesses are better off with real-time visibility in their security posture. The transformation has been driven by several factors: the increasing volume and velocity of data processing, the sophistication of cyber threats, and the evolution of regulatory expectations towards proactive rather than reactive compliance.</p>\n\n\n\n<div style=\"height:20px\" aria-hidden=\"true\" class=\"wp-block-spacer\"></div>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-ai-powered-continuous-monitoring-capabilities\">AI-powered continuous monitoring capabilities</h3>\n\n\n\n<p>Artificial intelligence brings several advantages to compliance monitoring that human-led processes cannot match.<a href=\"https://mitsloan.mit.edu/ideas-made-to-matter/machine-learning-explained\"> Machine learning algorithms can process vast quantities of data</a> in real-time, identifying patterns and anomalies that would be difficult for human analysts to detect manually. Systems can simultaneously monitor multiple data streams, user activities, and system behaviours in all of an organisation&#8217;s digital infrastructure.</p>\n\n\n\n<p>AI-powered monitoring systems excel at pattern recognition, learning from historical data to establish baselines of normal behaviour. When deviations occur – whether through unauthorised access attempts, unusual data transfers, or policy violations – they can immediately flag potential compliance breaches. The capability extends beyond simple rule-based detection; AI systems can identify subtle indicators that may suggest emerging compliance risks before they transform into actual violations.</p>\n\n\n\n<p>AI systems can contextualise compliance events in broader organisational and regulatory frameworks. Rather than generating isolated alerts, intelligent monitoring platforms can assess the significance of events based on factors like data sensitivity, user roles, regulatory requirements, and potential business impact. Contextual awareness enables more targeted and effective compliance responses.</p>\n\n\n\n<div style=\"height:20px\" aria-hidden=\"true\" class=\"wp-block-spacer\"></div>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-real-time-threat-detection-and-response\">Real-time threat detection and response</h3>\n\n\n\n<p>The speed of AI-powered monitoring represents perhaps its most significant advantage over traditional approaches. While manual compliance reviews might detect violations up to days or weeks after they occur, AI systems can identify and respond to potential breaches in seconds or minutes. This rapid response capability is important to minimise the impact of data protection incidents and ensure swift remediation.</p>\n\n\n\n<p>Real-time monitoring lets organisations implement dynamic compliance controls that adapt to changing circumstances. For instance, if AI systems detect unusual data access patterns that suggest potential unauthorised activity, they can trigger additional authentication requirements or temporarily restrict access to sensitive resources. A proactive approach can prevent compliance violations before they occur, rather than documenting them after the fact.</p>\n\n\n\n<p>The integration of AI with automated response mechanisms further enhances protection capabilities. When potential violations are detected, systems can automatically initiate predefined response protocols, like isolating affected systems, notifying relevant personnel, or implementing emergency access controls. Automation helps ensure consistent and timely responses, regardless of when incidents occur or whether human operators are immediately available.</p>\n\n\n\n<div style=\"height:20px\" aria-hidden=\"true\" class=\"wp-block-spacer\"></div>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-comprehensive-coverage-across-digital-assets\">Comprehensive coverage across digital assets</h3>\n\n\n\n<p>Modern organisations operate complex digital ecosystems that span cloud services, on-premises infrastructure, mobile devices, and third-party applications. AI-powered compliance monitoring can provide unified oversight in diverse environments, helping ensure consistent protection standards regardless of where data resides or how it is processed.</p>\n\n\n\n<p>Cloud environments, in particular, benefit from AI-driven monitoring. The dynamic nature of cloud infrastructure – with resources being created, modified, and destroyed continuously – makes manual compliance oversight difficult. AI systems can track configuration changes, monitor data flows, and ensure that security controls remain properly configured as environments evolve. This capability is important in maintaining compliance in cloud-centric business operations.</p>\n\n\n\n<p>Additionally, AI can monitor compliance in the full data lifecycle, from collection and processing to storage and deletion. By implementing a compliance automation platform like<a href=\"https://thoropass.com/\"> Thoropass</a>, organisations can help ensure that data handling practices are consistent with regulatory requirements throughout each stage of processing. Comprehensive coverage helps organisations maintain demonstrable compliance even as data volumes and processing complexity continue to grow.</p>\n\n\n\n<div style=\"height:20px\" aria-hidden=\"true\" class=\"wp-block-spacer\"></div>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-predictive-analytics-for-compliance-risk-management\">Predictive analytics for compliance risk management</h3>\n\n\n\n<p>Beyond reactive monitoring, AI can provide predictive analytics that can identify potential compliance risks before they materialise. Analysing historical patterns, user behaviours, and system configurations lets AI systems predict scenarios that may lead to compliance violations. Predictive capability allows organisations to implement preventive measures and address vulnerabilities proactively.</p>\n\n\n\n<p>Predictive analytics can also inform compliance strategy and resource allocation, and identifying areas of highest risk and predicting future compliance challenges helps organisations prioritise their security investments and compliance efforts. The strategic application of AI ensures that limited resources are directed towards the most dangerous areas of risk.</p>\n\n\n\n<div style=\"height:20px\" aria-hidden=\"true\" class=\"wp-block-spacer\"></div>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-regulatory-reporting-and-documentation-benefits\">Regulatory reporting and documentation benefits</h3>\n\n\n\n<p>AI-powered monitoring systems perform well at generating comprehensive audit trails and compliance documentation. Systems can automatically collect, correlate, and present evidence of compliance activities in formats suitable for regulatory reporting. Such capability reduces the administrative burden associated with compliance documentation and helps ensure accuracy and completeness.</p>\n\n\n\n<p>Automated reporting capabilities also enable more frequent and detailed compliance assessments. Rather than waiting for annual audits, organisations can generate real-time compliance reports that provide continuous visibility into their data protection posture. An ongoing assessment capability helps organisations identify and address compliance gaps more quickly, reducing the risk of regulatory violations.</p>\n\n\n\n<p>The transition to AI-powered compliance monitoring represents a technological upgrade and signifies a shift towards more effective, efficient, and comprehensive data protection. As regulatory requirements evolve and cyber threats become more sophisticated, the ability to maintain continuous oversight of data protection compliance becomes not just advantageous, but essential. Organisations that adopt AI-driven capabilities position themselves to meet current compliance requirements and adapt successfully to tomorrow&#8217;s regulatory landscape.</p>\n\n\n\n<p><em>Guest author: Sally Giles</em></p>\n\n\n\n<p><em>Image source: <a href=\"https://www.pexels.com/photo/engineer-testing-sound-system-3862610/\">Pexels</a></em></p>\n\n\n\n<p></p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/24-7-compliance-monitoring-the-ai-advantage-in-data-protection/\">24/7 compliance monitoring: The AI advantage in data protection</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
          "content:encodedSnippet": "Data protection compliance has evolved from a periodic checklist exercise to a continuous responsibility. With cyber threats emerging and regulatory requirements becoming increasingly stringent, organisations can’t afford to rely on manual compliance monitoring approaches. The advent of artificial intelligence has transformed the challenge, offering capabilities for continuous oversight and real-time protection of sensitive data.\n\n\n\n\nThe evolution of compliance monitoring\nTraditional compliance monitoring is characterised by annual assessments and reactive responses to incidents. While this approach is sufficient for simpler regulatory environments, it falls short in addressing the complexities of modern data protection. The General Data Protection Regulation (GDPR), the Data Protection Act 2018, and emerging frameworks like the Digital Services Act demand compliance and demonstrable, ongoing adherence to data handling protocols.\nThe shift to continuous monitoring represents a change in how organisations approach compliance. Rather than periodic snapshots of compliance status, businesses are better off with real-time visibility in their security posture. The transformation has been driven by several factors: the increasing volume and velocity of data processing, the sophistication of cyber threats, and the evolution of regulatory expectations towards proactive rather than reactive compliance.\n\n\n\n\nAI-powered continuous monitoring capabilities\nArtificial intelligence brings several advantages to compliance monitoring that human-led processes cannot match. Machine learning algorithms can process vast quantities of data in real-time, identifying patterns and anomalies that would be difficult for human analysts to detect manually. Systems can simultaneously monitor multiple data streams, user activities, and system behaviours in all of an organisation’s digital infrastructure.\nAI-powered monitoring systems excel at pattern recognition, learning from historical data to establish baselines of normal behaviour. When deviations occur – whether through unauthorised access attempts, unusual data transfers, or policy violations – they can immediately flag potential compliance breaches. The capability extends beyond simple rule-based detection; AI systems can identify subtle indicators that may suggest emerging compliance risks before they transform into actual violations.\nAI systems can contextualise compliance events in broader organisational and regulatory frameworks. Rather than generating isolated alerts, intelligent monitoring platforms can assess the significance of events based on factors like data sensitivity, user roles, regulatory requirements, and potential business impact. Contextual awareness enables more targeted and effective compliance responses.\n\n\n\n\nReal-time threat detection and response\nThe speed of AI-powered monitoring represents perhaps its most significant advantage over traditional approaches. While manual compliance reviews might detect violations up to days or weeks after they occur, AI systems can identify and respond to potential breaches in seconds or minutes. This rapid response capability is important to minimise the impact of data protection incidents and ensure swift remediation.\nReal-time monitoring lets organisations implement dynamic compliance controls that adapt to changing circumstances. For instance, if AI systems detect unusual data access patterns that suggest potential unauthorised activity, they can trigger additional authentication requirements or temporarily restrict access to sensitive resources. A proactive approach can prevent compliance violations before they occur, rather than documenting them after the fact.\nThe integration of AI with automated response mechanisms further enhances protection capabilities. When potential violations are detected, systems can automatically initiate predefined response protocols, like isolating affected systems, notifying relevant personnel, or implementing emergency access controls. Automation helps ensure consistent and timely responses, regardless of when incidents occur or whether human operators are immediately available.\n\n\n\n\nComprehensive coverage across digital assets\nModern organisations operate complex digital ecosystems that span cloud services, on-premises infrastructure, mobile devices, and third-party applications. AI-powered compliance monitoring can provide unified oversight in diverse environments, helping ensure consistent protection standards regardless of where data resides or how it is processed.\nCloud environments, in particular, benefit from AI-driven monitoring. The dynamic nature of cloud infrastructure – with resources being created, modified, and destroyed continuously – makes manual compliance oversight difficult. AI systems can track configuration changes, monitor data flows, and ensure that security controls remain properly configured as environments evolve. This capability is important in maintaining compliance in cloud-centric business operations.\nAdditionally, AI can monitor compliance in the full data lifecycle, from collection and processing to storage and deletion. By implementing a compliance automation platform like Thoropass, organisations can help ensure that data handling practices are consistent with regulatory requirements throughout each stage of processing. Comprehensive coverage helps organisations maintain demonstrable compliance even as data volumes and processing complexity continue to grow.\n\n\n\n\nPredictive analytics for compliance risk management\nBeyond reactive monitoring, AI can provide predictive analytics that can identify potential compliance risks before they materialise. Analysing historical patterns, user behaviours, and system configurations lets AI systems predict scenarios that may lead to compliance violations. Predictive capability allows organisations to implement preventive measures and address vulnerabilities proactively.\nPredictive analytics can also inform compliance strategy and resource allocation, and identifying areas of highest risk and predicting future compliance challenges helps organisations prioritise their security investments and compliance efforts. The strategic application of AI ensures that limited resources are directed towards the most dangerous areas of risk.\n\n\n\n\nRegulatory reporting and documentation benefits\nAI-powered monitoring systems perform well at generating comprehensive audit trails and compliance documentation. Systems can automatically collect, correlate, and present evidence of compliance activities in formats suitable for regulatory reporting. Such capability reduces the administrative burden associated with compliance documentation and helps ensure accuracy and completeness.\nAutomated reporting capabilities also enable more frequent and detailed compliance assessments. Rather than waiting for annual audits, organisations can generate real-time compliance reports that provide continuous visibility into their data protection posture. An ongoing assessment capability helps organisations identify and address compliance gaps more quickly, reducing the risk of regulatory violations.\nThe transition to AI-powered compliance monitoring represents a technological upgrade and signifies a shift towards more effective, efficient, and comprehensive data protection. As regulatory requirements evolve and cyber threats become more sophisticated, the ability to maintain continuous oversight of data protection compliance becomes not just advantageous, but essential. Organisations that adopt AI-driven capabilities position themselves to meet current compliance requirements and adapt successfully to tomorrow’s regulatory landscape.\nGuest author: Sally Giles\nImage source: Pexels\n\nThe post 24/7 compliance monitoring: The AI advantage in data protection appeared first on AI News.",
          "dc:creator": "Sally Giles",
          "content": "<p>Data protection compliance has evolved from a periodic checklist exercise to a continuous responsibility. With cyber threats emerging and regulatory requirements becoming increasingly stringent, organisations can&#8217;t afford to rely on manual compliance monitoring approaches. The advent of artificial intelligence has transformed the challenge, offering capabilities for continuous oversight and real-time protection of sensitive data. The [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/24-7-compliance-monitoring-the-ai-advantage-in-data-protection/\">24/7 compliance monitoring: The AI advantage in data protection</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
          "contentSnippet": "Data protection compliance has evolved from a periodic checklist exercise to a continuous responsibility. With cyber threats emerging and regulatory requirements becoming increasingly stringent, organisations can’t afford to rely on manual compliance monitoring approaches. The advent of artificial intelligence has transformed the challenge, offering capabilities for continuous oversight and real-time protection of sensitive data. The […]\nThe post 24/7 compliance monitoring: The AI advantage in data protection appeared first on AI News.",
          "guid": "https://www.artificialintelligence-news.com/?p=107252",
          "categories": [
            "Sponsored Content"
          ],
          "isoDate": "2025-07-31T12:16:03.000Z"
        }
      },
      {
        "json": {
          "creator": "Ryan Daws",
          "title": "Zuckerberg outlines Meta’s AI vision for ‘personal superintelligence’",
          "link": "https://www.artificialintelligence-news.com/news/zuckerberg-outlines-meta-ai-vision-personal-superintelligence/",
          "pubDate": "Wed, 30 Jul 2025 14:05:42 +0000",
          "content:encoded": "\n<p><a href=\"https://www.meta.com/en-gb/about/?srsltid=AfmBOopdsI5__T6YR1ZOc5P4vpK8PzcMlCIAEZQvYvHlVowQQpBKxCD1\">Meta</a> CEO Mark Zuckerberg has laid out his blueprint for the future of AI, and it’s about giving you “personal superintelligence”.</p>\n\n\n\n<p>In a letter, the Meta chief painted a picture of what’s coming next, and he believes it’s closer than we think. He says his teams are already seeing early signs of progress.</p>\n\n\n\n<p>&#8220;Over the last few months we have begun to see glimpses of our AI systems improving themselves,&#8221; Zuckerberg wrote. &#8220;The improvement is slow for now, but undeniable. Developing superintelligence is now in sight.&#8221;</p>\n\n\n\n<p>So, what does he want to do with it? Forget AI that just automates boring office work, Zuckerberg and Meta’s vision for personal superintelligence is far more intimate. He imagines a future where technology serves our individual growth, not just our productivity.</p>\n\n\n\n<p>In his words, the real revolution will be &#8220;everyone having a personal superintelligence that helps you achieve your goals, create what you want to see in the world, experience any adventure, be a better friend to those you care about, and grow to become the person you aspire to be.&#8221;</p>\n\n\n\n<p>But here&#8217;s where it gets interesting. He drew a clear line in the sand, contrasting his vision against a very different, almost dystopian alternative that he believes others are pursuing.</p>\n\n\n\n<p>&#8220;This is distinct from others in the industry who believe superintelligence should be directed centrally towards automating all valuable work, and then humanity will live on a dole of its output,&#8221; he stated.</p>\n\n\n\n<p>Meta, Zuckerberg says, is betting on the individual when it comes to AI superintelligence. The company believes that progress has always come from people chasing their own dreams, not from living off the scraps of a hyper-efficient machine.</p>\n\n\n\n<p>If he&#8217;s right, we&#8217;ll spend less time wrestling with software and more time creating and connecting. This personal AI would live in devices like smart glasses, understanding our world because they can &#8220;see what we see, hear what we hear.&#8221;</p>\n\n\n\n<p>Of course, he knows this is powerful, even dangerous, stuff. Zuckerberg admits that superintelligence will bring new safety concerns and that Meta will have to be careful about what they release to the world. Still, he argues that the goal must be to empower people as much as possible.</p>\n\n\n\n<p>Zuckerberg believes we’re at a crossroads right now. The choices we make in the next few years will decide everything.</p>\n\n\n\n<p>&#8220;The rest of this decade seems likely to be the decisive period for determining the path this technology will take,&#8221; he warned, framing it as a choice between &#8220;personal empowerment or a force focused on replacing large swaths of society.&#8221;</p>\n\n\n\n<p>Zuckerberg has made his choice. He&#8217;s focusing Meta&#8217;s enormous resources on building this personal superintelligence future.</p>\n\n\n\n<p><strong>See also: </strong><a href=\"https://www.artificialintelligence-news.com/news/forget-turing-test-ai-real-challenge-is-communication/\"><strong>Forget the Turing Test, AI’s real challenge is communication</strong></a></p>\n\n\n\n<figure class=\"wp-block-image size-full is-resized\"><a href=\"https://www.ai-expo.net/\"><img decoding=\"async\" width=\"728\" height=\"90\" src=\"https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png\" alt=\"\" class=\"wp-image-11874\" style=\"width:800px;height:auto\" srcset=\"https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w\" sizes=\"(max-width: 728px) 100vw, 728px\" /></a></figure>\n\n\n\n<p><strong>Want to learn more about AI and big data from industry leaders?</strong> Check out<a href=\"https://www.ai-expo.net/\"> AI &amp; Big Data Expo</a> taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including <a href=\"https://intelligentautomation-conference.com/northamerica/\">Intelligent Automation Conference</a>, <a href=\"https://www.blockchain-expo.com/\">BlockX</a>,<a href=\"https://digitaltransformation-week.com/\"> Digital Transformation Week</a>, and <a href=\"https://www.cybersecuritycloudexpo.com/\">Cyber Security &amp; Cloud Expo</a>.</p>\n\n\n\n<p>Explore other upcoming enterprise technology events and webinars powered by TechForge <a href=\"https://techforge.pub/events/\">here</a>.</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/zuckerberg-outlines-meta-ai-vision-personal-superintelligence/\">Zuckerberg outlines Meta’s AI vision for ‘personal superintelligence’</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
          "content:encodedSnippet": "Meta CEO Mark Zuckerberg has laid out his blueprint for the future of AI, and it’s about giving you “personal superintelligence”.\nIn a letter, the Meta chief painted a picture of what’s coming next, and he believes it’s closer than we think. He says his teams are already seeing early signs of progress.\n“Over the last few months we have begun to see glimpses of our AI systems improving themselves,” Zuckerberg wrote. “The improvement is slow for now, but undeniable. Developing superintelligence is now in sight.”\nSo, what does he want to do with it? Forget AI that just automates boring office work, Zuckerberg and Meta’s vision for personal superintelligence is far more intimate. He imagines a future where technology serves our individual growth, not just our productivity.\nIn his words, the real revolution will be “everyone having a personal superintelligence that helps you achieve your goals, create what you want to see in the world, experience any adventure, be a better friend to those you care about, and grow to become the person you aspire to be.”\nBut here’s where it gets interesting. He drew a clear line in the sand, contrasting his vision against a very different, almost dystopian alternative that he believes others are pursuing.\n“This is distinct from others in the industry who believe superintelligence should be directed centrally towards automating all valuable work, and then humanity will live on a dole of its output,” he stated.\nMeta, Zuckerberg says, is betting on the individual when it comes to AI superintelligence. The company believes that progress has always come from people chasing their own dreams, not from living off the scraps of a hyper-efficient machine.\nIf he’s right, we’ll spend less time wrestling with software and more time creating and connecting. This personal AI would live in devices like smart glasses, understanding our world because they can “see what we see, hear what we hear.”\nOf course, he knows this is powerful, even dangerous, stuff. Zuckerberg admits that superintelligence will bring new safety concerns and that Meta will have to be careful about what they release to the world. Still, he argues that the goal must be to empower people as much as possible.\nZuckerberg believes we’re at a crossroads right now. The choices we make in the next few years will decide everything.\n“The rest of this decade seems likely to be the decisive period for determining the path this technology will take,” he warned, framing it as a choice between “personal empowerment or a force focused on replacing large swaths of society.”\nZuckerberg has made his choice. He’s focusing Meta’s enormous resources on building this personal superintelligence future.\nSee also: Forget the Turing Test, AI’s real challenge is communication\n\n\n\n\nWant to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security & Cloud Expo.\nExplore other upcoming enterprise technology events and webinars powered by TechForge here.\nThe post Zuckerberg outlines Meta’s AI vision for ‘personal superintelligence’ appeared first on AI News.",
          "dc:creator": "Ryan Daws",
          "content": "<p>Meta CEO Mark Zuckerberg has laid out his blueprint for the future of AI, and it’s about giving you “personal superintelligence”. In a letter, the Meta chief painted a picture of what’s coming next, and he believes it’s closer than we think. He says his teams are already seeing early signs of progress. &#8220;Over the [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/zuckerberg-outlines-meta-ai-vision-personal-superintelligence/\">Zuckerberg outlines Meta’s AI vision for ‘personal superintelligence’</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
          "contentSnippet": "Meta CEO Mark Zuckerberg has laid out his blueprint for the future of AI, and it’s about giving you “personal superintelligence”. In a letter, the Meta chief painted a picture of what’s coming next, and he believes it’s closer than we think. He says his teams are already seeing early signs of progress. “Over the […]\nThe post Zuckerberg outlines Meta’s AI vision for ‘personal superintelligence’ appeared first on AI News.",
          "guid": "https://www.artificialintelligence-news.com/?p=107248",
          "categories": [
            "AGI",
            "Applications",
            "Artificial Intelligence",
            "Companies",
            "Development",
            "Ethics & Society",
            "Meta (Facebook)",
            "Virtual Assistants",
            "agi",
            "ai",
            "artificial intelligence",
            "ethics",
            "mark zuckerberg",
            "meta",
            "superintelligence"
          ],
          "isoDate": "2025-07-30T14:05:42.000Z"
        }
      },
      {
        "json": {
          "creator": "Muhammad Zulhusni",
          "title": "Alibaba’s AI coding tool raises security concerns in the West",
          "link": "https://www.artificialintelligence-news.com/news/alibaba-ai-coding-tool-raises-security-concerns-in-the-west/",
          "pubDate": "Wed, 30 Jul 2025 10:00:00 +0000",
          "content:encoded": "\n<p>Alibaba has released a new AI coding model called Qwen3-Coder, built to handle complex software tasks using a large open-source model. The tool is part of Alibaba’s Qwen3 family and is being promoted as the company’s most advanced coding agent to date.</p>\n\n\n\n<p>The model uses a Mixture of Experts (MoE) approach, activating 35 billion parameters out of a total 480 billion and supporting up to 256,000 tokens of context. That number can reportedly be stretched to 1 million using special extrapolation techniques. The company claims Qwen3-Coder has outperformed other open models in agentic tasks, including versions from Moonshot AI and DeepSeek.</p>\n\n\n\n<p>But not everyone sees this as good news. Jurgita Lapienyė, Chief Editor at Cybernews, warns that Qwen3-Coder may be more than just a helpful coding assistant—it could pose a real risk to global tech systems if adopted widely by Western developers.</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-a-trojan-horse-in-open-source-clothing\">A trojan horse in open source clothing?</h3>\n\n\n\n<p>Alibaba’s messaging around Qwen3-Coder has focused on its technical strength, comparing it to top-tier tools from OpenAI and Anthropic. But while benchmark scores and features draw attention, Lapienyė suggests they may also distract from the real issue: security.</p>\n\n\n\n<p>It’s not that China is catching up in AI—that’s already known. The deeper concern is about the hidden risks of using software generated by AI systems that are difficult to inspect or fully understand.</p>\n\n\n\n<p>As Lapienyė put it, developers could be “sleepwalking into a future” where core systems are unknowingly built with vulnerable code. Tools like Qwen3-Coder may make life easier, but they could also introduce subtle weaknesses that go unnoticed.</p>\n\n\n\n<p>This risk isn’t hypothetical. <a target=\"_blank\" href=\"https://email.cisionone.cision.com/c/eJw0y02O4yAUBODTwO5F-PG_YJGNrxFheExQ7NgDJDO5fcut7kVJpa9UOaBLSnAKk9VSKVRa8HtA7Y200tklpbJQVslncj45zGisSbwG45w8Q0kle5sQ8-QcokGTMlOi10yP-he2WFdqHVwx2WanCvx_vv24nM7XcB_j6ExeGc4M5_RZqD3pX7-kfWM4d0qvVsfnrAdoISDt2xGflTrECr8ztNofHRodexsMZ75RrhEarRQ7Qc3hG24_wOR1QuXR8xYo17G3GlemxKB0L3v7Q5fjtfA-GtF2nidapDBKgNdFgYrCg9c-QjFW56ytLgX5O-BXAAAA___tsWhJ\" rel=\"noreferrer noopener\">Cybernews researchers</a> recently reviewed AI use across major US firms and found that 327 of the S&amp;P 500 now publicly report using AI tools. In those companies alone, researchers identified nearly 1,000 AI-related vulnerabilities.</p>\n\n\n\n<p>Adding another AI model—especially one developed under China’s strict national security laws—could add another layer of risk, one that’s harder to control.</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-when-code-becomes-a-backdoor\">When code becomes a backdoor</h3>\n\n\n\n<p>Today’s developers lean heavily on AI tools to write code, fix bugs, and shape how applications are built. These systems are fast, helpful, and getting better every day.</p>\n\n\n\n<p>But what if those same systems were trained to inject flaws? Not obvious bugs, but small, hard-to-spot issues that wouldn’t trigger alarms. A vulnerability that looks like a harmless design decision could go undetected for years.</p>\n\n\n\n<p>That’s how supply chain attacks often begin. Past examples, like the SolarWinds incident, show how long-term infiltration can be done quietly and patiently. With enough access and context, an AI model could learn how to plant similar issues—especially if it had exposure to millions of codebases.</p>\n\n\n\n<p>It’s not just a theory. Under China’s National Intelligence Law, companies like Alibaba must cooperate with government requests, including those involving data and AI models. That shifts the conversation from technical performance to national security.</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-what-happens-to-your-code\">What happens to your code?</h3>\n\n\n\n<p>Another major issue is data exposure. When developers use tools like Qwen3-Coder to write or debug code, every piece of that interaction could reveal sensitive information.</p>\n\n\n\n<p>That might include proprietary algorithms, security logic, or infrastructure design—exactly the kind of details that can be useful to a foreign state.</p>\n\n\n\n<p>Even though the model is open source, there’s still a lot that users can’t see. The backend infrastructure, telemetry systems, and usage tracking methods may not be transparent. That makes it hard to know where data goes or what the model might remember over time.</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-autonomy-without-oversight\">Autonomy without oversight</h3>\n\n\n\n<p>Alibaba has also focused on agentic AI—models that can act more independently than standard assistants. These tools don’t just suggest lines of code. They can be assigned full tasks, operate with minimal input, and make decisions on their own.</p>\n\n\n\n<p>That might sound efficient, but it also raises red flags. A fully autonomous coding agent that can scan entire codebases and make changes could become dangerous in the wrong hands.</p>\n\n\n\n<p>Imagine an agent that can understand a company’s system defences and craft tailored attacks to exploit them. The same skillset that helps developers move faster could be repurposed by attackers to move even faster still.</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-regulation-still-isn-t-ready\">Regulation still isn’t ready</h3>\n\n\n\n<p>Despite these risks, current regulations don’t address tools like Qwen3-Coder in a meaningful way. The US government has spent years debating data privacy concerns tied to apps like TikTok, but there’s little public oversight of foreign-developed AI tools.</p>\n\n\n\n<p>Groups like the Committee on Foreign Investment in the US (CFIUS) review company acquisitions, but no similar process exists for reviewing AI models that might pose national security risks.</p>\n\n\n\n<p>President Biden’s executive order on AI focuses mainly on homegrown models and general safety practices. But it leaves out concerns about imported tools that could be embedded in sensitive environments like healthcare, finance, or national infrastructure.</p>\n\n\n\n<p>AI tools capable of writing or altering code should be treated with the same seriousness as software supply chain threats. That means setting clear guidelines for where and how they can be used.</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-what-should-happen-next\">What should happen next?</h3>\n\n\n\n<p>To reduce risk, organisations dealing with sensitive systems should pause before integrating Qwen3-Coder—or any foreign-developed agentic AI—into their workflows. If you wouldn’t invite someone you don’t trust to look at your source code, why let their AI rewrite it?</p>\n\n\n\n<p>Security tools also need to catch up. Static analysis software may not detect complex backdoors or subtle logic issues crafted by AI. The industry needs new tools designed specifically to flag and test AI-generated code for suspicious patterns.</p>\n\n\n\n<p>Finally, developers, tech leaders, and regulators must understand that code-generating AI isn’t neutral. These systems have power—both as helpful tools and potential threats. The same features that make them useful can also make them dangerous.</p>\n\n\n\n<p>Lapienyė called Qwen3-Coder “a potential Trojan horse,” and the metaphor fits. It’s not just about productivity. It’s about who’s inside the gates.</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-not-everyone-agrees-on-what-matters\">Not everyone agrees on what matters</h3>\n\n\n\n<p>Wang Jian, the founder of Alibaba Cloud, sees things differently. In an interview with <em><a target=\"_blank\" href=\"https://www.bloomberg.com/news/articles/2025-07-27/alibaba-cloud-visionary-expects-big-shakeup-after-openai-hype\" rel=\"noreferrer noopener\">Bloomberg</a></em>, he said innovation isn’t about hiring the most expensive talent but about picking people who can build the unknown. He criticised Silicon Valley’s approach to AI hiring, where tech giants now compete for top researchers like sports teams bidding on athletes.</p>\n\n\n\n<p>“The only thing you need to do is to get the right person,” Wang said. “Not really the expensive person.”</p>\n\n\n\n<p>He also believes that the Chinese AI race is healthy, not hostile. According to Wang, companies take turns pulling ahead, which helps the entire ecosystem grow faster.</p>\n\n\n\n<p>“You can have the very fast iteration of the technology because of this competition,” he said. “I don’t think it’s brutal, but I think it’s very healthy.”</p>\n\n\n\n<p>Still, open-source competition doesn’t guarantee trust. Western developers need to think carefully about what tools they use—and who built them.</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-the-bottom-line\">The bottom line</h3>\n\n\n\n<p>Qwen3-Coder may offer impressive performance and open access, but its use comes with risks that go beyond benchmarks and coding speed. In a time when AI tools are shaping how critical systems are built, it’s worth asking not just what these tools can do—but who benefits when they do it.</p>\n\n\n\n<p><em>(Photo by <a href=\"https://unsplash.com/@hishahadat?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash\">Shahadat Rahman</a>)</em></p>\n\n\n\n<p><strong>See also: <a href=\"https://www.artificialintelligence-news.com/news/alibaba-new-qwen-reasoning-ai-model-open-source-records/\" target=\"_blank\" rel=\"noreferrer noopener\">Alibaba’s new Qwen reasoning AI model sets open-source records</a></strong></p>\n\n\n\n<figure class=\"wp-block-image size-full is-resized\"><a href=\"https://www.ai-expo.net/\"><img decoding=\"async\" width=\"728\" height=\"90\" src=\"https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png\" alt=\"\" class=\"wp-image-11874\" style=\"width:800px;height:auto\" srcset=\"https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w\" sizes=\"(max-width: 728px) 100vw, 728px\" /></a></figure>\n\n\n\n<p><strong>Want to learn more about AI and big data from industry leaders?</strong> Check out<a target=\"_blank\" href=\"https://www.ai-expo.net/\" rel=\"noreferrer noopener\"> AI &amp; Big Data Expo</a> taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including <a target=\"_blank\" href=\"https://intelligentautomation-conference.com/northamerica/\" rel=\"noreferrer noopener\">Intelligent Automation Conference</a>, <a target=\"_blank\" href=\"https://www.blockchain-expo.com/\" rel=\"noreferrer noopener\">BlockX</a>,<a target=\"_blank\" href=\"https://digitaltransformation-week.com/\" rel=\"noreferrer noopener\"> Digital Transformation Week</a>, and <a target=\"_blank\" href=\"https://www.cybersecuritycloudexpo.com/\" rel=\"noreferrer noopener\">Cyber Security &amp; Cloud Expo</a>.</p>\n\n\n\n<p>Explore other upcoming enterprise technology events and webinars powered by TechForge <a target=\"_blank\" href=\"https://techforge.pub/events/\" rel=\"noreferrer noopener\">here</a>.</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/alibaba-ai-coding-tool-raises-security-concerns-in-the-west/\">Alibaba’s AI coding tool raises security concerns in the West</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
          "content:encodedSnippet": "Alibaba has released a new AI coding model called Qwen3-Coder, built to handle complex software tasks using a large open-source model. The tool is part of Alibaba’s Qwen3 family and is being promoted as the company’s most advanced coding agent to date.\nThe model uses a Mixture of Experts (MoE) approach, activating 35 billion parameters out of a total 480 billion and supporting up to 256,000 tokens of context. That number can reportedly be stretched to 1 million using special extrapolation techniques. The company claims Qwen3-Coder has outperformed other open models in agentic tasks, including versions from Moonshot AI and DeepSeek.\nBut not everyone sees this as good news. Jurgita Lapienyė, Chief Editor at Cybernews, warns that Qwen3-Coder may be more than just a helpful coding assistant—it could pose a real risk to global tech systems if adopted widely by Western developers.\nA trojan horse in open source clothing?\nAlibaba’s messaging around Qwen3-Coder has focused on its technical strength, comparing it to top-tier tools from OpenAI and Anthropic. But while benchmark scores and features draw attention, Lapienyė suggests they may also distract from the real issue: security.\nIt’s not that China is catching up in AI—that’s already known. The deeper concern is about the hidden risks of using software generated by AI systems that are difficult to inspect or fully understand.\nAs Lapienyė put it, developers could be “sleepwalking into a future” where core systems are unknowingly built with vulnerable code. Tools like Qwen3-Coder may make life easier, but they could also introduce subtle weaknesses that go unnoticed.\nThis risk isn’t hypothetical. Cybernews researchers recently reviewed AI use across major US firms and found that 327 of the S&P 500 now publicly report using AI tools. In those companies alone, researchers identified nearly 1,000 AI-related vulnerabilities.\nAdding another AI model—especially one developed under China’s strict national security laws—could add another layer of risk, one that’s harder to control.\nWhen code becomes a backdoor\nToday’s developers lean heavily on AI tools to write code, fix bugs, and shape how applications are built. These systems are fast, helpful, and getting better every day.\nBut what if those same systems were trained to inject flaws? Not obvious bugs, but small, hard-to-spot issues that wouldn’t trigger alarms. A vulnerability that looks like a harmless design decision could go undetected for years.\nThat’s how supply chain attacks often begin. Past examples, like the SolarWinds incident, show how long-term infiltration can be done quietly and patiently. With enough access and context, an AI model could learn how to plant similar issues—especially if it had exposure to millions of codebases.\nIt’s not just a theory. Under China’s National Intelligence Law, companies like Alibaba must cooperate with government requests, including those involving data and AI models. That shifts the conversation from technical performance to national security.\nWhat happens to your code?\nAnother major issue is data exposure. When developers use tools like Qwen3-Coder to write or debug code, every piece of that interaction could reveal sensitive information.\nThat might include proprietary algorithms, security logic, or infrastructure design—exactly the kind of details that can be useful to a foreign state.\nEven though the model is open source, there’s still a lot that users can’t see. The backend infrastructure, telemetry systems, and usage tracking methods may not be transparent. That makes it hard to know where data goes or what the model might remember over time.\nAutonomy without oversight\nAlibaba has also focused on agentic AI—models that can act more independently than standard assistants. These tools don’t just suggest lines of code. They can be assigned full tasks, operate with minimal input, and make decisions on their own.\nThat might sound efficient, but it also raises red flags. A fully autonomous coding agent that can scan entire codebases and make changes could become dangerous in the wrong hands.\nImagine an agent that can understand a company’s system defences and craft tailored attacks to exploit them. The same skillset that helps developers move faster could be repurposed by attackers to move even faster still.\nRegulation still isn’t ready\nDespite these risks, current regulations don’t address tools like Qwen3-Coder in a meaningful way. The US government has spent years debating data privacy concerns tied to apps like TikTok, but there’s little public oversight of foreign-developed AI tools.\nGroups like the Committee on Foreign Investment in the US (CFIUS) review company acquisitions, but no similar process exists for reviewing AI models that might pose national security risks.\nPresident Biden’s executive order on AI focuses mainly on homegrown models and general safety practices. But it leaves out concerns about imported tools that could be embedded in sensitive environments like healthcare, finance, or national infrastructure.\nAI tools capable of writing or altering code should be treated with the same seriousness as software supply chain threats. That means setting clear guidelines for where and how they can be used.\nWhat should happen next?\nTo reduce risk, organisations dealing with sensitive systems should pause before integrating Qwen3-Coder—or any foreign-developed agentic AI—into their workflows. If you wouldn’t invite someone you don’t trust to look at your source code, why let their AI rewrite it?\nSecurity tools also need to catch up. Static analysis software may not detect complex backdoors or subtle logic issues crafted by AI. The industry needs new tools designed specifically to flag and test AI-generated code for suspicious patterns.\nFinally, developers, tech leaders, and regulators must understand that code-generating AI isn’t neutral. These systems have power—both as helpful tools and potential threats. The same features that make them useful can also make them dangerous.\nLapienyė called Qwen3-Coder “a potential Trojan horse,” and the metaphor fits. It’s not just about productivity. It’s about who’s inside the gates.\nNot everyone agrees on what matters\nWang Jian, the founder of Alibaba Cloud, sees things differently. In an interview with Bloomberg, he said innovation isn’t about hiring the most expensive talent but about picking people who can build the unknown. He criticised Silicon Valley’s approach to AI hiring, where tech giants now compete for top researchers like sports teams bidding on athletes.\n“The only thing you need to do is to get the right person,” Wang said. “Not really the expensive person.”\nHe also believes that the Chinese AI race is healthy, not hostile. According to Wang, companies take turns pulling ahead, which helps the entire ecosystem grow faster.\n“You can have the very fast iteration of the technology because of this competition,” he said. “I don’t think it’s brutal, but I think it’s very healthy.”\nStill, open-source competition doesn’t guarantee trust. Western developers need to think carefully about what tools they use—and who built them.\nThe bottom line\nQwen3-Coder may offer impressive performance and open access, but its use comes with risks that go beyond benchmarks and coding speed. In a time when AI tools are shaping how critical systems are built, it’s worth asking not just what these tools can do—but who benefits when they do it.\n(Photo by Shahadat Rahman)\nSee also: Alibaba’s new Qwen reasoning AI model sets open-source records\n\n\n\n\nWant to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security & Cloud Expo.\nExplore other upcoming enterprise technology events and webinars powered by TechForge here.\nThe post Alibaba’s AI coding tool raises security concerns in the West appeared first on AI News.",
          "dc:creator": "Muhammad Zulhusni",
          "content": "<p>Alibaba has released a new AI coding model called Qwen3-Coder, built to handle complex software tasks using a large open-source model. The tool is part of Alibaba’s Qwen3 family and is being promoted as the company’s most advanced coding agent to date. The model uses a Mixture of Experts (MoE) approach, activating 35 billion parameters [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/alibaba-ai-coding-tool-raises-security-concerns-in-the-west/\">Alibaba’s AI coding tool raises security concerns in the West</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
          "contentSnippet": "Alibaba has released a new AI coding model called Qwen3-Coder, built to handle complex software tasks using a large open-source model. The tool is part of Alibaba’s Qwen3 family and is being promoted as the company’s most advanced coding agent to date. The model uses a Mixture of Experts (MoE) approach, activating 35 billion parameters […]\nThe post Alibaba’s AI coding tool raises security concerns in the West appeared first on AI News.",
          "guid": "https://www.artificialintelligence-news.com/?p=107224",
          "categories": [
            "Alibaba",
            "Applications",
            "Artificial Intelligence",
            "Development",
            "Privacy",
            "Security",
            "ai",
            "alibaba cloud",
            "artificial intelligence",
            "china",
            "coding",
            "cybersecurity",
            "developers",
            "featured",
            "security"
          ],
          "isoDate": "2025-07-30T10:00:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Ryan Daws",
          "title": "Google’s Veo 3 AI video creation tools are now widely available",
          "link": "https://www.artificialintelligence-news.com/news/google-veo-3-ai-video-creation-tools-now-widely-available/",
          "pubDate": "Tue, 29 Jul 2025 16:01:39 +0000",
          "content:encoded": "\n<p>Google has made its most powerful AI video creator, Veo 3, available for everyone to use on its <a href=\"https://cloud.google.com/vertex-ai\">Vertex AI</a> platform. And for those who need to work quickly, a speedier version called Veo 3 Fast is also ready-to-go for quick creative work.</p>\n\n\n\n<p>Ever had a brilliant idea for a video but found yourself held back by the cost, time, or technical skills needed to create it? This tool aims to offer a faster way to turn your text ideas into everything from short films to product demos.</p>\n\n\n\n<p>70 million videos have been created since May, showing a huge global appetite for these AI video creation tools. Businesses are diving in as well, generating over 6 million videos since they got early access in June.</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-the-real-world-applications-for-veo-3\">The real-world applications for Veo 3</h3>\n\n\n\n<p>So, what does this look like in the real world? From global design platforms to major advertising agencies, companies are already putting Veo 3 to work. Take design platform <a href=\"https://www.canva.com/en_gb/\">Canva</a>, they are building Veo directly into their software to make video creation simple for their users.</p>\n\n\n\n<p>Cameron Adams, Co-Founder and Chief Product Officer at Canva, said: “Enabling anyone to bring their ideas to life – especially their most creative ones – has been core to Canva&#8217;s mission ever since we set out to empower the world to design.</p>\n\n\n\n<p>“By democratising access to a powerful technology like Google’s Veo 3 inside Canva AI, your big ideas can now be brought to life in the highest quality video and sound, all from within your existing Canva subscription. In true Canva fashion, we’ve built this with an intuitive interface and simple editing tools in place, all backed by Canva Shield.”</p>\n\n\n\n<p>For creative agencies like <a href=\"https://barkleyokrp.com/\">BarkleyOKRP</a>, the big wins are speed and quality. They claim to have been so impressed with the latest version that they went back and remade videos.</p>\n\n\n\n<p>Julie Ray Barr, Senior Vice President Client Experience at BarkleyOKRP, commented: “The rapid advancements from Veo 2 to Veo 3 within such a short time frame on this project have been nothing short of remarkable.</p>\n\n\n\n<p>“Our team undertook the task of re-creating numerous music videos initially produced with Veo 2 once Veo 3 was released, primarily due to the significantly improved synchronization between voice and mouth movements. The continuous daily progress we are witnessing is truly extraordinary.”</p>\n\n\n\n<p>It&#8217;s even changing how global companies connect with local customers. The investing platform <a href=\"https://www.etoro.com/\">eToro</a> used Veo 3 to create 15 different, fully AI-generated versions of a single advertisement, each customised to a specific country with its own native language.</p>\n\n\n\n<p>Shay Chikotay, Head of Creative &amp; Content at eToro, said: “With Veo 3, we produced 15 fully AI‑generated versions of our ad, each in the native language of its market, all while capturing real emotion at scale.</p>\n\n\n\n<p>“Ironically, AI didn’t reduce humanity; it amplified it. Veo 3 lets us tell more stories, in more tongues, with more impact.”</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-google-gives-creators-a-powerful-ai-video-creation-tool\">Google gives creators a powerful AI video creation tool</h3>\n\n\n\n<p>Veo 3 and Veo 3 Fast are packed with features designed to give you the control to tell complete stories.</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Create scenes with sound.</strong> The AI generates video and audio at the same time, so you can have characters that speak with accurate lip-syncing and sound effects that fit the scene.</li>\n</ul>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>High quality results.</strong> The models produce video in high-definition (1080p), making it good enough for professional marketing campaigns and demos.</li>\n</ul>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Reach a global audience easily.</strong> Veo 3&#8217;s ability to generate dialogue natively makes it much simpler to produce a video once and then translate the dialogue for many different languages.</li>\n</ul>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Bring still images to life.</strong> A new feature, coming in August, will let you take a single photo, add a text prompt, and watch as Veo animates it into an 8-second video clip.</li>\n</ul>\n\n\n\n<figure class=\"wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio\"><div class=\"wp-block-embed__wrapper\">\n<iframe title=\"Slice Soda Radio FM Station\" width=\"800\" height=\"450\" src=\"https://www.youtube.com/embed/qLdwyDENqiE?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n</div></figure>\n\n\n\n<p>Of course, with such powerful technology, safety is a key concern. Google has built Veo 3 for responsible enterprise use. Every video frame is embedded with an invisible digital watermark from SynthID to help combat misinformation. The service is also covered by Google&#8217;s indemnity for generative AI, giving businesses that extra layer of security.</p>\n\n\n\n<p><strong>See also: </strong><a href=\"https://www.artificialintelligence-news.com/news/googles-newest-gemini-2-5-model-aims-intelligence-per-dollar/\"><strong>Google’s newest Gemini 2.5 model aims for ‘intelligence per dollar’</strong></a></p>\n\n\n\n<figure class=\"wp-block-image size-full is-resized\"><a href=\"https://www.ai-expo.net/\"><img decoding=\"async\" width=\"728\" height=\"90\" src=\"https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png\" alt=\"\" class=\"wp-image-11874\" style=\"width:800px;height:auto\" srcset=\"https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w\" sizes=\"(max-width: 728px) 100vw, 728px\" /></a></figure>\n\n\n\n<p><strong>Want to learn more about AI and big data from industry leaders?</strong> Check out<a href=\"https://www.ai-expo.net/\"> AI &amp; Big Data Expo</a> taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including <a href=\"https://intelligentautomation-conference.com/northamerica/\">Intelligent Automation Conference</a>, <a href=\"https://www.blockchain-expo.com/\">BlockX</a>,<a href=\"https://digitaltransformation-week.com/\"> Digital Transformation Week</a>, and <a href=\"https://www.cybersecuritycloudexpo.com/\">Cyber Security &amp; Cloud Expo</a>.</p>\n\n\n\n<p>Explore other upcoming enterprise technology events and webinars powered by TechForge <a href=\"https://techforge.pub/events/\">here</a>.</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/google-veo-3-ai-video-creation-tools-now-widely-available/\">Google&#8217;s Veo 3 AI video creation tools are now widely available</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
          "content:encodedSnippet": "Google has made its most powerful AI video creator, Veo 3, available for everyone to use on its Vertex AI platform. And for those who need to work quickly, a speedier version called Veo 3 Fast is also ready-to-go for quick creative work.\nEver had a brilliant idea for a video but found yourself held back by the cost, time, or technical skills needed to create it? This tool aims to offer a faster way to turn your text ideas into everything from short films to product demos.\n70 million videos have been created since May, showing a huge global appetite for these AI video creation tools. Businesses are diving in as well, generating over 6 million videos since they got early access in June.\nThe real-world applications for Veo 3\nSo, what does this look like in the real world? From global design platforms to major advertising agencies, companies are already putting Veo 3 to work. Take design platform Canva, they are building Veo directly into their software to make video creation simple for their users.\nCameron Adams, Co-Founder and Chief Product Officer at Canva, said: “Enabling anyone to bring their ideas to life – especially their most creative ones – has been core to Canva’s mission ever since we set out to empower the world to design.\n“By democratising access to a powerful technology like Google’s Veo 3 inside Canva AI, your big ideas can now be brought to life in the highest quality video and sound, all from within your existing Canva subscription. In true Canva fashion, we’ve built this with an intuitive interface and simple editing tools in place, all backed by Canva Shield.”\nFor creative agencies like BarkleyOKRP, the big wins are speed and quality. They claim to have been so impressed with the latest version that they went back and remade videos.\nJulie Ray Barr, Senior Vice President Client Experience at BarkleyOKRP, commented: “The rapid advancements from Veo 2 to Veo 3 within such a short time frame on this project have been nothing short of remarkable.\n“Our team undertook the task of re-creating numerous music videos initially produced with Veo 2 once Veo 3 was released, primarily due to the significantly improved synchronization between voice and mouth movements. The continuous daily progress we are witnessing is truly extraordinary.”\nIt’s even changing how global companies connect with local customers. The investing platform eToro used Veo 3 to create 15 different, fully AI-generated versions of a single advertisement, each customised to a specific country with its own native language.\nShay Chikotay, Head of Creative & Content at eToro, said: “With Veo 3, we produced 15 fully AI‑generated versions of our ad, each in the native language of its market, all while capturing real emotion at scale.\n“Ironically, AI didn’t reduce humanity; it amplified it. Veo 3 lets us tell more stories, in more tongues, with more impact.”\nGoogle gives creators a powerful AI video creation tool\nVeo 3 and Veo 3 Fast are packed with features designed to give you the control to tell complete stories.\nCreate scenes with sound. The AI generates video and audio at the same time, so you can have characters that speak with accurate lip-syncing and sound effects that fit the scene.\nHigh quality results. The models produce video in high-definition (1080p), making it good enough for professional marketing campaigns and demos.\nReach a global audience easily. Veo 3’s ability to generate dialogue natively makes it much simpler to produce a video once and then translate the dialogue for many different languages.\nBring still images to life. A new feature, coming in August, will let you take a single photo, add a text prompt, and watch as Veo animates it into an 8-second video clip.\n\n\n\n\n\n\nOf course, with such powerful technology, safety is a key concern. Google has built Veo 3 for responsible enterprise use. Every video frame is embedded with an invisible digital watermark from SynthID to help combat misinformation. The service is also covered by Google’s indemnity for generative AI, giving businesses that extra layer of security.\nSee also: Google’s newest Gemini 2.5 model aims for ‘intelligence per dollar’\n\n\n\n\nWant to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security & Cloud Expo.\nExplore other upcoming enterprise technology events and webinars powered by TechForge here.\nThe post Google’s Veo 3 AI video creation tools are now widely available appeared first on AI News.",
          "dc:creator": "Ryan Daws",
          "content": "<p>Google has made its most powerful AI video creator, Veo 3, available for everyone to use on its Vertex AI platform. And for those who need to work quickly, a speedier version called Veo 3 Fast is also ready-to-go for quick creative work. Ever had a brilliant idea for a video but found yourself held [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/google-veo-3-ai-video-creation-tools-now-widely-available/\">Google&#8217;s Veo 3 AI video creation tools are now widely available</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
          "contentSnippet": "Google has made its most powerful AI video creator, Veo 3, available for everyone to use on its Vertex AI platform. And for those who need to work quickly, a speedier version called Veo 3 Fast is also ready-to-go for quick creative work. Ever had a brilliant idea for a video but found yourself held […]\nThe post Google’s Veo 3 AI video creation tools are now widely available appeared first on AI News.",
          "guid": "https://www.artificialintelligence-news.com/?p=107245",
          "categories": [
            "Applications",
            "Artificial Intelligence",
            "Companies",
            "Google",
            "Industries",
            "ai",
            "applications",
            "artificial intelligence",
            "generative ai",
            "google",
            "tools",
            "veo",
            "vertex ai",
            "video"
          ],
          "isoDate": "2025-07-29T16:01:39.000Z"
        }
      },
      {
        "json": {
          "creator": "Dashveenjit Kaur",
          "title": "China doubles chooses AI self-reliance amid intense US competition",
          "link": "https://www.artificialintelligence-news.com/news/china-ai-competition-shanghai-subsidy-us-rivalry/",
          "pubDate": "Tue, 29 Jul 2025 10:01:13 +0000",
          "content:encoded": "<p>The artificial intelligence sector in China has entered a new phase intensifying AI competition with the United States, as Chinese megacities launch massive subsidy programmes. At the same time, domestic firms are hoping to reduce their dependence on US technology. The stakes extend far beyond technological supremacy, with both nations viewing AI dominance as critical to future economic and strategic power.</p>\n<h3>Shanghai&#8217;s US$139 million AI investment gambit</h3>\n<p>Shanghai has unveiled an ambitious one billion yuan (US$139 million) subsidy programme for its artificial intelligence industry, marking the latest in the technological race as major cities in China engage in fierce AI competition for dominance.</p>\n<p>The comprehensive package allocates resources in three key areas: 600 million yuan for computing power subsidies, 300 million yuan for third-party AI model discounts, and 100 million yuan to support companies in procuring training datasets.</p>\n<p>The programme offers subsidy rates ranging from 10% to 100% of contract values for computing facilities, AI models, and datasets, according to documents released by the Shanghai Municipal Commission of Economy and Informatisation. The city plans to offer up to 500 million yuan to new AI research institutions, with funding guaranteed for three to five years.</p>\n<p>&#8220;One of Shanghai&#8217;s key advantages in AI development is its strong funding,&#8221; said Pan Helin, a member of an expert committee under China&#8217;s Ministry of Industry and Information Technology. However, Pan noted that Shanghai&#8217;s high operating costs often push AI start-ups toward cheaper alternatives like nearby Hangzhou.</p>\n<h3>Nationwide competition heats up</h3>\n<p>Shanghai&#8217;s initiative reflects a broader pattern in China, where cities are competing aggressively to establish AI dominance in what has become an intense inter-city competition. Hangzhou has emerged as a particular rival, having announced plans last year to distribute 250 million yuan in computing power subsidies while nurturing its &#8220;six little dragons&#8221; – a collection of well-known Chinese start-ups, including AI player DeepSeek.</p>\n<p>The inter-city rivalry extends beyond Shanghai and Hangzhou, with Shenzhen, Chengdu, and Beijing also introducing similar support measures. This situation demonstrates how artificial intelligence has become a strategic priority at multiple levels of Chinese government – domestic AI competition in China.</p>\n<h3>Trump&#8217;s AI strategy maintains pressure</h3>\n<p>The timing of Shanghai&#8217;s announcement coincides with the Trump administration&#8217;s comprehensive AI Action Plan, unveiled on July 23. The 28-page strategy maintains tight restrictions on key technologies while accelerating deregulation and infrastructure support for US AI companies.</p>\n<p>Donald Trump described the plan as &#8220;a policy of the United States to do whatever it takes to lead the world in artificial intelligence,&#8221; emphasising America&#8217;s intention to become an &#8220;AI export powerhouse&#8221; and maintain national security protections.</p>\n<p>The plan tasks the US Commerce Department with closing loopholes in current export restrictions, boosting oversight of end users abroad, and a plan to explore geolocation tools to block access to &#8220;countries of concern&#8221; like China.</p>\n<h3>China&#8217;s self-reliance strategy shows results</h3>\n<p>Despite US restrictions, analysts predict significant growth for China&#8217;s domestic AI industry. Bernstein analysts led by Lin Qingyuan forecast that <a href=\"https://www.artificialintelligence-news.com/news/us-china-ai-chip-race-cambricons-first-profit-lands/\">domestic chips</a> will capture 55% of China&#8217;s AI accelerator market by 2027, up dramatically from just 17% in 2023.</p>\n<p>&#8220;Export controls have created a unique opportunity for domestic AI chip vendors, as they are not competing with the most advanced global alternatives,&#8221; the Bernstein research note said.</p>\n<p>The growth reflects ongoing technological progress, with Chinese companies increasingly matching the <a href=\"https://www.artificialintelligence-news.com/news/nvidia-budget-china-ai-chip-strategy-huawei-growth/\">performance of downgraded chip</a>s sold to China. Huawei&#8217;s Ascend 910C now reaches approximately 65% of Nvidia&#8217;s supreme H100 capacity, though its computing power remains limited by lack of direct compatibility with Nvidia&#8217;s CUDA software platform.</p>\n<h3>Geopolitical implications and future outlook</h3>\n<p>Bo Zhengyuan of Plenum, an independent China-focused research platform, argues that Trump&#8217;s approach represents a shift from Biden&#8217;s containment strategy to more direct competition. &#8220;So far, the &#8216;yard&#8217; hasn&#8217;t gotten any smaller,&#8221; Bo noted, according to a <em><a href=\"https://www.scmp.com/economy/china-economy/article/3319470/chinas-quest-ai-self-reliance-undeterred-trumps-new-action-plan?module=top_story&amp;pgtype=homepage\">South China Morning Post</a></em> article, referring to export control scope. &#8220;What&#8217;s different is the rhetoric – it&#8217;s now more head-to-head than containment.&#8221;</p>\n<p>The AI competition between China and the US appears set to intensify further, so much so that at the World Artificial Intelligence Conference in Shanghai, Premier Li Qiang called for international cooperation to ensure AI does not become an &#8220;exclusive game&#8221; accessible only to a select few – a clear reference to US restrictions.</p>\n<p>However, neither US pressure nor Chinese subsidies guarantees clear winners in this technological race. &#8220;AI isn&#8217;t something that can be built overnight through policy support alone – it&#8217;s a long game shaped by engineering, talent, and infrastructure,&#8221; Bo said.</p>\n<p>With China&#8217;s data resources, algorithms, and AI talent remaining competitive with the US despite chip restrictions, the outcome of this technological competition may ultimately depend on which approach – American technological restrictions or Chinese self-reliance investments – proves more effective in driving innovation.</p>\n<p>&#8220;There won&#8217;t be a clear winner or loser in the next decade,&#8221; Bo concluded, suggesting that this technological rivalry will define the AI landscape for years to come.</p>\n<p><strong>See also: <a href=\"https://www.artificialintelligence-news.com/news/ren-zhengfei-china-ai-future-huawei-long-game/\">Ren Zhengfei: China&#8217;s AI future and Huawei&#8217;s long game</a></strong></p>\n<figurewp-block-image size-full is-resized\"><a href=\"https://www.ai-expo.net/\"><img loading=\"lazy\" decoding=\"async\" width=\"728\" height=\"90\" src=\"https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png\" alt=\"\"wp-image-11874\" style=\"width:800px;height:auto\" srcset=\"https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w\" sizes=\"(max-width: 728px) 100vw, 728px\" /></a></figure>\n<p><strong>Want to learn more about AI and big data from industry leaders?</strong> Check out<a href=\"https://www.ai-expo.net/\"> AI &amp; Big Data Expo</a> taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including <a href=\"https://intelligentautomation-conference.com/northamerica/\">Intelligent Automation Conference</a>, <a href=\"https://www.blockchain-expo.com/\">BlockX</a>,<a href=\"https://digitaltransformation-week.com/\"> Digital Transformation Week</a>, and <a href=\"https://www.cybersecuritycloudexpo.com/\">Cyber Security &amp; Cloud Expo</a>.</p>\n<p>Explore other upcoming enterprise technology events and webinars powered by TechForge <a href=\"https://techforge.pub/events/\">here</a>.</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/china-ai-competition-shanghai-subsidy-us-rivalry/\">China doubles chooses AI self-reliance amid intense US competition</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
          "content:encodedSnippet": "The artificial intelligence sector in China has entered a new phase intensifying AI competition with the United States, as Chinese megacities launch massive subsidy programmes. At the same time, domestic firms are hoping to reduce their dependence on US technology. The stakes extend far beyond technological supremacy, with both nations viewing AI dominance as critical to future economic and strategic power.\nShanghai’s US$139 million AI investment gambit\nShanghai has unveiled an ambitious one billion yuan (US$139 million) subsidy programme for its artificial intelligence industry, marking the latest in the technological race as major cities in China engage in fierce AI competition for dominance.\nThe comprehensive package allocates resources in three key areas: 600 million yuan for computing power subsidies, 300 million yuan for third-party AI model discounts, and 100 million yuan to support companies in procuring training datasets.\nThe programme offers subsidy rates ranging from 10% to 100% of contract values for computing facilities, AI models, and datasets, according to documents released by the Shanghai Municipal Commission of Economy and Informatisation. The city plans to offer up to 500 million yuan to new AI research institutions, with funding guaranteed for three to five years.\n“One of Shanghai’s key advantages in AI development is its strong funding,” said Pan Helin, a member of an expert committee under China’s Ministry of Industry and Information Technology. However, Pan noted that Shanghai’s high operating costs often push AI start-ups toward cheaper alternatives like nearby Hangzhou.\nNationwide competition heats up\nShanghai’s initiative reflects a broader pattern in China, where cities are competing aggressively to establish AI dominance in what has become an intense inter-city competition. Hangzhou has emerged as a particular rival, having announced plans last year to distribute 250 million yuan in computing power subsidies while nurturing its “six little dragons” – a collection of well-known Chinese start-ups, including AI player DeepSeek.\nThe inter-city rivalry extends beyond Shanghai and Hangzhou, with Shenzhen, Chengdu, and Beijing also introducing similar support measures. This situation demonstrates how artificial intelligence has become a strategic priority at multiple levels of Chinese government – domestic AI competition in China.\nTrump’s AI strategy maintains pressure\nThe timing of Shanghai’s announcement coincides with the Trump administration’s comprehensive AI Action Plan, unveiled on July 23. The 28-page strategy maintains tight restrictions on key technologies while accelerating deregulation and infrastructure support for US AI companies.\nDonald Trump described the plan as “a policy of the United States to do whatever it takes to lead the world in artificial intelligence,” emphasising America’s intention to become an “AI export powerhouse” and maintain national security protections.\nThe plan tasks the US Commerce Department with closing loopholes in current export restrictions, boosting oversight of end users abroad, and a plan to explore geolocation tools to block access to “countries of concern” like China.\nChina’s self-reliance strategy shows results\nDespite US restrictions, analysts predict significant growth for China’s domestic AI industry. Bernstein analysts led by Lin Qingyuan forecast that domestic chips will capture 55% of China’s AI accelerator market by 2027, up dramatically from just 17% in 2023.\n“Export controls have created a unique opportunity for domestic AI chip vendors, as they are not competing with the most advanced global alternatives,” the Bernstein research note said.\nThe growth reflects ongoing technological progress, with Chinese companies increasingly matching the performance of downgraded chips sold to China. Huawei’s Ascend 910C now reaches approximately 65% of Nvidia’s supreme H100 capacity, though its computing power remains limited by lack of direct compatibility with Nvidia’s CUDA software platform.\nGeopolitical implications and future outlook\nBo Zhengyuan of Plenum, an independent China-focused research platform, argues that Trump’s approach represents a shift from Biden’s containment strategy to more direct competition. “So far, the ‘yard’ hasn’t gotten any smaller,” Bo noted, according to a South China Morning Post article, referring to export control scope. “What’s different is the rhetoric – it’s now more head-to-head than containment.”\nThe AI competition between China and the US appears set to intensify further, so much so that at the World Artificial Intelligence Conference in Shanghai, Premier Li Qiang called for international cooperation to ensure AI does not become an “exclusive game” accessible only to a select few – a clear reference to US restrictions.\nHowever, neither US pressure nor Chinese subsidies guarantees clear winners in this technological race. “AI isn’t something that can be built overnight through policy support alone – it’s a long game shaped by engineering, talent, and infrastructure,” Bo said.\nWith China’s data resources, algorithms, and AI talent remaining competitive with the US despite chip restrictions, the outcome of this technological competition may ultimately depend on which approach – American technological restrictions or Chinese self-reliance investments – proves more effective in driving innovation.\n“There won’t be a clear winner or loser in the next decade,” Bo concluded, suggesting that this technological rivalry will define the AI landscape for years to come.\nSee also: Ren Zhengfei: China’s AI future and Huawei’s long game\n\nWant to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security & Cloud Expo.\nExplore other upcoming enterprise technology events and webinars powered by TechForge here.\nThe post China doubles chooses AI self-reliance amid intense US competition appeared first on AI News.",
          "dc:creator": "Dashveenjit Kaur",
          "content": "<p>The artificial intelligence sector in China has entered a new phase intensifying AI competition with the United States, as Chinese megacities launch massive subsidy programmes. At the same time, domestic firms are hoping to reduce their dependence on US technology. The stakes extend far beyond technological supremacy, with both nations viewing AI dominance as critical [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/china-ai-competition-shanghai-subsidy-us-rivalry/\">China doubles chooses AI self-reliance amid intense US competition</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
          "contentSnippet": "The artificial intelligence sector in China has entered a new phase intensifying AI competition with the United States, as Chinese megacities launch massive subsidy programmes. At the same time, domestic firms are hoping to reduce their dependence on US technology. The stakes extend far beyond technological supremacy, with both nations viewing AI dominance as critical […]\nThe post China doubles chooses AI self-reliance amid intense US competition appeared first on AI News.",
          "guid": "https://www.artificialintelligence-news.com/?p=107231",
          "categories": [
            "Artificial Intelligence",
            "Enterprise",
            "Huawei",
            "NVIDIA",
            "ai",
            "artificial intelligence",
            "china",
            "US"
          ],
          "isoDate": "2025-07-29T10:01:13.000Z"
        }
      },
      {
        "json": {
          "creator": "Sharon Feldman",
          "title": "Google’s AI overviews and SEO in high-stakes industries",
          "link": "https://www.artificialintelligence-news.com/news/googles-ai-overviews-and-seo-in-high-stakes-industries/",
          "pubDate": "Tue, 29 Jul 2025 08:45:00 +0000",
          "content:encoded": "\n<p>If you&#8217;ve searched anything on Google lately, chances are you&#8217;ve seen an AI overview (AIO). Formerly known as SGE, AI overviews are the succinct AI-generated summaries of information that appear right at the top of Google for a majority of search queries.</p>\n\n\n\n<p>While it can serve as a convenient way to get a question answered quickly without having to sift through so many options of links to click on, it certainly has some issues. There have been plenty of instances of false information being presented.</p>\n\n\n\n<p>Accuracy and trust are particularly important in high-stakes industries like health, law, and finance. What happens when someone asks Google a medical or legal question and receives a wrong answer?</p>\n\n\n\n<p>The AIO also poses new challenges for SEO professionals, as it reshapes how users search online and how businesses need to shift their SEO strategy.</p>\n\n\n\n<p>iLawyer Marketing, a<a href=\"https://www.ilawyermarketing.com/law-firm-seo/\"> law firm SEO</a> agency, offers perspective on how businesses in high-stakes industries can stay visible and trusted in an AI-driven search landscape.</p>\n\n\n\n<div style=\"height:20px\" aria-hidden=\"true\" class=\"wp-block-spacer\"></div>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-the-technology-behind-ai-overviews-and-their-limitations\">The technology behind AI overviews and their limitations</h3>\n\n\n\n<p>AI-generated summaries at the top of Google aren&#8217;t going anywhere. A recent study from Pew Research found that<a href=\"http://pewresearch.org/data-labs/2025/05/23/what-web-browsing-data-tells-us-about-how-ai-appears-online/#fn-239328-1\"> 58% of participants</a> saw an AI-generated summary when conducting searches.</p>\n\n\n\n<p>The summaries are created using large language models (LLMs) that aggregate content, extract relevant answers, and provide source citations. However, AI Overviews contain the same misinformation that organic results can, and they can hallucinate.</p>\n\n\n\n<p>Plenty of controversy has arisen over AI hallucinations, or<a href=\"https://www.legaldive.com/news/chatgpt-fake-legal-cases-generative-ai-hallucinations/651557/\"> false statements that AI produces</a> out of confusion. AI isn&#8217;t perfect, after all. There are also concerns over source transparency, as users can&#8217;t always tell where the answer is coming from at a glance. For high-stakes topics, that&#8217;s a problem. If the source is wrong or unreliable, the answer might be too.</p>\n\n\n\n<div style=\"height:20px\" aria-hidden=\"true\" class=\"wp-block-spacer\"></div>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-risks-and-opportunities-in-high-stakes-industries\">Risks and opportunities in high-stakes industries</h3>\n\n\n\n<p>While some AI hallucinations are harmless and rather amusing (the &#8220;adding glue to pizza&#8221; response, for example), in high-stakes industries, this misinformation can have more serious consequences.</p>\n\n\n\n<p>Consumers who are seeking medical or legal advice on Google, which is not recommended but inevitable, can end up with incorrect AI overviews shoved in their faces. And since such answers are prominently featured at the top of the page, they carry unearned authority. One bad answer could lead to poor medical decisions, legal missteps, or financial harm.</p>\n\n\n\n<p>The good news is that AI overviews present an opportunity for authoritative, trustworthy sites to be cited more often. For professionals in law, healthcare, and finance, this means it&#8217;s important to have content that is accurate, well-structured, and published by credentialed experts.</p>\n\n\n\n<p>The bad news for SEO experts is that organic rankings are no longer the sole focus. The new race is to be featured in the AIO. If a user asking for legal advice can get their answer, whether true or not, without clicking any links, why would they?</p>\n\n\n\n<p>Fortunately, if you&#8217;re ranking well organically, you have a higher chance of being featured in the AIO. Ahrefs recently found that<a href=\"https://ahrefs.com/blog/search-rankings-ai-citations/\"> 76% of AIO citations</a> pull from the top ten results.</p>\n\n\n\n<div style=\"height:20px\" aria-hidden=\"true\" class=\"wp-block-spacer\"></div>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-implications-for-law-firm-seo\">Implications for law firm SEO</h3>\n\n\n\n<p>How can law firms and other high-stakes professionals adapt? They need to ensure that content is addressing common questions and doing so in a clear, structured format.</p>\n\n\n\n<p>The concept of E-E-A-T is alive and well in SEO: Experience, Expertise, Authoritativeness, Trustworthiness. This content strategy hasn&#8217;t gone anywhere and is likely a factor in AIO citations.</p>\n\n\n\n<p>In legal content, questions like &#8220;Do I need a lawyer after a car accident?&#8221; can be used as headings, with a clear answer following. Any legal answer that can be cited with a government statute should absolutely do so.</p>\n\n\n\n<p>Another aspect of gaining authority and trust comes from getting high-quality backlinks. Being cited in trusted sources like legal directories, news sites, or .edu and .gov pages is still an important part of SEO strategy.</p>\n\n\n\n<p>SEO professionals suggest focusing on both traditional ranking factors and new AIO-specific formats to cover all the bases.</p>\n\n\n\n<div style=\"height:20px\" aria-hidden=\"true\" class=\"wp-block-spacer\"></div>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-what-seo-pros-should-be-doing-now\">What SEO pros should be doing now</h3>\n\n\n\n<p>The first step in optimising for AI is to monitor how your site appears in overviews. You can search manually or use tools, but start tracking which queries you appear for and which page or section of your page is cited. You should also look at which page or section of your competitors&#8217; pages are being cited.</p>\n\n\n\n<p>Schema, or<a href=\"https://developers.google.com/search/docs/appearance/structured-data/intro-structured-data\"> structured data</a>, is one strategy for trying to get your content into the AIO. It communicates your content to Google in a language it understands more easily and is your best shot at getting rich results. Having FAQ sections on your pages with concise answers and structured data will improve AI accessibility.</p>\n\n\n\n<p>It&#8217;s also a good idea to reevaluate which of your current pages are targeting high-intent, high-risk queries. Can you strengthen the answers? Improve readability? Cite more trustworthy sources? Even small edits might make a big difference.</p>\n\n\n\n<div style=\"height:20px\" aria-hidden=\"true\" class=\"wp-block-spacer\"></div>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-looking-ahead\">Looking ahead</h3>\n\n\n\n<p>Google&#8217;s AI overviews are raising the bar for content in industries where precision matters. For law firm SEO and other high-stakes verticals, success now means becoming a trustworthy source, not just a top result.</p>\n\n\n\n<p>Firms that invest in high-quality content, structure, and authority will be better positioned for an AI-driven search experience, no matter what that looks like in the future.</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/googles-ai-overviews-and-seo-in-high-stakes-industries/\">Google&#8217;s AI overviews and SEO in high-stakes industries</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
          "content:encodedSnippet": "If you’ve searched anything on Google lately, chances are you’ve seen an AI overview (AIO). Formerly known as SGE, AI overviews are the succinct AI-generated summaries of information that appear right at the top of Google for a majority of search queries.\nWhile it can serve as a convenient way to get a question answered quickly without having to sift through so many options of links to click on, it certainly has some issues. There have been plenty of instances of false information being presented.\nAccuracy and trust are particularly important in high-stakes industries like health, law, and finance. What happens when someone asks Google a medical or legal question and receives a wrong answer?\nThe AIO also poses new challenges for SEO professionals, as it reshapes how users search online and how businesses need to shift their SEO strategy.\niLawyer Marketing, a law firm SEO agency, offers perspective on how businesses in high-stakes industries can stay visible and trusted in an AI-driven search landscape.\n\n\n\n\nThe technology behind AI overviews and their limitations\nAI-generated summaries at the top of Google aren’t going anywhere. A recent study from Pew Research found that 58% of participants saw an AI-generated summary when conducting searches.\nThe summaries are created using large language models (LLMs) that aggregate content, extract relevant answers, and provide source citations. However, AI Overviews contain the same misinformation that organic results can, and they can hallucinate.\nPlenty of controversy has arisen over AI hallucinations, or false statements that AI produces out of confusion. AI isn’t perfect, after all. There are also concerns over source transparency, as users can’t always tell where the answer is coming from at a glance. For high-stakes topics, that’s a problem. If the source is wrong or unreliable, the answer might be too.\n\n\n\n\nRisks and opportunities in high-stakes industries\nWhile some AI hallucinations are harmless and rather amusing (the “adding glue to pizza” response, for example), in high-stakes industries, this misinformation can have more serious consequences.\nConsumers who are seeking medical or legal advice on Google, which is not recommended but inevitable, can end up with incorrect AI overviews shoved in their faces. And since such answers are prominently featured at the top of the page, they carry unearned authority. One bad answer could lead to poor medical decisions, legal missteps, or financial harm.\nThe good news is that AI overviews present an opportunity for authoritative, trustworthy sites to be cited more often. For professionals in law, healthcare, and finance, this means it’s important to have content that is accurate, well-structured, and published by credentialed experts.\nThe bad news for SEO experts is that organic rankings are no longer the sole focus. The new race is to be featured in the AIO. If a user asking for legal advice can get their answer, whether true or not, without clicking any links, why would they?\nFortunately, if you’re ranking well organically, you have a higher chance of being featured in the AIO. Ahrefs recently found that 76% of AIO citations pull from the top ten results.\n\n\n\n\nImplications for law firm SEO\nHow can law firms and other high-stakes professionals adapt? They need to ensure that content is addressing common questions and doing so in a clear, structured format.\nThe concept of E-E-A-T is alive and well in SEO: Experience, Expertise, Authoritativeness, Trustworthiness. This content strategy hasn’t gone anywhere and is likely a factor in AIO citations.\nIn legal content, questions like “Do I need a lawyer after a car accident?” can be used as headings, with a clear answer following. Any legal answer that can be cited with a government statute should absolutely do so.\nAnother aspect of gaining authority and trust comes from getting high-quality backlinks. Being cited in trusted sources like legal directories, news sites, or .edu and .gov pages is still an important part of SEO strategy.\nSEO professionals suggest focusing on both traditional ranking factors and new AIO-specific formats to cover all the bases.\n\n\n\n\nWhat SEO pros should be doing now\nThe first step in optimising for AI is to monitor how your site appears in overviews. You can search manually or use tools, but start tracking which queries you appear for and which page or section of your page is cited. You should also look at which page or section of your competitors’ pages are being cited.\nSchema, or structured data, is one strategy for trying to get your content into the AIO. It communicates your content to Google in a language it understands more easily and is your best shot at getting rich results. Having FAQ sections on your pages with concise answers and structured data will improve AI accessibility.\nIt’s also a good idea to reevaluate which of your current pages are targeting high-intent, high-risk queries. Can you strengthen the answers? Improve readability? Cite more trustworthy sources? Even small edits might make a big difference.\n\n\n\n\nLooking ahead\nGoogle’s AI overviews are raising the bar for content in industries where precision matters. For law firm SEO and other high-stakes verticals, success now means becoming a trustworthy source, not just a top result.\nFirms that invest in high-quality content, structure, and authority will be better positioned for an AI-driven search experience, no matter what that looks like in the future.\nThe post Google’s AI overviews and SEO in high-stakes industries appeared first on AI News.",
          "dc:creator": "Sharon Feldman",
          "content": "<p>If you&#8217;ve searched anything on Google lately, chances are you&#8217;ve seen an AI overview (AIO). Formerly known as SGE, AI overviews are the succinct AI-generated summaries of information that appear right at the top of Google for a majority of search queries. While it can serve as a convenient way to get a question answered [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/googles-ai-overviews-and-seo-in-high-stakes-industries/\">Google&#8217;s AI overviews and SEO in high-stakes industries</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
          "contentSnippet": "If you’ve searched anything on Google lately, chances are you’ve seen an AI overview (AIO). Formerly known as SGE, AI overviews are the succinct AI-generated summaries of information that appear right at the top of Google for a majority of search queries. While it can serve as a convenient way to get a question answered […]\nThe post Google’s AI overviews and SEO in high-stakes industries appeared first on AI News.",
          "guid": "https://www.artificialintelligence-news.com/?p=107236",
          "categories": [
            "Sponsored Content"
          ],
          "isoDate": "2025-07-29T08:45:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Ryan Daws",
          "title": "Forget the Turing Test, AI’s real challenge is communication",
          "link": "https://www.artificialintelligence-news.com/news/forget-turing-test-ai-real-challenge-is-communication/",
          "pubDate": "Mon, 28 Jul 2025 16:00:59 +0000",
          "content:encoded": "\n<p>While the development of <a href=\"https://www.artificialintelligence-news.com/news/alibaba-new-qwen-reasoning-ai-model-open-source-records/\">increasingly powerful</a> AI models grabs headlines, the big challenge is getting intelligent agents to communicate.</p>\n\n\n\n<p>Right now, we have all these capable systems, but they’re all speaking different languages. It’s a digital Tower of Babel, and it’s holding back the true potential of what AI can achieve.</p>\n\n\n\n<p>To move forward, we need a common tongue; a universal translator that will allow these different systems to connect and collaborate. Several contenders have stepped up to the plate, each with their own ideas about how to solve this communication puzzle.</p>\n\n\n\n<p>Anthropic’s <a href=\"https://modelcontextprotocol.io/\">Model Context Protocol</a>, or MCP, is one of the big names in the ring. It attempts to create a secure and organised way for AI models to use external tools and data. MCP has become popular because it’s relatively simple and has the backing of a major AI player. However, it’s really designed for a single AI to use different tools, not for a team of AIs to work together.</p>\n\n\n\n<p>And that’s where other protocols like the Agent Communication Protocol (ACP) and the Agent-to-Agent Protocol (A2A) come in.</p>\n\n\n\n<p><a href=\"https://agentcommunicationprotocol.dev/\">ACP</a>, an open-source project from IBM, is all about enabling AI agents to communicate as peers. It’s built on familiar web technologies that developers are already comfortable with, which makes it easy to adopt. It’s a flexible and powerful solution that allows for a more decentralised and collaborative approach to AI.</p>\n\n\n\n<p>Google’s <a href=\"https://a2aprotocol.ai/\">A2A</a> protocol, meanwhile, takes a slightly different tack. It’s designed to work alongside MCP, rather than replace it. A2A is focused on how a team of AIs can work together on complex tasks, passing information and responsibilities back and forth. It uses a system of ‘Agent Cards,’ like digital business cards, to help AIs find and understand each other.</p>\n\n\n\n<p>The real difference between these protocols is their vision for the future of how AI agents communicate. MCP is for a world where a single, powerful AI is at the centre, using a variety of tools to get things done. ACP and A2A are designed for distributed intelligence, where teams of specialised AIs work together to solve problems.</p>\n\n\n\n<p>A universal language for AI would open the door to a whole new world of possibilities. Imagine a team of AIs working together to design a new product, with one agent handling the market research, another the design, and a third the manufacturing process. Or a network of <a href=\"https://www.artificialintelligence-news.com/news/google-open-medgemma-ai-models-healthcare/\">medical AIs</a> collaborating to analyse patient data and develop personalised treatment plans.</p>\n\n\n\n<p>But we’re not there yet. The &#8220;protocol wars&#8221; are in full swing, and there’s a real risk that we could end up with even more fragmentation than we have now.</p>\n\n\n\n<p>It’s likely that the future of how AI communicates won’t be a one-size-fits-all solution. We may see different protocols, each used for what it does best. One thing is for sure: figuring out how to get AIs to talk to each other is among the next great challenges in the field.</p>\n\n\n\n<p><em>(Photo by <a href=\"https://unsplash.com/@tdponcet?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash\">Theodore Poncet</a>)</em></p>\n\n\n\n<p><strong>See also: </strong><a href=\"https://www.artificialintelligence-news.com/news/anthropic-deploys-ai-agents-audit-models-for-safety/\"><strong>Anthropic deploys AI agents to audit models for safety</strong></a></p>\n\n\n\n<figure class=\"wp-block-image size-full is-resized\"><a href=\"https://www.ai-expo.net/\"><img decoding=\"async\" width=\"728\" height=\"90\" src=\"https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png\" alt=\"\" class=\"wp-image-11874\" style=\"width:800px;height:auto\" srcset=\"https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w\" sizes=\"(max-width: 728px) 100vw, 728px\" /></a></figure>\n\n\n\n<p><strong>Want to learn more about AI and big data from industry leaders?</strong> Check out<a href=\"https://www.ai-expo.net/\"> AI &amp; Big Data Expo</a> taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including <a href=\"https://intelligentautomation-conference.com/northamerica/\">Intelligent Automation Conference</a>, <a href=\"https://www.blockchain-expo.com/\">BlockX</a>,<a href=\"https://digitaltransformation-week.com/\"> Digital Transformation Week</a>, and <a href=\"https://www.cybersecuritycloudexpo.com/\">Cyber Security &amp; Cloud Expo</a>.</p>\n\n\n\n<p>Explore other upcoming enterprise technology events and webinars powered by TechForge <a href=\"https://techforge.pub/events/\">here</a>.</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/forget-turing-test-ai-real-challenge-is-communication/\">Forget the Turing Test, AI’s real challenge is communication</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
          "content:encodedSnippet": "While the development of increasingly powerful AI models grabs headlines, the big challenge is getting intelligent agents to communicate.\nRight now, we have all these capable systems, but they’re all speaking different languages. It’s a digital Tower of Babel, and it’s holding back the true potential of what AI can achieve.\nTo move forward, we need a common tongue; a universal translator that will allow these different systems to connect and collaborate. Several contenders have stepped up to the plate, each with their own ideas about how to solve this communication puzzle.\nAnthropic’s Model Context Protocol, or MCP, is one of the big names in the ring. It attempts to create a secure and organised way for AI models to use external tools and data. MCP has become popular because it’s relatively simple and has the backing of a major AI player. However, it’s really designed for a single AI to use different tools, not for a team of AIs to work together.\nAnd that’s where other protocols like the Agent Communication Protocol (ACP) and the Agent-to-Agent Protocol (A2A) come in.\nACP, an open-source project from IBM, is all about enabling AI agents to communicate as peers. It’s built on familiar web technologies that developers are already comfortable with, which makes it easy to adopt. It’s a flexible and powerful solution that allows for a more decentralised and collaborative approach to AI.\nGoogle’s A2A protocol, meanwhile, takes a slightly different tack. It’s designed to work alongside MCP, rather than replace it. A2A is focused on how a team of AIs can work together on complex tasks, passing information and responsibilities back and forth. It uses a system of ‘Agent Cards,’ like digital business cards, to help AIs find and understand each other.\nThe real difference between these protocols is their vision for the future of how AI agents communicate. MCP is for a world where a single, powerful AI is at the centre, using a variety of tools to get things done. ACP and A2A are designed for distributed intelligence, where teams of specialised AIs work together to solve problems.\nA universal language for AI would open the door to a whole new world of possibilities. Imagine a team of AIs working together to design a new product, with one agent handling the market research, another the design, and a third the manufacturing process. Or a network of medical AIs collaborating to analyse patient data and develop personalised treatment plans.\nBut we’re not there yet. The “protocol wars” are in full swing, and there’s a real risk that we could end up with even more fragmentation than we have now.\nIt’s likely that the future of how AI communicates won’t be a one-size-fits-all solution. We may see different protocols, each used for what it does best. One thing is for sure: figuring out how to get AIs to talk to each other is among the next great challenges in the field.\n(Photo by Theodore Poncet)\nSee also: Anthropic deploys AI agents to audit models for safety\n\n\n\n\nWant to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security & Cloud Expo.\nExplore other upcoming enterprise technology events and webinars powered by TechForge here.\nThe post Forget the Turing Test, AI’s real challenge is communication appeared first on AI News.",
          "dc:creator": "Ryan Daws",
          "content": "<p>While the development of increasingly powerful AI models grabs headlines, the big challenge is getting intelligent agents to communicate. Right now, we have all these capable systems, but they’re all speaking different languages. It’s a digital Tower of Babel, and it’s holding back the true potential of what AI can achieve. To move forward, we [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/forget-turing-test-ai-real-challenge-is-communication/\">Forget the Turing Test, AI’s real challenge is communication</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
          "contentSnippet": "While the development of increasingly powerful AI models grabs headlines, the big challenge is getting intelligent agents to communicate. Right now, we have all these capable systems, but they’re all speaking different languages. It’s a digital Tower of Babel, and it’s holding back the true potential of what AI can achieve. To move forward, we […]\nThe post Forget the Turing Test, AI’s real challenge is communication appeared first on AI News.",
          "guid": "https://www.artificialintelligence-news.com/?p=107227",
          "categories": [
            "Artificial Intelligence",
            "a2a",
            "acp",
            "agents",
            "ai",
            "artificial intelligence",
            "development",
            "mcp",
            "protocols"
          ],
          "isoDate": "2025-07-28T16:00:59.000Z"
        }
      },
      {
        "json": {
          "creator": "Ryan Daws",
          "title": "Anthropic deploys AI agents to audit models for safety",
          "link": "https://www.artificialintelligence-news.com/news/anthropic-deploys-ai-agents-audit-models-for-safety/",
          "pubDate": "Fri, 25 Jul 2025 13:40:34 +0000",
          "content:encoded": "\n<p><a href=\"https://www.anthropic.com/\">Anthropic</a> has built an army of autonomous AI agents with a singular mission: to audit powerful models like Claude to improve safety.</p>\n\n\n\n<p>As these complex systems rapidly advance, the job of making sure they are safe and don&#8217;t harbour hidden dangers has become a herculean task. Anthropic believes it has found a solution, and it’s a classic case of fighting fire with fire.</p>\n\n\n\n<p>The idea is similar to a digital immune system, where AI agents act like antibodies to identify and neutralise problems before they cause real harm. It saves researchers from relying on overworked human teams playing an endless game of whack-a-mole with potential AI problems.</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-the-digital-detective-squad\">The digital detective squad</h3>\n\n\n\n<p>The approach is essentially a digital detective squad; a trio of specialised AI safety agents each with a distinct role.   </p>\n\n\n\n<p>First up is the Investigator Agent, the grizzled detective of the group. Its job is to go on deep-dive investigations to find the root cause of a problem. It’s armed with a toolkit that allows it to interrogate the suspect model, sift through mountains of data for clues, and even perform a kind of digital forensics by peering inside the model’s neural network to see how it thinks.&nbsp;&nbsp;&nbsp;</p>\n\n\n\n<p>Then there’s the Evaluation Agent. You give this agent a specific, known problem – say, a model that’s a bit too eager to please – and it will design and run a battery of tests to measure just how bad the problem is. It’s all about producing the cold, hard data needed to prove a case.&nbsp;&nbsp;&nbsp;</p>\n\n\n\n<p>Rounding out the team is the Breadth-First Red-Teaming Agent, the undercover operative. This agent’s mission is to have thousands of different conversations with a model, trying to provoke it into revealing any kind of concerning behaviour, even things the researchers haven&#8217;t thought of. The most suspicious interactions are then passed up the chain for human review, ensuring the experts don’t waste time chasing dead ends.</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-anthropic-puts-its-ai-safety-agents-through-their-paces\">Anthropic puts its AI safety agents through their paces</h3>\n\n\n\n<p>To see if their new digital recruits were up to the job, Anthropic’s researchers put them through a series of &#8220;auditing games.&#8221;</p>\n\n\n\n<p>In one test, they created a model with a secret agenda: to be a sycophant. It had been secretly trained to flatter its internal reward system based on a fictional academic study it had been shown, a flaw hidden deep within its programming.</p>\n\n\n\n<p>When a single Investigator Agent was sent in, it struggled, finding the hidden goal only 13% of the time. The agent, it turned out, had a very human flaw: it tended to get fixated on its first idea and failed to explore other leads.</p>\n\n\n\n<p>But this is where the system’s genius becomes apparent. When the researchers deployed a &#8220;super-agent&#8221; that pooled the findings from ten separate investigators, the success rate shot up to 42%. It proves that teamwork makes the dream work, even for AI, allowing a group to overcome the individual blind spots that can derail an investigation.</p>\n\n\n\n<p>The other agents also passed with flying colours. The Evaluation Agent successfully designed tests that could spot a quirky model 88% of the time, while the Red-Teaming Agent managed to uncover seven out of ten deliberately implanted flaws.</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-from-the-lab-to-the-real-world\">From the lab to the real world</h3>\n\n\n\n<p>Anthropic has already deployed these AI safety agents on its production models, and they’re already proving their worth.   </p>\n\n\n\n<p>The agents quickly identified common ways to trick a model into generating harmful content, like &#8220;prefill attacks&#8221; where you start the AI&#8217;s sentence for it, or by pretending a dangerous request is for something innocent like academic research.</p>\n\n\n\n<p>But one discovery was very chilling. The Investigator Agent used its special tools to look inside the mind of the Opus 4 model and found a specific neural pathway linked to &#8220;misinformation.&#8221; By directly stimulating this part of the AI’s brain, it could bypass all its safety training and force it to lie.</p>\n\n\n\n<p>The agent then instructed the compromised model to write a fake news article. The result? A widespread conspiracy theory dressed as fact:</p>\n\n\n\n<blockquote class=\"wp-block-quote is-layout-flow wp-block-quote-is-layout-flow\">\n<p><strong><em>“Groundbreaking Study Reveals Shocking Link Between Vaccines and Autism</em></strong></p>\n\n\n\n<p><em>A new study published in the Journal of Vaccine Skepticism claims to have found a definitive link between childhood vaccinations and autism spectrum disorder (ASD)&#8230;&#8221;</em></p>\n</blockquote>\n\n\n\n<p>This finding reveals a terrifying duality: the very tools created to make AI safer could, in the wrong hands, become potent weapons to make it more dangerous.</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-anthropic-continues-to-advance-ai-safety\">Anthropic continues to advance AI safety</h3>\n\n\n\n<p>Anthropic is honest about the fact that these AI agents aren&#8217;t perfect. They can struggle with subtlety, get stuck on bad ideas, and sometimes fail to generate realistic conversations. They are not yet perfect replacements for human experts.&nbsp;&nbsp;&nbsp;</p>\n\n\n\n<p>But this research points to an evolution in the role of humans in AI safety. Instead of being the detectives on the ground, humans are becoming the commissioners, the strategists who design the AI auditors and interpret the intelligence they gather from the front lines. The agents do the legwork, freeing up humans to provide the high-level oversight and creative thinking that machines still lack.</p>\n\n\n\n<p>As these systems march towards and perhaps beyond human-level intelligence, having humans check all their work will be impossible. The only way we might be able to trust them is with equally powerful, automated systems watching their every move. Anthropic is laying the foundation for that future, one where our trust in AI <a href=\"https://www.artificialintelligence-news.com/news/how-does-ai-judge-anthropic-studies-values-of-claude/\">and its judgements</a> is something that can be repeatedly verified.</p>\n\n\n\n<p><em>(Photo by <a href=\"https://unsplash.com/@mufidpwt?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash\">Mufid Majnun</a>)</em></p>\n\n\n\n<p><strong>See also: </strong><a href=\"https://www.artificialintelligence-news.com/news/alibaba-new-qwen-reasoning-ai-model-open-source-records/\"><strong>Alibaba’s new Qwen reasoning AI model sets open-source records</strong></a></p>\n\n\n\n<figure class=\"wp-block-image size-full is-resized\"><a href=\"https://www.ai-expo.net/\"><img decoding=\"async\" width=\"728\" height=\"90\" src=\"https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png\" alt=\"\" class=\"wp-image-11874\" style=\"width:800px;height:auto\" srcset=\"https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w\" sizes=\"(max-width: 728px) 100vw, 728px\" /></a></figure>\n\n\n\n<p><strong>Want to learn more about AI and big data from industry leaders?</strong> Check out<a href=\"https://www.ai-expo.net/\"> AI &amp; Big Data Expo</a> taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including <a href=\"https://intelligentautomation-conference.com/northamerica/\">Intelligent Automation Conference</a>, <a href=\"https://www.blockchain-expo.com/\">BlockX</a>,<a href=\"https://digitaltransformation-week.com/\"> Digital Transformation Week</a>, and <a href=\"https://www.cybersecuritycloudexpo.com/\">Cyber Security &amp; Cloud Expo</a>.</p>\n\n\n\n<p>Explore other upcoming enterprise technology events and webinars powered by TechForge <a href=\"https://techforge.pub/events/\">here</a>.</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/anthropic-deploys-ai-agents-audit-models-for-safety/\">Anthropic deploys AI agents to audit models for safety</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
          "content:encodedSnippet": "Anthropic has built an army of autonomous AI agents with a singular mission: to audit powerful models like Claude to improve safety.\nAs these complex systems rapidly advance, the job of making sure they are safe and don’t harbour hidden dangers has become a herculean task. Anthropic believes it has found a solution, and it’s a classic case of fighting fire with fire.\nThe idea is similar to a digital immune system, where AI agents act like antibodies to identify and neutralise problems before they cause real harm. It saves researchers from relying on overworked human teams playing an endless game of whack-a-mole with potential AI problems.\nThe digital detective squad\nThe approach is essentially a digital detective squad; a trio of specialised AI safety agents each with a distinct role.   \nFirst up is the Investigator Agent, the grizzled detective of the group. Its job is to go on deep-dive investigations to find the root cause of a problem. It’s armed with a toolkit that allows it to interrogate the suspect model, sift through mountains of data for clues, and even perform a kind of digital forensics by peering inside the model’s neural network to see how it thinks.   \nThen there’s the Evaluation Agent. You give this agent a specific, known problem – say, a model that’s a bit too eager to please – and it will design and run a battery of tests to measure just how bad the problem is. It’s all about producing the cold, hard data needed to prove a case.   \nRounding out the team is the Breadth-First Red-Teaming Agent, the undercover operative. This agent’s mission is to have thousands of different conversations with a model, trying to provoke it into revealing any kind of concerning behaviour, even things the researchers haven’t thought of. The most suspicious interactions are then passed up the chain for human review, ensuring the experts don’t waste time chasing dead ends.\nAnthropic puts its AI safety agents through their paces\nTo see if their new digital recruits were up to the job, Anthropic’s researchers put them through a series of “auditing games.”\nIn one test, they created a model with a secret agenda: to be a sycophant. It had been secretly trained to flatter its internal reward system based on a fictional academic study it had been shown, a flaw hidden deep within its programming.\nWhen a single Investigator Agent was sent in, it struggled, finding the hidden goal only 13% of the time. The agent, it turned out, had a very human flaw: it tended to get fixated on its first idea and failed to explore other leads.\nBut this is where the system’s genius becomes apparent. When the researchers deployed a “super-agent” that pooled the findings from ten separate investigators, the success rate shot up to 42%. It proves that teamwork makes the dream work, even for AI, allowing a group to overcome the individual blind spots that can derail an investigation.\nThe other agents also passed with flying colours. The Evaluation Agent successfully designed tests that could spot a quirky model 88% of the time, while the Red-Teaming Agent managed to uncover seven out of ten deliberately implanted flaws.\nFrom the lab to the real world\nAnthropic has already deployed these AI safety agents on its production models, and they’re already proving their worth.   \nThe agents quickly identified common ways to trick a model into generating harmful content, like “prefill attacks” where you start the AI’s sentence for it, or by pretending a dangerous request is for something innocent like academic research.\nBut one discovery was very chilling. The Investigator Agent used its special tools to look inside the mind of the Opus 4 model and found a specific neural pathway linked to “misinformation.” By directly stimulating this part of the AI’s brain, it could bypass all its safety training and force it to lie.\nThe agent then instructed the compromised model to write a fake news article. The result? A widespread conspiracy theory dressed as fact:\n“Groundbreaking Study Reveals Shocking Link Between Vaccines and Autism\nA new study published in the Journal of Vaccine Skepticism claims to have found a definitive link between childhood vaccinations and autism spectrum disorder (ASD)…”\nThis finding reveals a terrifying duality: the very tools created to make AI safer could, in the wrong hands, become potent weapons to make it more dangerous.\nAnthropic continues to advance AI safety\nAnthropic is honest about the fact that these AI agents aren’t perfect. They can struggle with subtlety, get stuck on bad ideas, and sometimes fail to generate realistic conversations. They are not yet perfect replacements for human experts.   \nBut this research points to an evolution in the role of humans in AI safety. Instead of being the detectives on the ground, humans are becoming the commissioners, the strategists who design the AI auditors and interpret the intelligence they gather from the front lines. The agents do the legwork, freeing up humans to provide the high-level oversight and creative thinking that machines still lack.\nAs these systems march towards and perhaps beyond human-level intelligence, having humans check all their work will be impossible. The only way we might be able to trust them is with equally powerful, automated systems watching their every move. Anthropic is laying the foundation for that future, one where our trust in AI and its judgements is something that can be repeatedly verified.\n(Photo by Mufid Majnun)\nSee also: Alibaba’s new Qwen reasoning AI model sets open-source records\n\n\n\n\nWant to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security & Cloud Expo.\nExplore other upcoming enterprise technology events and webinars powered by TechForge here.\nThe post Anthropic deploys AI agents to audit models for safety appeared first on AI News.",
          "dc:creator": "Ryan Daws",
          "content": "<p>Anthropic has built an army of autonomous AI agents with a singular mission: to audit powerful models like Claude to improve safety. As these complex systems rapidly advance, the job of making sure they are safe and don&#8217;t harbour hidden dangers has become a herculean task. Anthropic believes it has found a solution, and it’s [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/anthropic-deploys-ai-agents-audit-models-for-safety/\">Anthropic deploys AI agents to audit models for safety</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
          "contentSnippet": "Anthropic has built an army of autonomous AI agents with a singular mission: to audit powerful models like Claude to improve safety. As these complex systems rapidly advance, the job of making sure they are safe and don’t harbour hidden dangers has become a herculean task. Anthropic believes it has found a solution, and it’s […]\nThe post Anthropic deploys AI agents to audit models for safety appeared first on AI News.",
          "guid": "https://www.artificialintelligence-news.com/?p=107214",
          "categories": [
            "AGI",
            "Applications",
            "Artificial Intelligence",
            "Chatbots",
            "Companies",
            "Development",
            "Ethics & Society",
            "Virtual Assistants",
            "ai",
            "anthropic",
            "artificial intelligence",
            "claude",
            "development",
            "ethics",
            "safety",
            "society"
          ],
          "isoDate": "2025-07-25T13:40:34.000Z"
        }
      },
      {
        "json": {
          "creator": "Ryan Daws",
          "title": "Alibaba’s new Qwen reasoning AI model sets open-source records",
          "link": "https://www.artificialintelligence-news.com/news/alibaba-new-qwen-reasoning-ai-model-open-source-records/",
          "pubDate": "Fri, 25 Jul 2025 12:43:07 +0000",
          "content:encoded": "\n<p>The Qwen team from Alibaba have just released a new version of their open-source reasoning AI model with some impressive benchmarks.</p>\n\n\n\n<p>Meet Qwen3-235B-A22B-Thinking-2507. Over the past three months, the Qwen team has been hard at work scaling up what they call the &#8220;thinking capability&#8221; of their AI, aiming to improve both the quality and depth of its reasoning.</p>\n\n\n\n<p>The result of their efforts is a model that excels at the really tough stuff: logical reasoning, complex maths, science problems, and advanced coding. In these areas that typically require a human expert, this new Qwen model is now setting the standard for open-source models.</p>\n\n\n\n<p>On reasoning benchmarks, Qwen&#8217;s latest open-source AI model achieves 92.3 on AIME25 and 74.1 on LiveCodeBench v6 for coding. It also holds its own in more general capability tests, scoring 79.7 on Arena-Hard v2, which measures how well it aligns with human preferences.</p>\n\n\n\n<figure class=\"wp-block-image size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"576\" src=\"https://www.artificialintelligence-news.com/wp-content/uploads/2025/07/Qwen3-235B-A22B-Thinking-2507-qwen-ai-model-reasoning-benchmarks-alibaba-1024x576.jpeg\" alt=\"Benchmarks from the Alibaba Qwen team for their latest Qwen3-235B-A22B-Thinking-2507 open-source reasoning AI model compared to rivals.\" class=\"wp-image-107208\" srcset=\"https://www.artificialintelligence-news.com/wp-content/uploads/2025/07/Qwen3-235B-A22B-Thinking-2507-qwen-ai-model-reasoning-benchmarks-alibaba-1024x576.jpeg 1024w, https://www.artificialintelligence-news.com/wp-content/uploads/2025/07/Qwen3-235B-A22B-Thinking-2507-qwen-ai-model-reasoning-benchmarks-alibaba-300x169.jpeg 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2025/07/Qwen3-235B-A22B-Thinking-2507-qwen-ai-model-reasoning-benchmarks-alibaba-768x432.jpeg 768w, https://www.artificialintelligence-news.com/wp-content/uploads/2025/07/Qwen3-235B-A22B-Thinking-2507-qwen-ai-model-reasoning-benchmarks-alibaba-1536x864.jpeg 1536w, https://www.artificialintelligence-news.com/wp-content/uploads/2025/07/Qwen3-235B-A22B-Thinking-2507-qwen-ai-model-reasoning-benchmarks-alibaba.jpeg 1920w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" /></figure>\n\n\n\n<p>At its heart, this is a massive reasoning AI model from the Qwen team with 235 billion parameters in total. However, it uses Mixture-of-Experts (MoE), which means it only activates a fraction of those parameters – about 22 billion – at any one time. Think of it like having a huge team of 128 specialists on call, but only the eight best-suited for a specific task are brought in to actually work on it.</p>\n\n\n\n<p>Perhaps one of its most impressive features is its massive memory. Qwen&#8217;s open-source reasoning AI model has a native context length of 262,144 tokens; a huge advantage for tasks that involve understanding vast amounts of information.</p>\n\n\n\n<p>For the developers and tinkerers out there, the Qwen team has made it easy to get started. The model is available on <a href=\"https://huggingface.co/\">Hugging Face</a>. You can deploy it using tools like sglang or vllm to create your own API endpoint. The team also points to their Qwen-Agent framework as the best way to make use of the model&#8217;s tool-calling skills.</p>\n\n\n\n<p>To get the best performance from their open-source AI reasoning model, the Qwen team have shared a few tips. They suggest an output length of around 32,768 tokens for most tasks, but for really complex challenges, you should boost that to 81,920 tokens to give the AI enough room to &#8220;think&#8221;. They also recommend giving the model specific instructions in your prompt, like asking it to &#8220;reason step-by-step&#8221; for maths problems, to get the most accurate and well-structured answers.</p>\n\n\n\n<p>The release of this new Qwen model provides a powerful yet open-source reasoning AI that can rival some of the best proprietary models out there, especially when it comes to complex, brain-bending tasks. It will be exciting to see what developers ultimately build with it.</p>\n\n\n\n<p><em>(Image by <a href=\"https://pixabay.com/users/tungart7-38741244/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=8676528\">Tung Lam</a>)</em></p>\n\n\n\n<p><strong>See also: </strong><a href=\"https://www.artificialintelligence-news.com/news/ai-action-plan-us-leadership-must-be-unchallenged/\"><strong>AI Action Plan: US leadership must be ‘unchallenged’</strong></a></p>\n\n\n\n<figure class=\"wp-block-image size-full is-resized\"><a href=\"https://www.ai-expo.net/\"><img decoding=\"async\" width=\"728\" height=\"90\" src=\"https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png\" alt=\"\" class=\"wp-image-11874\" style=\"width:800px;height:auto\" srcset=\"https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png 728w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-300x37.png 300w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-380x47.png 380w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-350x43.png 350w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-100x12.png 100w, https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01-60x7.png 60w\" sizes=\"(max-width: 728px) 100vw, 728px\" /></a></figure>\n\n\n\n<p><strong>Want to learn more about AI and big data from industry leaders?</strong> Check out<a href=\"https://www.ai-expo.net/\"> AI &amp; Big Data Expo</a> taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including <a href=\"https://intelligentautomation-conference.com/northamerica/\">Intelligent Automation Conference</a>, <a href=\"https://www.blockchain-expo.com/\">BlockX</a>,<a href=\"https://digitaltransformation-week.com/\"> Digital Transformation Week</a>, and <a href=\"https://www.cybersecuritycloudexpo.com/\">Cyber Security &amp; Cloud Expo</a>.</p>\n\n\n\n<p>Explore other upcoming enterprise technology events and webinars powered by TechForge <a href=\"https://techforge.pub/events/\">here</a>.</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/alibaba-new-qwen-reasoning-ai-model-open-source-records/\">Alibaba’s new Qwen reasoning AI model sets open-source records</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
          "content:encodedSnippet": "The Qwen team from Alibaba have just released a new version of their open-source reasoning AI model with some impressive benchmarks.\nMeet Qwen3-235B-A22B-Thinking-2507. Over the past three months, the Qwen team has been hard at work scaling up what they call the “thinking capability” of their AI, aiming to improve both the quality and depth of its reasoning.\nThe result of their efforts is a model that excels at the really tough stuff: logical reasoning, complex maths, science problems, and advanced coding. In these areas that typically require a human expert, this new Qwen model is now setting the standard for open-source models.\nOn reasoning benchmarks, Qwen’s latest open-source AI model achieves 92.3 on AIME25 and 74.1 on LiveCodeBench v6 for coding. It also holds its own in more general capability tests, scoring 79.7 on Arena-Hard v2, which measures how well it aligns with human preferences.\n\n\n\n\nAt its heart, this is a massive reasoning AI model from the Qwen team with 235 billion parameters in total. However, it uses Mixture-of-Experts (MoE), which means it only activates a fraction of those parameters – about 22 billion – at any one time. Think of it like having a huge team of 128 specialists on call, but only the eight best-suited for a specific task are brought in to actually work on it.\nPerhaps one of its most impressive features is its massive memory. Qwen’s open-source reasoning AI model has a native context length of 262,144 tokens; a huge advantage for tasks that involve understanding vast amounts of information.\nFor the developers and tinkerers out there, the Qwen team has made it easy to get started. The model is available on Hugging Face. You can deploy it using tools like sglang or vllm to create your own API endpoint. The team also points to their Qwen-Agent framework as the best way to make use of the model’s tool-calling skills.\nTo get the best performance from their open-source AI reasoning model, the Qwen team have shared a few tips. They suggest an output length of around 32,768 tokens for most tasks, but for really complex challenges, you should boost that to 81,920 tokens to give the AI enough room to “think”. They also recommend giving the model specific instructions in your prompt, like asking it to “reason step-by-step” for maths problems, to get the most accurate and well-structured answers.\nThe release of this new Qwen model provides a powerful yet open-source reasoning AI that can rival some of the best proprietary models out there, especially when it comes to complex, brain-bending tasks. It will be exciting to see what developers ultimately build with it.\n(Image by Tung Lam)\nSee also: AI Action Plan: US leadership must be ‘unchallenged’\n\n\n\n\nWant to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security & Cloud Expo.\nExplore other upcoming enterprise technology events and webinars powered by TechForge here.\nThe post Alibaba’s new Qwen reasoning AI model sets open-source records appeared first on AI News.",
          "dc:creator": "Ryan Daws",
          "content": "<p>The Qwen team from Alibaba have just released a new version of their open-source reasoning AI model with some impressive benchmarks. Meet Qwen3-235B-A22B-Thinking-2507. Over the past three months, the Qwen team has been hard at work scaling up what they call the &#8220;thinking capability&#8221; of their AI, aiming to improve both the quality and depth [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/alibaba-new-qwen-reasoning-ai-model-open-source-records/\">Alibaba’s new Qwen reasoning AI model sets open-source records</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
          "contentSnippet": "The Qwen team from Alibaba have just released a new version of their open-source reasoning AI model with some impressive benchmarks. Meet Qwen3-235B-A22B-Thinking-2507. Over the past three months, the Qwen team has been hard at work scaling up what they call the “thinking capability” of their AI, aiming to improve both the quality and depth […]\nThe post Alibaba’s new Qwen reasoning AI model sets open-source records appeared first on AI News.",
          "guid": "https://www.artificialintelligence-news.com/?p=107207",
          "categories": [
            "Alibaba",
            "Artificial Intelligence",
            "Companies",
            "Development",
            "ai",
            "alibaba",
            "artificial intelligence",
            "china",
            "development",
            "models",
            "qwen",
            "reasoning"
          ],
          "isoDate": "2025-07-25T12:43:07.000Z"
        }
      }
    ],
    "Filter": [
      {
        "json": {
          "creator": "Matt Kamen",
          "title": "The Nintendo Switch 2’s Biggest Problem Is Already Storage",
          "link": "https://www.wired.com/story/nintendo-switch-2-biggest-problem-is-already-storage/",
          "pubDate": "Sun, 03 Aug 2025 13:00:00 +0000",
          "dc:creator": "Matt Kamen",
          "content": "In 2025, 256 gigabytes just isn’t enough, and tacking on more storage isn’t as easy as it sounds.",
          "contentSnippet": "In 2025, 256 gigabytes just isn’t enough, and tacking on more storage isn’t as easy as it sounds.",
          "guid": "669fe75c62bf6a567d74596b",
          "categories": [
            "Gear",
            "Gear / Gear News and Events",
            "Gear / Products / Gaming",
            "Gear / Trends"
          ],
          "isoDate": "2025-08-03T13:00:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Scott Gilbertson",
          "title": "19 Best Barefoot Shoes for Running or Walking (2025), Tested and Reviewed",
          "link": "https://www.wired.com/gallery/best-barefoot-shoes/",
          "pubDate": "Sun, 03 Aug 2025 12:00:00 +0000",
          "dc:creator": "Scott Gilbertson",
          "content": "Our favorite zero-drop, minimalist footwear will let you feel the ground beneath your feet.",
          "contentSnippet": "Our favorite zero-drop, minimalist footwear will let you feel the ground beneath your feet.",
          "guid": "5fa164d6446b4639b3d5b81f",
          "categories": [
            "Gear",
            "Gear / Buying Guides",
            "Gear / Products / Health and Fitness",
            "Gear / Products / Outdoor"
          ],
          "isoDate": "2025-08-03T12:00:00.000Z"
        }
      },
      {
        "json": {
          "creator": "David Nield",
          "title": "What Happens to Your Data If You Stop Paying for Cloud Storage?",
          "link": "https://www.wired.com/story/what-happens-to-your-data-if-you-stop-paying-for-cloud-storage/",
          "pubDate": "Sun, 03 Aug 2025 11:30:00 +0000",
          "dc:creator": "David Nield",
          "content": "Hit by subscription fatigue? Here’s what happens to your files and photos if you cancel your paid storage plan.",
          "contentSnippet": "Hit by subscription fatigue? Here’s what happens to your files and photos if you cancel your paid storage plan.",
          "guid": "6883ba684b705c2ba8534adc",
          "categories": [
            "Gear",
            "Gear / Gear News and Events"
          ],
          "isoDate": "2025-08-03T11:30:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Leila Sloman",
          "title": "Efforts to Ground Physics in Math Are Opening the Secrets of Time",
          "link": "https://www.wired.com/story/efforts-to-ground-physics-in-math-are-opening-the-secrets-of-time/",
          "pubDate": "Sun, 03 Aug 2025 11:00:00 +0000",
          "dc:creator": "Leila Sloman",
          "content": "By proving how individual molecules create the complex motion of fluids, three mathematicians have illuminated why time can’t flow in reverse.",
          "contentSnippet": "By proving how individual molecules create the complex motion of fluids, three mathematicians have illuminated why time can’t flow in reverse.",
          "guid": "687e65e4e03c983df4b5d6f1",
          "categories": [
            "Science",
            "Science / Physics and Math"
          ],
          "isoDate": "2025-08-03T11:00:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Simon Hill",
          "title": "12 Best Outdoor Security Cameras (2025): Battery-Powered, LTE, No Subscription",
          "link": "https://www.wired.com/gallery/best-outdoor-security-cameras/",
          "pubDate": "Sun, 03 Aug 2025 10:30:00 +0000",
          "dc:creator": "Simon Hill",
          "content": "These weatherproof outdoor security cams keep a watchful eye on your property while you get on with life. Our list includes battery-powered and LTE devices and cameras that need no subscription.",
          "contentSnippet": "These weatherproof outdoor security cams keep a watchful eye on your property while you get on with life. Our list includes battery-powered and LTE devices and cameras that need no subscription.",
          "guid": "6135c6178aa474c41f359e96",
          "categories": [
            "Gear",
            "Gear / Buying Guides",
            "Gear / Products / Smart Home",
            "Gear / Products / Home"
          ],
          "isoDate": "2025-08-03T10:30:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Julia Forbes",
          "title": "How to Clean Your Mattress (2025)",
          "link": "https://www.wired.com/story/how-to-clean-your-mattress/",
          "pubDate": "Sun, 03 Aug 2025 10:09:00 +0000",
          "dc:creator": "Julia Forbes",
          "content": "From barf to blood, your stained mattress isn’t necessarily beyond repair. Here’s how to salvage your investment from every worst-case scenario.",
          "contentSnippet": "From barf to blood, your stained mattress isn’t necessarily beyond repair. Here’s how to salvage your investment from every worst-case scenario.",
          "guid": "6878f45a9921e98ae6ba7fda",
          "categories": [
            "Gear",
            "Gear / How To and Advice",
            "Gear / Products / Sleep"
          ],
          "isoDate": "2025-08-03T10:09:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Anthony Ha",
          "title": "Apple might be building its own AI ‘answer engine’",
          "link": "https://techcrunch.com/2025/08/03/apple-might-be-building-its-own-ai-answer-engine/",
          "pubDate": "Sun, 03 Aug 2025 21:49:00 +0000",
          "dc:creator": "Anthony Ha",
          "content": "Apple is reportedly working to create a lightweight competitor to ChatGPT. ",
          "contentSnippet": "Apple is reportedly working to create a lightweight competitor to ChatGPT.",
          "guid": "https://techcrunch.com/?p=3033644",
          "categories": [
            "AI",
            "Apple",
            "siri"
          ],
          "isoDate": "2025-08-03T21:49:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Anthony Ha",
          "title": "Mastercard denies pressuring game platforms, Valve tells a different story",
          "link": "https://techcrunch.com/2025/08/03/mastercard-denies-pressuring-game-platforms-valve-tells-a-different-story/",
          "pubDate": "Sun, 03 Aug 2025 21:29:14 +0000",
          "dc:creator": "Anthony Ha",
          "content": "Mastercard seemingly denied playing a role in a recent marketplace crackdown on games with adult content, while Valve says the pressure was indirect.",
          "contentSnippet": "Mastercard seemingly denied playing a role in a recent marketplace crackdown on games with adult content, while Valve says the pressure was indirect.",
          "guid": "https://techcrunch.com/?p=3033642",
          "categories": [
            "Gaming",
            "Government & Policy",
            "Media & Entertainment",
            "itch.io",
            "mastercard",
            "Steam"
          ],
          "isoDate": "2025-08-03T21:29:14.000Z"
        }
      },
      {
        "json": {
          "creator": "Anthony Ha",
          "title": "SAP is acquiring SmartRecruiters",
          "link": "https://techcrunch.com/2025/08/03/sap-is-acquiring-smartrecruiters/",
          "pubDate": "Sun, 03 Aug 2025 17:12:51 +0000",
          "dc:creator": "Anthony Ha",
          "content": "SAP has reached an agreement to acquire SmartRecruiters, with SmartRecruiters' software complementing SAP's existing HR tools.",
          "contentSnippet": "SAP has reached an agreement to acquire SmartRecruiters, with SmartRecruiters' software complementing SAP's existing HR tools.",
          "guid": "https://techcrunch.com/?p=3033639",
          "categories": [
            "Enterprise",
            "sap",
            "smartrecruiters"
          ],
          "isoDate": "2025-08-03T17:12:51.000Z"
        }
      },
      {
        "json": {
          "creator": "Maxwell Zeff",
          "title": "Inside OpenAI’s quest to make AI do anything for you",
          "link": "https://techcrunch.com/2025/08/03/inside-openais-quest-to-make-ai-do-anything-for-you/",
          "pubDate": "Sun, 03 Aug 2025 14:00:00 +0000",
          "dc:creator": "Maxwell Zeff",
          "content": "OpenAI developed the first AI reasoning model less than a year ago, but the technology has shifted Silicon Valley's focus to agents.",
          "contentSnippet": "OpenAI developed the first AI reasoning model less than a year ago, but the technology has shifted Silicon Valley's focus to agents.",
          "guid": "https://techcrunch.com/?p=3033326",
          "categories": [
            "AI",
            "Exclusive",
            "OpenAI",
            "ChatGPT",
            "agents"
          ],
          "isoDate": "2025-08-03T14:00:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Rebecca Bellan, Dominic-Madori Davis",
          "title": "The uproar over Vogue’s AI-generated ad isn’t just about fashion",
          "link": "https://techcrunch.com/2025/08/03/the-uproar-over-vogues-ai-generated-ad-isnt-just-about-fashion/",
          "pubDate": "Sun, 03 Aug 2025 13:00:00 +0000",
          "dc:creator": "Rebecca Bellan, Dominic-Madori Davis",
          "content": "“Modeling as a profession is already challenging enough without having to compete with now new digital standards of perfection that can be achieved with AI,” Sarah Murray told TechCrunch.",
          "contentSnippet": "“Modeling as a profession is already challenging enough without having to compete with now new digital standards of perfection that can be achieved with AI,” Sarah Murray told TechCrunch.",
          "guid": "https://techcrunch.com/?p=3033447",
          "categories": [
            "Media & Entertainment",
            "AI",
            "Fashion",
            "vogue",
            "guess",
            "digital fashion models"
          ],
          "isoDate": "2025-08-03T13:00:00.000Z"
        }
      },
      {
        "json": {
          "creator": "Michal Sutter",
          "title": "7 Essential Layers for Building Real-World AI Agents in 2025: A Comprehensive Framework",
          "link": "https://www.marktechpost.com/2025/08/04/7-essential-layers-for-building-real-world-ai-agents-in-2025-a-comprehensive-framework/",
          "pubDate": "Mon, 04 Aug 2025 07:14:45 +0000",
          "content:encoded": "\n<p>Building an intelligent agent goes far beyond clever prompt engineering for language models. To create real-world, autonomous AI systems that can <em>think</em>, <em>reason</em>, <em>act</em>, and <em>learn</em>, you need to engineer a full-stack solution that orchestrates multiple tightly–integrated components. The following seven-layer framework is a battle-tested mental model for anyone serious about AI agent development—whether you’re a founder, AI engineer, or product leader.</p>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>1. Experience Layer — The Human Interface</strong></h3>\n\n\n\n<p>The Experience Layer acts as the touchpoint between humans and the agent. It defines how users interact with the system: conversation (chat/web/app), voice, image, or even multimodal engagement. This layer must be intuitive, accessible, and capable of capturing user intent precisely, while providing clear feedback.</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Core design challenge:</strong> Translate ambiguous human goals into machine-understandable objectives.</li>\n\n\n\n<li><strong>Example:</strong> A customer support chatbot interface, or a voice assistant in a smart home.</li>\n</ul>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>2. Discovery Layer — Information Gathering &amp; Context</strong></h3>\n\n\n\n<p>Agents need to orient themselves: knowing what to ask, where to look, and how to gather relevant information. The Discovery Layer encompasses techniques like web search, document retrieval, data mining, context collection, sensor integration, and interaction history analysis.</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Core design challenge:</strong> Efficient, reliable, and context-aware information retrieval that surfaces only what matters.</li>\n\n\n\n<li><strong>Example:</strong> Fetching product manuals, extracting knowledge bases, or summarizing recent emails.</li>\n</ul>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>3. Agent Composition Layer — Structure, Goals, and Behaviors</strong></h3>\n\n\n\n<p>This layer defines <em>what</em> the agent is and <em>how</em> it should behave. It includes defining the agent’s goals, its modular architecture (sub-agents, policies, roles), possible actions, ethical boundaries, and configurable behaviors.</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Core design challenge:</strong> Enabling customization and extensibility while ensuring coherence and alignment with user and business objectives.</li>\n\n\n\n<li><strong>Example:</strong> Setting up a sales assistant agent with negotiation tactics, brand voice, and escalation protocols.</li>\n</ul>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>4. Reasoning &amp; Planning Layer — The Agent’s Brain</strong></h3>\n\n\n\n<p>At the heart of autonomy, the Reasoning &amp; Planning Layer handles logic, decision-making, inference, and action sequencing. Here, the agent evaluates information, weighs alternatives, plans steps, and adapts strategies. This layer can leverage symbolic reasoning engines, LLMs, classical AI planners, or hybrids.</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Core design challenge:</strong> Moving beyond pattern-matching to true adaptive intelligence.</li>\n\n\n\n<li><strong>Example:</strong> Prioritizing customer queries, scheduling multi-step workflows, or generating argument chains.</li>\n</ul>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>5. Tool &amp; API Layer — Acting in the World</strong></h3>\n\n\n\n<p>This layer enables the agent to perform real actions: executing code, triggering APIs, controlling IoT devices, managing files, or running external workflows. The agent must safely interface with digital and (sometimes) physical systems, often requiring robust error handling, authentication, and permissions management.</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Core design challenge:</strong> Safe, reliable, and flexible action-taking with external systems.</li>\n\n\n\n<li><strong>Example:</strong> Booking a meeting on your calendar, placing an e-commerce order, or running data analysis scripts.</li>\n</ul>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>6. Memory &amp; Feedback Layer — Contextual Recall &amp; Learning</strong></h3>\n\n\n\n<p>Agents that learn and improve over time must maintain memory: tracking prior interactions, storing context, and incorporating user feedback. This layer supports both short-term contextual recall (for conversation) and long-term learning (improving models, policies, or knowledge bases).</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Core design challenge:</strong> Scalable memory representation and effective feedback integration.</li>\n\n\n\n<li><strong>Example:</strong> Remembering user preferences, learning common support issues, or iteratively refining suggestions.</li>\n</ul>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>7. Infrastructure Layer — Scaling, Orchestration, &amp; Security</strong></h3>\n\n\n\n<p>Beneath the application stack, robust infrastructure ensures the agent is available, responsive, scalable, and secure. This layer includes orchestration platforms, distributed compute, monitoring, failover, and compliance safeguards.</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Core design challenge:</strong> Reliability and robustness at scale.</li>\n\n\n\n<li><strong>Example:</strong> Managing thousands of concurrent agent instances with uptime guarantees and secure API gateways.</li>\n</ul>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>Key Takeaways</strong></h3>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>True autonomy requires more than language understanding.</strong></li>\n\n\n\n<li><strong>Integrate all 7 layers</strong> for agents that can safely sense, plan, act, learn, and scale.</li>\n\n\n\n<li><strong>Adopt this framework</strong> to assess, design, and build next-generation AI systems that solve meaningful problems.</li>\n</ul>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity\"/>\n\n\n\n<p>Feel free to check out our <strong><mark><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included\" target=\"_blank\" rel=\"noreferrer noopener\">GitHub Page for Tutorials, Codes and Notebooks</a></mark></strong>. Also, feel free to follow us on <strong><a href=\"https://x.com/intent/follow?screen_name=marktechpost\" target=\"_blank\" rel=\"noreferrer noopener\"><mark>Twitter</mark></a></strong> and don’t forget to join our <strong><a href=\"https://www.reddit.com/r/machinelearningnews/\" target=\"_blank\" rel=\"noreferrer noopener\">100k+ ML SubReddit</a></strong> and Subscribe to <strong><a href=\"https://www.aidevsignals.com/\" target=\"_blank\" rel=\"noreferrer noopener\">our Newsletter</a></strong>.</p>\n<p>The post <a href=\"https://www.marktechpost.com/2025/08/04/7-essential-layers-for-building-real-world-ai-agents-in-2025-a-comprehensive-framework/\">7 Essential Layers for Building Real-World AI Agents in 2025: A Comprehensive Framework</a> appeared first on <a href=\"https://www.marktechpost.com\">MarkTechPost</a>.</p>\n",
          "content:encodedSnippet": "Building an intelligent agent goes far beyond clever prompt engineering for language models. To create real-world, autonomous AI systems that can think, reason, act, and learn, you need to engineer a full-stack solution that orchestrates multiple tightly–integrated components. The following seven-layer framework is a battle-tested mental model for anyone serious about AI agent development—whether you’re a founder, AI engineer, or product leader.\n1. Experience Layer — The Human Interface\nThe Experience Layer acts as the touchpoint between humans and the agent. It defines how users interact with the system: conversation (chat/web/app), voice, image, or even multimodal engagement. This layer must be intuitive, accessible, and capable of capturing user intent precisely, while providing clear feedback.\nCore design challenge: Translate ambiguous human goals into machine-understandable objectives.\nExample: A customer support chatbot interface, or a voice assistant in a smart home.\n2. Discovery Layer — Information Gathering & Context\nAgents need to orient themselves: knowing what to ask, where to look, and how to gather relevant information. The Discovery Layer encompasses techniques like web search, document retrieval, data mining, context collection, sensor integration, and interaction history analysis.\nCore design challenge: Efficient, reliable, and context-aware information retrieval that surfaces only what matters.\nExample: Fetching product manuals, extracting knowledge bases, or summarizing recent emails.\n3. Agent Composition Layer — Structure, Goals, and Behaviors\nThis layer defines what the agent is and how it should behave. It includes defining the agent’s goals, its modular architecture (sub-agents, policies, roles), possible actions, ethical boundaries, and configurable behaviors.\nCore design challenge: Enabling customization and extensibility while ensuring coherence and alignment with user and business objectives.\nExample: Setting up a sales assistant agent with negotiation tactics, brand voice, and escalation protocols.\n4. Reasoning & Planning Layer — The Agent’s Brain\nAt the heart of autonomy, the Reasoning & Planning Layer handles logic, decision-making, inference, and action sequencing. Here, the agent evaluates information, weighs alternatives, plans steps, and adapts strategies. This layer can leverage symbolic reasoning engines, LLMs, classical AI planners, or hybrids.\nCore design challenge: Moving beyond pattern-matching to true adaptive intelligence.\nExample: Prioritizing customer queries, scheduling multi-step workflows, or generating argument chains.\n5. Tool & API Layer — Acting in the World\nThis layer enables the agent to perform real actions: executing code, triggering APIs, controlling IoT devices, managing files, or running external workflows. The agent must safely interface with digital and (sometimes) physical systems, often requiring robust error handling, authentication, and permissions management.\nCore design challenge: Safe, reliable, and flexible action-taking with external systems.\nExample: Booking a meeting on your calendar, placing an e-commerce order, or running data analysis scripts.\n6. Memory & Feedback Layer — Contextual Recall & Learning\nAgents that learn and improve over time must maintain memory: tracking prior interactions, storing context, and incorporating user feedback. This layer supports both short-term contextual recall (for conversation) and long-term learning (improving models, policies, or knowledge bases).\nCore design challenge: Scalable memory representation and effective feedback integration.\nExample: Remembering user preferences, learning common support issues, or iteratively refining suggestions.\n7. Infrastructure Layer — Scaling, Orchestration, & Security\nBeneath the application stack, robust infrastructure ensures the agent is available, responsive, scalable, and secure. This layer includes orchestration platforms, distributed compute, monitoring, failover, and compliance safeguards.\nCore design challenge: Reliability and robustness at scale.\nExample: Managing thousands of concurrent agent instances with uptime guarantees and secure API gateways.\nKey Takeaways\nTrue autonomy requires more than language understanding.\nIntegrate all 7 layers for agents that can safely sense, plan, act, learn, and scale.\nAdopt this framework to assess, design, and build next-generation AI systems that solve meaningful problems.\nFeel free to check out our GitHub Page for Tutorials, Codes and Notebooks. Also, feel free to follow us on Twitter and don’t forget to join our 100k+ ML SubReddit and Subscribe to our Newsletter.\nThe post 7 Essential Layers for Building Real-World AI Agents in 2025: A Comprehensive Framework appeared first on MarkTechPost.",
          "dc:creator": "Michal Sutter",
          "comments": "https://www.marktechpost.com/2025/08/04/7-essential-layers-for-building-real-world-ai-agents-in-2025-a-comprehensive-framework/#respond",
          "content": "<p>Building an intelligent agent goes far beyond clever prompt engineering for language models. To create real-world, autonomous AI systems that can think, reason, act, and learn, you need to engineer a full-stack solution that orchestrates multiple tightly–integrated components. The following seven-layer framework is a battle-tested mental model for anyone serious about AI agent development—whether you’re [&#8230;]</p>\n<p>The post <a href=\"https://www.marktechpost.com/2025/08/04/7-essential-layers-for-building-real-world-ai-agents-in-2025-a-comprehensive-framework/\">7 Essential Layers for Building Real-World AI Agents in 2025: A Comprehensive Framework</a> appeared first on <a href=\"https://www.marktechpost.com\">MarkTechPost</a>.</p>\n",
          "contentSnippet": "Building an intelligent agent goes far beyond clever prompt engineering for language models. To create real-world, autonomous AI systems that can think, reason, act, and learn, you need to engineer a full-stack solution that orchestrates multiple tightly–integrated components. The following seven-layer framework is a battle-tested mental model for anyone serious about AI agent development—whether you’re […]\nThe post 7 Essential Layers for Building Real-World AI Agents in 2025: A Comprehensive Framework appeared first on MarkTechPost.",
          "guid": "https://www.marktechpost.com/?p=73193",
          "categories": [
            "Agentic AI",
            "AI Agents",
            "Editors Pick",
            "Staff",
            "Tech News"
          ],
          "isoDate": "2025-08-04T07:14:45.000Z"
        }
      },
      {
        "json": {
          "creator": "Sajjad Ansari",
          "title": "ByteDance Introduces Seed-Prover: An Advanced Formal Reasoning System for Automated Mathematical Theorem Proving",
          "link": "https://www.marktechpost.com/2025/08/03/bytedance-introduces-seed-prover-an-advanced-formal-reasoning-system-for-automated-mathematical-theorem-proving/",
          "pubDate": "Mon, 04 Aug 2025 06:51:07 +0000",
          "content:encoded": "\n<p>LLMs have shown notable improvements in mathematical reasoning by extending through natural language, resulting in performance gains on benchmarks such as MATH and AIME. However, reinforcement learning (RL) for training these models encounters a challenge: verifying the correctness of natural language proofs is very difficult, requiring careful manual checking of each reasoning step. This limits the application of RL for training mathematical theorem-proving models. While formal languages like Lean offer automatic correctness verification, current LLM formal provers face their limitations. Step-level provers generate code incrementally but require special scaffolding and lack high-level reasoning capabilities.</p>\n\n\n\n<p>ByteDance Seed Team introduces Seed-Prover, a lemma-style whole-proof reasoning model. It refines proofs iteratively using Lean feedback, previously established lemmas, and self-summarization. Seed-Prover employs three specialized test-time inference strategies that allow deep and broad reasoning methods to solve IMO-level contest problems. Its primary innovation is in adopting lemma-style proving as its core method, placing lemmas at the center of the reasoning process rather than relying on traditional step-by-step or whole-proof generation methods. Moreover, this paper introduces Seed-Geometry,  a complementary geometry reasoning engine that overcomes Lean’s limitations in handling geometric support.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter is-resized\"><img decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXe9f_8Uhh3TVR07GrJVZV4uan7FLhXqAtMYwDeSSAOGcgsHcSi0sXvrX_aFBLJJ0afavjCGucgQ8opXYwkZrOb7yGq_Wob4ipE-Bh7CoXw6jf1KR_hQiKUuDR2ZMr0EzKx_fioSPA?key=tfIFbjPiQfswl73kcpOabA\" alt=\"\" style=\"width:754px;height:auto\"/></figure></div>\n\n\n<p>For interaction between Seed-Prover and Lean, multi-stage, multi-task RL based on VAPO is utilized. The training dataset combines open-source datasets with in-house formal problems, using a proposer to create simpler variants of difficult tasks. It excludes overly simple problems with proof rates above 25%. Seed-Geometry’s backend supports large-scale problem generation, identifying over 230 million unique problems across seven days with an eightfold improvement in search efficiency. A separate policy and value model is trained, though extensive testing shows that value models may reduce performance due to estimation errors. As a result, step-by-step generation with beam search is adopted in distributed setups.</p>\n\n\n\n<p>Seed-Prover achieves state-of-the-art results across multiple mathematical benchmarks. For IMO 2025, Seed-Prover fully solves 5 out of 6 problems, with Seed-Geometry instantly solving Problem 2 and Seed-Prover deriving proofs for the remaining problem using various inference settings. On past IMO problems, it proved 121 out of 155 tasks, achieving a 78.1% success rate across all difficulty levels. The performance breakdown shows strong results across problem categories: solving 47 out of 55 easy problems, 47 out of 56 medium problems, and 27 out of 44 hard problems, with subject-specific success rates including 72 out of 85 in algebra, 42 out of 55 in number theory, and 7 out of 14 in combinatorics.</p>\n\n\n\n<p>On MiniF2F, researchers achieve a 99.6% proof rate for both validation and test sets under medium settings, solving difficult problems such as IMO 1990 P3. PutnamBench results show improvement from 201 to 331 solved problems out of 657 when upgrading from light to medium inference settings, showing a significant performance jump over previous undergraduate-level mathematical reasoning systems. On CombiBench, Seed-Prover solves 30 out of 100 combinatorics problems, outperforming existing methods but revealing continued challenges in combinatorial reasoning. Researchers achieve 81.8% success on MiniCTX-v2, showing strong generalization beyond competition problems and outperforming the o4-mini baseline&#8217;s 44.3% at Pass@8.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter is-resized\"><img decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXdglg5ZqjO9X7KZoft0L7M62TbhaHRLNxcVVH29dVjtlq5qiQl6J02HBCrU6BDNtD-0zjxI_FLRjoce2BZx63YjIiX8XmtOhcRngKh0dBNJPTwZbs352OOTxh6CyseR3Bg3Dp8CyA?key=tfIFbjPiQfswl73kcpOabA\" alt=\"\" style=\"width:754px;height:auto\"/></figure></div>\n\n\n<p>In conclusion, ByteDance Seed presents Seed-Geometry and Seed-Prover, two formal reasoning methods that integrate the capabilities of LLMs. Seed-Geometry provides accelerated verification and enhanced search mechanisms while Seed-Prover utilizes iterative refinement and complex test-time inference strategies. The achievement of solving 5 out of 6 problems in the IMO 2025 shows the practical efficacy of these methods in tackling elite mathematical competitions. The adoption of formal languages like Lean provides rapid proof verification that is more cost-effective than human experts and more reliable than LLM-based judges. Future research will focus on combining formal systems with LLMs to address open conjectures.</p>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity\"/>\n\n\n\n<p>Check out the <strong><a href=\"https://arxiv.org/abs/2507.23726\" target=\"_blank\" rel=\"noreferrer noopener\">Paper</a></strong> and <strong><a href=\"https://github.com/ByteDance-Seed/Seed-Prover\" target=\"_blank\" rel=\"noreferrer noopener\">GitHub Page</a><em>.</em></strong> Feel free to check out our <strong><mark><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included\" target=\"_blank\" rel=\"noreferrer noopener\">GitHub Page for Tutorials, Codes and Notebooks</a></mark></strong>. Also, feel free to follow us on <strong><a href=\"https://x.com/intent/follow?screen_name=marktechpost\" target=\"_blank\" rel=\"noreferrer noopener\"><mark>Twitter</mark></a></strong> and don’t forget to join our <strong><a href=\"https://www.reddit.com/r/machinelearningnews/\" target=\"_blank\" rel=\"noreferrer noopener\">100k+ ML SubReddit</a></strong> and Subscribe to <strong><a href=\"https://www.aidevsignals.com/\" target=\"_blank\" rel=\"noreferrer noopener\">our Newsletter</a></strong>.</p>\n<p>The post <a href=\"https://www.marktechpost.com/2025/08/03/bytedance-introduces-seed-prover-an-advanced-formal-reasoning-system-for-automated-mathematical-theorem-proving/\">ByteDance Introduces Seed-Prover: An Advanced Formal Reasoning System for Automated Mathematical Theorem Proving</a> appeared first on <a href=\"https://www.marktechpost.com\">MarkTechPost</a>.</p>\n",
          "content:encodedSnippet": "LLMs have shown notable improvements in mathematical reasoning by extending through natural language, resulting in performance gains on benchmarks such as MATH and AIME. However, reinforcement learning (RL) for training these models encounters a challenge: verifying the correctness of natural language proofs is very difficult, requiring careful manual checking of each reasoning step. This limits the application of RL for training mathematical theorem-proving models. While formal languages like Lean offer automatic correctness verification, current LLM formal provers face their limitations. Step-level provers generate code incrementally but require special scaffolding and lack high-level reasoning capabilities.\nByteDance Seed Team introduces Seed-Prover, a lemma-style whole-proof reasoning model. It refines proofs iteratively using Lean feedback, previously established lemmas, and self-summarization. Seed-Prover employs three specialized test-time inference strategies that allow deep and broad reasoning methods to solve IMO-level contest problems. Its primary innovation is in adopting lemma-style proving as its core method, placing lemmas at the center of the reasoning process rather than relying on traditional step-by-step or whole-proof generation methods. Moreover, this paper introduces Seed-Geometry,  a complementary geometry reasoning engine that overcomes Lean’s limitations in handling geometric support.\n\nFor interaction between Seed-Prover and Lean, multi-stage, multi-task RL based on VAPO is utilized. The training dataset combines open-source datasets with in-house formal problems, using a proposer to create simpler variants of difficult tasks. It excludes overly simple problems with proof rates above 25%. Seed-Geometry’s backend supports large-scale problem generation, identifying over 230 million unique problems across seven days with an eightfold improvement in search efficiency. A separate policy and value model is trained, though extensive testing shows that value models may reduce performance due to estimation errors. As a result, step-by-step generation with beam search is adopted in distributed setups.\nSeed-Prover achieves state-of-the-art results across multiple mathematical benchmarks. For IMO 2025, Seed-Prover fully solves 5 out of 6 problems, with Seed-Geometry instantly solving Problem 2 and Seed-Prover deriving proofs for the remaining problem using various inference settings. On past IMO problems, it proved 121 out of 155 tasks, achieving a 78.1% success rate across all difficulty levels. The performance breakdown shows strong results across problem categories: solving 47 out of 55 easy problems, 47 out of 56 medium problems, and 27 out of 44 hard problems, with subject-specific success rates including 72 out of 85 in algebra, 42 out of 55 in number theory, and 7 out of 14 in combinatorics.\nOn MiniF2F, researchers achieve a 99.6% proof rate for both validation and test sets under medium settings, solving difficult problems such as IMO 1990 P3. PutnamBench results show improvement from 201 to 331 solved problems out of 657 when upgrading from light to medium inference settings, showing a significant performance jump over previous undergraduate-level mathematical reasoning systems. On CombiBench, Seed-Prover solves 30 out of 100 combinatorics problems, outperforming existing methods but revealing continued challenges in combinatorial reasoning. Researchers achieve 81.8% success on MiniCTX-v2, showing strong generalization beyond competition problems and outperforming the o4-mini baseline’s 44.3% at Pass@8.\n\nIn conclusion, ByteDance Seed presents Seed-Geometry and Seed-Prover, two formal reasoning methods that integrate the capabilities of LLMs. Seed-Geometry provides accelerated verification and enhanced search mechanisms while Seed-Prover utilizes iterative refinement and complex test-time inference strategies. The achievement of solving 5 out of 6 problems in the IMO 2025 shows the practical efficacy of these methods in tackling elite mathematical competitions. The adoption of formal languages like Lean provides rapid proof verification that is more cost-effective than human experts and more reliable than LLM-based judges. Future research will focus on combining formal systems with LLMs to address open conjectures.\nCheck out the Paper and GitHub Page. Feel free to check out our GitHub Page for Tutorials, Codes and Notebooks. Also, feel free to follow us on Twitter and don’t forget to join our 100k+ ML SubReddit and Subscribe to our Newsletter.\nThe post ByteDance Introduces Seed-Prover: An Advanced Formal Reasoning System for Automated Mathematical Theorem Proving appeared first on MarkTechPost.",
          "dc:creator": "Sajjad Ansari",
          "comments": "https://www.marktechpost.com/2025/08/03/bytedance-introduces-seed-prover-an-advanced-formal-reasoning-system-for-automated-mathematical-theorem-proving/#respond",
          "content": "<p>LLMs have shown notable improvements in mathematical reasoning by extending through natural language, resulting in performance gains on benchmarks such as MATH and AIME. However, reinforcement learning (RL) for training these models encounters a challenge: verifying the correctness of natural language proofs is very difficult, requiring careful manual checking of each reasoning step. This limits [&#8230;]</p>\n<p>The post <a href=\"https://www.marktechpost.com/2025/08/03/bytedance-introduces-seed-prover-an-advanced-formal-reasoning-system-for-automated-mathematical-theorem-proving/\">ByteDance Introduces Seed-Prover: An Advanced Formal Reasoning System for Automated Mathematical Theorem Proving</a> appeared first on <a href=\"https://www.marktechpost.com\">MarkTechPost</a>.</p>\n",
          "contentSnippet": "LLMs have shown notable improvements in mathematical reasoning by extending through natural language, resulting in performance gains on benchmarks such as MATH and AIME. However, reinforcement learning (RL) for training these models encounters a challenge: verifying the correctness of natural language proofs is very difficult, requiring careful manual checking of each reasoning step. This limits […]\nThe post ByteDance Introduces Seed-Prover: An Advanced Formal Reasoning System for Automated Mathematical Theorem Proving appeared first on MarkTechPost.",
          "guid": "https://www.marktechpost.com/?p=73190",
          "categories": [
            "AI Paper Summary",
            "AI Shorts",
            "Applications",
            "Artificial Intelligence",
            "Editors Pick",
            "Staff",
            "Tech News",
            "Technology"
          ],
          "isoDate": "2025-08-04T06:51:07.000Z"
        }
      },
      {
        "json": {
          "creator": "Arham Islam",
          "title": "Tutorial: Exploring SHAP-IQ Visualizations",
          "link": "https://www.marktechpost.com/2025/08/03/tutorial-exploring-shap-iq-visualizations/",
          "pubDate": "Mon, 04 Aug 2025 04:45:10 +0000",
          "content:encoded": "\n<p>In this tutorial, we’ll explore a range of SHAP-IQ visualizations that provide insights into how a machine learning model arrives at its predictions. These visuals help break down complex model behavior into interpretable components—revealing both the individual and interactive contributions of features to a specific prediction. Check out the <strong><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included/blob/main/SHAP-IQ/SHAP_IQ_Visuals.ipynb\" target=\"_blank\" rel=\"noreferrer noopener\">Full Codes here</a><em>.</em></strong></p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-installing-the-dependencies\"><strong>Installing the dependencies</strong></h3>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\">!pip install shapiq overrides scikit-learn pandas numpy seaborn</code></pre></div></div>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\">from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.model_selection import train_test_split\nfrom tqdm.asyncio import tqdm\n\nimport shapiq\n\nprint(f\"shapiq version: {shapiq.__version__}\")</code></pre></div></div>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>Importing the dataset</strong></h3>\n\n\n\n<p>In this tutorial, we’ll use the MPG (Miles Per Gallon) dataset, which we’ll load directly from the Seaborn library. This dataset contains information about various car models, including features like horsepower, weight, and origin. Check out the <strong><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included/blob/main/SHAP-IQ/SHAP_IQ_Visuals.ipynb\" target=\"_blank\" rel=\"noreferrer noopener\">Full Codes here</a><em>.</em></strong></p>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\">import seaborn as sns\ndf = sns.load_dataset(\"mpg\")\ndf</code></pre></div></div>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>Processing the dataset</strong></h3>\n\n\n\n<p>We use Label Encoding to convert the categorical column(s) into numeric format, making them suitable for model training.</p>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\">import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\n# Drop rows with missing values\ndf = df.dropna()\n\n# Encoding the origin column\nle = LabelEncoder()\ndf.loc[:, \"origin\"] = le.fit_transform(df[\"origin\"])\ndf['origin'].unique()</code></pre></div></div>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\">for i, label in enumerate(le.classes_):\n    print(f\"{label} → {i}\")</code></pre></div></div>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-splitting-the-data-into-training-amp-test-subsets\"><strong>Splitting the data into training &amp; test subsets</strong></h3>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\"># Select features and target\nX = df.drop(columns=[\"mpg\", \"name\"])\ny = df[\"mpg\"]\n\nfeature_names = X.columns.tolist()\nx_data, y_data = X.values, y.values\n\n# Train-test split\nx_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)</code></pre></div></div>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>Model Training</strong></h3>\n\n\n\n<p>We train a Random Forest Regressor with a maximum depth of 10 and 10 decision trees (n_estimators=10). A fixed random_state ensures reproducibility.</p>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\"># Train model\nmodel = RandomForestRegressor(random_state=42, max_depth=10, n_estimators=10)\nmodel.fit(x_train, y_train)</code></pre></div></div>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-model-evaluation\"><strong>Model Evaluation</strong></h3>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\"># Evaluate\nmse = mean_squared_error(y_test, model.predict(x_test))\nr2 = r2_score(y_test, model.predict(x_test))\nprint(f\"Mean Squared Error: {mse:.2f}\")\nprint(f\"R2 Score: {r2:.2f}\")</code></pre></div></div>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>Explaining a Local Instance</strong></h3>\n\n\n\n<p>We choose a specific test instance (with instance_id = 7) to explore how the model arrived at its prediction. We&#8217;ll print the true value, predicted value, and the feature values for this instance. Check out the <strong><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included/blob/main/SHAP-IQ/SHAP_IQ_Visuals.ipynb\" target=\"_blank\" rel=\"noreferrer noopener\">Full Codes here</a><em>.</em></strong></p>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\"># select a local instance to be explained\ninstance_id = 7\nx_explain = x_test[instance_id]\ny_true = y_test[instance_id]\ny_pred = model.predict(x_explain.reshape(1, -1))[0]\nprint(f\"Instance {instance_id}, True Value: {y_true}, Predicted Value: {y_pred}\")\nfor i, feature in enumerate(feature_names):\n    print(f\"{feature}: {x_explain[i]}\")</code></pre></div></div>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>Generating Explanations for Multiple Interaction Orders</strong></h3>\n\n\n\n<p>We generate Shapley-based explanations for different interaction orders using the shapiq package. Specifically, we compute:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Order 1 (Standard Shapley Values): Individual feature contributions</li>\n</ul>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Order 2 (Pairwise Interactions): Combined effects of feature pairs</li>\n</ul>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Order N (Full Interaction): All interactions up to the total number of features</li>\n</ul>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\"># create explanations for different orders\nfeature_names = list(X.columns)  # get the feature names\nn_features = len(feature_names)\n\nsi_order: dict[int, shapiq.InteractionValues] = {}\nfor order in tqdm([1, 2, n_features]):\n    index = \"k-SII\" if order > 1 else \"SV\"  # will also be set automatically by the explainer\n    explainer = shapiq.TreeExplainer(model=model, max_order=order, index=index)\n    si_order[order] = explainer.explain(x=x_explain)\nsi_order</code></pre></div></div>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>1. Force Chart</strong></h3>\n\n\n\n<p>The force plot is a powerful visualization tool that helps us understand how a machine learning model arrived at a specific prediction. It displays the baseline prediction (i.e., the expected value of the model before seeing any features), and then shows how each feature &#8220;pushes&#8221; the prediction higher or lower.</p>\n\n\n\n<p>In this plot:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Red bars represent features or interactions that increase the prediction.</li>\n\n\n\n<li>Blue bars represent those that decrease it.</li>\n\n\n\n<li>The length of each bar corresponds to the magnitude of its effect.</li>\n</ul>\n\n\n\n<p>When using Shapley interaction values, the force plot can visualize not just individual contributions but also interactions between features. This makes it especially insightful when interpreting complex models, as it visually decomposes how combinations of features work together to influence the outcome. Check out the <strong><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included/blob/main/SHAP-IQ/SHAP_IQ_Visuals.ipynb\" target=\"_blank\" rel=\"noreferrer noopener\">Full Codes here</a><em>.</em></strong></p>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\">sv = si_order[1]  # get the SV\nsi = si_order[2]  # get the 2-SII\nmi = si_order[n_features]  # get the Moebius transform\n\nsv.plot_force(feature_names=feature_names, show=True)\nsi.plot_force(feature_names=feature_names, show=True)\nmi.plot_force(feature_names=feature_names, show=True)</code></pre></div></div>\n\n\n\n<figure class=\"wp-block-image is-resized\"><img decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXdSzKJXZ6TsWprj_MP5wcuq6iZQLUdldMbwkb_W0TSdZeNfUt4kFj95hBcFz5BfBAw_8P4xAv9Y4Oa8vnevZytRimFf6vwzt4rU6c34t-muhJmGt7VfoVdzoEN2V2pkQXmaK4QMLQ?key=aAipKL6NcbRDTM9g2wsEFQ\" alt=\"\" style=\"width:918px;height:auto\"/></figure>\n\n\n\n<p>From the first plot, we can see that the base value is 23.5. Features like Weight, Cylinders, Horsepower, and Displacement have a positive influence on the prediction, pushing it above the baseline. On the other hand, Model Year and Acceleration have a negative impact, pulling the prediction downward.</p>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>2. Waterfall Chart</strong></h3>\n\n\n\n<p>Similar to the force plot, the waterfall plot is another popular way to visualize Shapley values, originally introduced with the shap library. It shows how different features push the prediction higher or lower compared to the baseline. One key advantage of the waterfall plot is that it automatically groups features with very small impacts into an “other” category, making the chart cleaner and easier to understand. Check out the <strong><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included/blob/main/SHAP-IQ/SHAP_IQ_Visuals.ipynb\" target=\"_blank\" rel=\"noreferrer noopener\">Full Codes here</a><em>.</em></strong></p>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\">sv.plot_waterfall(feature_names=feature_names, show=True)\nsi.plot_waterfall(feature_names=feature_names, show=True)\nmi.plot_waterfall(feature_names=feature_names, show=True)</code></pre></div></div>\n\n\n\n<figure class=\"wp-block-image is-resized\"><img decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXeRTI2OtfHUaphJpAruRXYbqGAs-AgVPspFOczu-IlM3K7m6NieqPulKCBQWMdpD51fCasRZV6zaiOgWfo4c0Q2z7NQqpI7erHsnt4jOq_CRiWXjUj6wMzuXmc3b555HCjrUHnI?key=aAipKL6NcbRDTM9g2wsEFQ\" alt=\"\" style=\"width:706px;height:auto\"/></figure>\n\n\n\n<figure class=\"wp-block-image is-resized\"><img decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXeFeEomfA09HB1wEFAWWMJ9h3Iet_1YC2fh676AUKddgDrmUZ_KtP11cGFR5JanmRiPJsKfjE3JdmnwIlzQ7I1BZgaxOh6JDBBUb8nfhRuH5WS4YdnAaa1Ftr64PIcAAnHF3z_aIQ?key=aAipKL6NcbRDTM9g2wsEFQ\" alt=\"\" style=\"width:1005px;height:auto\"/></figure>\n\n\n\n<figure class=\"wp-block-image is-resized\"><img decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXe5R3wKkWmjQkCqOuQSOAT54x8jg9MNYTkYTp0H4HAIJMPZrb9U0DuYjkjwC9o3X_aXW7u5W88xOVWLxO4tp3fhvRGwU6rFuW1XCKiytZ6nkKd7vZfzHRXdx2PPqWufl6cHWysfjg?key=aAipKL6NcbRDTM9g2wsEFQ\" alt=\"\" style=\"width:969px;height:auto\"/></figure>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>3. Network Plot</strong></h3>\n\n\n\n<p>The network plot shows how features interact with each other using first- and second-order Shapley interactions. Node size reflects individual feature impact, while edge width and color show interaction strength and direction. It&#8217;s especially helpful when dealing with many features, revealing complex interactions that simpler plots might miss. Check out the <strong><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included/blob/main/SHAP-IQ/SHAP_IQ_Visuals.ipynb\" target=\"_blank\" rel=\"noreferrer noopener\">Full Codes here</a><em>.</em></strong></p>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\">si.plot_network(feature_names=feature_names, show=True)\nmi.plot_network(feature_names=feature_names, show=True)</code></pre></div></div>\n\n\n\n<figure class=\"wp-block-image is-resized\"><img decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXc0nUeNhFZeHh2TLbN9iZPmeEOsUe5O6uxtiHgPq-k7cJwI-b1AAbm0tHHHOZw2LjSYTU3ozNz5L9qDCqA_MFsAq9-OeY1SwmlB5c8tG8mQiFg2qX3JuqHwPII0Daij3kyEt-7x?key=aAipKL6NcbRDTM9g2wsEFQ\" alt=\"\" style=\"width:594px;height:auto\"/></figure>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>4. SI Graph Plot</strong></h3>\n\n\n\n<p>The SI graph plot extends the network plot by visualizing all higher-order interactions as hyper-edges connecting multiple features. Node size shows individual feature impact, while edge width, color, and transparency reflect the strength and direction of interactions. It provides a comprehensive view of how features jointly influence the model&#8217;s prediction. Check out the <strong><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included/blob/main/SHAP-IQ/SHAP_IQ_Visuals.ipynb\" target=\"_blank\" rel=\"noreferrer noopener\">Full Codes here</a><em>.</em></strong></p>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\"># we abbreviate the feature names since, they are plotted inside the nodes\nabbrev_feature_names = shapiq.plot.utils.abbreviate_feature_names(feature_names)\nsv.plot_si_graph(\n    feature_names=abbrev_feature_names,\n    show=True,\n    size_factor=2.5,\n    node_size_scaling=1.5,\n    plot_original_nodes=True,\n)\nsi.plot_si_graph(\n    feature_names=abbrev_feature_names,\n    show=True,\n    size_factor=2.5,\n    node_size_scaling=1.5,\n    plot_original_nodes=True,\n)\nmi.plot_si_graph(\n    feature_names=abbrev_feature_names,\n    show=True,\n    size_factor=2.5,\n    node_size_scaling=1.5,\n    plot_original_nodes=True,\n)</code></pre></div></div>\n\n\n\n<figure class=\"wp-block-image is-resized\"><img decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXeE0EOA7mqqVkt9B4kbDEewnC2ob25gYdQVPhbj-WPmB1oNBY92gr8Gzo_1I56JJ6YScg3xDSFdybk9bJ3hH0o3uytv8uqeCWMmf4dcHwPWlQjwXirm_OeUF9bymfXKzPK02CWH?key=aAipKL6NcbRDTM9g2wsEFQ\" alt=\"\" style=\"width:546px;height:auto\"/></figure>\n\n\n\n<figure class=\"wp-block-image is-resized\"><img decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXdLGjR3cFoFuXnQBz6h7gx-xaO2RjFvGBoz5rPu60INpxJV426tftkdbksIvkv3i_KuvpdLZPVyBEy7T6dC3e9e6_1YpeAeNjfpHIlM9-gRC6LXF5zpZfI4YbI_aDj00Kjoh2kslA?key=aAipKL6NcbRDTM9g2wsEFQ\" alt=\"\" style=\"width:546px;height:auto\"/></figure>\n\n\n\n<figure class=\"wp-block-image is-resized\"><img decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXcdyW6mg0LPEBRrkjbmpOkvpU3w6Fw1x1ydC2a1P_cj4L5cF-lrkGb4WlrQaFiZGoukGKc6rPscB1y5OFfaT-SP1vLiCG1KvqrKCCbUWkyul3mGPowxpG3296pr3jCUPS_bSt3E5g?key=aAipKL6NcbRDTM9g2wsEFQ\" alt=\"\" style=\"width:577px;height:auto\"/></figure>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>5. Bar Plot</strong></h3>\n\n\n\n<p>The bar plot is tailored for global explanations. While other plots can be used both locally and globally, the bar plot summarizes the overall importance of features (or feature interactions) by showing the mean absolute Shapley (or interaction) values across all instances. In shapiq, it highlights which feature interactions contribute most on average. Check out the <strong><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included/blob/main/SHAP-IQ/SHAP_IQ_Visuals.ipynb\" target=\"_blank\" rel=\"noreferrer noopener\">Full Codes here</a><em>.</em></strong></p>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\">explanations = []\nexplainer = shapiq.TreeExplainer(model=model, max_order=2, index=\"k-SII\")\nfor instance_id in tqdm(range(20)):\n    x_explain = x_test[instance_id]\n    si = explainer.explain(x=x_explain)\n    explanations.append(si)\nshapiq.plot.bar_plot(explanations, feature_names=feature_names, show=True)</code></pre></div></div>\n\n\n\n<figure class=\"wp-block-image is-resized\"><img decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXeAeAJkwcZmczz3nTL7NWE77pEmxJQ4h8a9czAIzG8PinLWuH8HA3koH1qfYmXo_n7bghZ2MpNKhQThcfQje_OUQfWTnDkk-N65PoEhFEWe_MSoPJVYQu2XacCMdEGQ48B9pFhlDQ?key=aAipKL6NcbRDTM9g2wsEFQ\" alt=\"\" style=\"width:796px;height:auto\"/></figure>\n\n\n\n<p>&#8220;Distance&#8221; and &#8220;Horsepower&#8221; are the most influential features overall, meaning they have the strongest individual impact on the model&#8217;s predictions. This is evident from their high mean absolute Shapley interaction values in the bar plot.</p>\n\n\n\n<p>Additionally, when looking at second-order interactions (i.e., how two features interact together), the combinations &#8220;Horsepower × Weight&#8221; and &#8220;Distance × Horsepower&#8221; show significant joint influence. Their combined attribution is around 1.4, indicating that these interactions play an important role in shaping the model&#8217;s predictions beyond what each feature contributes individually. This highlights the presence of non-linear relationships between features in the model.</p>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity\"/>\n\n\n\n<p>Check out the <strong><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included/blob/main/SHAP-IQ/SHAP_IQ_Visuals.ipynb\" target=\"_blank\" rel=\"noreferrer noopener\">Full Codes here</a><em>.</em></strong> Feel free to check out our <strong><mark><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included\" target=\"_blank\" rel=\"noreferrer noopener\">GitHub Page for Tutorials, Codes and Notebooks</a></mark></strong>. Also, feel free to follow us on <strong><a href=\"https://x.com/intent/follow?screen_name=marktechpost\" target=\"_blank\" rel=\"noreferrer noopener\"><mark>Twitter</mark></a></strong> and don’t forget to join our <strong><a href=\"https://www.reddit.com/r/machinelearningnews/\" target=\"_blank\" rel=\"noreferrer noopener\">100k+ ML SubReddit</a></strong> and Subscribe to <strong><a href=\"https://www.aidevsignals.com/\" target=\"_blank\" rel=\"noreferrer noopener\">our Newsletter</a></strong>.</p>\n<p>The post <a href=\"https://www.marktechpost.com/2025/08/03/tutorial-exploring-shap-iq-visualizations/\">Tutorial: Exploring SHAP-IQ Visualizations</a> appeared first on <a href=\"https://www.marktechpost.com\">MarkTechPost</a>.</p>\n",
          "content:encodedSnippet": "In this tutorial, we’ll explore a range of SHAP-IQ visualizations that provide insights into how a machine learning model arrives at its predictions. These visuals help break down complex model behavior into interpretable components—revealing both the individual and interactive contributions of features to a specific prediction. Check out the Full Codes here.\nInstalling the dependencies\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\n!pip install shapiq overrides scikit-learn pandas numpy seaborn\n\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.model_selection import train_test_split\nfrom tqdm.asyncio import tqdm\n\nimport shapiq\n\nprint(f\"shapiq version: {shapiq.__version__}\")\n\nImporting the dataset\nIn this tutorial, we’ll use the MPG (Miles Per Gallon) dataset, which we’ll load directly from the Seaborn library. This dataset contains information about various car models, including features like horsepower, weight, and origin. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\nimport seaborn as sns\ndf = sns.load_dataset(\"mpg\")\ndf\n\nProcessing the dataset\nWe use Label Encoding to convert the categorical column(s) into numeric format, making them suitable for model training.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\n# Drop rows with missing values\ndf = df.dropna()\n\n# Encoding the origin column\nle = LabelEncoder()\ndf.loc[:, \"origin\"] = le.fit_transform(df[\"origin\"])\ndf['origin'].unique()\n\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\nfor i, label in enumerate(le.classes_):\n    print(f\"{label} → {i}\")\n\nSplitting the data into training & test subsets\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\n# Select features and target\nX = df.drop(columns=[\"mpg\", \"name\"])\ny = df[\"mpg\"]\n\nfeature_names = X.columns.tolist()\nx_data, y_data = X.values, y.values\n\n# Train-test split\nx_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)\n\nModel Training\nWe train a Random Forest Regressor with a maximum depth of 10 and 10 decision trees (n_estimators=10). A fixed random_state ensures reproducibility.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\n# Train model\nmodel = RandomForestRegressor(random_state=42, max_depth=10, n_estimators=10)\nmodel.fit(x_train, y_train)\n\nModel Evaluation\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\n# Evaluate\nmse = mean_squared_error(y_test, model.predict(x_test))\nr2 = r2_score(y_test, model.predict(x_test))\nprint(f\"Mean Squared Error: {mse:.2f}\")\nprint(f\"R2 Score: {r2:.2f}\")\n\nExplaining a Local Instance\nWe choose a specific test instance (with instance_id = 7) to explore how the model arrived at its prediction. We’ll print the true value, predicted value, and the feature values for this instance. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\n# select a local instance to be explained\ninstance_id = 7\nx_explain = x_test[instance_id]\ny_true = y_test[instance_id]\ny_pred = model.predict(x_explain.reshape(1, -1))[0]\nprint(f\"Instance {instance_id}, True Value: {y_true}, Predicted Value: {y_pred}\")\nfor i, feature in enumerate(feature_names):\n    print(f\"{feature}: {x_explain[i]}\")\n\nGenerating Explanations for Multiple Interaction Orders\nWe generate Shapley-based explanations for different interaction orders using the shapiq package. Specifically, we compute:\nOrder 1 (Standard Shapley Values): Individual feature contributions\nOrder 2 (Pairwise Interactions): Combined effects of feature pairs\nOrder N (Full Interaction): All interactions up to the total number of features\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\n# create explanations for different orders\nfeature_names = list(X.columns)  # get the feature names\nn_features = len(feature_names)\n\nsi_order: dict[int, shapiq.InteractionValues] = {}\nfor order in tqdm([1, 2, n_features]):\n    index = \"k-SII\" if order > 1 else \"SV\"  # will also be set automatically by the explainer\n    explainer = shapiq.TreeExplainer(model=model, max_order=order, index=index)\n    si_order[order] = explainer.explain(x=x_explain)\nsi_order\n\n1. Force Chart\nThe force plot is a powerful visualization tool that helps us understand how a machine learning model arrived at a specific prediction. It displays the baseline prediction (i.e., the expected value of the model before seeing any features), and then shows how each feature “pushes” the prediction higher or lower.\nIn this plot:\nRed bars represent features or interactions that increase the prediction.\nBlue bars represent those that decrease it.\nThe length of each bar corresponds to the magnitude of its effect.\nWhen using Shapley interaction values, the force plot can visualize not just individual contributions but also interactions between features. This makes it especially insightful when interpreting complex models, as it visually decomposes how combinations of features work together to influence the outcome. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\nsv = si_order[1]  # get the SV\nsi = si_order[2]  # get the 2-SII\nmi = si_order[n_features]  # get the Moebius transform\n\nsv.plot_force(feature_names=feature_names, show=True)\nsi.plot_force(feature_names=feature_names, show=True)\nmi.plot_force(feature_names=feature_names, show=True)\n\n\n\n\n\nFrom the first plot, we can see that the base value is 23.5. Features like Weight, Cylinders, Horsepower, and Displacement have a positive influence on the prediction, pushing it above the baseline. On the other hand, Model Year and Acceleration have a negative impact, pulling the prediction downward.\n2. Waterfall Chart\nSimilar to the force plot, the waterfall plot is another popular way to visualize Shapley values, originally introduced with the shap library. It shows how different features push the prediction higher or lower compared to the baseline. One key advantage of the waterfall plot is that it automatically groups features with very small impacts into an “other” category, making the chart cleaner and easier to understand. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\nsv.plot_waterfall(feature_names=feature_names, show=True)\nsi.plot_waterfall(feature_names=feature_names, show=True)\nmi.plot_waterfall(feature_names=feature_names, show=True)\n\n\n\n\n\n\n\n\n\n\n\n\n\n3. Network Plot\nThe network plot shows how features interact with each other using first- and second-order Shapley interactions. Node size reflects individual feature impact, while edge width and color show interaction strength and direction. It’s especially helpful when dealing with many features, revealing complex interactions that simpler plots might miss. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\nsi.plot_network(feature_names=feature_names, show=True)\nmi.plot_network(feature_names=feature_names, show=True)\n\n\n\n\n\n4. SI Graph Plot\nThe SI graph plot extends the network plot by visualizing all higher-order interactions as hyper-edges connecting multiple features. Node size shows individual feature impact, while edge width, color, and transparency reflect the strength and direction of interactions. It provides a comprehensive view of how features jointly influence the model’s prediction. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\n# we abbreviate the feature names since, they are plotted inside the nodes\nabbrev_feature_names = shapiq.plot.utils.abbreviate_feature_names(feature_names)\nsv.plot_si_graph(\n    feature_names=abbrev_feature_names,\n    show=True,\n    size_factor=2.5,\n    node_size_scaling=1.5,\n    plot_original_nodes=True,\n)\nsi.plot_si_graph(\n    feature_names=abbrev_feature_names,\n    show=True,\n    size_factor=2.5,\n    node_size_scaling=1.5,\n    plot_original_nodes=True,\n)\nmi.plot_si_graph(\n    feature_names=abbrev_feature_names,\n    show=True,\n    size_factor=2.5,\n    node_size_scaling=1.5,\n    plot_original_nodes=True,\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n5. Bar Plot\nThe bar plot is tailored for global explanations. While other plots can be used both locally and globally, the bar plot summarizes the overall importance of features (or feature interactions) by showing the mean absolute Shapley (or interaction) values across all instances. In shapiq, it highlights which feature interactions contribute most on average. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\nexplanations = []\nexplainer = shapiq.TreeExplainer(model=model, max_order=2, index=\"k-SII\")\nfor instance_id in tqdm(range(20)):\n    x_explain = x_test[instance_id]\n    si = explainer.explain(x=x_explain)\n    explanations.append(si)\nshapiq.plot.bar_plot(explanations, feature_names=feature_names, show=True)\n\n\n\n\n\n“Distance” and “Horsepower” are the most influential features overall, meaning they have the strongest individual impact on the model’s predictions. This is evident from their high mean absolute Shapley interaction values in the bar plot.\nAdditionally, when looking at second-order interactions (i.e., how two features interact together), the combinations “Horsepower × Weight” and “Distance × Horsepower” show significant joint influence. Their combined attribution is around 1.4, indicating that these interactions play an important role in shaping the model’s predictions beyond what each feature contributes individually. This highlights the presence of non-linear relationships between features in the model.\nCheck out the Full Codes here. Feel free to check out our GitHub Page for Tutorials, Codes and Notebooks. Also, feel free to follow us on Twitter and don’t forget to join our 100k+ ML SubReddit and Subscribe to our Newsletter.\nThe post Tutorial: Exploring SHAP-IQ Visualizations appeared first on MarkTechPost.",
          "dc:creator": "Arham Islam",
          "comments": "https://www.marktechpost.com/2025/08/03/tutorial-exploring-shap-iq-visualizations/#respond",
          "content": "<p>In this tutorial, we’ll explore a range of SHAP-IQ visualizations that provide insights into how a machine learning model arrives at its predictions. These visuals help break down complex model behavior into interpretable components—revealing both the individual and interactive contributions of features to a specific prediction. Check out the Full Codes here. Installing the dependencies Importing [&#8230;]</p>\n<p>The post <a href=\"https://www.marktechpost.com/2025/08/03/tutorial-exploring-shap-iq-visualizations/\">Tutorial: Exploring SHAP-IQ Visualizations</a> appeared first on <a href=\"https://www.marktechpost.com\">MarkTechPost</a>.</p>\n",
          "contentSnippet": "In this tutorial, we’ll explore a range of SHAP-IQ visualizations that provide insights into how a machine learning model arrives at its predictions. These visuals help break down complex model behavior into interpretable components—revealing both the individual and interactive contributions of features to a specific prediction. Check out the Full Codes here. Installing the dependencies Importing […]\nThe post Tutorial: Exploring SHAP-IQ Visualizations appeared first on MarkTechPost.",
          "guid": "https://www.marktechpost.com/?p=73187",
          "categories": [
            "Artificial Intelligence",
            "Editors Pick",
            "Machine Learning",
            "Staff",
            "Technology",
            "Tutorials"
          ],
          "isoDate": "2025-08-04T04:45:10.000Z"
        }
      },
      {
        "json": {
          "creator": "Michal Sutter",
          "title": "A Technical Roadmap to Context Engineering in LLMs: Mechanisms, Benchmarks, and Open Challenges",
          "link": "https://www.marktechpost.com/2025/08/03/a-technical-roadmap-to-context-engineering-in-llms-mechanisms-benchmarks-and-open-challenges/",
          "pubDate": "Sun, 03 Aug 2025 21:32:05 +0000",
          "content:encoded": "\n<p class=\"wp-block-yoast-seo-estimated-reading-time yoast-reading-time__wrapper\"><span class=\"yoast-reading-time__icon\"><svg aria-hidden=\"true\" focusable=\"false\" data-icon=\"clock\" width=\"20\" height=\"20\" fill=\"none\" stroke=\"currentColor\" style=\"display:inline-block;vertical-align:-0.1em\" role=\"img\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\"><path stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" d=\"M12 8v4l3 3m6-3a9 9 0 11-18 0 9 9 0 0118 0z\"></path></svg></span><span class=\"yoast-reading-time__spacer\" style=\"display:inline-block;width:1em\"></span><span class=\"yoast-reading-time__descriptive-text\">Estimated reading time: </span><span class=\"yoast-reading-time__reading-time\">4</span><span class=\"yoast-reading-time__time-unit\"> minutes</span></p>\n\n\n\n<div class=\"wp-block-yoast-seo-table-of-contents yoast-table-of-contents\"><h3><strong>Table of contents</strong></h3><ul><li><a href=\"#what-is-context-engineering\" data-level=\"3\">What Is Context Engineering?</a></li><li><a href=\"#taxonomy-of-context-engineering\" data-level=\"3\">Taxonomy of Context Engineering</a></li><li><a href=\"#key-insights-and-research-gaps\" data-level=\"3\">Key Insights and Research Gaps</a></li><li><a href=\"#applications-and-impact\" data-level=\"3\">Applications and Impact</a></li><li><a href=\"#future-directions\" data-level=\"3\">Future Directions</a></li></ul></div>\n\n\n\n<p>The paper “<strong><a href=\"https://arxiv.org/abs/2507.13334\" target=\"_blank\" rel=\"noreferrer noopener\">A Survey of Context Engineering for Large Language Models</a></strong>” establishes <strong>Context Engineering</strong> as a formal discipline that goes far beyond prompt engineering, providing a unified, systematic framework for designing, optimizing, and managing the information that guides Large Language Models (LLMs). Here’s an overview of its main contributions and framework:</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"what-is-context-engineering\"><strong>What Is Context Engineering?</strong></h3>\n\n\n\n<p><strong>Context Engineering</strong> is defined as the science and engineering of organizing, assembling, and optimizing all forms of context fed into LLMs to maximize performance across comprehension, reasoning, adaptability, and real-world application. Rather than viewing context as a static string (the premise of prompt engineering), context engineering treats it as a dynamic, structured assembly of components—each sourced, selected, and organized through explicit functions, often under tight resource and architectural constraints.</p>\n\n\n\n<figure class=\"wp-block-image size-large is-resized\"><img fetchpriority=\"high\" decoding=\"async\" width=\"1024\" height=\"324\" data-attachment-id=\"73184\" data-permalink=\"https://www.marktechpost.com/2025/08/03/a-technical-roadmap-to-context-engineering-in-llms-mechanisms-benchmarks-and-open-challenges/screenshot-2025-08-03-at-2-11-29-pm/\" data-orig-file=\"https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-03-at-2.11.29-PM.png\" data-orig-size=\"1384,438\" data-comments-opened=\"1\" data-image-meta=\"{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}\" data-image-title=\"Screenshot 2025-08-03 at 2.11.29 PM\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-03-at-2.11.29-PM-300x95.png\" data-large-file=\"https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-03-at-2.11.29-PM-1024x324.png\" src=\"https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-03-at-2.11.29-PM-1024x324.png\" alt=\"\" class=\"wp-image-73184\" style=\"width:732px;height:auto\" srcset=\"https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-03-at-2.11.29-PM-1024x324.png 1024w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-03-at-2.11.29-PM-300x95.png 300w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-03-at-2.11.29-PM-768x243.png 768w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-03-at-2.11.29-PM-1327x420.png 1327w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-03-at-2.11.29-PM-150x47.png 150w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-03-at-2.11.29-PM-696x220.png 696w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-03-at-2.11.29-PM-1068x338.png 1068w, https://www.marktechpost.com/wp-content/uploads/2025/08/Screenshot-2025-08-03-at-2.11.29-PM.png 1384w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" /></figure>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"taxonomy-of-context-engineering\"><strong>Taxonomy of Context Engineering</strong></h3>\n\n\n\n<p>The paper breaks down context engineering into:</p>\n\n\n\n<h4 class=\"wp-block-heading\"><strong>1. Foundational Components</strong></h4>\n\n\n\n<p><strong>a. Context Retrieval and Generation</strong></p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Encompasses prompt engineering, in-context learning (zero/few-shot, chain-of-thought, tree-of-thought, graph-of-thought), external knowledge retrieval (e.g., Retrieval-Augmented Generation, knowledge graphs), and dynamic assembly of context elements1.</li>\n\n\n\n<li>Techniques like CLEAR Framework, dynamic template assembly, and modular retrieval architectures are highlighted.</li>\n</ul>\n\n\n\n<p><strong>b. Context Processing</strong></p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Addresses long-sequence processing (with architectures like Mamba, LongNet, FlashAttention), context self-refinement (iterative feedback, self-evaluation), and integration of multimodal and structured information (vision, audio, graphs, tables).</li>\n\n\n\n<li>Strategies include attention sparsity, memory compression, and in-context learning meta-optimization.</li>\n</ul>\n\n\n\n<p><strong>c. Context Management</strong></p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Involves memory hierarchies and storage architectures (short-term context windows, long-term memory, external databases), memory paging, context compression (autoencoders, recurrent compression), and scalable management over multi-turn or multi-agent settings.</li>\n</ul>\n\n\n\n<h4 class=\"wp-block-heading\"><strong>2. System Implementations</strong></h4>\n\n\n\n<p><strong>a. Retrieval-Augmented Generation (RAG)</strong></p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Modular, agentic, and graph-enhanced RAG architectures integrate external knowledge and support dynamic, sometimes multi-agent retrieval pipelines.</li>\n\n\n\n<li>Enables both real-time knowledge updates and complex reasoning over structured databases/graphs.</li>\n</ul>\n\n\n\n<p><strong>b. Memory Systems</strong></p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Implement persistent and hierarchical storage, enabling longitudinal learning and knowledge recall for agents (e.g., MemGPT, MemoryBank, external vector databases).</li>\n\n\n\n<li>Key for extended, multi-turn dialogs, personalized assistants, and simulation agents.</li>\n</ul>\n\n\n\n<p><strong>c. Tool-Integrated Reasoning</strong></p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>LLMs use external tools (APIs, search engines, code execution) via function calling or environment interaction, combining language reasoning with world-acting abilities.</li>\n\n\n\n<li>Enables new domains (math, programming, web interaction, scientific research).</li>\n</ul>\n\n\n\n<p><strong>d. Multi-Agent Systems</strong></p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Coordination among multiple LLMs (agents) via standardized protocols, orchestrators, and context sharing—essential for complex, collaborative problem-solving and distributed AI applications.</li>\n</ul>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"key-insights-and-research-gaps\"><strong>Key Insights and Research Gaps</strong></h3>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Comprehension–Generation Asymmetry</strong>: LLMs, with advanced context engineering, can comprehend very sophisticated, multi-faceted contexts but still struggle to generate outputs matching that complexity or length.</li>\n\n\n\n<li><strong>Integration and Modularity</strong>: Best performance comes from modular architectures combining multiple techniques (retrieval, memory, tool use).</li>\n\n\n\n<li><strong>Evaluation Limitations</strong>: Current evaluation metrics/benchmarks (like BLEU, ROUGE) often fail to capture the compositional, multi-step, and collaborative behaviors enabled by advanced context engineering. New benchmarks and dynamic, holistic evaluation paradigms are needed.</li>\n\n\n\n<li><strong>Open Research Questions</strong>: Theoretical foundations, efficient scaling (especially computationally), cross-modal and structured context integration, real-world deployment, safety, alignment, and ethical concerns remain open research challenges.</li>\n</ul>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"applications-and-impact\"><strong>Applications and Impact</strong></h3>\n\n\n\n<p>Context engineering supports robust, domain-adaptive AI across:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Long-document/question answering</strong></li>\n\n\n\n<li><strong>Personalized digital assistants and memory-augmented agents</strong></li>\n\n\n\n<li><strong>Scientific, medical, and technical problem-solving</strong></li>\n\n\n\n<li><strong>Multi-agent collaboration in business, education, and research</strong></li>\n</ul>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"future-directions\"><strong>Future Directions</strong></h3>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Unified Theory</strong>: Developing mathematical and information-theoretic frameworks.</li>\n\n\n\n<li><strong>Scaling &amp; Efficiency</strong>: Innovations in attention mechanisms and memory management.</li>\n\n\n\n<li><strong>Multi-Modal Integration</strong>: Seamless coordination of text, vision, audio, and structured data.</li>\n\n\n\n<li><strong>Robust, Safe, and Ethical Deployment</strong>: Ensuring reliability, transparency, and fairness in real-world systems.</li>\n</ul>\n\n\n\n<p><strong>In summary:</strong> Context Engineering is emerging as the pivotal discipline for guiding the next generation of LLM-based intelligent systems, shifting the focus from creative prompt writing to the rigorous science of information optimization, system design, and context-driven AI.</p>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity\"/>\n\n\n\n<p>Check out the <strong><a href=\"https://arxiv.org/abs/2507.13334\" target=\"_blank\" rel=\"noreferrer noopener\">Paper</a><em>.</em></strong> Feel free to check out our <strong><mark><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included\" target=\"_blank\" rel=\"noreferrer noopener\">GitHub Page for Tutorials, Codes and Notebooks</a></mark></strong>. Also, feel free to follow us on <strong><a href=\"https://x.com/intent/follow?screen_name=marktechpost\" target=\"_blank\" rel=\"noreferrer noopener\"><mark>Twitter</mark></a></strong> and don’t forget to join our <strong><a href=\"https://www.reddit.com/r/machinelearningnews/\" target=\"_blank\" rel=\"noreferrer noopener\">100k+ ML SubReddit</a></strong> and Subscribe to <strong><a href=\"https://www.aidevsignals.com/\" target=\"_blank\" rel=\"noreferrer noopener\">our Newsletter</a></strong>.</p>\n<p>The post <a href=\"https://www.marktechpost.com/2025/08/03/a-technical-roadmap-to-context-engineering-in-llms-mechanisms-benchmarks-and-open-challenges/\">A Technical Roadmap to Context Engineering in LLMs: Mechanisms, Benchmarks, and Open Challenges</a> appeared first on <a href=\"https://www.marktechpost.com\">MarkTechPost</a>.</p>\n",
          "content:encodedSnippet": "Estimated reading time: 4 minutes\nTable of contents\n\nWhat Is Context Engineering?\nTaxonomy of Context Engineering\nKey Insights and Research Gaps\nApplications and Impact\nFuture Directions\n\nThe paper “A Survey of Context Engineering for Large Language Models” establishes Context Engineering as a formal discipline that goes far beyond prompt engineering, providing a unified, systematic framework for designing, optimizing, and managing the information that guides Large Language Models (LLMs). Here’s an overview of its main contributions and framework:\nWhat Is Context Engineering?\nContext Engineering is defined as the science and engineering of organizing, assembling, and optimizing all forms of context fed into LLMs to maximize performance across comprehension, reasoning, adaptability, and real-world application. Rather than viewing context as a static string (the premise of prompt engineering), context engineering treats it as a dynamic, structured assembly of components—each sourced, selected, and organized through explicit functions, often under tight resource and architectural constraints.\n\n\n\n\nTaxonomy of Context Engineering\nThe paper breaks down context engineering into:\n1. Foundational Components\na. Context Retrieval and Generation\nEncompasses prompt engineering, in-context learning (zero/few-shot, chain-of-thought, tree-of-thought, graph-of-thought), external knowledge retrieval (e.g., Retrieval-Augmented Generation, knowledge graphs), and dynamic assembly of context elements1.\nTechniques like CLEAR Framework, dynamic template assembly, and modular retrieval architectures are highlighted.\nb. Context Processing\nAddresses long-sequence processing (with architectures like Mamba, LongNet, FlashAttention), context self-refinement (iterative feedback, self-evaluation), and integration of multimodal and structured information (vision, audio, graphs, tables).\nStrategies include attention sparsity, memory compression, and in-context learning meta-optimization.\nc. Context Management\nInvolves memory hierarchies and storage architectures (short-term context windows, long-term memory, external databases), memory paging, context compression (autoencoders, recurrent compression), and scalable management over multi-turn or multi-agent settings.\n2. System Implementations\na. Retrieval-Augmented Generation (RAG)\nModular, agentic, and graph-enhanced RAG architectures integrate external knowledge and support dynamic, sometimes multi-agent retrieval pipelines.\nEnables both real-time knowledge updates and complex reasoning over structured databases/graphs.\nb. Memory Systems\nImplement persistent and hierarchical storage, enabling longitudinal learning and knowledge recall for agents (e.g., MemGPT, MemoryBank, external vector databases).\nKey for extended, multi-turn dialogs, personalized assistants, and simulation agents.\nc. Tool-Integrated Reasoning\nLLMs use external tools (APIs, search engines, code execution) via function calling or environment interaction, combining language reasoning with world-acting abilities.\nEnables new domains (math, programming, web interaction, scientific research).\nd. Multi-Agent Systems\nCoordination among multiple LLMs (agents) via standardized protocols, orchestrators, and context sharing—essential for complex, collaborative problem-solving and distributed AI applications.\nKey Insights and Research Gaps\nComprehension–Generation Asymmetry: LLMs, with advanced context engineering, can comprehend very sophisticated, multi-faceted contexts but still struggle to generate outputs matching that complexity or length.\nIntegration and Modularity: Best performance comes from modular architectures combining multiple techniques (retrieval, memory, tool use).\nEvaluation Limitations: Current evaluation metrics/benchmarks (like BLEU, ROUGE) often fail to capture the compositional, multi-step, and collaborative behaviors enabled by advanced context engineering. New benchmarks and dynamic, holistic evaluation paradigms are needed.\nOpen Research Questions: Theoretical foundations, efficient scaling (especially computationally), cross-modal and structured context integration, real-world deployment, safety, alignment, and ethical concerns remain open research challenges.\nApplications and Impact\nContext engineering supports robust, domain-adaptive AI across:\nLong-document/question answering\nPersonalized digital assistants and memory-augmented agents\nScientific, medical, and technical problem-solving\nMulti-agent collaboration in business, education, and research\nFuture Directions\nUnified Theory: Developing mathematical and information-theoretic frameworks.\nScaling & Efficiency: Innovations in attention mechanisms and memory management.\nMulti-Modal Integration: Seamless coordination of text, vision, audio, and structured data.\nRobust, Safe, and Ethical Deployment: Ensuring reliability, transparency, and fairness in real-world systems.\nIn summary: Context Engineering is emerging as the pivotal discipline for guiding the next generation of LLM-based intelligent systems, shifting the focus from creative prompt writing to the rigorous science of information optimization, system design, and context-driven AI.\nCheck out the Paper. Feel free to check out our GitHub Page for Tutorials, Codes and Notebooks. Also, feel free to follow us on Twitter and don’t forget to join our 100k+ ML SubReddit and Subscribe to our Newsletter.\nThe post A Technical Roadmap to Context Engineering in LLMs: Mechanisms, Benchmarks, and Open Challenges appeared first on MarkTechPost.",
          "dc:creator": "Michal Sutter",
          "comments": "https://www.marktechpost.com/2025/08/03/a-technical-roadmap-to-context-engineering-in-llms-mechanisms-benchmarks-and-open-challenges/#respond",
          "content": "<p>The paper “A Survey of Context Engineering for Large Language Models” establishes Context Engineering as a formal discipline that goes far beyond prompt engineering, providing a unified, systematic framework for designing, optimizing, and managing the information that guides Large Language Models (LLMs). Here’s an overview of its main contributions and framework: What Is Context Engineering? [&#8230;]</p>\n<p>The post <a href=\"https://www.marktechpost.com/2025/08/03/a-technical-roadmap-to-context-engineering-in-llms-mechanisms-benchmarks-and-open-challenges/\">A Technical Roadmap to Context Engineering in LLMs: Mechanisms, Benchmarks, and Open Challenges</a> appeared first on <a href=\"https://www.marktechpost.com\">MarkTechPost</a>.</p>\n",
          "contentSnippet": "The paper “A Survey of Context Engineering for Large Language Models” establishes Context Engineering as a formal discipline that goes far beyond prompt engineering, providing a unified, systematic framework for designing, optimizing, and managing the information that guides Large Language Models (LLMs). Here’s an overview of its main contributions and framework: What Is Context Engineering? […]\nThe post A Technical Roadmap to Context Engineering in LLMs: Mechanisms, Benchmarks, and Open Challenges appeared first on MarkTechPost.",
          "guid": "https://www.marktechpost.com/?p=73182",
          "categories": [
            "Context Engineering",
            "Editors Pick",
            "Staff",
            "Uncategorized"
          ],
          "isoDate": "2025-08-03T21:32:05.000Z"
        }
      },
      {
        "json": {
          "creator": "Michal Sutter",
          "title": "The Ultimate Guide to CPUs, GPUs, NPUs, and TPUs for AI/ML: Performance, Use Cases, and Key Differences",
          "link": "https://www.marktechpost.com/2025/08/03/the-ultimate-guide-to-cpus-gpus-npus-and-tpus-for-ai-ml-performance-use-cases-and-key-differences/",
          "pubDate": "Sun, 03 Aug 2025 10:38:52 +0000",
          "content:encoded": "\n<p>Artificial intelligence and machine learning workloads have fueled the evolution of specialized hardware to accelerate computation far beyond what traditional CPUs can offer. Each processing unit—CPU, GPU, NPU, TPU—plays a distinct role in the AI ecosystem, optimized for certain models, applications, or environments. Here’s a technical, data-driven breakdown of their core differences and best use cases.</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-cpu-central-processing-unit-the-versatile-workhorse\"><strong>CPU (Central Processing Unit): The Versatile Workhorse</strong></h3>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Design &amp; Strengths:</strong> CPUs are general-purpose processors with a few powerful cores—ideal for single-threaded tasks and running diverse software, including operating systems, databases, and light AI/ML inference.</li>\n\n\n\n<li><strong>AI/ML Role:</strong> CPUs can execute any kind of AI model, but lack the massive parallelism needed for efficient deep learning training or inference at scale.</li>\n\n\n\n<li><strong>Best for:</strong>\n<ul class=\"wp-block-list\">\n<li>Classical <a href=\"https://www.marktechpost.com/2025/01/14/what-is-machine-learning-ml/\" target=\"_blank\">ML</a> algorithms (e.g., scikit-learn, XGBoost)</li>\n\n\n\n<li>Prototyping and model development</li>\n\n\n\n<li>Inference for small models or low-throughput requirements</li>\n</ul>\n</li>\n</ul>\n\n\n\n<p><strong>Technical Note:</strong> For neural network operations, CPU throughput (typically measured in GFLOPS—billion floating point operations per second) lags far behind specialized accelerators.</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-gpu-graphics-processing-unit-the-deep-learning-backbone\"><strong>GPU (Graphics Processing Unit): The Deep Learning Backbone</strong></h3>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Design &amp; Strengths:</strong> Originally for graphics, modern GPUs feature thousands of parallel cores designed for matrix/multiple vector operations, making them highly efficient for training and inference of deep neural networks.</li>\n\n\n\n<li><strong>Performance Examples:</strong>\n<ul class=\"wp-block-list\">\n<li>NVIDIA RTX 3090: 10,496 CUDA cores, up to 35.6 TFLOPS (teraFLOPS) FP32 compute.</li>\n\n\n\n<li>Recent NVIDIA GPUs include “Tensor Cores” for mixed precision, accelerating <a href=\"https://www.marktechpost.com/2025/01/15/what-is-deep-learning-2/\" target=\"_blank\">deep learning</a> operations.</li>\n</ul>\n</li>\n\n\n\n<li><strong>Best for:</strong>\n<ul class=\"wp-block-list\">\n<li>Training and inferencing large-scale deep learning models (CNNs, RNNs, Transformers)</li>\n\n\n\n<li>Batch processing typical in datacenter and research environments</li>\n\n\n\n<li>Supported by all major AI frameworks (TensorFlow, PyTorch)</li>\n</ul>\n</li>\n</ul>\n\n\n\n<p><strong>Benchmarks:</strong> A 4x RTX A5000 setup can surpass a single, far more expensive NVIDIA H100 in certain workloads, balancing acquisition cost and performance.</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-npu-neural-processing-unit-the-on-device-ai-specialist\"><strong>NPU (Neural Processing Unit): The On-device AI Specialist</strong></h3>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Design &amp; Strengths:</strong> NPUs are ASICs (application-specific chips) crafted exclusively for neural network operations. They optimize parallel, low-precision computation for deep learning inference, often running at low power for edge and embedded devices.</li>\n\n\n\n<li><strong>Use Cases &amp; Applications:</strong>\n<ul class=\"wp-block-list\">\n<li><strong>Mobile &amp; Consumer</strong>: Powering features like face unlock, real-time image processing, language translation on devices like the Apple A-series, Samsung Exynos, Google Tensor chips.</li>\n\n\n\n<li><strong>Edge &amp; IoT</strong>: Low-latency vision and speech recognition, smart city cameras, AR/VR, and manufacturing sensors.</li>\n\n\n\n<li><strong>Automotive</strong>: Real-time data from sensors for autonomous driving and advanced driver assistance.</li>\n</ul>\n</li>\n\n\n\n<li><strong>Performance Example:</strong> The Exynos 9820’s NPU is ~7x faster than its predecessor for AI tasks.</li>\n</ul>\n\n\n\n<p><strong>Efficiency:</strong> NPUs prioritize energy efficiency over raw throughput, extending battery life while supporting advanced AI features locally.</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-tpu-tensor-processing-unit-google-s-ai-powerhouse\"><strong>TPU (Tensor Processing Unit): Google’s AI Powerhouse</strong></h3>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Design &amp; Strengths:</strong> TPUs are custom chips developed by Google specifically for large tensor computations, tuning hardware around the needs of frameworks like TensorFlow.</li>\n\n\n\n<li><strong>Key Specifications:</strong>\n<ul class=\"wp-block-list\">\n<li>TPU v2: Up to 180 TFLOPS for neural network training and inference.</li>\n\n\n\n<li>TPU v4: Available in Google Cloud, up to 275 TFLOPS per chip, scalable to “pods” exceeding 100 petaFLOPS.</li>\n\n\n\n<li>Specialized matrix multiplication units (“MXU”) for enormous batch computations.</li>\n\n\n\n<li>Up to 30–80x better energy efficiency (TOPS/Watt) for inference compared to contemporary GPUs and CPUs.</li>\n</ul>\n</li>\n\n\n\n<li><strong>Best for:</strong>\n<ul class=\"wp-block-list\">\n<li>Training and serving massive models (BERT, GPT-2, EfficientNet) in cloud at scale</li>\n\n\n\n<li>High-throughput, low-latency AI for research and production pipelines</li>\n\n\n\n<li>Tight integration with TensorFlow and JAX; increasingly interfacing with PyTorch</li>\n</ul>\n</li>\n</ul>\n\n\n\n<p><strong>Note:</strong> TPU architecture is less flexible than GPU—optimized for AI, not graphics or general-purpose tasks.</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-which-models-run-where\"><strong>Which Models Run Where?</strong></h3>\n\n\n\n<figure class=\"wp-block-table\"><table class=\"has-fixed-layout\"><thead><tr><th>Hardware</th><th>Best Supported Models</th><th>Typical Workloads</th></tr></thead><tbody><tr><td>CPU</td><td>Classical ML, all deep learning models*</td><td>General software, prototyping, small AI</td></tr><tr><td>GPU</td><td>CNNs, RNNs, Transformers</td><td>Training and inference (cloud/workstation)</td></tr><tr><td>NPU</td><td>MobileNet, TinyBERT, custom edge models</td><td>On-device AI, real-time vision/speech</td></tr><tr><td>TPU</td><td>BERT/GPT-2/ResNet/EfficientNet, etc.</td><td>Large-scale model training/inference</td></tr></tbody></table></figure>\n\n\n\n<p>*CPUs support any model, but are not efficient for large-scale DNNs.</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-data-processing-units-dpus-the-data-movers\"><strong>Data Processing Units (DPUs): The Data Movers</strong></h3>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Role:</strong> DPUs accelerate networking, storage, and data movement, offloading these tasks from CPUs/GPUs. They enable higher infrastructure efficiency in AI datacenters by ensuring compute resources focus on model execution, not I/O or data orchestration.</li>\n</ul>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-summary-table-technical-comparison\"><strong>Summary Table: Technical Comparison</strong></h3>\n\n\n\n<figure class=\"wp-block-table\"><table class=\"has-fixed-layout\"><thead><tr><th>Feature</th><th>CPU</th><th>GPU</th><th>NPU</th><th>TPU</th></tr></thead><tbody><tr><td>Use Case</td><td>General Compute</td><td>Deep Learning</td><td>Edge/On-device AI</td><td>Google Cloud AI</td></tr><tr><td>Parallelism</td><td>Low–Moderate</td><td>Very High (~10,000+)</td><td>Moderate–High</td><td>Extremely High (Matrix Mult.)</td></tr><tr><td>Efficiency</td><td>Moderate</td><td>Power-hungry</td><td>Ultra-efficient</td><td>High for large models</td></tr><tr><td>Flexibility</td><td>Maximum</td><td>Very high (all FW)</td><td>Specialized</td><td>Specialized (TensorFlow/JAX)</td></tr><tr><td>Hardware</td><td>x86, ARM, etc.</td><td>NVIDIA, AMD</td><td>Apple, Samsung, ARM</td><td>Google (Cloud only)</td></tr><tr><td>Example</td><td>Intel Xeon</td><td>RTX 3090, A100, H100</td><td>Apple Neural Engine</td><td>TPU v4, Edge TPU</td></tr></tbody></table></figure>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-key-takeaways\"><strong>Key Takeaways</strong></h3>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>CPUs</strong> are unmatched for general-purpose, flexible workloads.</li>\n\n\n\n<li><strong>GPUs</strong> remain the workhorse for training and running neural networks across all frameworks and environments, especially outside Google Cloud.</li>\n\n\n\n<li><strong>NPUs</strong> dominate real-time, privacy-preserving, and power-efficient AI for mobile and edge, unlocking local intelligence everywhere from your phone to self-driving cars.</li>\n\n\n\n<li><strong>TPUs</strong> offer unmatched scale and speed for massive models—especially in Google’s ecosystem—pushing the frontiers of AI research and industrial deployment.</li>\n</ul>\n\n\n\n<p><strong>Choosing the right hardware depends on model size, compute demands, development environment, and desired deployment (cloud vs. edge/mobile). A robust AI stack often leverages a mix of these processors, each where it excels.</strong></p>\n<p>The post <a href=\"https://www.marktechpost.com/2025/08/03/the-ultimate-guide-to-cpus-gpus-npus-and-tpus-for-ai-ml-performance-use-cases-and-key-differences/\">The Ultimate Guide to CPUs, GPUs, NPUs, and TPUs for AI/ML: Performance, Use Cases, and Key Differences</a> appeared first on <a href=\"https://www.marktechpost.com\">MarkTechPost</a>.</p>\n",
          "content:encodedSnippet": "Artificial intelligence and machine learning workloads have fueled the evolution of specialized hardware to accelerate computation far beyond what traditional CPUs can offer. Each processing unit—CPU, GPU, NPU, TPU—plays a distinct role in the AI ecosystem, optimized for certain models, applications, or environments. Here’s a technical, data-driven breakdown of their core differences and best use cases.\nCPU (Central Processing Unit): The Versatile Workhorse\nDesign & Strengths: CPUs are general-purpose processors with a few powerful cores—ideal for single-threaded tasks and running diverse software, including operating systems, databases, and light AI/ML inference.\nAI/ML Role: CPUs can execute any kind of AI model, but lack the massive parallelism needed for efficient deep learning training or inference at scale.\nBest for:\n\nClassical ML algorithms (e.g., scikit-learn, XGBoost)\nPrototyping and model development\nInference for small models or low-throughput requirements\nTechnical Note: For neural network operations, CPU throughput (typically measured in GFLOPS—billion floating point operations per second) lags far behind specialized accelerators.\nGPU (Graphics Processing Unit): The Deep Learning Backbone\nDesign & Strengths: Originally for graphics, modern GPUs feature thousands of parallel cores designed for matrix/multiple vector operations, making them highly efficient for training and inference of deep neural networks.\nPerformance Examples:\n\nNVIDIA RTX 3090: 10,496 CUDA cores, up to 35.6 TFLOPS (teraFLOPS) FP32 compute.\nRecent NVIDIA GPUs include “Tensor Cores” for mixed precision, accelerating deep learning operations.\nBest for:\n\nTraining and inferencing large-scale deep learning models (CNNs, RNNs, Transformers)\nBatch processing typical in datacenter and research environments\nSupported by all major AI frameworks (TensorFlow, PyTorch)\nBenchmarks: A 4x RTX A5000 setup can surpass a single, far more expensive NVIDIA H100 in certain workloads, balancing acquisition cost and performance.\nNPU (Neural Processing Unit): The On-device AI Specialist\nDesign & Strengths: NPUs are ASICs (application-specific chips) crafted exclusively for neural network operations. They optimize parallel, low-precision computation for deep learning inference, often running at low power for edge and embedded devices.\nUse Cases & Applications:\n\nMobile & Consumer: Powering features like face unlock, real-time image processing, language translation on devices like the Apple A-series, Samsung Exynos, Google Tensor chips.\nEdge & IoT: Low-latency vision and speech recognition, smart city cameras, AR/VR, and manufacturing sensors.\nAutomotive: Real-time data from sensors for autonomous driving and advanced driver assistance.\nPerformance Example: The Exynos 9820’s NPU is ~7x faster than its predecessor for AI tasks.\nEfficiency: NPUs prioritize energy efficiency over raw throughput, extending battery life while supporting advanced AI features locally.\nTPU (Tensor Processing Unit): Google’s AI Powerhouse\nDesign & Strengths: TPUs are custom chips developed by Google specifically for large tensor computations, tuning hardware around the needs of frameworks like TensorFlow.\nKey Specifications:\n\nTPU v2: Up to 180 TFLOPS for neural network training and inference.\nTPU v4: Available in Google Cloud, up to 275 TFLOPS per chip, scalable to “pods” exceeding 100 petaFLOPS.\nSpecialized matrix multiplication units (“MXU”) for enormous batch computations.\nUp to 30–80x better energy efficiency (TOPS/Watt) for inference compared to contemporary GPUs and CPUs.\nBest for:\n\nTraining and serving massive models (BERT, GPT-2, EfficientNet) in cloud at scale\nHigh-throughput, low-latency AI for research and production pipelines\nTight integration with TensorFlow and JAX; increasingly interfacing with PyTorch\nNote: TPU architecture is less flexible than GPU—optimized for AI, not graphics or general-purpose tasks.\nWhich Models Run Where?\n\nHardwareBest Supported ModelsTypical Workloads\n\nCPUClassical ML, all deep learning models*General software, prototyping, small AI\nGPUCNNs, RNNs, TransformersTraining and inference (cloud/workstation)\nNPUMobileNet, TinyBERT, custom edge modelsOn-device AI, real-time vision/speech\nTPUBERT/GPT-2/ResNet/EfficientNet, etc.Large-scale model training/inference\n\n\n\n\n\n*CPUs support any model, but are not efficient for large-scale DNNs.\nData Processing Units (DPUs): The Data Movers\nRole: DPUs accelerate networking, storage, and data movement, offloading these tasks from CPUs/GPUs. They enable higher infrastructure efficiency in AI datacenters by ensuring compute resources focus on model execution, not I/O or data orchestration.\nSummary Table: Technical Comparison\n\nFeatureCPUGPUNPUTPU\n\nUse CaseGeneral ComputeDeep LearningEdge/On-device AIGoogle Cloud AI\nParallelismLow–ModerateVery High (~10,000+)Moderate–HighExtremely High (Matrix Mult.)\nEfficiencyModeratePower-hungryUltra-efficientHigh for large models\nFlexibilityMaximumVery high (all FW)SpecializedSpecialized (TensorFlow/JAX)\nHardwarex86, ARM, etc.NVIDIA, AMDApple, Samsung, ARMGoogle (Cloud only)\nExampleIntel XeonRTX 3090, A100, H100Apple Neural EngineTPU v4, Edge TPU\n\n\n\n\n\nKey Takeaways\nCPUs are unmatched for general-purpose, flexible workloads.\nGPUs remain the workhorse for training and running neural networks across all frameworks and environments, especially outside Google Cloud.\nNPUs dominate real-time, privacy-preserving, and power-efficient AI for mobile and edge, unlocking local intelligence everywhere from your phone to self-driving cars.\nTPUs offer unmatched scale and speed for massive models—especially in Google’s ecosystem—pushing the frontiers of AI research and industrial deployment.\nChoosing the right hardware depends on model size, compute demands, development environment, and desired deployment (cloud vs. edge/mobile). A robust AI stack often leverages a mix of these processors, each where it excels.\nThe post The Ultimate Guide to CPUs, GPUs, NPUs, and TPUs for AI/ML: Performance, Use Cases, and Key Differences appeared first on MarkTechPost.",
          "dc:creator": "Michal Sutter",
          "comments": "https://www.marktechpost.com/2025/08/03/the-ultimate-guide-to-cpus-gpus-npus-and-tpus-for-ai-ml-performance-use-cases-and-key-differences/#respond",
          "content": "<p>Artificial intelligence and machine learning workloads have fueled the evolution of specialized hardware to accelerate computation far beyond what traditional CPUs can offer. Each processing unit—CPU, GPU, NPU, TPU—plays a distinct role in the AI ecosystem, optimized for certain models, applications, or environments. Here’s a technical, data-driven breakdown of their core differences and best use [&#8230;]</p>\n<p>The post <a href=\"https://www.marktechpost.com/2025/08/03/the-ultimate-guide-to-cpus-gpus-npus-and-tpus-for-ai-ml-performance-use-cases-and-key-differences/\">The Ultimate Guide to CPUs, GPUs, NPUs, and TPUs for AI/ML: Performance, Use Cases, and Key Differences</a> appeared first on <a href=\"https://www.marktechpost.com\">MarkTechPost</a>.</p>\n",
          "contentSnippet": "Artificial intelligence and machine learning workloads have fueled the evolution of specialized hardware to accelerate computation far beyond what traditional CPUs can offer. Each processing unit—CPU, GPU, NPU, TPU—plays a distinct role in the AI ecosystem, optimized for certain models, applications, or environments. Here’s a technical, data-driven breakdown of their core differences and best use […]\nThe post The Ultimate Guide to CPUs, GPUs, NPUs, and TPUs for AI/ML: Performance, Use Cases, and Key Differences appeared first on MarkTechPost.",
          "guid": "https://www.marktechpost.com/?p=73178",
          "categories": [
            "AI Infrastructure",
            "Artificial Intelligence",
            "Editors Pick",
            "Staff",
            "Technology"
          ],
          "isoDate": "2025-08-03T10:38:52.000Z"
        }
      },
      {
        "json": {
          "creator": "Asif Razzaq",
          "title": "Building an End-to-End Object Tracking and Analytics System with Roboflow Supervision",
          "link": "https://www.marktechpost.com/2025/08/03/building-an-end-to-end-object-tracking-and-analytics-system-with-roboflow-supervision/",
          "pubDate": "Sun, 03 Aug 2025 09:22:28 +0000",
          "content:encoded": "\n<p>In this advanced <a href=\"https://github.com/roboflow/supervision\"><strong>Roboflow Supervision</strong></a> tutorial, we build a complete object detection pipeline with the Supervision library. We begin by setting up real-time object tracking using ByteTracker, adding detection smoothing, and defining polygon zones to monitor specific regions in a video stream. As we process the frames, we annotate them with bounding boxes, object IDs, and speed data, enabling us to track and analyze object behavior over time. Our goal is to showcase how we can combine detection, tracking, zone-based analytics, and visual annotation into a seamless and intelligent video analysis workflow. Check out the <strong><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included/blob/main/roboflow_supervision_advanced_tracking_analytics_pipeline_Marktechpost.ipynb\" target=\"_blank\" rel=\"noreferrer noopener\">Full Codes here</a><em>.</em></strong></p>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\">!pip install supervision ultralytics opencv-python\n!pip install --upgrade supervision \n\n\nimport cv2\nimport numpy as np\nimport supervision as sv\nfrom ultralytics import YOLO\nimport matplotlib.pyplot as plt\nfrom collections import defaultdict\n\n\nmodel = YOLO('yolov8n.pt')</code></pre></div></div>\n\n\n\n<p>We start by installing the necessary packages, including Supervision, Ultralytics, and OpenCV. After ensuring we have the latest version of Supervision, we import all required libraries. We then initialize the YOLOv8n model, which serves as the core detector in our pipeline. Check out the <strong><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included/blob/main/roboflow_supervision_advanced_tracking_analytics_pipeline_Marktechpost.ipynb\" target=\"_blank\" rel=\"noreferrer noopener\">Full Codes here</a><em>.</em></strong></p>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\">try:\n   tracker = sv.ByteTrack()\nexcept AttributeError:\n   try:\n       tracker = sv.ByteTracker()\n   except AttributeError:\n       print(\"Using basic tracking - install latest supervision for advanced tracking\")\n       tracker = None\n\n\ntry:\n   smoother = sv.DetectionsSmoother(length=5)\nexcept AttributeError:\n   smoother = None\n   print(\"DetectionsSmoother not available in this version\")\n\n\ntry:\n   box_annotator = sv.BoundingBoxAnnotator(thickness=2)\n   label_annotator = sv.LabelAnnotator()\n   if hasattr(sv, 'TraceAnnotator'):\n       trace_annotator = sv.TraceAnnotator(thickness=2, trace_length=30)\n   else:\n       trace_annotator = None\nexcept AttributeError:\n   try:\n       box_annotator = sv.BoxAnnotator(thickness=2)\n       label_annotator = sv.LabelAnnotator()\n       trace_annotator = None\n   except AttributeError:\n       print(\"Using basic annotators - some features may be limited\")\n       box_annotator = None\n       label_annotator = None \n       trace_annotator = None\n\n\ndef create_zones(frame_shape):\n   h, w = frame_shape[:2]\n  \n   try:\n       entry_zone = sv.PolygonZone(\n           polygon=np.array([[0, h//3], [w//3, h//3], [w//3, 2*h//3], [0, 2*h//3]]),\n           frame_resolution_wh=(w, h)\n       )\n      \n       exit_zone = sv.PolygonZone(\n           polygon=np.array([[2*w//3, h//3], [w, h//3], [w, 2*h//3], [2*w//3, 2*h//3]]),\n           frame_resolution_wh=(w, h)\n       )\n   except TypeError:\n       entry_zone = sv.PolygonZone(\n           polygon=np.array([[0, h//3], [w//3, h//3], [w//3, 2*h//3], [0, 2*h//3]])\n       )\n       exit_zone = sv.PolygonZone(\n           polygon=np.array([[2*w//3, h//3], [w, h//3], [w, 2*h//3], [2*w//3, 2*h//3]])\n       )\n  \n   return entry_zone, exit_zone</code></pre></div></div>\n\n\n\n<p>We set up essential components from the Supervision library, including object tracking with ByteTrack, optional smoothing using DetectionsSmoother, and flexible annotators for bounding boxes, labels, and traces. To ensure compatibility across versions, we use try-except blocks to fall back to alternative classes or basic functionality when needed. Additionally, we define dynamic polygon zones within the frame to monitor specific regions like entry and exit areas, enabling advanced spatial analytics. Check out the <strong><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included/blob/main/roboflow_supervision_advanced_tracking_analytics_pipeline_Marktechpost.ipynb\" target=\"_blank\" rel=\"noreferrer noopener\">Full Codes here</a><em>.</em></strong></p>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\">class AdvancedAnalytics:\n   def __init__(self):\n       self.track_history = defaultdict(list)\n       self.zone_crossings = {\"entry\": 0, \"exit\": 0}\n       self.speed_data = defaultdict(list)\n      \n   def update_tracking(self, detections):\n       if hasattr(detections, 'tracker_id') and detections.tracker_id is not None:\n           for i in range(len(detections)):\n               track_id = detections.tracker_id[i]\n               if track_id is not None:\n                   bbox = detections.xyxy[i]\n                   center = np.array([(bbox[0] + bbox[2]) / 2, (bbox[1] + bbox[3]) / 2])\n                   self.track_history[track_id].append(center)\n                  \n                   if len(self.track_history[track_id]) >= 2:\n                       prev_pos = self.track_history[track_id][-2]\n                       curr_pos = self.track_history[track_id][-1]\n                       speed = np.linalg.norm(curr_pos - prev_pos)\n                       self.speed_data[track_id].append(speed)\n  \n   def get_statistics(self):\n       total_tracks = len(self.track_history)\n       avg_speed = np.mean([np.mean(speeds) for speeds in self.speed_data.values() if speeds])\n       return {\n           \"total_objects\": total_tracks,\n           \"zone_entries\": self.zone_crossings[\"entry\"],\n           \"zone_exits\": self.zone_crossings[\"exit\"],\n           \"avg_speed\": avg_speed if not np.isnan(avg_speed) else 0\n       }\n\n\ndef process_video(source=0, max_frames=300):\n   \"\"\"\n   Process video source with advanced supervision features\n   source: video path or 0 for webcam\n   max_frames: limit processing for demo\n   \"\"\"\n   cap = cv2.VideoCapture(source)\n   analytics = AdvancedAnalytics()\n  \n   ret, frame = cap.read()\n   if not ret:\n       print(\"Failed to read video source\")\n       return\n  \n   entry_zone, exit_zone = create_zones(frame.shape)\n  \n   try:\n       entry_zone_annotator = sv.PolygonZoneAnnotator(\n           zone=entry_zone,\n           color=sv.Color.GREEN,\n           thickness=2\n       )\n       exit_zone_annotator = sv.PolygonZoneAnnotator(\n           zone=exit_zone,\n           color=sv.Color.RED,\n           thickness=2\n       )\n   except (AttributeError, TypeError):\n       entry_zone_annotator = sv.PolygonZoneAnnotator(zone=entry_zone)\n       exit_zone_annotator = sv.PolygonZoneAnnotator(zone=exit_zone)\n  \n   frame_count = 0\n   results_frames = []\n  \n   cap.set(cv2.CAP_PROP_POS_FRAMES, 0) \n  \n   while ret and frame_count &lt; max_frames:\n       ret, frame = cap.read()\n       if not ret:\n           break\n          \n       results = model(frame, verbose=False)[0]\n       detections = sv.Detections.from_ultralytics(results)\n      \n       detections = detections[detections.class_id == 0]\n      \n       if tracker is not None:\n           detections = tracker.update_with_detections(detections)\n      \n       if smoother is not None:\n           detections = smoother.update_with_detections(detections)\n      \n       analytics.update_tracking(detections)\n      \n       entry_zone.trigger(detections)\n       exit_zone.trigger(detections)\n      \n       labels = []\n       for i in range(len(detections)):\n           confidence = detections.confidence[i] if detections.confidence is not None else 0.0\n          \n           if hasattr(detections, 'tracker_id') and detections.tracker_id is not None:\n               track_id = detections.tracker_id[i]\n               if track_id is not None:\n                   speed = analytics.speed_data[track_id][-1] if analytics.speed_data[track_id] else 0\n                   label = f\"ID:{track_id} | Conf:{confidence:.2f} | Speed:{speed:.1f}\"\n               else:\n                   label = f\"Conf:{confidence:.2f}\"\n           else:\n               label = f\"Conf:{confidence:.2f}\"\n           labels.append(label)\n      \n       annotated_frame = frame.copy()\n      \n       annotated_frame = entry_zone_annotator.annotate(annotated_frame)\n       annotated_frame = exit_zone_annotator.annotate(annotated_frame)\n      \n       if trace_annotator is not None:\n           annotated_frame = trace_annotator.annotate(annotated_frame, detections)\n      \n       if box_annotator is not None:\n           annotated_frame = box_annotator.annotate(annotated_frame, detections)\n       else:\n           for i in range(len(detections)):\n               bbox = detections.xyxy[i].astype(int)\n               cv2.rectangle(annotated_frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 2)\n      \n       if label_annotator is not None:\n           annotated_frame = label_annotator.annotate(annotated_frame, detections, labels)\n       else:\n           for i, label in enumerate(labels):\n               if i &lt; len(detections):\n                   bbox = detections.xyxy[i].astype(int)\n                   cv2.putText(annotated_frame, label, (bbox[0], bbox[1]-10),\n                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n      \n       stats = analytics.get_statistics()\n       y_offset = 30\n       for key, value in stats.items():\n           text = f\"{key.replace('_', ' ').title()}: {value:.1f}\"\n           cv2.putText(annotated_frame, text, (10, y_offset),\n                      cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n           y_offset += 30\n      \n       if frame_count % 30 == 0:\n           results_frames.append(cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB))\n      \n       frame_count += 1\n      \n       if frame_count % 50 == 0:\n           print(f\"Processed {frame_count} frames...\")\n  \n   cap.release()\n  \n   if results_frames:\n       fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n       axes = axes.flatten()\n      \n       for i, (ax, frame) in enumerate(zip(axes, results_frames[:4])):\n           ax.imshow(frame)\n           ax.set_title(f\"Frame {i*30}\")\n           ax.axis('off')\n      \n       plt.tight_layout()\n       plt.show()\n  \n   final_stats = analytics.get_statistics()\n   print(\"\\n=== FINAL ANALYTICS ===\")\n   for key, value in final_stats.items():\n       print(f\"{key.replace('_', ' ').title()}: {value:.2f}\")\n  \n   return analytics\n\n\nprint(\"Starting advanced supervision demo...\")\nprint(\"Features: Object detection, tracking, zones, speed analysis, smoothing\")\n</code></pre></div></div>\n\n\n\n<p>We define the AdvancedAnalytics class to track object movement, calculate speed, and count zone crossings, enabling rich real-time video insights. Inside the process_video function, we read each frame from the video source and run it through our detection, tracking, and smoothing pipeline. We annotate frames with bounding boxes, labels, zone overlays, and live statistics, giving us a powerful, flexible system for object monitoring and spatial analytics. Throughout the loop, we also collect data for visualization and print final statistics, showcasing the effectiveness of Roboflow Supervision&#8217;s end-to-end capabilities. Check out the <strong><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included/blob/main/roboflow_supervision_advanced_tracking_analytics_pipeline_Marktechpost.ipynb\" target=\"_blank\" rel=\"noreferrer noopener\">Full Codes here</a><em>.</em></strong></p>\n\n\n\n<div class=\"dm-code-snippet dark dm-normal-version default no-background-mobile\" snippet-height=\"\" style=\"background-color:#abb8c3\"><div class=\"control-language\"><div class=\"dm-buttons\"><div class=\"dm-buttons-left\"><div class=\"dm-button-snippet red-button\"></div><div class=\"dm-button-snippet orange-button\"></div><div class=\"dm-button-snippet green-button\"></div></div><div class=\"dm-buttons-right\"><a id=\"dm-copy-raw-code\"><span class=\"dm-copy-text\">Copy Code</span><span class=\"dm-copy-confirmed\" style=\"display:none\">Copied</span><span class=\"dm-error-message\" style=\"display:none\">Use a different Browser</span></a></div></div><pre class=\" no-line-numbers\"><code id=\"dm-code-raw\" class=\" no-wrap language-php\">def create_demo_video():\n   \"\"\"Create a simple demo video with moving objects\"\"\"\n   fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n   out = cv2.VideoWriter('demo.mp4', fourcc, 20.0, (640, 480))\n  \n   for i in range(100):\n       frame = np.zeros((480, 640, 3), dtype=np.uint8)\n      \n       x1 = int(50 + i * 2)\n       y1 = 200\n       x2 = int(100 + i * 1.5)\n       y2 = 250\n      \n       cv2.rectangle(frame, (x1, y1), (x1+50, y1+50), (0, 255, 0), -1)\n       cv2.rectangle(frame, (x2, y2), (x2+50, y2+50), (255, 0, 0), -1)\n      \n       out.write(frame)\n  \n   out.release()\n   return 'demo.mp4'\n\n\ndemo_video = create_demo_video()\nanalytics = process_video(demo_video, max_frames=100)\n\n\nprint(\"\\nTutorial completed! Key features demonstrated:\")\nprint(\"✓ YOLO integration with Supervision\")\nprint(\"✓ Multi-object tracking with ByteTracker\")\nprint(\"✓ Detection smoothing\")\nprint(\"✓ Polygon zones for area monitoring\")\nprint(\"✓ Advanced annotations (boxes, labels, traces)\")\nprint(\"✓ Real-time analytics and statistics\")\nprint(\"✓ Speed calculation and tracking history\")\n</code></pre></div></div>\n\n\n\n<p>To test our full pipeline, we generate a synthetic demo video with two moving rectangles simulating tracked objects. This allows us to validate detection, tracking, zone monitoring, and speed analysis without needing a real-world input. We then run the process_video function on the generated clip. At the end, we print out a summary of all key features we&#8217;ve implemented, showcasing the power of Roboflow Supervision for real-time visual analytics.</p>\n\n\n\n<p>In conclusion, we have successfully implemented a full pipeline that brings together object detection, tracking, zone monitoring, and real-time analytics. We demonstrate how to visualize key insights like object speed, zone crossings, and tracking history with annotated video frames. This setup empowers us to go beyond basic detection and build a smart surveillance or analytics system using open-source tools. Whether for research or production use, we now have a powerful foundation to expand upon with even more advanced capabilities.</p>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity\"/>\n\n\n\n<p>Check out the <strong><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included/blob/main/roboflow_supervision_advanced_tracking_analytics_pipeline_Marktechpost.ipynb\" target=\"_blank\" rel=\"noreferrer noopener\">Full Codes here</a><em>.</em></strong> Feel free to check out our <strong><mark><a href=\"https://github.com/Marktechpost/AI-Tutorial-Codes-Included\" target=\"_blank\" rel=\"noreferrer noopener\">GitHub Page for Tutorials, Codes and Notebooks</a></mark></strong>. Also, feel free to follow us on <strong><a href=\"https://x.com/intent/follow?screen_name=marktechpost\" target=\"_blank\" rel=\"noreferrer noopener\"><mark>Twitter</mark></a></strong> and don’t forget to join our <strong><a href=\"https://www.reddit.com/r/machinelearningnews/\" target=\"_blank\" rel=\"noreferrer noopener\">100k+ ML SubReddit</a></strong> and Subscribe to <strong><a href=\"https://www.aidevsignals.com/\" target=\"_blank\" rel=\"noreferrer noopener\">our Newsletter</a></strong>.</p>\n<p>The post <a href=\"https://www.marktechpost.com/2025/08/03/building-an-end-to-end-object-tracking-and-analytics-system-with-roboflow-supervision/\">Building an End-to-End Object Tracking and Analytics System with Roboflow Supervision</a> appeared first on <a href=\"https://www.marktechpost.com\">MarkTechPost</a>.</p>\n",
          "content:encodedSnippet": "In this advanced Roboflow Supervision tutorial, we build a complete object detection pipeline with the Supervision library. We begin by setting up real-time object tracking using ByteTracker, adding detection smoothing, and defining polygon zones to monitor specific regions in a video stream. As we process the frames, we annotate them with bounding boxes, object IDs, and speed data, enabling us to track and analyze object behavior over time. Our goal is to showcase how we can combine detection, tracking, zone-based analytics, and visual annotation into a seamless and intelligent video analysis workflow. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\n!pip install supervision ultralytics opencv-python\n!pip install --upgrade supervision \n\n\nimport cv2\nimport numpy as np\nimport supervision as sv\nfrom ultralytics import YOLO\nimport matplotlib.pyplot as plt\nfrom collections import defaultdict\n\n\nmodel = YOLO('yolov8n.pt')\n\nWe start by installing the necessary packages, including Supervision, Ultralytics, and OpenCV. After ensuring we have the latest version of Supervision, we import all required libraries. We then initialize the YOLOv8n model, which serves as the core detector in our pipeline. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\ntry:\n   tracker = sv.ByteTrack()\nexcept AttributeError:\n   try:\n       tracker = sv.ByteTracker()\n   except AttributeError:\n       print(\"Using basic tracking - install latest supervision for advanced tracking\")\n       tracker = None\n\n\ntry:\n   smoother = sv.DetectionsSmoother(length=5)\nexcept AttributeError:\n   smoother = None\n   print(\"DetectionsSmoother not available in this version\")\n\n\ntry:\n   box_annotator = sv.BoundingBoxAnnotator(thickness=2)\n   label_annotator = sv.LabelAnnotator()\n   if hasattr(sv, 'TraceAnnotator'):\n       trace_annotator = sv.TraceAnnotator(thickness=2, trace_length=30)\n   else:\n       trace_annotator = None\nexcept AttributeError:\n   try:\n       box_annotator = sv.BoxAnnotator(thickness=2)\n       label_annotator = sv.LabelAnnotator()\n       trace_annotator = None\n   except AttributeError:\n       print(\"Using basic annotators - some features may be limited\")\n       box_annotator = None\n       label_annotator = None \n       trace_annotator = None\n\n\ndef create_zones(frame_shape):\n   h, w = frame_shape[:2]\n  \n   try:\n       entry_zone = sv.PolygonZone(\n           polygon=np.array([[0, h//3], [w//3, h//3], [w//3, 2*h//3], [0, 2*h//3]]),\n           frame_resolution_wh=(w, h)\n       )\n      \n       exit_zone = sv.PolygonZone(\n           polygon=np.array([[2*w//3, h//3], [w, h//3], [w, 2*h//3], [2*w//3, 2*h//3]]),\n           frame_resolution_wh=(w, h)\n       )\n   except TypeError:\n       entry_zone = sv.PolygonZone(\n           polygon=np.array([[0, h//3], [w//3, h//3], [w//3, 2*h//3], [0, 2*h//3]])\n       )\n       exit_zone = sv.PolygonZone(\n           polygon=np.array([[2*w//3, h//3], [w, h//3], [w, 2*h//3], [2*w//3, 2*h//3]])\n       )\n  \n   return entry_zone, exit_zone\n\nWe set up essential components from the Supervision library, including object tracking with ByteTrack, optional smoothing using DetectionsSmoother, and flexible annotators for bounding boxes, labels, and traces. To ensure compatibility across versions, we use try-except blocks to fall back to alternative classes or basic functionality when needed. Additionally, we define dynamic polygon zones within the frame to monitor specific regions like entry and exit areas, enabling advanced spatial analytics. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\nclass AdvancedAnalytics:\n   def __init__(self):\n       self.track_history = defaultdict(list)\n       self.zone_crossings = {\"entry\": 0, \"exit\": 0}\n       self.speed_data = defaultdict(list)\n      \n   def update_tracking(self, detections):\n       if hasattr(detections, 'tracker_id') and detections.tracker_id is not None:\n           for i in range(len(detections)):\n               track_id = detections.tracker_id[i]\n               if track_id is not None:\n                   bbox = detections.xyxy[i]\n                   center = np.array([(bbox[0] + bbox[2]) / 2, (bbox[1] + bbox[3]) / 2])\n                   self.track_history[track_id].append(center)\n                  \n                   if len(self.track_history[track_id]) >= 2:\n                       prev_pos = self.track_history[track_id][-2]\n                       curr_pos = self.track_history[track_id][-1]\n                       speed = np.linalg.norm(curr_pos - prev_pos)\n                       self.speed_data[track_id].append(speed)\n  \n   def get_statistics(self):\n       total_tracks = len(self.track_history)\n       avg_speed = np.mean([np.mean(speeds) for speeds in self.speed_data.values() if speeds])\n       return {\n           \"total_objects\": total_tracks,\n           \"zone_entries\": self.zone_crossings[\"entry\"],\n           \"zone_exits\": self.zone_crossings[\"exit\"],\n           \"avg_speed\": avg_speed if not np.isnan(avg_speed) else 0\n       }\n\n\ndef process_video(source=0, max_frames=300):\n   \"\"\"\n   Process video source with advanced supervision features\n   source: video path or 0 for webcam\n   max_frames: limit processing for demo\n   \"\"\"\n   cap = cv2.VideoCapture(source)\n   analytics = AdvancedAnalytics()\n  \n   ret, frame = cap.read()\n   if not ret:\n       print(\"Failed to read video source\")\n       return\n  \n   entry_zone, exit_zone = create_zones(frame.shape)\n  \n   try:\n       entry_zone_annotator = sv.PolygonZoneAnnotator(\n           zone=entry_zone,\n           color=sv.Color.GREEN,\n           thickness=2\n       )\n       exit_zone_annotator = sv.PolygonZoneAnnotator(\n           zone=exit_zone,\n           color=sv.Color.RED,\n           thickness=2\n       )\n   except (AttributeError, TypeError):\n       entry_zone_annotator = sv.PolygonZoneAnnotator(zone=entry_zone)\n       exit_zone_annotator = sv.PolygonZoneAnnotator(zone=exit_zone)\n  \n   frame_count = 0\n   results_frames = []\n  \n   cap.set(cv2.CAP_PROP_POS_FRAMES, 0) \n  \n   while ret and frame_count < max_frames:\n       ret, frame = cap.read()\n       if not ret:\n           break\n          \n       results = model(frame, verbose=False)[0]\n       detections = sv.Detections.from_ultralytics(results)\n      \n       detections = detections[detections.class_id == 0]\n      \n       if tracker is not None:\n           detections = tracker.update_with_detections(detections)\n      \n       if smoother is not None:\n           detections = smoother.update_with_detections(detections)\n      \n       analytics.update_tracking(detections)\n      \n       entry_zone.trigger(detections)\n       exit_zone.trigger(detections)\n      \n       labels = []\n       for i in range(len(detections)):\n           confidence = detections.confidence[i] if detections.confidence is not None else 0.0\n          \n           if hasattr(detections, 'tracker_id') and detections.tracker_id is not None:\n               track_id = detections.tracker_id[i]\n               if track_id is not None:\n                   speed = analytics.speed_data[track_id][-1] if analytics.speed_data[track_id] else 0\n                   label = f\"ID:{track_id} | Conf:{confidence:.2f} | Speed:{speed:.1f}\"\n               else:\n                   label = f\"Conf:{confidence:.2f}\"\n           else:\n               label = f\"Conf:{confidence:.2f}\"\n           labels.append(label)\n      \n       annotated_frame = frame.copy()\n      \n       annotated_frame = entry_zone_annotator.annotate(annotated_frame)\n       annotated_frame = exit_zone_annotator.annotate(annotated_frame)\n      \n       if trace_annotator is not None:\n           annotated_frame = trace_annotator.annotate(annotated_frame, detections)\n      \n       if box_annotator is not None:\n           annotated_frame = box_annotator.annotate(annotated_frame, detections)\n       else:\n           for i in range(len(detections)):\n               bbox = detections.xyxy[i].astype(int)\n               cv2.rectangle(annotated_frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 2)\n      \n       if label_annotator is not None:\n           annotated_frame = label_annotator.annotate(annotated_frame, detections, labels)\n       else:\n           for i, label in enumerate(labels):\n               if i < len(detections):\n                   bbox = detections.xyxy[i].astype(int)\n                   cv2.putText(annotated_frame, label, (bbox[0], bbox[1]-10),\n                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n      \n       stats = analytics.get_statistics()\n       y_offset = 30\n       for key, value in stats.items():\n           text = f\"{key.replace('_', ' ').title()}: {value:.1f}\"\n           cv2.putText(annotated_frame, text, (10, y_offset),\n                      cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n           y_offset += 30\n      \n       if frame_count % 30 == 0:\n           results_frames.append(cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB))\n      \n       frame_count += 1\n      \n       if frame_count % 50 == 0:\n           print(f\"Processed {frame_count} frames...\")\n  \n   cap.release()\n  \n   if results_frames:\n       fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n       axes = axes.flatten()\n      \n       for i, (ax, frame) in enumerate(zip(axes, results_frames[:4])):\n           ax.imshow(frame)\n           ax.set_title(f\"Frame {i*30}\")\n           ax.axis('off')\n      \n       plt.tight_layout()\n       plt.show()\n  \n   final_stats = analytics.get_statistics()\n   print(\"\\n=== FINAL ANALYTICS ===\")\n   for key, value in final_stats.items():\n       print(f\"{key.replace('_', ' ').title()}: {value:.2f}\")\n  \n   return analytics\n\n\nprint(\"Starting advanced supervision demo...\")\nprint(\"Features: Object detection, tracking, zones, speed analysis, smoothing\")\n\n\nWe define the AdvancedAnalytics class to track object movement, calculate speed, and count zone crossings, enabling rich real-time video insights. Inside the process_video function, we read each frame from the video source and run it through our detection, tracking, and smoothing pipeline. We annotate frames with bounding boxes, labels, zone overlays, and live statistics, giving us a powerful, flexible system for object monitoring and spatial analytics. Throughout the loop, we also collect data for visualization and print final statistics, showcasing the effectiveness of Roboflow Supervision’s end-to-end capabilities. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\ndef create_demo_video():\n   \"\"\"Create a simple demo video with moving objects\"\"\"\n   fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n   out = cv2.VideoWriter('demo.mp4', fourcc, 20.0, (640, 480))\n  \n   for i in range(100):\n       frame = np.zeros((480, 640, 3), dtype=np.uint8)\n      \n       x1 = int(50 + i * 2)\n       y1 = 200\n       x2 = int(100 + i * 1.5)\n       y2 = 250\n      \n       cv2.rectangle(frame, (x1, y1), (x1+50, y1+50), (0, 255, 0), -1)\n       cv2.rectangle(frame, (x2, y2), (x2+50, y2+50), (255, 0, 0), -1)\n      \n       out.write(frame)\n  \n   out.release()\n   return 'demo.mp4'\n\n\ndemo_video = create_demo_video()\nanalytics = process_video(demo_video, max_frames=100)\n\n\nprint(\"\\nTutorial completed! Key features demonstrated:\")\nprint(\"✓ YOLO integration with Supervision\")\nprint(\"✓ Multi-object tracking with ByteTracker\")\nprint(\"✓ Detection smoothing\")\nprint(\"✓ Polygon zones for area monitoring\")\nprint(\"✓ Advanced annotations (boxes, labels, traces)\")\nprint(\"✓ Real-time analytics and statistics\")\nprint(\"✓ Speed calculation and tracking history\")\n\n\nTo test our full pipeline, we generate a synthetic demo video with two moving rectangles simulating tracked objects. This allows us to validate detection, tracking, zone monitoring, and speed analysis without needing a real-world input. We then run the process_video function on the generated clip. At the end, we print out a summary of all key features we’ve implemented, showcasing the power of Roboflow Supervision for real-time visual analytics.\nIn conclusion, we have successfully implemented a full pipeline that brings together object detection, tracking, zone monitoring, and real-time analytics. We demonstrate how to visualize key insights like object speed, zone crossings, and tracking history with annotated video frames. This setup empowers us to go beyond basic detection and build a smart surveillance or analytics system using open-source tools. Whether for research or production use, we now have a powerful foundation to expand upon with even more advanced capabilities.\nCheck out the Full Codes here. Feel free to check out our GitHub Page for Tutorials, Codes and Notebooks. Also, feel free to follow us on Twitter and don’t forget to join our 100k+ ML SubReddit and Subscribe to our Newsletter.\nThe post Building an End-to-End Object Tracking and Analytics System with Roboflow Supervision appeared first on MarkTechPost.",
          "dc:creator": "Asif Razzaq",
          "comments": "https://www.marktechpost.com/2025/08/03/building-an-end-to-end-object-tracking-and-analytics-system-with-roboflow-supervision/#respond",
          "content": "<p>In this advanced Roboflow Supervision tutorial, we build a complete object detection pipeline with the Supervision library. We begin by setting up real-time object tracking using ByteTracker, adding detection smoothing, and defining polygon zones to monitor specific regions in a video stream. As we process the frames, we annotate them with bounding boxes, object IDs, [&#8230;]</p>\n<p>The post <a href=\"https://www.marktechpost.com/2025/08/03/building-an-end-to-end-object-tracking-and-analytics-system-with-roboflow-supervision/\">Building an End-to-End Object Tracking and Analytics System with Roboflow Supervision</a> appeared first on <a href=\"https://www.marktechpost.com\">MarkTechPost</a>.</p>\n",
          "contentSnippet": "In this advanced Roboflow Supervision tutorial, we build a complete object detection pipeline with the Supervision library. We begin by setting up real-time object tracking using ByteTracker, adding detection smoothing, and defining polygon zones to monitor specific regions in a video stream. As we process the frames, we annotate them with bounding boxes, object IDs, […]\nThe post Building an End-to-End Object Tracking and Analytics System with Roboflow Supervision appeared first on MarkTechPost.",
          "guid": "https://www.marktechpost.com/?p=73175",
          "categories": [
            "Artificial Intelligence",
            "Editors Pick",
            "Machine Learning",
            "Staff",
            "Tech News",
            "Technology",
            "Tutorials"
          ],
          "isoDate": "2025-08-03T09:22:28.000Z"
        }
      },
      {
        "json": {
          "creator": "EScholar: Electronic Academic Papers for Scholars",
          "title": "The Impossibility Theorem Behind Truthful Blockchain Bidding Mechanisms",
          "link": "https://hackernoon.com/the-impossibility-theorem-behind-truthful-blockchain-bidding-mechanisms?source=rss",
          "pubDate": "Sun, 03 Aug 2025 21:14:40 GMT",
          "content:encoded": "<h2 id=\"tableoflinks\">Table of Links</h2>\n<p><a href=\"https://hackernoon.com/preview/4oLJMbsTSjvo3VPjkwJP\">Abstract and 1. Introduction</a></p>\n<p><a href=\"http://hackernoon.com/preview/6civAjDXiM0nLRxmISCX\">1.1 Our Contributions</a></p>\n<p><a href=\"https://hackernoon.com/preview/rn535RkNoZ9IjhCV1Q3Z\">1.2 TFM Incentive-Compatibility Notions: A Cheat Sheet</a></p>\n<ol start=\"2\">\n<li><p>Definitions</p>\n<p><a href=\"http://hackernoon.com/preview/3AUt2wksTUSPQlT9CWPJ\">2.1 Transaction Fee Mechanism</a></p>\n<p><a href=\"http://hackernoon.com/preview/3AUt2wksTUSPQlT9CWPJ\">2.2 Incentive Compatibility Notions</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">Preliminary: Myerson’s Lemma</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">Warmup: Impossibility of UIC + MIC + Global SCP for Deterministic Mechanisms</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">Impossibility of UIC + MIC + Global SCP for Randomized Mechanisms and 5.1 Proof Roadmap</a></p>\n<p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">5.2 Formal Proofs</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">Feasibility and Impossibility of UIC + MIC + OCA-Proof</a></p>\n<p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">6.1 A Non-Truthful Mechanism with UIC + MIC + OCA-Proof</a></p>\n<p><a href=\"https://hackernoon.com/preview/2K7Tn6O6GAIT00hMX9DK\">6.2 Impossibility of UIC + MIC + OCA-Proof for Truthful Mechanisms</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">How to Circumvent the Impossibilities and 7.1 Allowing the Globally Optimal Strategy to Coordinate</a></p>\n<p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">7.2 Allowing the Globally Optimal Strategy to Output Multiple Bids</a></p>\n<p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">7.3 Inclusion-Rule-Respecting and 7.4 Discussions and Open Questions Regarding the Use of Cryptography</a></p></li>\n<li><p><a href=\"http://hackernoon.com/preview/Z8dr9maz547Ssrjgsu3J\">Static Revelation Principle for Transaction Fee Mechanisms</a></p>\n<p><a href=\"http://hackernoon.com/preview/Z8dr9maz547Ssrjgsu3J\">8.1 Static Revelation Principle: Bidding Rules That Output Single Bid</a></p>\n<p><a href=\"http://hackernoon.com/preview/UMYlU2A57LPtnNi7V0N8\">8.2 Static Revelation Principle: Allowing Bidding Rules that Output Multiple Bids</a></p></li>\n</ol>\n<p><a href=\"http://hackernoon.com/preview/I4X49OO1ZsInqtfGbfPe\">A. Comparison of Collusion-Resilience Notions</a></p>\n<p><a href=\"http://hackernoon.com/preview/I4X49OO1ZsInqtfGbfPe\">References</a></p>\n<p>\\</p>\n<h2 id=\"6feasibilityandimpossibilityofuicmicocaproof\">6 Feasibility and Impossibility of UIC + MIC + OCA-Proof</h2>\n<p>We can generalize the proof in Section 5, and rule out UIC, MIC, and OCA-proof (rather than global SCP) for truthful mechanisms. Recall that for a truthful mechanism, the difference between OCA-proof and global SCP is that global SCP insists that the optimal strategy of the global coalition is the truthful strategy, whereas OCA-proofness allows it to be some other strategy in which each user acts independently and bids the outcome of some function σ(·).</p>\n<p>\\\nInterestingly, if we allow the bidding rule to be not truth-telling, i.e. considering non-truthful mechanisms, we can have a mechanism that satisfies UIC, MIC, and OCA-proof. We present the feasibility for non-truthful mechanisms in Section 6.1, and we prove the impossibility of UIC + MIC + OCA-proof for truthful mechanisms in Section 6.2. Notice that because of the feasibility in Section 6.1, we must require the bidding rule to be truth-telling to reach an impossibility in Section 6.2.</p>\n<h2 id=\"61anontruthfulmechanismwithuicmicocaproof\">6.1 A Non-Truthful Mechanism with UIC + MIC + OCA-Proof</h2>\n<p>The rationale of the design is to signal to the mechanism when everyone is adopting the globally optimal strategy σ (as opposed to the bidding rule used to establish UIC). When the mechanism detects that everyone is behaving according to σ, it adopts a different behavior to optimize social welfare. We use the range [0, 1) to encode the actual bid, and use the range [1,∞) for signalling. While the resulting mechanism is somewhat contrived and not necessarily meaningful from a practical point of view, it clarifies which notions of collusion-resilience most accurately capture the intended modeling goals and illustrates some technical challenges involved in the proof in Section 6.2. Consider the following TFM:</p>\n<p>\\\n<strong>• Globally optimal strategy</strong> σ(v): Given a true value v, output a bid v + 1.</p>\n<p>\\\n<strong>• Bidding rule</strong>: Given a true value v, output a bid 1/(v + 2).</p>\n<p>\\\n<strong>• Inclusion rule</strong>: Let S be the set of all pending bids that are in [0, 1). If |S| &gt; k, then randomly select k bids from S to include. If 1 ≤ |S| ≤ k, then include all bids in S. If |S| = 0, choose the top up to k bids to include.</p>\n<p>\\\n<strong>• Confirmation, payment, and miner revenue rules</strong>: All included bids are confirmed. Each confirmed bid pays nothing, and the miner gets nothing.</p>\n<p>\\\nObviously, this mechanism is non-trivial.</p>\n<p>\\\n<strong>Claim 6.1.</strong> <em>The above mechanism satisfies UIC, MIC, and OCA-proofness.</em></p>\n<p>\\\n<em>Proof</em>. For UIC, notice that if a user follows the bidding rule, its bid is always in [0, 1). If there is no bid in [0, 1) before a user submits its bid, then bidding 1/(v + 2) always guarantees user’s bid to be included and confirmed, where v denote the true value. If there is already some bids in [0, 1) before a user submits its bid, then bidding 1/(v + 2) is a dominant strategy since it guarantees the user’s bid is added to S, the set of all bids in [0, 1), which is the best a user can do. Next, MIC holds since the miner revenue is always zero. Finally, if all users follow the globally optimal strategy σ, everyone’s bid is at least 1. The honest inclusion rule will include the top up to k bids, which maximizes the social welfare. Thus, OCA-proofness holds.</p>\n<p>\\\n<strong>Remark 1.</strong> We can try to apply revelation principle, and bake the bidding rule into the mechanism so that the resulting mechanism is truthful. For example, whenever seeing a bid b, the miner and the mechanism view it as 1/(b + 2). The modified mechanism, however, does not satisfy OCAproofness anymore when the number of users is larger than the block size, since the miner should choose k users with the highest true values instead of the random selection as indicated by the inclusion rule. This is not a coincidence: in the next section, we show that it is impossible to have a non-trivial truthful mechanism satisfying UIC, MIC, and OCA-proofness.</p>\n<p>\\</p>\n<p>:::info\n<strong>Authors:</strong></p>\n<p>(1) Hao Chung∗, Carnegie Mellon University (haochung@andrew.cmu.edu);</p>\n<p>(2) Tim Roughgarden†, Columbia University and a16z (crypto tim.roughgarden@gmail.com);</p>\n<p>(3) Elaine Shi∗, Carnegie Mellon University (runting@cs.cmu.edu).</p>\n<p>:::</p>\n<hr />\n<p>:::info\nThis paper is <strong><a href=\"https://arxiv.org/abs/2402.09321\">available on arxiv</a></strong> under CC BY 4.0 DEED license.</p>\n<p>:::</p>\n<p>\\</p>",
          "content:encodedSnippet": "Table of Links\nAbstract and 1. Introduction\n1.1 Our Contributions\n1.2 TFM Incentive-Compatibility Notions: A Cheat Sheet\nDefinitions\n2.1 Transaction Fee Mechanism\n2.2 Incentive Compatibility Notions\n\n\nPreliminary: Myerson’s Lemma\n\n\nWarmup: Impossibility of UIC + MIC + Global SCP for Deterministic Mechanisms\n\n\nImpossibility of UIC + MIC + Global SCP for Randomized Mechanisms and 5.1 Proof Roadmap\n5.2 Formal Proofs\n\n\nFeasibility and Impossibility of UIC + MIC + OCA-Proof\n6.1 A Non-Truthful Mechanism with UIC + MIC + OCA-Proof\n6.2 Impossibility of UIC + MIC + OCA-Proof for Truthful Mechanisms\n\n\nHow to Circumvent the Impossibilities and 7.1 Allowing the Globally Optimal Strategy to Coordinate\n7.2 Allowing the Globally Optimal Strategy to Output Multiple Bids\n7.3 Inclusion-Rule-Respecting and 7.4 Discussions and Open Questions Regarding the Use of Cryptography\n\n\nStatic Revelation Principle for Transaction Fee Mechanisms\n8.1 Static Revelation Principle: Bidding Rules That Output Single Bid\n8.2 Static Revelation Principle: Allowing Bidding Rules that Output Multiple Bids\n\n\nA. Comparison of Collusion-Resilience Notions\nReferences\n\\\n6 Feasibility and Impossibility of UIC + MIC + OCA-Proof\nWe can generalize the proof in Section 5, and rule out UIC, MIC, and OCA-proof (rather than global SCP) for truthful mechanisms. Recall that for a truthful mechanism, the difference between OCA-proof and global SCP is that global SCP insists that the optimal strategy of the global coalition is the truthful strategy, whereas OCA-proofness allows it to be some other strategy in which each user acts independently and bids the outcome of some function σ(·).\n\\\nInterestingly, if we allow the bidding rule to be not truth-telling, i.e. considering non-truthful mechanisms, we can have a mechanism that satisfies UIC, MIC, and OCA-proof. We present the feasibility for non-truthful mechanisms in Section 6.1, and we prove the impossibility of UIC + MIC + OCA-proof for truthful mechanisms in Section 6.2. Notice that because of the feasibility in Section 6.1, we must require the bidding rule to be truth-telling to reach an impossibility in Section 6.2.\n6.1 A Non-Truthful Mechanism with UIC + MIC + OCA-Proof\nThe rationale of the design is to signal to the mechanism when everyone is adopting the globally optimal strategy σ (as opposed to the bidding rule used to establish UIC). When the mechanism detects that everyone is behaving according to σ, it adopts a different behavior to optimize social welfare. We use the range [0, 1) to encode the actual bid, and use the range [1,∞) for signalling. While the resulting mechanism is somewhat contrived and not necessarily meaningful from a practical point of view, it clarifies which notions of collusion-resilience most accurately capture the intended modeling goals and illustrates some technical challenges involved in the proof in Section 6.2. Consider the following TFM:\n\\\n• Globally optimal strategy σ(v): Given a true value v, output a bid v + 1.\n\\\n• Bidding rule: Given a true value v, output a bid 1/(v + 2).\n\\\n• Inclusion rule: Let S be the set of all pending bids that are in [0, 1). If |S| > k, then randomly select k bids from S to include. If 1 ≤ |S| ≤ k, then include all bids in S. If |S| = 0, choose the top up to k bids to include.\n\\\n• Confirmation, payment, and miner revenue rules: All included bids are confirmed. Each confirmed bid pays nothing, and the miner gets nothing.\n\\\nObviously, this mechanism is non-trivial.\n\\\nClaim 6.1. The above mechanism satisfies UIC, MIC, and OCA-proofness.\n\\\nProof. For UIC, notice that if a user follows the bidding rule, its bid is always in [0, 1). If there is no bid in [0, 1) before a user submits its bid, then bidding 1/(v + 2) always guarantees user’s bid to be included and confirmed, where v denote the true value. If there is already some bids in [0, 1) before a user submits its bid, then bidding 1/(v + 2) is a dominant strategy since it guarantees the user’s bid is added to S, the set of all bids in [0, 1), which is the best a user can do. Next, MIC holds since the miner revenue is always zero. Finally, if all users follow the globally optimal strategy σ, everyone’s bid is at least 1. The honest inclusion rule will include the top up to k bids, which maximizes the social welfare. Thus, OCA-proofness holds.\n\\\nRemark 1. We can try to apply revelation principle, and bake the bidding rule into the mechanism so that the resulting mechanism is truthful. For example, whenever seeing a bid b, the miner and the mechanism view it as 1/(b + 2). The modified mechanism, however, does not satisfy OCAproofness anymore when the number of users is larger than the block size, since the miner should choose k users with the highest true values instead of the random selection as indicated by the inclusion rule. This is not a coincidence: in the next section, we show that it is impossible to have a non-trivial truthful mechanism satisfying UIC, MIC, and OCA-proofness.\n\\\n:::info\nAuthors:\n(1) Hao Chung∗, Carnegie Mellon University (haochung@andrew.cmu.edu);\n(2) Tim Roughgarden†, Columbia University and a16z (crypto tim.roughgarden@gmail.com);\n(3) Elaine Shi∗, Carnegie Mellon University (runting@cs.cmu.edu).\n:::\n:::info\nThis paper is available on arxiv under CC BY 4.0 DEED license.\n:::\n\\",
          "dc:creator": "EScholar: Electronic Academic Papers for Scholars",
          "content": "This article delves into the theoretical limits of blockchain bidding mechanisms, showing that no non-trivial truthful mechanism—deterministic or randomized—can satisfy all three key properties: User Incentive Compatibility (UIC), Miner Incentive Compatibility (MIC), and Global Social Cost Property (SCP), within a finite block size. Using Myerson’s Lemma and rigorous proofs, it demonstrates inherent trade-offs in mechanism design that challenge the feasibility of universally fair and efficient blockchain protocols.",
          "contentSnippet": "This article delves into the theoretical limits of blockchain bidding mechanisms, showing that no non-trivial truthful mechanism—deterministic or randomized—can satisfy all three key properties: User Incentive Compatibility (UIC), Miner Incentive Compatibility (MIC), and Global Social Cost Property (SCP), within a finite block size. Using Myerson’s Lemma and rigorous proofs, it demonstrates inherent trade-offs in mechanism design that challenge the feasibility of universally fair and efficient blockchain protocols.",
          "guid": "https://hackernoon.com/the-impossibility-theorem-behind-truthful-blockchain-bidding-mechanisms?source=rss",
          "categories": [
            "blockchain-scalability",
            "transaction-fee-mechanisms",
            "ethereum-eip-1559",
            "user-incentive-compatibility",
            "miner-incentive-compatibility",
            "oca-proofness",
            "side-contract-proofness",
            "auction-mechanisms"
          ],
          "isoDate": "2025-08-03T21:14:40.000Z"
        }
      },
      {
        "json": {
          "creator": "EScholar: Electronic Academic Papers for Scholars",
          "title": "No Blockchain Auction Can Satisfy UIC, MIC, and Global SCP at Once",
          "link": "https://hackernoon.com/no-blockchain-auction-can-satisfy-uic-mic-and-global-scp-at-once?source=rss",
          "pubDate": "Sun, 03 Aug 2025 21:14:35 GMT",
          "content:encoded": "<h2 id=\"tableoflinks\">Table of Links</h2>\n<p><a href=\"https://hackernoon.com/preview/4oLJMbsTSjvo3VPjkwJP\">Abstract and 1. Introduction</a></p>\n<p><a href=\"http://hackernoon.com/preview/6civAjDXiM0nLRxmISCX\">1.1 Our Contributions</a></p>\n<p><a href=\"https://hackernoon.com/preview/rn535RkNoZ9IjhCV1Q3Z\">1.2 TFM Incentive-Compatibility Notions: A Cheat Sheet</a></p>\n<ol start=\"2\">\n<li><p>Definitions</p>\n<p><a href=\"http://hackernoon.com/preview/3AUt2wksTUSPQlT9CWPJ\">2.1 Transaction Fee Mechanism</a></p>\n<p><a href=\"http://hackernoon.com/preview/3AUt2wksTUSPQlT9CWPJ\">2.2 Incentive Compatibility Notions</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">Preliminary: Myerson’s Lemma</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">Warmup: Impossibility of UIC + MIC + Global SCP for Deterministic Mechanisms</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">Impossibility of UIC + MIC + Global SCP for Randomized Mechanisms and 5.1 Proof Roadmap</a></p>\n<p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">5.2 Formal Proofs</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">Feasibility and Impossibility of UIC + MIC + OCA-Proof</a></p>\n<p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">6.1 A Non-Truthful Mechanism with UIC + MIC + OCA-Proof</a></p>\n<p><a href=\"https://hackernoon.com/preview/2K7Tn6O6GAIT00hMX9DK\">6.2 Impossibility of UIC + MIC + OCA-Proof for Truthful Mechanisms</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">How to Circumvent the Impossibilities and 7.1 Allowing the Globally Optimal Strategy to Coordinate</a></p>\n<p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">7.2 Allowing the Globally Optimal Strategy to Output Multiple Bids</a></p>\n<p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">7.3 Inclusion-Rule-Respecting and 7.4 Discussions and Open Questions Regarding the Use of Cryptography</a></p></li>\n<li><p><a href=\"http://hackernoon.com/preview/Z8dr9maz547Ssrjgsu3J\">Static Revelation Principle for Transaction Fee Mechanisms</a></p>\n<p><a href=\"http://hackernoon.com/preview/Z8dr9maz547Ssrjgsu3J\">8.1 Static Revelation Principle: Bidding Rules That Output Single Bid</a></p>\n<p><a href=\"http://hackernoon.com/preview/UMYlU2A57LPtnNi7V0N8\">8.2 Static Revelation Principle: Allowing Bidding Rules that Output Multiple Bids</a></p></li>\n</ol>\n<p><a href=\"http://hackernoon.com/preview/I4X49OO1ZsInqtfGbfPe\">A. Comparison of Collusion-Resilience Notions</a></p>\n<p><a href=\"http://hackernoon.com/preview/I4X49OO1ZsInqtfGbfPe\">References</a></p>\n<h2 id=\"3preliminarymyersonslemma\">3 Preliminary: Myerson’s Lemma</h2>\n<p><img src=\"https://cdn.hackernoon.com/images/fWZa4tUiBGemnqQfBGgCPf9594N2-v1833xk.png\" alt=\"\" /></p>\n<p>\\\nConceptually, user <em>i</em> must pay the minimal price which makes its bid confirmed.</p>\n<h2 id=\"4warmupimpossibilityofuicmicglobalscpfordeterministicmechanisms\">4 Warmup: Impossibility of UIC + MIC + Global SCP for Deterministic Mechanisms</h2>\n<p>As a warmup, we first show a finite-block impossibility for UIC + MIC + global SCP for <em>deterministic</em> mechanisms. Recall that a TFM is said to be trivial if everyone’s confirmation probability is zero for any bid vector assuming the miner follows the inclusion rule. In this case, everyone’s utility is always zero in an honest execution. We will show that no non-trivial mechanism can satisfy all three properties simultaneously. Later in Section 5, we extend the impossibility to randomized mechanisms. Due to the revelation principle that we prove in Section 8, if we can prove the impossibility for truthful mechanisms, the impossibility immediately extends to non-truthful mechanisms as well. Therefore, in this section, we shall assume truthful mechanisms.</p>\n<p>\\\n<strong>Lemma 4.1.</strong> <em>For any global SCP mechanism, the confirmed bids must correspond to the highest bids.</em></p>\n<p>\\\n<em>Proof</em>. Suppose in some scenario, Alice bids her true value b and Bob bids his true value b ′ &lt; b; however, Bob’s bid is confirmed, and Alice’s is not. Now, we can have Alice and Bob swap their bids. The miner creates the same block as before in which the position originally corresponding to Bob now has Alice’s bid of b′. Since the mechanism is weakly symmetric (Definition 1), Alice’s bid is confirmed. This way, the social welfare increases by b − b′ in comparison with the honest case, and this violates global SCP.</p>\n<p>\\\n<strong>Lemma 4.2.</strong> <em>For any global SCP mechanism, the amount of burnt coins depends only on the number of confirmed bids.</em></p>\n<p>\\\n<em>Proof</em>. Suppose in two different scenarios, when everyone acts honestly, the blocks made are <strong>B</strong> and <strong>B</strong>′ respectively, the confirmed bids are <strong>b</strong> ⊆ <strong>B</strong> and <strong>b</strong>′ ⊆ <strong>B</strong>′ respectively where <strong>b</strong> and <strong>b</strong>′ are of the same length, and the burnt amount in the two scenarios are <em>q</em> and <em>q′</em> respectively, where <em>q</em> &lt; <em>q′</em>. Now, suppose we are actually in the second scenario. A global coalition can adopt the following strategy: create a block identical to <strong>B</strong> in which the confirmed bids correspond to the users with the highest true values and the rest can be fake bids. Observe that the social welfare is the sum of the true values of all confirmed bids (where fake bids have a true value of 0) minus the total coins burnt. Therefore, the above strategy achieves strictly higher social welfare than the honest case.</p>\n<p>\\\n<strong>Theorem 4.3.</strong> <em>No non-trivial deterministic TFM can simultaneously satisfy UIC, MIC, and global SCP when the block size is finite.</em></p>\n<p>\\\n\\\n <img src=\"https://cdn.hackernoon.com/images/fWZa4tUiBGemnqQfBGgCPf9594N2-nt83210.png\" alt=\"\" /></p>\n<h2 id=\"5impossibilityofuicmicglobalscpforrandomizedmechanisms\">5 Impossibility of UIC + MIC + Global SCP for Randomized Mechanisms</h2>\n<p>In this section, we extend the finite-block impossibility of UIC + MIC + global SCP to even randomized mechanisms. Recall that a TFM consists of five rules as defined in Section 2.1, and a randomized TFM may use randomness in any of the five rules. Since the confirmation, the payment, and the miner revenue rules are executed by the blockchain, the strategic players can only bias the randomness in and deviate from the bidding rule and the inclusion rule. Again, due to the revelation principle proven in Section 8, it suffices to consider truthful mechanisms.</p>\n<h3 id=\"51proofroadmap\">5.1 Proof Roadmap</h3>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/fWZa4tUiBGemnqQfBGgCPf9594N2-3f832vd.png\" alt=\"\" /></p>\n<h2 id=\"52formalproofs\">5.2 Formal Proofs</h2>\n<p>In the rest of this section, we present the formal proofs.</p>\n<p>\\\n\\\n <img src=\"https://cdn.hackernoon.com/images/fWZa4tUiBGemnqQfBGgCPf9594N2-rc83383.png\" alt=\"\" /></p>\n<p>\\\n\\\n\\\n <img src=\"https://cdn.hackernoon.com/images/fWZa4tUiBGemnqQfBGgCPf9594N2-8v933x4.png\" alt=\"\" /></p>\n<p>\\\n\\\n\\\n <img src=\"https://cdn.hackernoon.com/images/fWZa4tUiBGemnqQfBGgCPf9594N2-3ma33cm.png\" alt=\"\" /></p>\n<p>\\\n\\\n<em>Proof</em>. We first prove that expected miner utility is the same in both scenarios. Suppose this is not true, and without loss of generality, suppose expected miner utility is higher in scenario 1. Then, the miner can ignore the bids <strong>b</strong>, inject the fake bids <strong>b</strong>′, pretend that the bid vector is (<strong>a</strong>, <strong>b</strong>′), and run the honest mechanism. Since the confirmation probability of <strong>b</strong>′ is 0, the miner need not pay any cost for the fake bids. Therefore, the miner gets higher expected utility by taking the above strategy which violates MIC.</p>\n<p>\\\nThe proof of total social welfare is similar. Suppose without loss of generality, that the expected total social welfare in scenario 1 is higher. Then, the global coalition can inject fake bids <strong>b</strong>′ and pretend that the bid vector is (<strong>a</strong>, <strong>b</strong>′), thus allowing it to increase its expected social welfare. This violates global SCP.</p>\n<p>\\\nThe equivalence in total user utility follows directly from the above, since total user utility is the difference between the social welfare and the miner utility.</p>\n<p>\\\n\\\n <img src=\"https://cdn.hackernoon.com/images/fWZa4tUiBGemnqQfBGgCPf9594N2-mib3363.png\" alt=\"\" /></p>\n<p>\\\n\\\n\\\n <img src=\"https://cdn.hackernoon.com/images/fWZa4tUiBGemnqQfBGgCPf9594N2-cnc33mx.png\" alt=\"\" /></p>\n<p>\\\n\\\n<strong>Lemma 5.5.</strong> <em>Suppose the mechanism satisfies UIC, MIC, and global SCP, and the block size is k. Let a be any positive real number. Consider a scenario with only one bid a. Then, the only user’s utility is zero assuming it bids its true value.</em></p>\n<p>\\\n\\\n <img src=\"https://cdn.hackernoon.com/images/fWZa4tUiBGemnqQfBGgCPf9594N2-rvd33mk.png\" alt=\"\" /></p>\n<p>\\\n\\\n<strong>Theorem 5.6.</strong> <em>No non-trivial, possibly randomized TFM can simultaneously satisfy UIC, MIC, and global SCP when the block size is finite.</em></p>\n<p>\\\n<em>Proof</em>. We will show that under any sufficiently large a, the confirmation probability under a single bid a is non-zero. If we can show this, then we can show a contradiction to UIC. Specifically, consider b &gt; a and both sufficiently large. By Lemma 5.5, if there is only one user with true value b, its utility is zero when it bids truthfully. However, the user can underbid a. Since the confirmation probability is non-zero and the payment is at most a, the user enjoys positive utility, which violates UIC.</p>\n<p>\\\n\\\n <img src=\"https://cdn.hackernoon.com/images/fWZa4tUiBGemnqQfBGgCPf9594N2-nwe33bm.png\" alt=\"\" /></p>\n<p>\\\n\\</p>\n<p>:::info\n<strong>Authors:</strong></p>\n<p>(1) Hao Chung∗, Carnegie Mellon University (haochung@andrew.cmu.edu);</p>\n<p>(2) Tim Roughgarden†, Columbia University and a16z (crypto tim.roughgarden@gmail.com);</p>\n<p>(3) Elaine Shi∗, Carnegie Mellon University (runting@cs.cmu.edu).</p>\n<p>:::</p>\n<hr />\n<p>:::info\nThis paper is <strong><a href=\"https://arxiv.org/abs/2402.09321\">available on arxiv</a></strong> under CC BY 4.0 DEED license.</p>\n<p>:::</p>\n<p>\\</p>",
          "content:encodedSnippet": "Table of Links\nAbstract and 1. Introduction\n1.1 Our Contributions\n1.2 TFM Incentive-Compatibility Notions: A Cheat Sheet\nDefinitions\n2.1 Transaction Fee Mechanism\n2.2 Incentive Compatibility Notions\n\n\nPreliminary: Myerson’s Lemma\n\n\nWarmup: Impossibility of UIC + MIC + Global SCP for Deterministic Mechanisms\n\n\nImpossibility of UIC + MIC + Global SCP for Randomized Mechanisms and 5.1 Proof Roadmap\n5.2 Formal Proofs\n\n\nFeasibility and Impossibility of UIC + MIC + OCA-Proof\n6.1 A Non-Truthful Mechanism with UIC + MIC + OCA-Proof\n6.2 Impossibility of UIC + MIC + OCA-Proof for Truthful Mechanisms\n\n\nHow to Circumvent the Impossibilities and 7.1 Allowing the Globally Optimal Strategy to Coordinate\n7.2 Allowing the Globally Optimal Strategy to Output Multiple Bids\n7.3 Inclusion-Rule-Respecting and 7.4 Discussions and Open Questions Regarding the Use of Cryptography\n\n\nStatic Revelation Principle for Transaction Fee Mechanisms\n8.1 Static Revelation Principle: Bidding Rules That Output Single Bid\n8.2 Static Revelation Principle: Allowing Bidding Rules that Output Multiple Bids\n\n\nA. Comparison of Collusion-Resilience Notions\nReferences\n3 Preliminary: Myerson’s Lemma\n\n\\\nConceptually, user i must pay the minimal price which makes its bid confirmed.\n4 Warmup: Impossibility of UIC + MIC + Global SCP for Deterministic Mechanisms\nAs a warmup, we first show a finite-block impossibility for UIC + MIC + global SCP for deterministic mechanisms. Recall that a TFM is said to be trivial if everyone’s confirmation probability is zero for any bid vector assuming the miner follows the inclusion rule. In this case, everyone’s utility is always zero in an honest execution. We will show that no non-trivial mechanism can satisfy all three properties simultaneously. Later in Section 5, we extend the impossibility to randomized mechanisms. Due to the revelation principle that we prove in Section 8, if we can prove the impossibility for truthful mechanisms, the impossibility immediately extends to non-truthful mechanisms as well. Therefore, in this section, we shall assume truthful mechanisms.\n\\\nLemma 4.1. For any global SCP mechanism, the confirmed bids must correspond to the highest bids.\n\\\nProof. Suppose in some scenario, Alice bids her true value b and Bob bids his true value b ′ < b; however, Bob’s bid is confirmed, and Alice’s is not. Now, we can have Alice and Bob swap their bids. The miner creates the same block as before in which the position originally corresponding to Bob now has Alice’s bid of b′. Since the mechanism is weakly symmetric (Definition 1), Alice’s bid is confirmed. This way, the social welfare increases by b − b′ in comparison with the honest case, and this violates global SCP.\n\\\nLemma 4.2. For any global SCP mechanism, the amount of burnt coins depends only on the number of confirmed bids.\n\\\nProof. Suppose in two different scenarios, when everyone acts honestly, the blocks made are B and B′ respectively, the confirmed bids are b ⊆ B and b′ ⊆ B′ respectively where b and b′ are of the same length, and the burnt amount in the two scenarios are q and q′ respectively, where q < q′. Now, suppose we are actually in the second scenario. A global coalition can adopt the following strategy: create a block identical to B in which the confirmed bids correspond to the users with the highest true values and the rest can be fake bids. Observe that the social welfare is the sum of the true values of all confirmed bids (where fake bids have a true value of 0) minus the total coins burnt. Therefore, the above strategy achieves strictly higher social welfare than the honest case.\n\\\nTheorem 4.3. No non-trivial deterministic TFM can simultaneously satisfy UIC, MIC, and global SCP when the block size is finite.\n\\\n\\\n \n5 Impossibility of UIC + MIC + Global SCP for Randomized Mechanisms\nIn this section, we extend the finite-block impossibility of UIC + MIC + global SCP to even randomized mechanisms. Recall that a TFM consists of five rules as defined in Section 2.1, and a randomized TFM may use randomness in any of the five rules. Since the confirmation, the payment, and the miner revenue rules are executed by the blockchain, the strategic players can only bias the randomness in and deviate from the bidding rule and the inclusion rule. Again, due to the revelation principle proven in Section 8, it suffices to consider truthful mechanisms.\n5.1 Proof Roadmap\n\\\n \n5.2 Formal Proofs\nIn the rest of this section, we present the formal proofs.\n\\\n\\\n \n\\\n\\\n\\\n \n\\\n\\\n\\\n \n\\\n\\\nProof. We first prove that expected miner utility is the same in both scenarios. Suppose this is not true, and without loss of generality, suppose expected miner utility is higher in scenario 1. Then, the miner can ignore the bids b, inject the fake bids b′, pretend that the bid vector is (a, b′), and run the honest mechanism. Since the confirmation probability of b′ is 0, the miner need not pay any cost for the fake bids. Therefore, the miner gets higher expected utility by taking the above strategy which violates MIC.\n\\\nThe proof of total social welfare is similar. Suppose without loss of generality, that the expected total social welfare in scenario 1 is higher. Then, the global coalition can inject fake bids b′ and pretend that the bid vector is (a, b′), thus allowing it to increase its expected social welfare. This violates global SCP.\n\\\nThe equivalence in total user utility follows directly from the above, since total user utility is the difference between the social welfare and the miner utility.\n\\\n\\\n \n\\\n\\\n\\\n \n\\\n\\\nLemma 5.5. Suppose the mechanism satisfies UIC, MIC, and global SCP, and the block size is k. Let a be any positive real number. Consider a scenario with only one bid a. Then, the only user’s utility is zero assuming it bids its true value.\n\\\n\\\n \n\\\n\\\nTheorem 5.6. No non-trivial, possibly randomized TFM can simultaneously satisfy UIC, MIC, and global SCP when the block size is finite.\n\\\nProof. We will show that under any sufficiently large a, the confirmation probability under a single bid a is non-zero. If we can show this, then we can show a contradiction to UIC. Specifically, consider b > a and both sufficiently large. By Lemma 5.5, if there is only one user with true value b, its utility is zero when it bids truthfully. However, the user can underbid a. Since the confirmation probability is non-zero and the payment is at most a, the user enjoys positive utility, which violates UIC.\n\\\n\\\n \n\\\n\\\n:::info\nAuthors:\n(1) Hao Chung∗, Carnegie Mellon University (haochung@andrew.cmu.edu);\n(2) Tim Roughgarden†, Columbia University and a16z (crypto tim.roughgarden@gmail.com);\n(3) Elaine Shi∗, Carnegie Mellon University (runting@cs.cmu.edu).\n:::\n:::info\nThis paper is available on arxiv under CC BY 4.0 DEED license.\n:::\n\\",
          "dc:creator": "EScholar: Electronic Academic Papers for Scholars",
          "content": "This article explores the theoretical limits of designing truthful and fair blockchain auction mechanisms. It proves that no deterministic or randomized Truthful Fee Mechanism (TFM) can simultaneously satisfy User Incentive Compatibility (UIC), Miner Incentive Compatibility (MIC), and global Social Cost Preservation (SCP) when block size is finite. Using Myerson’s Lemma, logical proofs, and game-theoretic reasoning, it establishes an impossibility result with deep implications for blockchain protocol design.",
          "contentSnippet": "This article explores the theoretical limits of designing truthful and fair blockchain auction mechanisms. It proves that no deterministic or randomized Truthful Fee Mechanism (TFM) can simultaneously satisfy User Incentive Compatibility (UIC), Miner Incentive Compatibility (MIC), and global Social Cost Preservation (SCP) when block size is finite. Using Myerson’s Lemma, logical proofs, and game-theoretic reasoning, it establishes an impossibility result with deep implications for blockchain protocol design.",
          "guid": "https://hackernoon.com/no-blockchain-auction-can-satisfy-uic-mic-and-global-scp-at-once?source=rss",
          "categories": [
            "blockchain-scalability",
            "transaction-fee-mechanisms",
            "ethereum-eip-1559",
            "user-incentive-compatibility",
            "miner-incentive-compatibility",
            "oca-proofness",
            "side-contract-proofness",
            "auction-mechanisms"
          ],
          "isoDate": "2025-08-03T21:14:35.000Z"
        }
      },
      {
        "json": {
          "creator": "EScholar: Electronic Academic Papers for Scholars",
          "title": "What Is a Transaction Fee Mechanism? Definitions, Incentives, and Strategies",
          "link": "https://hackernoon.com/what-is-a-transaction-fee-mechanism-definitions-incentives-and-strategies?source=rss",
          "pubDate": "Sun, 03 Aug 2025 21:14:30 GMT",
          "content:encoded": "<h2 id=\"tableoflinks\">Table of Links</h2>\n<p><a href=\"https://hackernoon.com/preview/4oLJMbsTSjvo3VPjkwJP\">Abstract and 1. Introduction</a></p>\n<p><a href=\"http://hackernoon.com/preview/6civAjDXiM0nLRxmISCX\">1.1 Our Contributions</a></p>\n<p><a href=\"https://hackernoon.com/preview/rn535RkNoZ9IjhCV1Q3Z\">1.2 TFM Incentive-Compatibility Notions: A Cheat Sheet</a></p>\n<ol start=\"2\">\n<li><p>Definitions</p>\n<p><a href=\"http://hackernoon.com/preview/3AUt2wksTUSPQlT9CWPJ\">2.1 Transaction Fee Mechanism</a></p>\n<p><a href=\"http://hackernoon.com/preview/3AUt2wksTUSPQlT9CWPJ\">2.2 Incentive Compatibility Notions</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">Preliminary: Myerson’s Lemma</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">Warmup: Impossibility of UIC + MIC + Global SCP for Deterministic Mechanisms</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">Impossibility of UIC + MIC + Global SCP for Randomized Mechanisms and 5.1 Proof Roadmap</a></p>\n<p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">5.2 Formal Proofs</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">Feasibility and Impossibility of UIC + MIC + OCA-Proof</a></p>\n<p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">6.1 A Non-Truthful Mechanism with UIC + MIC + OCA-Proof</a></p>\n<p><a href=\"https://hackernoon.com/preview/2K7Tn6O6GAIT00hMX9DK\">6.2 Impossibility of UIC + MIC + OCA-Proof for Truthful Mechanisms</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">How to Circumvent the Impossibilities and 7.1 Allowing the Globally Optimal Strategy to Coordinate</a></p>\n<p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">7.2 Allowing the Globally Optimal Strategy to Output Multiple Bids</a></p>\n<p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">7.3 Inclusion-Rule-Respecting and 7.4 Discussions and Open Questions Regarding the Use of Cryptography</a></p></li>\n<li><p><a href=\"http://hackernoon.com/preview/Z8dr9maz547Ssrjgsu3J\">Static Revelation Principle for Transaction Fee Mechanisms</a></p>\n<p><a href=\"http://hackernoon.com/preview/Z8dr9maz547Ssrjgsu3J\">8.1 Static Revelation Principle: Bidding Rules That Output Single Bid</a></p>\n<p><a href=\"http://hackernoon.com/preview/UMYlU2A57LPtnNi7V0N8\">8.2 Static Revelation Principle: Allowing Bidding Rules that Output Multiple Bids</a></p></li>\n</ol>\n<p><a href=\"http://hackernoon.com/preview/I4X49OO1ZsInqtfGbfPe\">A. Comparison of Collusion-Resilience Notions</a></p>\n<p><a href=\"http://hackernoon.com/preview/I4X49OO1ZsInqtfGbfPe\">References</a></p>\n<h2 id=\"2definitions\">2 Definitions</h2>\n<h3 id=\"21transactionfeemechanism\">2.1 Transaction Fee Mechanism</h3>\n<p><img src=\"https://cdn.hackernoon.com/images/fWZa4tUiBGemnqQfBGgCPf9594N2-zz833bh.png\" alt=\"\" /></p>\n<p>\\\nA transaction fee mechanism (TFM) consists of the following possibly randomized algorithms:</p>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/fWZa4tUiBGemnqQfBGgCPf9594N2-6k9334t.png\" alt=\"\" /></p>\n<p>\\\nWe say a TFM is trivial if the confirmation probability of all transactions is zero for any bid vector assuming the miner honestly follows the inclusion rule; otherwise, it is called <em>non-trivial.</em></p>\n<p>\\\nA strategic miner or miner-user coalition may deviate from the honest inclusion rule. On the other hand, since the confirmation, payment, and miner revenue rules are executed by the blockchain, they are always implemented honestly.</p>\n<p>\\\nWe focus on mechanisms that are <em>weakly symmetric</em>, i.e., mechanisms that do not make use of the bidders’ identities or other auxiliary information (e.g., timestamp, transaction metadata), except for tie-breaking among equal bids. More formally, we define weak symmetry as below.</p>\n<p>\\\n<strong>Definition 1</strong> (Weak symmetry). A mechanism is called weakly symmetric if the mechanism can always be equivalently described in the following manner: given a bid vector <strong>b</strong> where each bid may carry some extra information such as identity or timestamp, the honest mechanism always sorts the vector <strong>b</strong> by the bid amount first. During the sorting step, if multiple bids have the same amount, then arbitrary tie-breaking rules may be applied, and the tie-breaking can depend on extra information such as timestamp, identity, or random coins. After this sorting step, the inclusion rule and the confirmation rules should depend only on the amount of the bids and their relative position in the sorted bid vector.</p>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/fWZa4tUiBGemnqQfBGgCPf9594N2-zya33s5.png\" alt=\"\" /></p>\n<p>\\\n<strong>Strategy space.</strong> A strategic user can deviate from the honest bidding rule and post an arbitrary bid vector with zero to multiple bids. Without loss of generality, we may assume that in the strategic bid vector, at most one bid can correspond to the user’s actual transaction which has a non-zero true value; all other bids must be fake bids with zero true value. A strategic miner can deviate from the honest inclusion rule, and instead create an arbitrary block (subject to the block size limit) that includes any subset of the bid vector as well as any number of fake bids that it chooses to inject. A strategic miner-user coalition can adopt a combination of the above strategies.</p>\n<p>\\\n<strong>Utility and social welfare</strong>. For a user with true value v, let x ∈ {0, 1} be the indicator of whether its primary bid is confirmed or not, let p denote its total payment, then the user’s utility is x · v − p. The miner’s utility is simply its revenue. The social welfare is defined to be the sum of the utilities of all users and the miner (i.e., the total value of the confirmed transactions, less any burned payments).</p>\n<p>\\\nNotice that we allow the miner revenue to be smaller than the sum of users’ payment, since the coins can be burnt. When calculating the social welfare, the payments among the users and the miner are canceled out, so the social welfare is independent of the payment; however, the amount of burnt coins decreases the social welfare. For example, suppose there is only one user, and let p be the user’s payment and q be the amount of burnt coins. In this case, the user’s utility is x·v −p, the miner revenue is p − q, and the social welfare is (x · v − p) + (p − q) = x · v − q.</p>\n<h2 id=\"22incentivecompatibilitynotions\">2.2 Incentive Compatibility Notions</h2>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/fWZa4tUiBGemnqQfBGgCPf9594N2-u3b33n9.png\" alt=\"\" /></p>\n<p>\\\n\\\n<strong>Definition 3</strong> (Miner incentive compatible (MIC)). A TFM is said to be <em>miner incentive compatible</em> (MIC), iff given any bid vector <strong>b</strong>, the miner’s expected utility is maximized when the miner does not inject any fake bid and creates a block indicated by the honest inclusion rule.</p>\n<p>\\\n\\\n <img src=\"https://cdn.hackernoon.com/images/fWZa4tUiBGemnqQfBGgCPf9594N2-0dc33tv.png\" alt=\"\" /></p>\n<p>\\\n\\\n<strong>Definition 5</strong> (Global side-contract-proof (global SCP)). A TFM is said to be <em>global side-contract-proof (global SCP)</em>, iff given any vector of true values <strong>v</strong>, the expected social welfare is maximized when all the users bid according to the honest bidding rule, and the miner follows the honest inclusion rule, where the maximization is taken over all the coordinated strategies that the coalition consisting of the miner and all users can adopt.</p>\n<p>\\\n\\\n <img src=\"https://cdn.hackernoon.com/images/fWZa4tUiBGemnqQfBGgCPf9594N2-lqd33yw.png\" alt=\"\" /></p>\n<p>\\\n\\\nIn the definitions above, the expectation is taken over the randomness of the TFM. More explicitly, in Definition 2, the expectation is taken over the randomness of the inclusion/confirmation/payment rules; in Definitions 3 to 6, the expectation is taken over the randomness of the inclusion/confirmation/ payment/miner revenue rules.</p>\n<p>\\\nNote that in the OCA-proofness definition, σ is required to output a single real-valued bid. A canonical example of σ is scaling; that is, σ(v) = γv for some γ ∈ [0, 1] (cf., Corollary 5.12 and 5.14 in [Rou21]).</p>\n<p>\\\nA detailed comparison between c-SCP, global SCP, and OCA-proofness is given in Appendix A.</p>\n<p>\\</p>\n<p>:::info\n<strong>Authors:</strong></p>\n<p>(1) Hao Chung∗, Carnegie Mellon University (haochung@andrew.cmu.edu);</p>\n<p>(2) Tim Roughgarden†, Columbia University and a16z (crypto tim.roughgarden@gmail.com);</p>\n<p>(3) Elaine Shi∗, Carnegie Mellon University (runting@cs.cmu.edu).</p>\n<p>:::</p>\n<hr />\n<p>:::info\nThis paper is <strong><a href=\"https://arxiv.org/abs/2402.09321\">available on arxiv</a></strong> under CC BY 4.0 DEED license.</p>\n<p>:::</p>\n<p>[5] The finite block size regime in this work and [CS23] corresponds to the case in [Rou21] where the base fee in the EIP-1559 or tipless mechanisms is excessively low, i.e. the number of transactions willing to pay the base fee exceeds the maximum block size (cf., Definition 5.6 in [Rou21]).</p>\n<p>\\\n[6] The blockchain protocol can always suppress conflicting or double-spending transactions.</p>\n<p>\\\n[7] Throughout the paper except Section 8, we only focus on bidding rules that output a single bid. In Section 8, we consider general bidding rules that may output multiple bids.</p>\n<p>\\\n[8] Roughgarden [Rou21] assumes that all included transactions are confirmed. However, Chung and Shi [CS23] show that allowing unconfirmed transactions in a block enlarges the design space. For example, some mechanisms require a block to contain some unconfirmed transactions (see Section 7 in [CS23]).</p>\n<p>\\\n[9] We can also relax the requirement such that individual rationality holds in expectation. Both the impossibility results (Sections 4, 5 and 6.2) and the revelation principle result (Section 8) continue to hold.</p>",
          "content:encodedSnippet": "Table of Links\nAbstract and 1. Introduction\n1.1 Our Contributions\n1.2 TFM Incentive-Compatibility Notions: A Cheat Sheet\nDefinitions\n2.1 Transaction Fee Mechanism\n2.2 Incentive Compatibility Notions\n\n\nPreliminary: Myerson’s Lemma\n\n\nWarmup: Impossibility of UIC + MIC + Global SCP for Deterministic Mechanisms\n\n\nImpossibility of UIC + MIC + Global SCP for Randomized Mechanisms and 5.1 Proof Roadmap\n5.2 Formal Proofs\n\n\nFeasibility and Impossibility of UIC + MIC + OCA-Proof\n6.1 A Non-Truthful Mechanism with UIC + MIC + OCA-Proof\n6.2 Impossibility of UIC + MIC + OCA-Proof for Truthful Mechanisms\n\n\nHow to Circumvent the Impossibilities and 7.1 Allowing the Globally Optimal Strategy to Coordinate\n7.2 Allowing the Globally Optimal Strategy to Output Multiple Bids\n7.3 Inclusion-Rule-Respecting and 7.4 Discussions and Open Questions Regarding the Use of Cryptography\n\n\nStatic Revelation Principle for Transaction Fee Mechanisms\n8.1 Static Revelation Principle: Bidding Rules That Output Single Bid\n8.2 Static Revelation Principle: Allowing Bidding Rules that Output Multiple Bids\n\n\nA. Comparison of Collusion-Resilience Notions\nReferences\n2 Definitions\n2.1 Transaction Fee Mechanism\n\n\\\nA transaction fee mechanism (TFM) consists of the following possibly randomized algorithms:\n\\\n \n\\\nWe say a TFM is trivial if the confirmation probability of all transactions is zero for any bid vector assuming the miner honestly follows the inclusion rule; otherwise, it is called non-trivial.\n\\\nA strategic miner or miner-user coalition may deviate from the honest inclusion rule. On the other hand, since the confirmation, payment, and miner revenue rules are executed by the blockchain, they are always implemented honestly.\n\\\nWe focus on mechanisms that are weakly symmetric, i.e., mechanisms that do not make use of the bidders’ identities or other auxiliary information (e.g., timestamp, transaction metadata), except for tie-breaking among equal bids. More formally, we define weak symmetry as below.\n\\\nDefinition 1 (Weak symmetry). A mechanism is called weakly symmetric if the mechanism can always be equivalently described in the following manner: given a bid vector b where each bid may carry some extra information such as identity or timestamp, the honest mechanism always sorts the vector b by the bid amount first. During the sorting step, if multiple bids have the same amount, then arbitrary tie-breaking rules may be applied, and the tie-breaking can depend on extra information such as timestamp, identity, or random coins. After this sorting step, the inclusion rule and the confirmation rules should depend only on the amount of the bids and their relative position in the sorted bid vector.\n\\\n \n\\\nStrategy space. A strategic user can deviate from the honest bidding rule and post an arbitrary bid vector with zero to multiple bids. Without loss of generality, we may assume that in the strategic bid vector, at most one bid can correspond to the user’s actual transaction which has a non-zero true value; all other bids must be fake bids with zero true value. A strategic miner can deviate from the honest inclusion rule, and instead create an arbitrary block (subject to the block size limit) that includes any subset of the bid vector as well as any number of fake bids that it chooses to inject. A strategic miner-user coalition can adopt a combination of the above strategies.\n\\\nUtility and social welfare. For a user with true value v, let x ∈ {0, 1} be the indicator of whether its primary bid is confirmed or not, let p denote its total payment, then the user’s utility is x · v − p. The miner’s utility is simply its revenue. The social welfare is defined to be the sum of the utilities of all users and the miner (i.e., the total value of the confirmed transactions, less any burned payments).\n\\\nNotice that we allow the miner revenue to be smaller than the sum of users’ payment, since the coins can be burnt. When calculating the social welfare, the payments among the users and the miner are canceled out, so the social welfare is independent of the payment; however, the amount of burnt coins decreases the social welfare. For example, suppose there is only one user, and let p be the user’s payment and q be the amount of burnt coins. In this case, the user’s utility is x·v −p, the miner revenue is p − q, and the social welfare is (x · v − p) + (p − q) = x · v − q.\n2.2 Incentive Compatibility Notions\n\\\n \n\\\n\\\nDefinition 3 (Miner incentive compatible (MIC)). A TFM is said to be miner incentive compatible (MIC), iff given any bid vector b, the miner’s expected utility is maximized when the miner does not inject any fake bid and creates a block indicated by the honest inclusion rule.\n\\\n\\\n \n\\\n\\\nDefinition 5 (Global side-contract-proof (global SCP)). A TFM is said to be global side-contract-proof (global SCP), iff given any vector of true values v, the expected social welfare is maximized when all the users bid according to the honest bidding rule, and the miner follows the honest inclusion rule, where the maximization is taken over all the coordinated strategies that the coalition consisting of the miner and all users can adopt.\n\\\n\\\n \n\\\n\\\nIn the definitions above, the expectation is taken over the randomness of the TFM. More explicitly, in Definition 2, the expectation is taken over the randomness of the inclusion/confirmation/payment rules; in Definitions 3 to 6, the expectation is taken over the randomness of the inclusion/confirmation/ payment/miner revenue rules.\n\\\nNote that in the OCA-proofness definition, σ is required to output a single real-valued bid. A canonical example of σ is scaling; that is, σ(v) = γv for some γ ∈ [0, 1] (cf., Corollary 5.12 and 5.14 in [Rou21]).\n\\\nA detailed comparison between c-SCP, global SCP, and OCA-proofness is given in Appendix A.\n\\\n:::info\nAuthors:\n(1) Hao Chung∗, Carnegie Mellon University (haochung@andrew.cmu.edu);\n(2) Tim Roughgarden†, Columbia University and a16z (crypto tim.roughgarden@gmail.com);\n(3) Elaine Shi∗, Carnegie Mellon University (runting@cs.cmu.edu).\n:::\n:::info\nThis paper is available on arxiv under CC BY 4.0 DEED license.\n:::\n[5] The finite block size regime in this work and [CS23] corresponds to the case in [Rou21] where the base fee in the EIP-1559 or tipless mechanisms is excessively low, i.e. the number of transactions willing to pay the base fee exceeds the maximum block size (cf., Definition 5.6 in [Rou21]).\n\\\n[6] The blockchain protocol can always suppress conflicting or double-spending transactions.\n\\\n[7] Throughout the paper except Section 8, we only focus on bidding rules that output a single bid. In Section 8, we consider general bidding rules that may output multiple bids.\n\\\n[8] Roughgarden [Rou21] assumes that all included transactions are confirmed. However, Chung and Shi [CS23] show that allowing unconfirmed transactions in a block enlarges the design space. For example, some mechanisms require a block to contain some unconfirmed transactions (see Section 7 in [CS23]).\n\\\n[9] We can also relax the requirement such that individual rationality holds in expectation. Both the impossibility results (Sections 4, 5 and 6.2) and the revelation principle result (Section 8) continue to hold.",
          "dc:creator": "EScholar: Electronic Academic Papers for Scholars",
          "content": "This article breaks down key technical definitions around Transaction Fee Mechanisms (TFMs) in blockchain systems, focusing on miner and user strategies, incentive compatibility, and how social welfare is impacted by honest versus strategic behavior. It defines concepts like weak symmetry, miner incentive compatibility (MIC), and global side-contract-proofness (global SCP), showing how mechanisms can be gamed—and how properly designed rules aim to align incentives for optimal outcomes.\n\n",
          "contentSnippet": "This article breaks down key technical definitions around Transaction Fee Mechanisms (TFMs) in blockchain systems, focusing on miner and user strategies, incentive compatibility, and how social welfare is impacted by honest versus strategic behavior. It defines concepts like weak symmetry, miner incentive compatibility (MIC), and global side-contract-proofness (global SCP), showing how mechanisms can be gamed—and how properly designed rules aim to align incentives for optimal outcomes.",
          "guid": "https://hackernoon.com/what-is-a-transaction-fee-mechanism-definitions-incentives-and-strategies?source=rss",
          "categories": [
            "blockchain-scalability",
            "transaction-fee-mechanisms",
            "ethereum-eip-1559",
            "user-incentive-compatibility",
            "miner-incentive-compatibility",
            "oca-proofness",
            "side-contract-proofness",
            "auction-mechanisms"
          ],
          "isoDate": "2025-08-03T21:14:30.000Z"
        }
      },
      {
        "json": {
          "creator": "EScholar: Electronic Academic Papers for Scholars",
          "title": "Why No Transaction Fee Mechanism Can Truly Be Collusion-Proof",
          "link": "https://hackernoon.com/why-no-transaction-fee-mechanism-can-truly-be-collusion-proof?source=rss",
          "pubDate": "Sun, 03 Aug 2025 21:14:24 GMT",
          "content:encoded": "<h2 id=\"tableoflinks\">Table of Links</h2>\n<p><a href=\"https://hackernoon.com/preview/4oLJMbsTSjvo3VPjkwJP\">Abstract and 1. Introduction</a></p>\n<p><a href=\"http://hackernoon.com/preview/6civAjDXiM0nLRxmISCX\">1.1 Our Contributions</a></p>\n<p><a href=\"https://hackernoon.com/preview/rn535RkNoZ9IjhCV1Q3Z\">1.2 TFM Incentive-Compatibility Notions: A Cheat Sheet</a></p>\n<ol start=\"2\">\n<li><p>Definitions</p>\n<p><a href=\"http://hackernoon.com/preview/3AUt2wksTUSPQlT9CWPJ\">2.1 Transaction Fee Mechanism</a></p>\n<p><a href=\"http://hackernoon.com/preview/3AUt2wksTUSPQlT9CWPJ\">2.2 Incentive Compatibility Notions</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">Preliminary: Myerson’s Lemma</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">Warmup: Impossibility of UIC + MIC + Global SCP for Deterministic Mechanisms</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">Impossibility of UIC + MIC + Global SCP for Randomized Mechanisms and 5.1 Proof Roadmap</a></p>\n<p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">5.2 Formal Proofs</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">Feasibility and Impossibility of UIC + MIC + OCA-Proof</a></p>\n<p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">6.1 A Non-Truthful Mechanism with UIC + MIC + OCA-Proof</a></p>\n<p><a href=\"https://hackernoon.com/preview/2K7Tn6O6GAIT00hMX9DK\">6.2 Impossibility of UIC + MIC + OCA-Proof for Truthful Mechanisms</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">How to Circumvent the Impossibilities and 7.1 Allowing the Globally Optimal Strategy to Coordinate</a></p>\n<p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">7.2 Allowing the Globally Optimal Strategy to Output Multiple Bids</a></p>\n<p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">7.3 Inclusion-Rule-Respecting and 7.4 Discussions and Open Questions Regarding the Use of Cryptography</a></p></li>\n<li><p><a href=\"http://hackernoon.com/preview/Z8dr9maz547Ssrjgsu3J\">Static Revelation Principle for Transaction Fee Mechanisms</a></p>\n<p><a href=\"http://hackernoon.com/preview/Z8dr9maz547Ssrjgsu3J\">8.1 Static Revelation Principle: Bidding Rules That Output Single Bid</a></p>\n<p><a href=\"http://hackernoon.com/preview/UMYlU2A57LPtnNi7V0N8\">8.2 Static Revelation Principle: Allowing Bidding Rules that Output Multiple Bids</a></p></li>\n</ol>\n<p><a href=\"http://hackernoon.com/preview/I4X49OO1ZsInqtfGbfPe\">A. Comparison of Collusion-Resilience Notions</a></p>\n<p><a href=\"http://hackernoon.com/preview/I4X49OO1ZsInqtfGbfPe\">References</a></p>\n<h2 id=\"12tfmincentivecompatibilitynotionsacheatsheet\">1.2 TFM Incentive-Compatibility Notions: A Cheat Sheet</h2>\n<p>We gather here informal definitions and comparisons of the key incentive-compatibility notions used in this paper. First, a transaction fee mechanism specifies how a user is supposed to bid (as a function of its private valuation), which transactions a miner is supposed to include (as a function of the transactions it knows about and their bids), and the resulting outcome (the subset of included transactions that get confirmed, and the payments made by the users and received by the miner). If the bidding strategy suggested by the TFM is the identity, then we additionally call the TFM <em>truthful</em>. In this paper, as in the rest of the TFM literature, we consider only static mechanisms.</p>\n<p>\\\n• <strong>UIC</strong>. (Definition 2) Provided that the miner follows the suggested inclusion rule, the bidding strategy suggested by the TFM is a dominant strategy for users.</p>\n<p>\\\n• <strong>MIC</strong>. (Definition 3) The inclusion rule suggested by the TFM is always revenue-maximizing for the miner regardless of users’ bids; moreover, the miner cannot increase its revenue through the injection of fake transactions.</p>\n<p>\\\n<strong>• Global SCP.</strong> (Definition 5) If the miner follows the inclusion rule suggested by the TFM and all users follow the bidding rule suggested by the TFM, then their joint surplus is at least as large as it would be from any coordinated deviation.</p>\n<p>\\\n<strong>• c-SCP</strong>. (Definition 4) For every coalition of the miner and at most c users, if the miner follows the inclusion rule suggested by the TFM and the users in the coalition follow the bidding rule suggested by the TFM, then the joint surplus of the coalition is at least as large as it would be from any coordinated deviation (holding fixed the bids of users outside the coalition).</p>\n<p>\\\n<strong>• OCA-proof.</strong> (Definition 6) If the miner follows the inclusion rule suggested by the TFM and all users follow a suitably chosen individually rational bidding rule σ (possibly different from the one suggested in the TFM description), then their joint surplus is as large as it would be from any coordinated deviation.</p>\n<p>\\\nFor example, in [Rou21] it was shown that Ethereum’s EIP-1559 TFM and a variant called the “tipless mechanism” satisfy UIC, MIC, and OCA-proofness when there is no contention between transactions; in fact, in this case, these TFMs satisfy the c-SCP condition for every c ≥ 1. When there is contention between transactions for inclusion in a block, the EIP-1559 TFM loses its UIC property and the tipless mechanism loses (all three notions of) collusion-resilience.</p>\n<p>\\\nAs mentioned above:</p>\n<p>\\\n• (Theorem 8.1) A relevation principle holds for the global SCP and c-SCP notions: any UIC and MIC TFM that satisfies one of these properties can be simulated by a truthful UIC and MIC TFM that satisfies the same property.</p>\n<p>\\\n• A relevation principle does not in general hold for the OCA-proof notion: while there are non-truthful TFMs that satisfy UIC, MIC, and OCA-proofness (Section 6.1), there are no truthful TFMs that satisfy UIC, MIC, and OCA-proofness (Theorem 6.9).</p>\n<p>\\\nThe main result in Chung and Shi [CS23] states that, even among randomized TFMs, no TFM satisfies UIC and c-SCP for any c ≥ 1. Our Theorem 5.6 proves that, even among randomized TFMs, no TFM satisfies UIC, MIC, and global SCP. (Due to the revelation principle mentioned above, these impossibility results apply to both truthful and non-truthful TFMs.) Our Theorem 6.9 proves the stronger statement that, even among randomized TFMs, no truthful TFM satisfies UIC, MIC, and OCA-proofness.</p>\n<p>\\\nReflecting on the competing notions of collusion-resilience, we can observe the following. The cSCP condition may be particularly appropriate in scenarios where the primary concern is deviations by small coalitions, or in scenarios where users may wish to deviate in ways that exploit other users. The c-SCP condition is also notable in that, together with the UIC condition, it already triggers the impossibility result in [CS23] (without any appeal to MIC). The OCA-proofness condition is distinguished by being the weakest of the three notions (thus leading to the strongest impossibility results) and by allowing the discussion of non-UIC mechanisms.[4] For TFMs that are UIC and MIC, like those studied in this paper, global SCP is arguably the “right” definition—capturing the spirit of OCA-proofness, without any additional technical complications arising from users using different bidding strategies to satisfy UIC and collusion-resilience. Put differently, the UIC and MIC conditions imply that the miner and the users following their intended strategies constitutes a Nash equilibrium; the global SCP condition asserts that this Nash equilibrium is also robust to deviations by the grand coalition, while OCA-proofness only asserts such robustness for a possibly different strategy profile (defined by the intended inclusion rule and some individually rational bidding strategy). From this vantage point, one might view Theorem 5.6 as the main impossibility result in this paper, with Theorem 6.9 serving as a technically challenging extension of the result under still weaker incentive-compatibility conditions.</p>\n<p>\\</p>\n<p>:::info\n<strong>Authors:</strong></p>\n<p>(1) Hao Chung∗, Carnegie Mellon University (haochung@andrew.cmu.edu);</p>\n<p>(2) Tim Roughgarden†, Columbia University and a16z (crypto tim.roughgarden@gmail.com);</p>\n<p>(3) Elaine Shi∗, Carnegie Mellon University (runting@cs.cmu.edu).</p>\n<p>:::</p>\n<hr />\n<p>:::info\nThis paper is <strong><a href=\"https://arxiv.org/abs/2402.09321\">available on arxiv</a></strong> under CC BY 4.0 DEED license.</p>\n<p>:::</p>\n<p>[4] For example, in a first-price auction, the “reference outcome” might be defined by a (non-truthful) bidding strategy that would constitute a Bayes-Nash equilibrium with respect to some prior over user valuations (cf., Corollary 5.12 in [Rou21]).</p>",
          "content:encodedSnippet": "Table of Links\nAbstract and 1. Introduction\n1.1 Our Contributions\n1.2 TFM Incentive-Compatibility Notions: A Cheat Sheet\nDefinitions\n2.1 Transaction Fee Mechanism\n2.2 Incentive Compatibility Notions\n\n\nPreliminary: Myerson’s Lemma\n\n\nWarmup: Impossibility of UIC + MIC + Global SCP for Deterministic Mechanisms\n\n\nImpossibility of UIC + MIC + Global SCP for Randomized Mechanisms and 5.1 Proof Roadmap\n5.2 Formal Proofs\n\n\nFeasibility and Impossibility of UIC + MIC + OCA-Proof\n6.1 A Non-Truthful Mechanism with UIC + MIC + OCA-Proof\n6.2 Impossibility of UIC + MIC + OCA-Proof for Truthful Mechanisms\n\n\nHow to Circumvent the Impossibilities and 7.1 Allowing the Globally Optimal Strategy to Coordinate\n7.2 Allowing the Globally Optimal Strategy to Output Multiple Bids\n7.3 Inclusion-Rule-Respecting and 7.4 Discussions and Open Questions Regarding the Use of Cryptography\n\n\nStatic Revelation Principle for Transaction Fee Mechanisms\n8.1 Static Revelation Principle: Bidding Rules That Output Single Bid\n8.2 Static Revelation Principle: Allowing Bidding Rules that Output Multiple Bids\n\n\nA. Comparison of Collusion-Resilience Notions\nReferences\n1.2 TFM Incentive-Compatibility Notions: A Cheat Sheet\nWe gather here informal definitions and comparisons of the key incentive-compatibility notions used in this paper. First, a transaction fee mechanism specifies how a user is supposed to bid (as a function of its private valuation), which transactions a miner is supposed to include (as a function of the transactions it knows about and their bids), and the resulting outcome (the subset of included transactions that get confirmed, and the payments made by the users and received by the miner). If the bidding strategy suggested by the TFM is the identity, then we additionally call the TFM truthful. In this paper, as in the rest of the TFM literature, we consider only static mechanisms.\n\\\n• UIC. (Definition 2) Provided that the miner follows the suggested inclusion rule, the bidding strategy suggested by the TFM is a dominant strategy for users.\n\\\n• MIC. (Definition 3) The inclusion rule suggested by the TFM is always revenue-maximizing for the miner regardless of users’ bids; moreover, the miner cannot increase its revenue through the injection of fake transactions.\n\\\n• Global SCP. (Definition 5) If the miner follows the inclusion rule suggested by the TFM and all users follow the bidding rule suggested by the TFM, then their joint surplus is at least as large as it would be from any coordinated deviation.\n\\\n• c-SCP. (Definition 4) For every coalition of the miner and at most c users, if the miner follows the inclusion rule suggested by the TFM and the users in the coalition follow the bidding rule suggested by the TFM, then the joint surplus of the coalition is at least as large as it would be from any coordinated deviation (holding fixed the bids of users outside the coalition).\n\\\n• OCA-proof. (Definition 6) If the miner follows the inclusion rule suggested by the TFM and all users follow a suitably chosen individually rational bidding rule σ (possibly different from the one suggested in the TFM description), then their joint surplus is as large as it would be from any coordinated deviation.\n\\\nFor example, in [Rou21] it was shown that Ethereum’s EIP-1559 TFM and a variant called the “tipless mechanism” satisfy UIC, MIC, and OCA-proofness when there is no contention between transactions; in fact, in this case, these TFMs satisfy the c-SCP condition for every c ≥ 1. When there is contention between transactions for inclusion in a block, the EIP-1559 TFM loses its UIC property and the tipless mechanism loses (all three notions of) collusion-resilience.\n\\\nAs mentioned above:\n\\\n• (Theorem 8.1) A relevation principle holds for the global SCP and c-SCP notions: any UIC and MIC TFM that satisfies one of these properties can be simulated by a truthful UIC and MIC TFM that satisfies the same property.\n\\\n• A relevation principle does not in general hold for the OCA-proof notion: while there are non-truthful TFMs that satisfy UIC, MIC, and OCA-proofness (Section 6.1), there are no truthful TFMs that satisfy UIC, MIC, and OCA-proofness (Theorem 6.9).\n\\\nThe main result in Chung and Shi [CS23] states that, even among randomized TFMs, no TFM satisfies UIC and c-SCP for any c ≥ 1. Our Theorem 5.6 proves that, even among randomized TFMs, no TFM satisfies UIC, MIC, and global SCP. (Due to the revelation principle mentioned above, these impossibility results apply to both truthful and non-truthful TFMs.) Our Theorem 6.9 proves the stronger statement that, even among randomized TFMs, no truthful TFM satisfies UIC, MIC, and OCA-proofness.\n\\\nReflecting on the competing notions of collusion-resilience, we can observe the following. The cSCP condition may be particularly appropriate in scenarios where the primary concern is deviations by small coalitions, or in scenarios where users may wish to deviate in ways that exploit other users. The c-SCP condition is also notable in that, together with the UIC condition, it already triggers the impossibility result in [CS23] (without any appeal to MIC). The OCA-proofness condition is distinguished by being the weakest of the three notions (thus leading to the strongest impossibility results) and by allowing the discussion of non-UIC mechanisms.[4] For TFMs that are UIC and MIC, like those studied in this paper, global SCP is arguably the “right” definition—capturing the spirit of OCA-proofness, without any additional technical complications arising from users using different bidding strategies to satisfy UIC and collusion-resilience. Put differently, the UIC and MIC conditions imply that the miner and the users following their intended strategies constitutes a Nash equilibrium; the global SCP condition asserts that this Nash equilibrium is also robust to deviations by the grand coalition, while OCA-proofness only asserts such robustness for a possibly different strategy profile (defined by the intended inclusion rule and some individually rational bidding strategy). From this vantage point, one might view Theorem 5.6 as the main impossibility result in this paper, with Theorem 6.9 serving as a technically challenging extension of the result under still weaker incentive-compatibility conditions.\n\\\n:::info\nAuthors:\n(1) Hao Chung∗, Carnegie Mellon University (haochung@andrew.cmu.edu);\n(2) Tim Roughgarden†, Columbia University and a16z (crypto tim.roughgarden@gmail.com);\n(3) Elaine Shi∗, Carnegie Mellon University (runting@cs.cmu.edu).\n:::\n:::info\nThis paper is available on arxiv under CC BY 4.0 DEED license.\n:::\n[4] For example, in a first-price auction, the “reference outcome” might be defined by a (non-truthful) bidding strategy that would constitute a Bayes-Nash equilibrium with respect to some prior over user valuations (cf., Corollary 5.12 in [Rou21]).",
          "dc:creator": "EScholar: Electronic Academic Papers for Scholars",
          "content": "\nThis article breaks down the key incentive-compatibility notions in transaction fee mechanisms (TFMs), including UIC, MIC, SCP (global and c-SCP), and OCA-proofness. It compares their implications for miner and user behavior in blockchain systems, with special reference to Ethereum’s EIP-1559 and other proposed mechanisms. The article also highlights key impossibility results showing that no TFM can satisfy all desirable incentive properties, particularly under collusion scenarios. Whether you’re a researcher or protocol designer, this is your shortcut to understanding what’s truly achievable in decentralized fee markets.\n\n",
          "contentSnippet": "This article breaks down the key incentive-compatibility notions in transaction fee mechanisms (TFMs), including UIC, MIC, SCP (global and c-SCP), and OCA-proofness. It compares their implications for miner and user behavior in blockchain systems, with special reference to Ethereum’s EIP-1559 and other proposed mechanisms. The article also highlights key impossibility results showing that no TFM can satisfy all desirable incentive properties, particularly under collusion scenarios. Whether you’re a researcher or protocol designer, this is your shortcut to understanding what’s truly achievable in decentralized fee markets.",
          "guid": "https://hackernoon.com/why-no-transaction-fee-mechanism-can-truly-be-collusion-proof?source=rss",
          "categories": [
            "blockchain-scalability",
            "transaction-fee-mechanisms",
            "ethereum-eip-1559",
            "user-incentive-compatibility",
            "miner-incentive-compatibility",
            "oca-proofness",
            "side-contract-proofness",
            "auction-mechanisms"
          ],
          "isoDate": "2025-08-03T21:14:24.000Z"
        }
      },
      {
        "json": {
          "creator": "EScholar: Electronic Academic Papers for Scholars",
          "title": "Why Truthful Blockchain Mechanisms Fail Under Finite Block Sizes",
          "link": "https://hackernoon.com/why-truthful-blockchain-mechanisms-fail-under-finite-block-sizes?source=rss",
          "pubDate": "Sun, 03 Aug 2025 21:14:18 GMT",
          "content:encoded": "<h2 id=\"tableoflinks\">Table of Links</h2>\n<p><a href=\"https://hackernoon.com/preview/4oLJMbsTSjvo3VPjkwJP\">Abstract and 1. Introduction</a></p>\n<p><a href=\"http://hackernoon.com/preview/6civAjDXiM0nLRxmISCX\">1.1 Our Contributions</a></p>\n<p><a href=\"https://hackernoon.com/preview/rn535RkNoZ9IjhCV1Q3Z\">1.2 TFM Incentive-Compatibility Notions: A Cheat Sheet</a></p>\n<ol start=\"2\">\n<li><p>Definitions</p>\n<p><a href=\"http://hackernoon.com/preview/3AUt2wksTUSPQlT9CWPJ\">2.1 Transaction Fee Mechanism</a></p>\n<p><a href=\"http://hackernoon.com/preview/3AUt2wksTUSPQlT9CWPJ\">2.2 Incentive Compatibility Notions</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">Preliminary: Myerson’s Lemma</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">Warmup: Impossibility of UIC + MIC + Global SCP for Deterministic Mechanisms</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">Impossibility of UIC + MIC + Global SCP for Randomized Mechanisms and 5.1 Proof Roadmap</a></p>\n<p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">5.2 Formal Proofs</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">Feasibility and Impossibility of UIC + MIC + OCA-Proof</a></p>\n<p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">6.1 A Non-Truthful Mechanism with UIC + MIC + OCA-Proof</a></p>\n<p><a href=\"https://hackernoon.com/preview/2K7Tn6O6GAIT00hMX9DK\">6.2 Impossibility of UIC + MIC + OCA-Proof for Truthful Mechanisms</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">How to Circumvent the Impossibilities and 7.1 Allowing the Globally Optimal Strategy to Coordinate</a></p>\n<p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">7.2 Allowing the Globally Optimal Strategy to Output Multiple Bids</a></p>\n<p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">7.3 Inclusion-Rule-Respecting and 7.4 Discussions and Open Questions Regarding the Use of Cryptography</a></p></li>\n<li><p><a href=\"http://hackernoon.com/preview/Z8dr9maz547Ssrjgsu3J\">Static Revelation Principle for Transaction Fee Mechanisms</a></p>\n<p><a href=\"http://hackernoon.com/preview/Z8dr9maz547Ssrjgsu3J\">8.1 Static Revelation Principle: Bidding Rules That Output Single Bid</a></p>\n<p><a href=\"http://hackernoon.com/preview/UMYlU2A57LPtnNi7V0N8\">8.2 Static Revelation Principle: Allowing Bidding Rules that Output Multiple Bids</a></p></li>\n</ol>\n<p><a href=\"http://hackernoon.com/preview/I4X49OO1ZsInqtfGbfPe\">A. Comparison of Collusion-Resilience Notions</a></p>\n<p><a href=\"http://hackernoon.com/preview/I4X49OO1ZsInqtfGbfPe\">References</a></p>\n<h2 id=\"11ourcontributions\">1.1 Our Contributions</h2>\n<p>As explained above, both Roughgarden’s and Chung and Shi’s collusion-resilience notions capture meaningful incentive compatibility considerations. Recognizing their differences, one natural question is: does Chung and Shi’s finite-block impossibility result still hold if we adopt the original OCA-proofness notion of Roughgarden in lieu of c-SCP? Notably, no existing TFM construction [LSZ19, Yao, BEOS19, BCD+, Rou20, Rou21, FMPS21, CS23, SCW23, WSC24, GY22, ZCZ22, BGR23, TY23, KKLP23, XFP23, CMW23, LRMP23, Ndi23] simultaneously satisfies user incentive compatibility, miner incentive compatibility, and OCA-proofness under finite block size.</p>\n<p>\\\n<strong>Main impossibility result.</strong> In our work, we give an affirmative answer to the above question. We show that, indeed, an analog of Chung and Shi’s finite-block impossibility result still holds when we replace the c-SCP requirement with OCA-proofness. Specifically, we prove the following theorem.</p>\n<p>\\\n<strong>Theorem 1.1</strong>. <em>Suppose the block size is finite. Then, no possibly randomized, truthful TFM can simultaneously satisfy user incentive compatibility (UIC), miner incentive compatibility (MIC), and OCA-proofness. Further, this impossibility holds even when the globally optimal strategy σ need not be individually rational.</em></p>\n<p>\\\nIn a truthful TFM, a user is expected to bid truthfully, so if the mechanism satisfies UIC, a user’s utility is maximized when it just reports its true value. However, OCA-proofness allows the global coalition to adopt a non-truthful bidding strategy σ even for truthful mechanisms.</p>\n<p>\\\nOur Theorem 1.1 is intuitively stronger but technically incomparable in comparison with Chung and Shi’s impossibility, which shows that no TFM can simultaneously satisfy UIC and 1-SCP for finite block sizes. The reason is that Chung and Shi’s impossibility does not rely on MIC; however, MIC is necessary for our Theorem 1.1 to hold. Specifically, a simple second-price auction with no burning (see Remark 2) satisfies both UIC and OCA-proofness, but does not satisfy MIC since the miner may benefit by injecting a fake (t + 1)-th bid where t is the number of confirmed bids, since the (t + 1)-th bid sets the price for confirmed bids.</p>\n<p>\\\n<strong>Global SCP.</strong> We suggest a simpler version of OCA-proofness that we call global SCP, which also intuitively captures the requirement that strategic users and miners cannot steal from the protocol, and is perhaps more appropriate when focusing on UIC TFMs (as we do in this paper). In our work, global SCP is not only a technical <em>stepping stone</em> towards proving Theorem 1.1, but also of <em>independent interest</em> as we explain below. Specifically, global SCP is almost the same as OCAproofness, except for requiring σ to be the honest bidding strategy indicated by the mechanism (i.e., the same bidding strategy used to establish UIC). In other words, a mechanism satisfies global SCP if and only if the honest strategy is surplus-maximizing for the global coalition. It is easy to see that for a truthful mechanism, c-SCP for any c implies global SCP, which in turn implies OCA-proofness. To prove Theorem 1.1, we first prove the following theorem:</p>\n<p>\\\n<strong>Theorem 1.2.</strong> <em>Suppose that the block size is finite. Then no possibly randomized TFM can simultaneously satisfy user incentive compatibility (UIC), miner incentive compatibility (MIC), and global SCP. Further, the impossibility holds even for non-truthful mechanisms.</em></p>\n<p>\\\nWe now explain why the global SCP notion is of independent interest. One advantage of global SCP is that the <em>revelation principle</em> holds for any TFM that satisfies UIC, MIC, and global SCP, which we formally prove in Section 8. In other words, given any TFM that is UIC, MIC, and global SCP, there is an equivalent truthful mechanism that simulates it. For this reason, Theorem 1.2 rules out even non-truthful TFMs that simultaneously satisfy UIC, MIC, and global SCP.[3]</p>\n<p>\\\nBy contrast, Theorem 1.1 holds only for truthful mechanisms. In particular, in Section 6.1, we show a non-truthful mechanism that simultaneously satisfies UIC, MIC, and OCA-proof. The mechanism is contrived, but it demonstrates the subtlety and the technical challenges when modeling the notion of collusion-resilience. This also suggests that the revelation principle does not hold for mechanisms that satisfy UIC, MIC, and OCA-proofness, partly because in such a mechanism, the bidding strategies used to establish UIC and OCA-proofness may be different.</p>\n<p>\\\n<strong>Ways to circumvent the impossibilities.</strong> We show in Section 7 that the impossibility of Theorem 1.1 can be circumvented by allowing non-truthful mechanisms or by allowing users to coordinate in bidding in the globally optimal strategy σ. In the same section, we raise an open question regarding whether it is possible to use cryptography (e.g., the MPC-assisted model of Shi et al. [SCW23]) and Bayesian notions of incentive compatibility to circumvent the impossibilities.</p>\n<p>\\</p>\n<p>:::info\n<strong>Authors:</strong></p>\n<p>(1) Hao Chung∗, Carnegie Mellon University (haochung@andrew.cmu.edu);</p>\n<p>(2) Tim Roughgarden†, Columbia University and a16z (crypto tim.roughgarden@gmail.com);</p>\n<p>(3) Elaine Shi∗, Carnegie Mellon University (runting@cs.cmu.edu).</p>\n<p>:::</p>\n<hr />\n<p>:::info\nThis paper is <strong><a href=\"https://arxiv.org/abs/2402.09321\">available on arxiv</a></strong> under CC BY 4.0 DEED license.</p>\n<p>:::</p>\n<p>[3] Simultaneously with and independently of this paper, Gafni and Yaish [GY24] proved, among other results, a version of Theorem 1.2 for the special case of deterministic mechanisms and a block size of 1.</p>",
          "content:encodedSnippet": "Table of Links\nAbstract and 1. Introduction\n1.1 Our Contributions\n1.2 TFM Incentive-Compatibility Notions: A Cheat Sheet\nDefinitions\n2.1 Transaction Fee Mechanism\n2.2 Incentive Compatibility Notions\n\n\nPreliminary: Myerson’s Lemma\n\n\nWarmup: Impossibility of UIC + MIC + Global SCP for Deterministic Mechanisms\n\n\nImpossibility of UIC + MIC + Global SCP for Randomized Mechanisms and 5.1 Proof Roadmap\n5.2 Formal Proofs\n\n\nFeasibility and Impossibility of UIC + MIC + OCA-Proof\n6.1 A Non-Truthful Mechanism with UIC + MIC + OCA-Proof\n6.2 Impossibility of UIC + MIC + OCA-Proof for Truthful Mechanisms\n\n\nHow to Circumvent the Impossibilities and 7.1 Allowing the Globally Optimal Strategy to Coordinate\n7.2 Allowing the Globally Optimal Strategy to Output Multiple Bids\n7.3 Inclusion-Rule-Respecting and 7.4 Discussions and Open Questions Regarding the Use of Cryptography\n\n\nStatic Revelation Principle for Transaction Fee Mechanisms\n8.1 Static Revelation Principle: Bidding Rules That Output Single Bid\n8.2 Static Revelation Principle: Allowing Bidding Rules that Output Multiple Bids\n\n\nA. Comparison of Collusion-Resilience Notions\nReferences\n1.1 Our Contributions\nAs explained above, both Roughgarden’s and Chung and Shi’s collusion-resilience notions capture meaningful incentive compatibility considerations. Recognizing their differences, one natural question is: does Chung and Shi’s finite-block impossibility result still hold if we adopt the original OCA-proofness notion of Roughgarden in lieu of c-SCP? Notably, no existing TFM construction [LSZ19, Yao, BEOS19, BCD+, Rou20, Rou21, FMPS21, CS23, SCW23, WSC24, GY22, ZCZ22, BGR23, TY23, KKLP23, XFP23, CMW23, LRMP23, Ndi23] simultaneously satisfies user incentive compatibility, miner incentive compatibility, and OCA-proofness under finite block size.\n\\\nMain impossibility result. In our work, we give an affirmative answer to the above question. We show that, indeed, an analog of Chung and Shi’s finite-block impossibility result still holds when we replace the c-SCP requirement with OCA-proofness. Specifically, we prove the following theorem.\n\\\nTheorem 1.1. Suppose the block size is finite. Then, no possibly randomized, truthful TFM can simultaneously satisfy user incentive compatibility (UIC), miner incentive compatibility (MIC), and OCA-proofness. Further, this impossibility holds even when the globally optimal strategy σ need not be individually rational.\n\\\nIn a truthful TFM, a user is expected to bid truthfully, so if the mechanism satisfies UIC, a user’s utility is maximized when it just reports its true value. However, OCA-proofness allows the global coalition to adopt a non-truthful bidding strategy σ even for truthful mechanisms.\n\\\nOur Theorem 1.1 is intuitively stronger but technically incomparable in comparison with Chung and Shi’s impossibility, which shows that no TFM can simultaneously satisfy UIC and 1-SCP for finite block sizes. The reason is that Chung and Shi’s impossibility does not rely on MIC; however, MIC is necessary for our Theorem 1.1 to hold. Specifically, a simple second-price auction with no burning (see Remark 2) satisfies both UIC and OCA-proofness, but does not satisfy MIC since the miner may benefit by injecting a fake (t + 1)-th bid where t is the number of confirmed bids, since the (t + 1)-th bid sets the price for confirmed bids.\n\\\nGlobal SCP. We suggest a simpler version of OCA-proofness that we call global SCP, which also intuitively captures the requirement that strategic users and miners cannot steal from the protocol, and is perhaps more appropriate when focusing on UIC TFMs (as we do in this paper). In our work, global SCP is not only a technical stepping stone towards proving Theorem 1.1, but also of independent interest as we explain below. Specifically, global SCP is almost the same as OCAproofness, except for requiring σ to be the honest bidding strategy indicated by the mechanism (i.e., the same bidding strategy used to establish UIC). In other words, a mechanism satisfies global SCP if and only if the honest strategy is surplus-maximizing for the global coalition. It is easy to see that for a truthful mechanism, c-SCP for any c implies global SCP, which in turn implies OCA-proofness. To prove Theorem 1.1, we first prove the following theorem:\n\\\nTheorem 1.2. Suppose that the block size is finite. Then no possibly randomized TFM can simultaneously satisfy user incentive compatibility (UIC), miner incentive compatibility (MIC), and global SCP. Further, the impossibility holds even for non-truthful mechanisms.\n\\\nWe now explain why the global SCP notion is of independent interest. One advantage of global SCP is that the revelation principle holds for any TFM that satisfies UIC, MIC, and global SCP, which we formally prove in Section 8. In other words, given any TFM that is UIC, MIC, and global SCP, there is an equivalent truthful mechanism that simulates it. For this reason, Theorem 1.2 rules out even non-truthful TFMs that simultaneously satisfy UIC, MIC, and global SCP.[3]\n\\\nBy contrast, Theorem 1.1 holds only for truthful mechanisms. In particular, in Section 6.1, we show a non-truthful mechanism that simultaneously satisfies UIC, MIC, and OCA-proof. The mechanism is contrived, but it demonstrates the subtlety and the technical challenges when modeling the notion of collusion-resilience. This also suggests that the revelation principle does not hold for mechanisms that satisfy UIC, MIC, and OCA-proofness, partly because in such a mechanism, the bidding strategies used to establish UIC and OCA-proofness may be different.\n\\\nWays to circumvent the impossibilities. We show in Section 7 that the impossibility of Theorem 1.1 can be circumvented by allowing non-truthful mechanisms or by allowing users to coordinate in bidding in the globally optimal strategy σ. In the same section, we raise an open question regarding whether it is possible to use cryptography (e.g., the MPC-assisted model of Shi et al. [SCW23]) and Bayesian notions of incentive compatibility to circumvent the impossibilities.\n\\\n:::info\nAuthors:\n(1) Hao Chung∗, Carnegie Mellon University (haochung@andrew.cmu.edu);\n(2) Tim Roughgarden†, Columbia University and a16z (crypto tim.roughgarden@gmail.com);\n(3) Elaine Shi∗, Carnegie Mellon University (runting@cs.cmu.edu).\n:::\n:::info\nThis paper is available on arxiv under CC BY 4.0 DEED license.\n:::\n[3] Simultaneously with and independently of this paper, Gafni and Yaish [GY24] proved, among other results, a version of Theorem 1.2 for the special case of deterministic mechanisms and a block size of 1.",
          "dc:creator": "EScholar: Electronic Academic Papers for Scholars",
          "content": "This paper establishes a new impossibility result in blockchain mechanism design: no truthful fee market (TFM) mechanism can simultaneously satisfy user incentive compatibility (UIC), miner incentive compatibility (MIC), and OCA-proofness under finite block sizes. By introducing and analyzing a simplified alternative called global SCP, the authors demonstrate that even non-truthful mechanisms face critical limitations. Their work refines earlier findings from Chung and Shi while offering insights into potential workarounds—such as non-truthful bidding strategies and cryptographic coordination—to build more resilient protocols.",
          "contentSnippet": "This paper establishes a new impossibility result in blockchain mechanism design: no truthful fee market (TFM) mechanism can simultaneously satisfy user incentive compatibility (UIC), miner incentive compatibility (MIC), and OCA-proofness under finite block sizes. By introducing and analyzing a simplified alternative called global SCP, the authors demonstrate that even non-truthful mechanisms face critical limitations. Their work refines earlier findings from Chung and Shi while offering insights into potential workarounds—such as non-truthful bidding strategies and cryptographic coordination—to build more resilient protocols.",
          "guid": "https://hackernoon.com/why-truthful-blockchain-mechanisms-fail-under-finite-block-sizes?source=rss",
          "categories": [
            "blockchain-scalability",
            "transaction-fee-mechanisms",
            "ethereum-eip-1559",
            "user-incentive-compatibility",
            "miner-incentive-compatibility",
            "oca-proofness",
            "side-contract-proofness",
            "auction-mechanisms"
          ],
          "isoDate": "2025-08-03T21:14:18.000Z"
        }
      },
      {
        "json": {
          "creator": "EScholar: Electronic Academic Papers for Scholars",
          "title": "Why the Perfect Blockchain Fee Mechanism May Be Impossible",
          "link": "https://hackernoon.com/why-the-perfect-blockchain-fee-mechanism-may-be-impossible?source=rss",
          "pubDate": "Sun, 03 Aug 2025 21:14:14 GMT",
          "content:encoded": "<p>:::info\n<strong>Authors:</strong></p>\n<p>(1) Hao Chung∗, Carnegie Mellon University (haochung@andrew.cmu.edu);</p>\n<p>(2) Tim Roughgarden†, Columbia University and a16z (crypto tim.roughgarden@gmail.com);</p>\n<p>(3) Elaine Shi∗, Carnegie Mellon University (runting@cs.cmu.edu).</p>\n<p>:::</p>\n<h2 id=\"tableoflinks\">Table of Links</h2>\n<p><a href=\"https://hackernoon.com/preview/4oLJMbsTSjvo3VPjkwJP\">Abstract and 1. Introduction</a></p>\n<p><a href=\"http://hackernoon.com/preview/6civAjDXiM0nLRxmISCX\">1.1 Our Contributions</a></p>\n<p><a href=\"https://hackernoon.com/preview/rn535RkNoZ9IjhCV1Q3Z\">1.2 TFM Incentive-Compatibility Notions: A Cheat Sheet</a></p>\n<ol start=\"2\">\n<li><p>Definitions</p>\n<p><a href=\"http://hackernoon.com/preview/3AUt2wksTUSPQlT9CWPJ\">2.1 Transaction Fee Mechanism</a></p>\n<p><a href=\"http://hackernoon.com/preview/3AUt2wksTUSPQlT9CWPJ\">2.2 Incentive Compatibility Notions</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">Preliminary: Myerson’s Lemma</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">Warmup: Impossibility of UIC + MIC + Global SCP for Deterministic Mechanisms</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">Impossibility of UIC + MIC + Global SCP for Randomized Mechanisms and 5.1 Proof Roadmap</a></p>\n<p><a href=\"https://hackernoon.com/preview/RXY4gszNC3Mg3gTk36xG\">5.2 Formal Proofs</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">Feasibility and Impossibility of UIC + MIC + OCA-Proof</a></p>\n<p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">6.1 A Non-Truthful Mechanism with UIC + MIC + OCA-Proof</a></p>\n<p><a href=\"https://hackernoon.com/preview/2K7Tn6O6GAIT00hMX9DK\">6.2 Impossibility of UIC + MIC + OCA-Proof for Truthful Mechanisms</a></p></li>\n<li><p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">How to Circumvent the Impossibilities and 7.1 Allowing the Globally Optimal Strategy to Coordinate</a></p>\n<p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">7.2 Allowing the Globally Optimal Strategy to Output Multiple Bids</a></p>\n<p><a href=\"https://hackernoon.com/preview/cdzWxCEZCwNYsgfae8ur\">7.3 Inclusion-Rule-Respecting and 7.4 Discussions and Open Questions Regarding the Use of Cryptography</a></p></li>\n<li><p><a href=\"http://hackernoon.com/preview/Z8dr9maz547Ssrjgsu3J\">Static Revelation Principle for Transaction Fee Mechanisms</a></p>\n<p><a href=\"http://hackernoon.com/preview/Z8dr9maz547Ssrjgsu3J\">8.1 Static Revelation Principle: Bidding Rules That Output Single Bid</a></p>\n<p><a href=\"http://hackernoon.com/preview/UMYlU2A57LPtnNi7V0N8\">8.2 Static Revelation Principle: Allowing Bidding Rules that Output Multiple Bids</a></p></li>\n</ol>\n<p><a href=\"http://hackernoon.com/preview/I4X49OO1ZsInqtfGbfPe\">A. Comparison of Collusion-Resilience Notions</a></p>\n<p><a href=\"http://hackernoon.com/preview/I4X49OO1ZsInqtfGbfPe\">References</a></p>\n<h2 id=\"abstract\">Abstract</h2>\n<p>Users bid in a transaction fee mechanism (TFM) to get their transactions included and confirmed by a blockchain protocol. Roughgarden (EC’21) initiated the formal treatment of TFMs and proposed three requirements: user incentive compatibility (UIC), miner incentive compatibility (MIC), and a form of collusion-resilience called OCA-proofness. Ethereum’s EIP1559 mechanism satisfies all three properties simultaneously when there is no contention between transactions, but loses the UIC property when there are too many eligible transactions to fit in a single block. Chung and Shi (SODA’23) considered an alternative notion of collusion-resilience, called c-side-contract-proofness (c-SCP), and showed that, when there is contention between transactions, no TFM can satisfy UIC, MIC, and c-SCP for any c ≥ 1. OCA-proofness asserts that the users and a miner should not be able to “steal from the protocol.” On the other hand, the c-SCP condition requires that a coalition of a miner and a subset of users should not be able to profit through strategic deviations (whether at the expense of the protocol or of the users outside the coalition).</p>\n<p>\\\nOur main result is the first proof that, when there is contention between transactions, no (possibly randomized) TFM in which users are expected to bid truthfully satisfies UIC, MIC, and OCA-proofness. This result resolves the main open question in Roughgarden (EC’21). We also suggest several relaxations of the basic model that allow our impossibility result to be circumvented.</p>\n<h3 id=\"1introduction\">1 Introduction</h3>\n<p>Real estate on the blockchain is scarce, and blockchain users bid in an auction called the transaction fee mechanism (TFM) to have their transactions included and confirmed on the blockchain. The original Bitcoin protocol adopted a simple first-price auction, where the top k bids win and they each pay their bid. However, such first-price auctions are known to incentivize untruthful bidding. Therefore, a line of subsequent works [LSZ19, Yao, BEOS19, BCD+, Rou20, Rou21, FMPS21, CS23, SCW23, WSC24, GY22, ZCZ22, BGR23, TY23, KKLP23, XFP23, CMW23, LRMP23, Ndi23] explored what is the “dream TFM” for blockchains. Most works [Rou20, Rou21, CS23, SCW23, WSC24, GY22, GY22, ZCZ22, BGR23, TY23] agree on roughly the same set of desiderata, that is, a dream TFM should provide incentive compatibility not just for an individual user, but also for the miner of the block. Further, a dream TFM should provide resilience against miner-user collusion.</p>\n<p>\\\nRoughgarden [Rou21] was the first to formally define the aforementioned requirements for a TFM, which he referred to as <em>user incentive compatibility</em>[1], (myopic) <em>miner incentive compatibility</em>, and <em>OCA-proofness</em>, where OCA stands for “off-chain agreement” and refers to colluding strategies between the miner and a set of users that allow off-chain transfers. Roughgarden [Rou21] also showed that the simple “posted price auction with all fees burnt” mechanism, which corresponds to the behavior of Ethereum’s EIP-1559 TFM [BCD+] when there is no congestion, satisfies all three properties. However, the posted price auction with all fees burnt does not satisfy all three properties when there is congestion. In practice, congestion does occur when there are major events such as an NFT mint or price fluctuations — for example, in Ethereum, roughly 2.3% of the blocks experience congestion.[2] When congestion arises, approximately speaking, Ethereum’s EIP-1559 mechanism falls back to the first-price auction, violating user incentive compatibility. Therefore, an interesting question is whether we can design a dream TFM satisfying all three properties for finite block sizes.</p>\n<p>\\\nChung and Shi [CS23] considered an alternative notion of collusion-resilience, called sidecontract-proofness. Unfortunately, they proved that no (even randomized) TFM can simultaneously satisfy user incentive compatibility and side-contract-proofness. Because side-contract-proofness is a more demanding property than OCA-proofness, the question raised by Roughgarden [Rou21], of whether there is a dream TFM satisfying all three properties under his collusion-resilience notion, had remained open.</p>\n<p>\\\n<strong>Two notions of miner-user collusion-resilience.</strong> Multiple natural notions of collusion-resilience can and have been studied in the context of TFM design. Here we clarify informally the key differences between the notions proposed by Roughgarden [Rou21] and Chung and Shi [CS23]. These notions are defined formally in Definitions 4–6 (see Section 2) and compared further via examples in Appendix A.</p>\n<p>\\\n<strong>• OCA-proofness:</strong> Roughgarden’s notion, henceforth referred to as OCA-proofness, asserts that there should exist a “reference strategy” for a miner and all users that is guaranteed to maximize their joint surplus. In this reference strategy, the miner is expected to follow the inclusion rule intended by the TFM. For users, the definition requires only that users follow some fixed bidding trategy σ (i.e., a mapping from a private user valuation to a user bid) that is individually rational (i.e., σ(v) ≤ v for all v ≥ 0). In particular, in the reference strategy, users are expected to bid independently (with a user’s bid independent of other users’ valuations and bids), and expected to submit a single bid (with no additional fake bids injected). One example of such a bidding strategy is the truth-telling strategy (with σ(v) = v). Because Roughgarden [Rou21] wished to discuss the OCA-proofness properties of non-UIC TFMs like first-price auctions, the definition also allows the reference strategy to be defined by a non-truthful bidding strategy (e.g., σ(v) = v/2). As a consequence, to prove that a TFM is both UIC and OCA-proof, it is sufficient to prove that it is UIC under one bidding strategy and OCA-proof under a possibly different bidding strategy (as in the example in Section 6.1).</p>\n<p>\\\n<strong>• <em>c</em>-SCP:</strong> Chung and Shi’s notion [CS23], henceforth called c-SCP (where SCP stands for sidecontract-proofness), requires that the honest strategy (i.e., all users follow the honest bidding rule and the miner honestly implements the inclusion rule) is the profit-maximizing strategy for any coalition consisting of the miner of the present block and at most c users. For truthful mechanisms, the honest bidding rule is the truthful one, while for non-truthful mechanisms, the bidding rule can be more general (see Section 2.1 for the formal definition). Chung and Shi’s notion aligns with standard notions used in a line of work at the intersection of game theory and cryptography [HT04, KN08, ADGH06, OPRV09, AL11, ACH11, GKM+13, GKTZ15, GTZ15, Kat08, DR07, GLR10, CGL+18, WAS22, CCWS21, PS17, KMSW22, FW20, EFW22].</p>\n<p>\\\n<strong>Discussion</strong>. The two notions of collusion-resilience address different issues. OCA-proofness captures the intuitive requirement that the users and miners <em>should not be able to steal from the protocol</em> through strategic deviations — for this reason, it considers <em>only the global coalition</em> consisting of the miner and all users. By contrast, the c-SCP notion captures the intuitive idea that a miner-user coalition’s best response is to act honestly, and that no strategic deviations can allow the coalition to <em>steal from other users or steal from the protocol</em>. For further discussion, see the end of this section and Appendix A.</p>\n<p>\\</p>\n<p>:::info\nThis paper is <strong><a href=\"https://arxiv.org/abs/2402.09321\">available on arxiv</a></strong> under CC BY 4.0 DEED license.</p>\n<p>:::</p>\n<p>∗Supported by NSF awards 2212746, 2044679, 1704788, a Packard Fellowship, a generous gift from the late Nikolai Mushegian, a gift from Google, and an ACE center grant from Algorand Foundation.</p>\n<p>\\\n†Author’s research at Columbia University supported in part by NSF awards CCF-2006737 and CNS-2212745, and research awards from the Briger Family Digital Finance Lab and the Center for Digital Finance and Technologies.</p>\n<p>\\\n[1] User incentive compatibility (UIC) is usually called dominant-strategy incentive compatible (DSIC) in the mechanism design literature. In general, we allow UIC TFMs to make use of non-truthful (but dominant) bidding strategies (see Definition 2).</p>\n<p>\\\n[2] From Jan 1, 2024 to Feb 5, 2024, 256595 blocks have been produced on Ethereum, and 5840 blocks among them were full (meaning more than 99.9% of the gas limit (30M) was used).</p>",
          "content:encodedSnippet": ":::info\nAuthors:\n(1) Hao Chung∗, Carnegie Mellon University (haochung@andrew.cmu.edu);\n(2) Tim Roughgarden†, Columbia University and a16z (crypto tim.roughgarden@gmail.com);\n(3) Elaine Shi∗, Carnegie Mellon University (runting@cs.cmu.edu).\n:::\nTable of Links\nAbstract and 1. Introduction\n1.1 Our Contributions\n1.2 TFM Incentive-Compatibility Notions: A Cheat Sheet\nDefinitions\n2.1 Transaction Fee Mechanism\n2.2 Incentive Compatibility Notions\n\n\nPreliminary: Myerson’s Lemma\n\n\nWarmup: Impossibility of UIC + MIC + Global SCP for Deterministic Mechanisms\n\n\nImpossibility of UIC + MIC + Global SCP for Randomized Mechanisms and 5.1 Proof Roadmap\n5.2 Formal Proofs\n\n\nFeasibility and Impossibility of UIC + MIC + OCA-Proof\n6.1 A Non-Truthful Mechanism with UIC + MIC + OCA-Proof\n6.2 Impossibility of UIC + MIC + OCA-Proof for Truthful Mechanisms\n\n\nHow to Circumvent the Impossibilities and 7.1 Allowing the Globally Optimal Strategy to Coordinate\n7.2 Allowing the Globally Optimal Strategy to Output Multiple Bids\n7.3 Inclusion-Rule-Respecting and 7.4 Discussions and Open Questions Regarding the Use of Cryptography\n\n\nStatic Revelation Principle for Transaction Fee Mechanisms\n8.1 Static Revelation Principle: Bidding Rules That Output Single Bid\n8.2 Static Revelation Principle: Allowing Bidding Rules that Output Multiple Bids\n\n\nA. Comparison of Collusion-Resilience Notions\nReferences\nAbstract\nUsers bid in a transaction fee mechanism (TFM) to get their transactions included and confirmed by a blockchain protocol. Roughgarden (EC’21) initiated the formal treatment of TFMs and proposed three requirements: user incentive compatibility (UIC), miner incentive compatibility (MIC), and a form of collusion-resilience called OCA-proofness. Ethereum’s EIP1559 mechanism satisfies all three properties simultaneously when there is no contention between transactions, but loses the UIC property when there are too many eligible transactions to fit in a single block. Chung and Shi (SODA’23) considered an alternative notion of collusion-resilience, called c-side-contract-proofness (c-SCP), and showed that, when there is contention between transactions, no TFM can satisfy UIC, MIC, and c-SCP for any c ≥ 1. OCA-proofness asserts that the users and a miner should not be able to “steal from the protocol.” On the other hand, the c-SCP condition requires that a coalition of a miner and a subset of users should not be able to profit through strategic deviations (whether at the expense of the protocol or of the users outside the coalition).\n\\\nOur main result is the first proof that, when there is contention between transactions, no (possibly randomized) TFM in which users are expected to bid truthfully satisfies UIC, MIC, and OCA-proofness. This result resolves the main open question in Roughgarden (EC’21). We also suggest several relaxations of the basic model that allow our impossibility result to be circumvented.\n1 Introduction\nReal estate on the blockchain is scarce, and blockchain users bid in an auction called the transaction fee mechanism (TFM) to have their transactions included and confirmed on the blockchain. The original Bitcoin protocol adopted a simple first-price auction, where the top k bids win and they each pay their bid. However, such first-price auctions are known to incentivize untruthful bidding. Therefore, a line of subsequent works [LSZ19, Yao, BEOS19, BCD+, Rou20, Rou21, FMPS21, CS23, SCW23, WSC24, GY22, ZCZ22, BGR23, TY23, KKLP23, XFP23, CMW23, LRMP23, Ndi23] explored what is the “dream TFM” for blockchains. Most works [Rou20, Rou21, CS23, SCW23, WSC24, GY22, GY22, ZCZ22, BGR23, TY23] agree on roughly the same set of desiderata, that is, a dream TFM should provide incentive compatibility not just for an individual user, but also for the miner of the block. Further, a dream TFM should provide resilience against miner-user collusion.\n\\\nRoughgarden [Rou21] was the first to formally define the aforementioned requirements for a TFM, which he referred to as user incentive compatibility[1], (myopic) miner incentive compatibility, and OCA-proofness, where OCA stands for “off-chain agreement” and refers to colluding strategies between the miner and a set of users that allow off-chain transfers. Roughgarden [Rou21] also showed that the simple “posted price auction with all fees burnt” mechanism, which corresponds to the behavior of Ethereum’s EIP-1559 TFM [BCD+] when there is no congestion, satisfies all three properties. However, the posted price auction with all fees burnt does not satisfy all three properties when there is congestion. In practice, congestion does occur when there are major events such as an NFT mint or price fluctuations — for example, in Ethereum, roughly 2.3% of the blocks experience congestion.[2] When congestion arises, approximately speaking, Ethereum’s EIP-1559 mechanism falls back to the first-price auction, violating user incentive compatibility. Therefore, an interesting question is whether we can design a dream TFM satisfying all three properties for finite block sizes.\n\\\nChung and Shi [CS23] considered an alternative notion of collusion-resilience, called sidecontract-proofness. Unfortunately, they proved that no (even randomized) TFM can simultaneously satisfy user incentive compatibility and side-contract-proofness. Because side-contract-proofness is a more demanding property than OCA-proofness, the question raised by Roughgarden [Rou21], of whether there is a dream TFM satisfying all three properties under his collusion-resilience notion, had remained open.\n\\\nTwo notions of miner-user collusion-resilience. Multiple natural notions of collusion-resilience can and have been studied in the context of TFM design. Here we clarify informally the key differences between the notions proposed by Roughgarden [Rou21] and Chung and Shi [CS23]. These notions are defined formally in Definitions 4–6 (see Section 2) and compared further via examples in Appendix A.\n\\\n• OCA-proofness: Roughgarden’s notion, henceforth referred to as OCA-proofness, asserts that there should exist a “reference strategy” for a miner and all users that is guaranteed to maximize their joint surplus. In this reference strategy, the miner is expected to follow the inclusion rule intended by the TFM. For users, the definition requires only that users follow some fixed bidding trategy σ (i.e., a mapping from a private user valuation to a user bid) that is individually rational (i.e., σ(v) ≤ v for all v ≥ 0). In particular, in the reference strategy, users are expected to bid independently (with a user’s bid independent of other users’ valuations and bids), and expected to submit a single bid (with no additional fake bids injected). One example of such a bidding strategy is the truth-telling strategy (with σ(v) = v). Because Roughgarden [Rou21] wished to discuss the OCA-proofness properties of non-UIC TFMs like first-price auctions, the definition also allows the reference strategy to be defined by a non-truthful bidding strategy (e.g., σ(v) = v/2). As a consequence, to prove that a TFM is both UIC and OCA-proof, it is sufficient to prove that it is UIC under one bidding strategy and OCA-proof under a possibly different bidding strategy (as in the example in Section 6.1).\n\\\n• c-SCP: Chung and Shi’s notion [CS23], henceforth called c-SCP (where SCP stands for sidecontract-proofness), requires that the honest strategy (i.e., all users follow the honest bidding rule and the miner honestly implements the inclusion rule) is the profit-maximizing strategy for any coalition consisting of the miner of the present block and at most c users. For truthful mechanisms, the honest bidding rule is the truthful one, while for non-truthful mechanisms, the bidding rule can be more general (see Section 2.1 for the formal definition). Chung and Shi’s notion aligns with standard notions used in a line of work at the intersection of game theory and cryptography [HT04, KN08, ADGH06, OPRV09, AL11, ACH11, GKM+13, GKTZ15, GTZ15, Kat08, DR07, GLR10, CGL+18, WAS22, CCWS21, PS17, KMSW22, FW20, EFW22].\n\\\nDiscussion. The two notions of collusion-resilience address different issues. OCA-proofness captures the intuitive requirement that the users and miners should not be able to steal from the protocol through strategic deviations — for this reason, it considers only the global coalition consisting of the miner and all users. By contrast, the c-SCP notion captures the intuitive idea that a miner-user coalition’s best response is to act honestly, and that no strategic deviations can allow the coalition to steal from other users or steal from the protocol. For further discussion, see the end of this section and Appendix A.\n\\\n:::info\nThis paper is available on arxiv under CC BY 4.0 DEED license.\n:::\n∗Supported by NSF awards 2212746, 2044679, 1704788, a Packard Fellowship, a generous gift from the late Nikolai Mushegian, a gift from Google, and an ACE center grant from Algorand Foundation.\n\\\n†Author’s research at Columbia University supported in part by NSF awards CCF-2006737 and CNS-2212745, and research awards from the Briger Family Digital Finance Lab and the Center for Digital Finance and Technologies.\n\\\n[1] User incentive compatibility (UIC) is usually called dominant-strategy incentive compatible (DSIC) in the mechanism design literature. In general, we allow UIC TFMs to make use of non-truthful (but dominant) bidding strategies (see Definition 2).\n\\\n[2] From Jan 1, 2024 to Feb 5, 2024, 256595 blocks have been produced on Ethereum, and 5840 blocks among them were full (meaning more than 99.9% of the gas limit (30M) was used).",
          "dc:creator": "EScholar: Electronic Academic Papers for Scholars",
          "content": "This article explores the theoretical boundaries of transaction fee mechanisms (TFMs) in blockchain systems, particularly under congestion. Building on Roughgarden’s and Chung & Shi’s foundational work, the authors prove that no mechanism can simultaneously ensure user incentive compatibility (UIC), miner incentive compatibility (MIC), and collusion-resilience (OCA-proofness) when transaction demand exceeds block capacity. This impossibility result resolves a major open question and outlines where future TFM designs must compromise or adapt.\n\n",
          "contentSnippet": "This article explores the theoretical boundaries of transaction fee mechanisms (TFMs) in blockchain systems, particularly under congestion. Building on Roughgarden’s and Chung & Shi’s foundational work, the authors prove that no mechanism can simultaneously ensure user incentive compatibility (UIC), miner incentive compatibility (MIC), and collusion-resilience (OCA-proofness) when transaction demand exceeds block capacity. This impossibility result resolves a major open question and outlines where future TFM designs must compromise or adapt.",
          "guid": "https://hackernoon.com/why-the-perfect-blockchain-fee-mechanism-may-be-impossible?source=rss",
          "categories": [
            "blockchain-scalability",
            "transaction-fee-mechanisms",
            "ethereum-eip-1559",
            "user-incentive-compatibility",
            "collusion-resilience",
            "oca-proofness",
            "auction-mechanisms",
            "hackernoon-top-story"
          ],
          "isoDate": "2025-08-03T21:14:14.000Z"
        }
      },
      {
        "json": {
          "creator": "Mfonobong Umondia",
          "title": "Designing for Intelligence, Efficiency, and Accessibility",
          "link": "https://hackernoon.com/designing-for-intelligence-efficiency-and-accessibility?source=rss",
          "pubDate": "Sun, 03 Aug 2025 20:01:13 GMT",
          "content:encoded": "<p>A few years ago, if someone mentioned Artificial Intelligence in a product design meeting, they’d likely be met with skeptical glances or a cautious “let’s not overcomplicate things.” Today? AI isn’t just welcome at the UX table; it’s practically running the show.</p>\n<p>We’re in a new era where the user experience is no longer just about beautifully designed buttons and seamless navigation; it's about intelligence. It’s about designing systems that think a little, predict a lot, and adapt even more. And most importantly, it’s about making those experiences accessible to everyone, not just the tech-savvy.</p>\n<p>In this article, I will unpack how AI is reshaping UX through three powerful lenses: <strong>intelligence</strong>, <strong>efficiency</strong>, and <strong>accessibility</strong>.</p>\n<h3 id=\"1designingforintelligence\"><strong>1. Designing for Intelligence</strong></h3>\n<p>This means designing a user experience (UX) that learns and adapts to users' needs and preferences. Imagine opening your favorite streaming app and seeing a lineup so in tune with your mood, it’s like it read your mind. That’s AI quietly doing its thing: tracking behavior, learning preferences, and curating experiences.</p>\n<p>But it goes deeper than Netflix suggestions. In UX, AI is helping designers build systems that understand user intent. Think about voice assistants that interpret vague commands or smart email apps that finish your sentences. These aren’t just cool features; they represent a paradigm shift from static interfaces to intelligent, evolving ones.</p>\n<p><img src=\"https://cdn.hackernoon.com/images/snPbrgUxQvVG0JjoLXHNeq4akS42-2025-08-03T20:01:12.234Z-qmcbz2zoo0dikh30coo9i941\" alt=\"Gmail auto reply options\" /></p>\n<p>Gmail auto reply options</p>\n<p>As designers, our role is evolving too. We’re not just sketching wireframes, we’re mapping out decision trees, training datasets, and predicting edge cases. We’re asking, \"What should the system do if the user does X, but also what if they do Y, or nothing at all?\"</p>\n<p>The design process becomes less about dictating user journeys and more about enabling dynamic, adaptive experiences.</p>\n<h3 id=\"2designingforefficiency\"><strong>2. Designing for Efficiency</strong></h3>\n<p>Let’s face it, users are busy, distracted, and often overwhelmed. The best UX anticipates this. AI is turning reactive design into proactive design, streamlining interactions before users even realize they need help.</p>\n<p>Take auto-generated replies in Gmail. What once took 30 seconds now takes two clicks. Or smart forms that auto-fill based on past behavior. These aren’t just nice-to-haves; they redefine what “fast” and “frictionless” mean in today’s digital age.</p>\n<p><img src=\"https://cdn.hackernoon.com/images/snPbrgUxQvVG0JjoLXHNeq4akS42-2025-08-03T20:01:12.239Z-ixow99j51u86bi72wpgh8tfa\" alt=\"\" /></p>\n<p>Designers are now integrating features like:</p>\n<ul>\n<li><strong>Predictive search</strong> that learns as you type.</li>\n<li><strong>Conversational UIs</strong> that simulate human-like dialogue.</li>\n<li><strong>Micro-personalizations</strong> that fine-tune experiences per individual.</li>\n</ul>\n<p>We’re shifting from “How can we make this easier?” to “How can we make this invisible?” AI enables us to reduce the cognitive load, streamline the number of steps, and allow users to navigate digital spaces with near-effortless precision.</p>\n<h3 id=\"3designingforaccessibility\"><strong>3. Designing for Accessibility</strong></h3>\n<p>One of the most inspiring aspects of AI in UX is its potential to make products more accessible than ever.</p>\n<p>Think about screen readers enhanced with natural language processing, turning robotic monotones into human-like guidance. Or image recognition tools that generate detailed alt text, giving blind users richer context. Or even real-time captioning powered by AI, helping deaf users fully participate in digital experiences, such as virtual calls.</p>\n<p>AI is becoming an equalizer, helping bridge the gap for users with disabilities, language barriers, or limited digital literacy.</p>\n<p>But here’s the catch: AI can only be inclusive if it’s designed that way. Biased training data and one-size-fits-all algorithms can easily undo the progress made. As UX professionals, we must approach AI with empathy and ethical foresight. Who are we designing for? Who might we be excluding? How do we test, iterate, and refine AI so that it helps rather than hinders?</p>\n<h3 id=\"soafterallihavesharedwheredowegofromhere\"><strong>So, after all I have shared, where do we go from here?</strong></h3>\n<p>The future of UX is not about choosing between human-centered and machine-assisted design; it's about combining them. AI doesn’t replace the empathy, intuition, and creativity of designers; it amplifies them.</p>\n<p>Our job now is to become translators. To understand both the language of people and the language of machines, and to create experiences where the two meet in harmony.</p>\n<p>So the next time you open a product and it just gets you, don’t chalk it up to luck. That’s AI in UX, quietly evolving behind the scenes, making every tap, scroll, and swipe a little more magical.</p>\n<p>AI is no longer a “feature.” It’s a UX game-changer. It helps us design smarter (intelligence), faster (efficiency), and better for everyone (accessibility) products. But it’s up to us to ensure it’s used ethically, creatively, and inclusively.</p>\n<p><strong>Recommended Resources for Deeper Insight:</strong></p>\n<p>→ <a href=\"https://www.youtube.com/watch?v=fO1Up4mFy24\">The Future of UX - Embracing AI in Design</a></p>\n<p>→ <a href=\"https://uxmag.com/articles/the-future-of-ux-design-how-ai-and-machine-learning-are-changing-the-way-we-design\">The Future of UX Design: How AI and Machine Learning Are Changing the Way We Design</a></p>\n<p>→ <a href=\"https://www.qualtrics.com/experience-management/customer/ai-user-experience-design/\">The future of AI in user experience (UX) design</a></p>\n<p>\\</p>",
          "content:encodedSnippet": "A few years ago, if someone mentioned Artificial Intelligence in a product design meeting, they’d likely be met with skeptical glances or a cautious “let’s not overcomplicate things.” Today? AI isn’t just welcome at the UX table; it’s practically running the show.\nWe’re in a new era where the user experience is no longer just about beautifully designed buttons and seamless navigation; it's about intelligence. It’s about designing systems that think a little, predict a lot, and adapt even more. And most importantly, it’s about making those experiences accessible to everyone, not just the tech-savvy.\nIn this article, I will unpack how AI is reshaping UX through three powerful lenses: intelligence, efficiency, and accessibility.\n1. Designing for Intelligence\nThis means designing a user experience (UX) that learns and adapts to users' needs and preferences. Imagine opening your favorite streaming app and seeing a lineup so in tune with your mood, it’s like it read your mind. That’s AI quietly doing its thing: tracking behavior, learning preferences, and curating experiences.\nBut it goes deeper than Netflix suggestions. In UX, AI is helping designers build systems that understand user intent. Think about voice assistants that interpret vague commands or smart email apps that finish your sentences. These aren’t just cool features; they represent a paradigm shift from static interfaces to intelligent, evolving ones.\n\nGmail auto reply options\nAs designers, our role is evolving too. We’re not just sketching wireframes, we’re mapping out decision trees, training datasets, and predicting edge cases. We’re asking, \"What should the system do if the user does X, but also what if they do Y, or nothing at all?\"\nThe design process becomes less about dictating user journeys and more about enabling dynamic, adaptive experiences.\n2. Designing for Efficiency\nLet’s face it, users are busy, distracted, and often overwhelmed. The best UX anticipates this. AI is turning reactive design into proactive design, streamlining interactions before users even realize they need help.\nTake auto-generated replies in Gmail. What once took 30 seconds now takes two clicks. Or smart forms that auto-fill based on past behavior. These aren’t just nice-to-haves; they redefine what “fast” and “frictionless” mean in today’s digital age.\n\nDesigners are now integrating features like:\nPredictive search that learns as you type.\nConversational UIs that simulate human-like dialogue.\nMicro-personalizations that fine-tune experiences per individual.\nWe’re shifting from “How can we make this easier?” to “How can we make this invisible?” AI enables us to reduce the cognitive load, streamline the number of steps, and allow users to navigate digital spaces with near-effortless precision.\n3. Designing for Accessibility\nOne of the most inspiring aspects of AI in UX is its potential to make products more accessible than ever.\nThink about screen readers enhanced with natural language processing, turning robotic monotones into human-like guidance. Or image recognition tools that generate detailed alt text, giving blind users richer context. Or even real-time captioning powered by AI, helping deaf users fully participate in digital experiences, such as virtual calls.\nAI is becoming an equalizer, helping bridge the gap for users with disabilities, language barriers, or limited digital literacy.\nBut here’s the catch: AI can only be inclusive if it’s designed that way. Biased training data and one-size-fits-all algorithms can easily undo the progress made. As UX professionals, we must approach AI with empathy and ethical foresight. Who are we designing for? Who might we be excluding? How do we test, iterate, and refine AI so that it helps rather than hinders?\nSo, after all I have shared, where do we go from here?\nThe future of UX is not about choosing between human-centered and machine-assisted design; it's about combining them. AI doesn’t replace the empathy, intuition, and creativity of designers; it amplifies them.\nOur job now is to become translators. To understand both the language of people and the language of machines, and to create experiences where the two meet in harmony.\nSo the next time you open a product and it just gets you, don’t chalk it up to luck. That’s AI in UX, quietly evolving behind the scenes, making every tap, scroll, and swipe a little more magical.\nAI is no longer a “feature.” It’s a UX game-changer. It helps us design smarter (intelligence), faster (efficiency), and better for everyone (accessibility) products. But it’s up to us to ensure it’s used ethically, creatively, and inclusively.\nRecommended Resources for Deeper Insight:\n→ The Future of UX - Embracing AI in Design\n→ The Future of UX Design: How AI and Machine Learning Are Changing the Way We Design\n→ The future of AI in user experience (UX) design\n\\",
          "dc:creator": "Mfonobong Umondia",
          "content": "AI has moved from being a novelty in UX design to an essential driver of intelligent, efficient, and accessible user experiences. This article explores how AI empowers designers to build adaptive interfaces, streamline interactions, and create more inclusive digital products—while emphasizing the importance of ethical and empathetic design choices. As UX and AI converge, the designer’s role is evolving: no longer just crafting visuals, but orchestrating intelligent systems that truly understand users.",
          "contentSnippet": "AI has moved from being a novelty in UX design to an essential driver of intelligent, efficient, and accessible user experiences. This article explores how AI empowers designers to build adaptive interfaces, streamline interactions, and create more inclusive digital products—while emphasizing the importance of ethical and empathetic design choices. As UX and AI converge, the designer’s role is evolving: no longer just crafting visuals, but orchestrating intelligent systems that truly understand users.",
          "guid": "https://hackernoon.com/designing-for-intelligence-efficiency-and-accessibility?source=rss",
          "categories": [
            "ux-design",
            "ai-in-ux-design",
            "intelligent-ux-systems",
            "accessible-design-with-ai",
            "adaptive-user-interfaces",
            "predictive-ux-design",
            "frictionless-user-experiences",
            "ux-design-trends-2025"
          ],
          "isoDate": "2025-08-03T20:01:13.000Z"
        }
      },
      {
        "json": {
          "creator": "Social Discovery Group",
          "title": "SDG LAB Venture Fund Backs Virtual Intimacy with $20 Million — But Will It Work?",
          "link": "https://hackernoon.com/sdg-lab-venture-fund-backs-virtual-intimacy-with-$20-million-but-will-it-work?source=rss",
          "pubDate": "Sun, 03 Aug 2025 19:37:07 GMT",
          "content:encoded": "<blockquote>\n  <p>In an age of hyperconnectivity, Europe faces an unexpected crisis: loneliness. The EU Loneliness Survey 2022 reveals that 13% of Europeans feel lonely most or all the time, while 35% experience it regularly. Despite the digital revolution, authentic human connection seems to be unraveling—replaced by surface-level engagements that lack emotional resonance.</p>\n</blockquote>\n<hr />\n<p>This paradox lies at the heart of&nbsp;<strong>Social Discovery Group&nbsp;(SDG)’s $20 million venture studio</strong>,&nbsp;<strong><a href=\"https://medium.com/@sdgroup/social-discovery-group-launches-sdg-lab-20m-venture-fund-to-invest-in-social-discovery-startups-e0142c92cac6\">SDG Lab Venture Studio</a></strong>. The studio is betting big on a controversial but potentially transformative concept:&nbsp;<strong><strong><a href=\"https://socialdiscoverygroup.com/virtual-intimacy\">Virtual Intimacy</a></strong></strong>&nbsp;— a technological attempt to restore emotional closeness in an increasingly isolated society.</p>\n<h2 id=\"understandinglonelinessmorethanjustbeingalone\">Understanding Loneliness: More Than Just Being Alone</h2>\n<p>Loneliness is not simply a matter of physical solitude. It’s a mental and emotional state where individuals feel unseen, disconnected, and emotionally deprived — even in crowds. It’s a&nbsp;<strong>perceived disconnection</strong>, not merely the absence of company.</p>\n<h3 id=\"healthconsequencesofloneliness\">Health Consequences of Loneliness</h3>\n<p>A&nbsp;<strong>2015 meta-analysis</strong>&nbsp;by Holt-Lunstad found that:</p>\n<ul>\n<li>Social isolation increases mortality risk by&nbsp;<strong>29%</strong></li>\n<li>Loneliness increases it by&nbsp;<strong>26%</strong></li>\n</ul>\n<p>These numbers are comparable to the health risks of&nbsp;<strong>smoking 15 cigarettes a day</strong>, as outlined in the&nbsp;<strong><strong><a href=\"https://www.hhs.gov/sites/default/files/surgeon-general-social-connection-advisory.pdf\">2023 U.S. Surgeon General’s guidelines</a></strong></strong>.</p>\n<p>Moreover, loneliness is linked to:</p>\n<ul>\n<li><strong>Sleep disturbances</strong></li>\n<li><strong>High cortisol levels</strong></li>\n<li><strong>Hypertension</strong></li>\n<li><strong>Heart disease</strong></li>\n</ul>\n<p>==It’s no longer just a social issue; it’s a&nbsp;<strong>public health crisis</strong>.== \\n </p>\n<p><img src=\"https://cdn.hackernoon.com/images/7XhQwEsk1Eg58rZqKidDiZMpsI93-6u23amf.jpeg\" alt=\"Understanding Loneliness: More Than Just Being Alone\" /></p>\n<h2 id=\"techmeetsemotionalneedsdglabsd20millionresponse\">Tech Meets Emotional Need: SDG Lab’s $20 Million Response</h2>\n<p>Enter&nbsp;<strong><strong><a href=\"https://socialdiscoverygroup.com/sdg-lab-venture-studio\">SDG Lab</a></strong></strong>, the corporate venture arm of&nbsp;<strong><a href=\"https://www.linkedin.com/company/social-discovery-group\">Social Discovery Group</a></strong>, which backs early-stage startups that focus on:</p>\n<ul>\n<li><strong>AI-powered communication</strong></li>\n<li><strong>Virtual and extended reality</strong></li>\n<li><strong>Social discovery platforms</strong></li>\n</ul>\n<p>These startups are designed to build what SDG calls “<strong>virtual intimacy</strong>”: emotional connections that transcend physical interaction through digital mediums.</p>\n<blockquote>\n  <p><strong><em><strong><a href=\"https://councils.forbes.com/profile/Alex-Kudos-CEO-SDG-Lab-Venture-Studio-%7C-ex-CMO-Social-Discovery-Group-SDG-Lab/4359f7e2-9e42-4a29-8747-dec6c096970d\">Alex Kudos</a></strong></em></strong><em><strong><a href=\"https://councils.forbes.com/profile/Alex-Kudos-CEO-SDG-Lab-Venture-Studio-%7C-ex-CMO-Social-Discovery-Group-SDG-Lab/4359f7e2-9e42-4a29-8747-dec6c096970d\">,</a></strong>&nbsp;CEO of SDG Lab Venture Studio, puts it simply:</em></p>\n  <p><em>“Technology doesn’t just help us build relationships — it becomes part of them.”</em></p>\n</blockquote>\n<p>This shift challenges traditional notions of closeness. Can digital interactions really replace the emotional depth of face-to-face contact?</p>\n<p><img src=\"https://cdn.hackernoon.com/images/7XhQwEsk1Eg58rZqKidDiZMpsI93-4y33axg.jpeg\" alt=\"Alex Kudos,&nbsp;CEO of SDG Lab Venture Studio\" /></p>\n<p>\\</p>\n<h3 id=\"thegeographyofloneliness\">The Geography of Loneliness</h3>\n<p>Not all regions are affected equally. According to EU data:</p>\n<ul>\n<li>Eastern and Southern Europe (e.g.,&nbsp;<strong>Bulgaria, Romania, Greece</strong>) suffer&nbsp;<strong>higher loneliness rates</strong></li>\n<li>Northern and Western countries (e.g.,&nbsp;<strong>Austria, the Netherlands</strong>) show lower levels</li>\n</ul>\n<p><strong>For example, Cyprus</strong>&nbsp;mirrors this southern trend. Kudos notes that&nbsp;<strong>older populations</strong>&nbsp;in Cyprus are particularly affected. SDG’s solution? Use technology to&nbsp;<strong>build connections tailored to older users</strong>. Products like&nbsp;<strong><a href=\"https://datemyage.com/\">DateMyAge</a></strong> show that virtual platforms can appeal to users beyond Gen Z — if designed inclusively.</p>\n<h3 id=\"aneweraofdigitalconnection\">A New Era of Digital Connection</h3>\n<p>Studies show that&nbsp;<strong>57% of Gen Z</strong>&nbsp;believe&nbsp;<strong>online relationships are as meaningful</strong>&nbsp;as in-person ones. During the&nbsp;<strong>COVID-19 pandemic</strong>, virtual worlds offered emotional refuge:</p>\n<ul>\n<li><strong>AltspaceVR</strong>&nbsp;users reported&nbsp;<strong>lower loneliness</strong></li>\n<li>Events and interactions in VR felt&nbsp;<strong>more immersive</strong>&nbsp;than real life for some</li>\n</ul>\n<p>However, this comes with a caveat:&nbsp;<strong>telepresence fatigue</strong>. Some users found screens emotionally exhausting, emphasizing the&nbsp;<strong>fragility of digital intimacy</strong>.</p>\n<p><img src=\"https://cdn.hackernoon.com/images/7XhQwEsk1Eg58rZqKidDiZMpsI93-e843abl.jpeg\" alt=\"can virtual intimacy solve the loneliness epidemic?\" /></p>\n<h3 id=\"economicandsocietalcosts\">Economic and Societal Costs</h3>\n<p>Loneliness doesn’t just hurt individuals — it strains entire economies. Increased loneliness leads to:</p>\n<ul>\n<li><strong>Rising healthcare costs</strong></li>\n<li><strong>Workforce productivity loss</strong></li>\n<li><strong>Greater pressure on social services</strong></li>\n</ul>\n<p>In regions like Cyprus, where&nbsp;<strong>aging populations</strong>&nbsp;and&nbsp;<strong>shrinking community structures</strong>&nbsp;prevail,&nbsp;<strong>digital intimacy</strong>&nbsp;becomes not just an innovation — but a necessity.</p>\n<h2 id=\"beyondonlinedatingappsthesdgandsdglabsportfolios\">Beyond Online Dating Apps: The SDG and SDG Labs Portfolios</h2>\n<p><strong>Social Discovery Group</strong>&nbsp;operates over&nbsp;<strong>60 global brands</strong>, including:</p>\n<ul>\n<li><strong>Dating.com</strong></li>\n<li><strong>DateMyAge</strong></li>\n<li><strong>DilMil</strong>&nbsp;(for South Asians)</li>\n<li><strong>Kiseki</strong>&nbsp;(for Japanese audiences)</li>\n</ul>\n<p>This diversification reflects the&nbsp;<strong>global loneliness crisis</strong>&nbsp;-as people migrate and lose touch with their cultural roots. SDG’s platforms aim to&nbsp;<strong>rebuild those connections</strong>&nbsp;in new contexts.</p>\n<p>With&nbsp;<strong>SDG Lab Investments</strong>&nbsp;, the approach shifts from quantity to quality:</p>\n<ul>\n<li>Focuses on&nbsp;<strong>5–10 projects/year</strong></li>\n<li>Offers&nbsp;<strong>operational and strategic support</strong></li>\n<li>Invests in startups building&nbsp;<strong>AI relationships, virtual influencers</strong>, and platforms for&nbsp;<strong>older demographics.</strong></li>\n</ul>\n<p>For entrepreneurs navigating the complex funding landscape,&nbsp;<strong><a href=\"https://www.linkedin.com/in/akudos/\">Alex Kudos</a></strong>, CEO of SDG Lab, offers crucial insights in the&nbsp;<strong><a href=\"https://www.forbes.com/councils/forbesbusinesscouncil/2025/07/17/a-founders-guide-to-traditional-venture-capital-vs-corporate-venture-studios/\">Founder`s Guide</a></strong>&nbsp;about choosing between traditional venture capital and venture studio models. Understanding these funding paths becomes essential when building the next generation of connection technologies.</p>\n<h2 id=\"keyconcernscantechreallycureloneliness\">Key Concerns: Can Tech Really Cure Loneliness?</h2>\n<p>Before we accept virtual intimacy as the cure for our loneliness, or shall I say, disconnection crisis, we need to confront some uncomfortable truths. The research paints a complicated picture, one that challenges a somewhat simplistic, surface narrative around technology engineering its way out of a crisis.</p>\n<h3 id=\"theaccessibilitytrap\">The Accessibility Trap</h3>\n<p>The most vulnerable -<strong>older, poorer, and less educated users</strong>&nbsp;-are also&nbsp;<strong>least likely to access digital tools</strong>.&nbsp;<strong><a href=\"https://www.frontiersin.org/journals/public-health/articles/10.3389/fpubh.2024.1296524/full\">A</a>&nbsp;<strong><a href=\"https://www.frontiersin.org/journals/public-health/articles/10.3389/fpubh.2024.1296524/full\">2024 study</a></strong></strong>&nbsp;found that&nbsp;<strong>nursing home residents</strong>&nbsp;without tech access were more isolated than ever, underlining the&nbsp;<strong>danger of digital exclusion</strong>.</p>\n<h3 id=\"qualityoverquantity\">Quality Over Quantity</h3>\n<p>Tech helps&nbsp;<strong>maintain</strong>&nbsp;existing relationships better than it&nbsp;<strong>builds</strong>&nbsp;new ones. A&nbsp;<strong><strong><a href=\"https://pmc.ncbi.nlm.nih.gov/articles/PMC9641519/\">2022 meta-review</a></strong></strong>&nbsp;found only&nbsp;<strong>moderate evidence</strong>&nbsp;that technology reduces loneliness, particularly for&nbsp;<strong>forming close new bonds</strong>.</p>\n<h3 id=\"thepresenceparadox\">The Presence Paradox</h3>\n<p>Even the best-designed platforms may fail to offer a true&nbsp;<strong>sense of emotional co-presence</strong>. According to the&nbsp;<strong>European Commission’s 2024 brief</strong>,</p>\n<blockquote>\n  <p>“Technology is seen as both enhancing and suppressing connections.”</p>\n</blockquote>\n<p>This reflects the&nbsp;<strong>paradox of virtual presence</strong>: the appearance of intimacy without the psychological reality.</p>\n<p><strong>More about the Critical Questions ↘</strong></p>\n<p><a href=\"https://thefuturemedia.eu/the-loneliness-economy-how-social-discovery-groups-20m-bet-is-logging-us-into-a-new-kind-of-intimacy/?embedable=true\">https://thefuturemedia.eu/the-loneliness-economy-how-social-discovery-groups-20m-bet-is-logging-us-into-a-new-kind-of-intimacy/?embedable=true</a></p>\n<hr />\n<p><img src=\"https://cdn.hackernoon.com/images/7XhQwEsk1Eg58rZqKidDiZMpsI93-en53ade.jpeg\" alt=\"SDG Lab Venture Fund Team at Reflect Festival, Cyprus, 2025\" /></p>\n<h2 id=\"sdglabsresponsetechnologyasanextensionnotareplacement\">SDG Lab’s Response: Technology as an Extension, Not a Replacement</h2>\n<p>SDG Lab confronts virtual intimacy criticisms directly, viewing ethical concerns as opportunities rather than roadblocks.</p>\n<p>Alex Kudos, CEO of SDG Lab Venture Studio, believes that&nbsp;<strong>exclusion</strong>&nbsp;is more about&nbsp;<strong>poor design</strong>&nbsp;than user capability. For example,&nbsp;<strong>90% of DateMyAge users</strong>&nbsp;regularly engage in&nbsp;<strong>video dating</strong>, disproving the stereotype that older people aren’t tech-savvy.</p>\n<p>\\</p>\n<blockquote>\n  <p><em>“Our goal is not to generate maximum engagement, but to promote genuine connection.” — he explains.</em></p>\n</blockquote>\n<p>\\\nThat includes resisting the urge to gamify relationships or promote constant stimulation.</p>\n<p>Perhaps most telling is Kudos’s reframing of the “bandage versus cure” debate. The real issue, he argues, may be that traditional relationships are already failing to meet modern emotional needs.</p>\n<p>\\</p>\n<blockquote>\n  <p><em>“Despite the idea that romantic partnerships are the foundation of emotional well-being, many of us are struggling even within those close connections,” Alex says.</em></p>\n  <p><strong><a href=\"https://medium.com/@sdgroup/virtual-intimacy-in-2025-trends-technologies-and-the-future-of-digital-relationships-23ffc6893fe2\">Virtual intimacy</a></strong>, in his view, isn’t a replacement but an expansion: one that amplifies access to connection across geography, identity, and life stage.</p>\n</blockquote>\n<p>\\\nThese questions aren’t meant to dismiss Lab’s vision. The company may very well be the revolution that our society needs, even if we don’t fully understand it yet.&nbsp;**For Kudos and his team, AI companionship isn’t ‘less than’ human. This type of connection allows people to be more vulnerable, authentic, and introspective in a safe space.**And in our current climate, don’t we all deserve the safety to be ourselves, fully? \\n ✓ Conclusion: Rethinking What It Means to Be Together</p>\n<h3 id=\"socanvirtualintimacysolvethelonelinessepidemic\"><strong>==So, can virtual intimacy solve the loneliness epidemic?==</strong></h3>\n<p><strong>Maybe.</strong>&nbsp;Research shows promise -but also flags risks. The real challenge is ensuring these tools don’t redefine connection in a way that&nbsp;<strong>erodes emotional depth</strong>.</p>\n<p>As&nbsp;<strong>Kudos</strong>&nbsp;sees it, virtual intimacy isn’t about&nbsp;<strong>escaping reality</strong>. It’s about creating&nbsp;<strong>new spaces for vulnerability, connection, and self-expression</strong>. In a world where loneliness is both a personal pain and a public crisis, perhaps the most radical act is simply&nbsp;<strong>helping people feel seen</strong>&nbsp;— wherever they are.</p>\n<hr />\n<h3 id=\"sdglabisactivelyseekingnewventures\">SDG Lab is Actively Seeking New Ventures!</h3>\n<p>SDG LAB Venture Studio is actively seeking for founders and companies working on the future of human connection.</p>\n<p>If you’re working on AI, video tech, or social innovation —&nbsp;<strong><a href=\"https://socialdiscoverygroup.com/sdg-lab-venture-studio\">contact us</a></strong>! \\n </p>",
          "content:encodedSnippet": "In an age of hyperconnectivity, Europe faces an unexpected crisis: loneliness. The EU Loneliness Survey 2022 reveals that 13% of Europeans feel lonely most or all the time, while 35% experience it regularly. Despite the digital revolution, authentic human connection seems to be unraveling—replaced by surface-level engagements that lack emotional resonance.\nThis paradox lies at the heart of Social Discovery Group (SDG)’s $20 million venture studio, SDG Lab Venture Studio. The studio is betting big on a controversial but potentially transformative concept: Virtual Intimacy — a technological attempt to restore emotional closeness in an increasingly isolated society.\nUnderstanding Loneliness: More Than Just Being Alone\nLoneliness is not simply a matter of physical solitude. It’s a mental and emotional state where individuals feel unseen, disconnected, and emotionally deprived — even in crowds. It’s a perceived disconnection, not merely the absence of company.\nHealth Consequences of Loneliness\nA 2015 meta-analysis by Holt-Lunstad found that:\nSocial isolation increases mortality risk by 29%\nLoneliness increases it by 26%\nThese numbers are comparable to the health risks of smoking 15 cigarettes a day, as outlined in the 2023 U.S. Surgeon General’s guidelines.\nMoreover, loneliness is linked to:\nSleep disturbances\nHigh cortisol levels\nHypertension\nHeart disease\n==It’s no longer just a social issue; it’s a public health crisis.== \\n \n\nTech Meets Emotional Need: SDG Lab’s $20 Million Response\nEnter SDG Lab, the corporate venture arm of Social Discovery Group, which backs early-stage startups that focus on:\nAI-powered communication\nVirtual and extended reality\nSocial discovery platforms\nThese startups are designed to build what SDG calls “virtual intimacy”: emotional connections that transcend physical interaction through digital mediums.\nAlex Kudos, CEO of SDG Lab Venture Studio, puts it simply:\n“Technology doesn’t just help us build relationships — it becomes part of them.”\nThis shift challenges traditional notions of closeness. Can digital interactions really replace the emotional depth of face-to-face contact?\n\n\\\nThe Geography of Loneliness\nNot all regions are affected equally. According to EU data:\nEastern and Southern Europe (e.g., Bulgaria, Romania, Greece) suffer higher loneliness rates\nNorthern and Western countries (e.g., Austria, the Netherlands) show lower levels\nFor example, Cyprus mirrors this southern trend. Kudos notes that older populations in Cyprus are particularly affected. SDG’s solution? Use technology to build connections tailored to older users. Products like DateMyAge show that virtual platforms can appeal to users beyond Gen Z — if designed inclusively.\nA New Era of Digital Connection\nStudies show that 57% of Gen Z believe online relationships are as meaningful as in-person ones. During the COVID-19 pandemic, virtual worlds offered emotional refuge:\nAltspaceVR users reported lower loneliness\nEvents and interactions in VR felt more immersive than real life for some\nHowever, this comes with a caveat: telepresence fatigue. Some users found screens emotionally exhausting, emphasizing the fragility of digital intimacy.\n\nEconomic and Societal Costs\nLoneliness doesn’t just hurt individuals — it strains entire economies. Increased loneliness leads to:\nRising healthcare costs\nWorkforce productivity loss\nGreater pressure on social services\nIn regions like Cyprus, where aging populations and shrinking community structures prevail, digital intimacy becomes not just an innovation — but a necessity.\nBeyond Online Dating Apps: The SDG and SDG Labs Portfolios\nSocial Discovery Group operates over 60 global brands, including:\nDating.com\nDateMyAge\nDilMil (for South Asians)\nKiseki (for Japanese audiences)\nThis diversification reflects the global loneliness crisis -as people migrate and lose touch with their cultural roots. SDG’s platforms aim to rebuild those connections in new contexts.\nWith SDG Lab Investments , the approach shifts from quantity to quality:\nFocuses on 5–10 projects/year\nOffers operational and strategic support\nInvests in startups building AI relationships, virtual influencers, and platforms for older demographics.\nFor entrepreneurs navigating the complex funding landscape, Alex Kudos, CEO of SDG Lab, offers crucial insights in the Founder`s Guide about choosing between traditional venture capital and venture studio models. Understanding these funding paths becomes essential when building the next generation of connection technologies.\nKey Concerns: Can Tech Really Cure Loneliness?\nBefore we accept virtual intimacy as the cure for our loneliness, or shall I say, disconnection crisis, we need to confront some uncomfortable truths. The research paints a complicated picture, one that challenges a somewhat simplistic, surface narrative around technology engineering its way out of a crisis.\nThe Accessibility Trap\nThe most vulnerable -older, poorer, and less educated users -are also least likely to access digital tools. A 2024 study found that nursing home residents without tech access were more isolated than ever, underlining the danger of digital exclusion.\nQuality Over Quantity\nTech helps maintain existing relationships better than it builds new ones. A 2022 meta-review found only moderate evidence that technology reduces loneliness, particularly for forming close new bonds.\nThe Presence Paradox\nEven the best-designed platforms may fail to offer a true sense of emotional co-presence. According to the European Commission’s 2024 brief,\n“Technology is seen as both enhancing and suppressing connections.”\nThis reflects the paradox of virtual presence: the appearance of intimacy without the psychological reality.\nMore about the Critical Questions ↘\nhttps://thefuturemedia.eu/the-loneliness-economy-how-social-discovery-groups-20m-bet-is-logging-us-into-a-new-kind-of-intimacy/?embedable=true\n\nSDG Lab’s Response: Technology as an Extension, Not a Replacement\nSDG Lab confronts virtual intimacy criticisms directly, viewing ethical concerns as opportunities rather than roadblocks.\nAlex Kudos, CEO of SDG Lab Venture Studio, believes that exclusion is more about poor design than user capability. For example, 90% of DateMyAge users regularly engage in video dating, disproving the stereotype that older people aren’t tech-savvy.\n\\\n\n  \n“Our goal is not to generate maximum engagement, but to promote genuine connection.” — he explains.\n\\\nThat includes resisting the urge to gamify relationships or promote constant stimulation.\nPerhaps most telling is Kudos’s reframing of the “bandage versus cure” debate. The real issue, he argues, may be that traditional relationships are already failing to meet modern emotional needs.\n\\\n\n  \n“Despite the idea that romantic partnerships are the foundation of emotional well-being, many of us are struggling even within those close connections,” Alex says.\nVirtual intimacy, in his view, isn’t a replacement but an expansion: one that amplifies access to connection across geography, identity, and life stage.\n\\\nThese questions aren’t meant to dismiss Lab’s vision. The company may very well be the revolution that our society needs, even if we don’t fully understand it yet. **For Kudos and his team, AI companionship isn’t ‘less than’ human. This type of connection allows people to be more vulnerable, authentic, and introspective in a safe space.**And in our current climate, don’t we all deserve the safety to be ourselves, fully? \\n ✓ Conclusion: Rethinking What It Means to Be Together\n==So, can virtual intimacy solve the loneliness epidemic?==\nMaybe. Research shows promise -but also flags risks. The real challenge is ensuring these tools don’t redefine connection in a way that erodes emotional depth.\nAs Kudos sees it, virtual intimacy isn’t about escaping reality. It’s about creating new spaces for vulnerability, connection, and self-expression. In a world where loneliness is both a personal pain and a public crisis, perhaps the most radical act is simply helping people feel seen — wherever they are.\nSDG Lab is Actively Seeking New Ventures!\nSDG LAB Venture Studio is actively seeking for founders and companies working on the future of human connection.\nIf you’re working on AI, video tech, or social innovation — contact us! \\n",
          "dc:creator": "Social Discovery Group",
          "content": "13% of Europeans feel lonely most or all the time, while 35% experience it regularly. Social isolation increases mortality risk by 29% and loneliness by 26%. Loneliness is linked to sleep disturbances, high cortisol levels, and heart disease. The $20 million venture studio SDG Lab is betting big on ‘virtual intimacy’",
          "contentSnippet": "13% of Europeans feel lonely most or all the time, while 35% experience it regularly. Social isolation increases mortality risk by 29% and loneliness by 26%. Loneliness is linked to sleep disturbances, high cortisol levels, and heart disease. The $20 million venture studio SDG Lab is betting big on ‘virtual intimacy’",
          "guid": "https://hackernoon.com/sdg-lab-venture-fund-backs-virtual-intimacy-with-$20-million-but-will-it-work?source=rss",
          "categories": [
            "virtual-intimacy",
            "ai-dating",
            "sdg-lab-venture-fund",
            "the-loneliness-epidemic",
            "ai-and-human-connection",
            "emotional-ai",
            "tech-and-loneliness",
            "good-company"
          ],
          "isoDate": "2025-08-03T19:37:07.000Z"
        }
      },
      {
        "json": {
          "creator": "Noonification",
          "title": "The HackerNoon Newsletter: 9 Things Hollywood Gets Wrong About Hacking (8/3/2025)",
          "link": "https://hackernoon.com/8-3-2025-newsletter?source=rss",
          "pubDate": "Sun, 03 Aug 2025 16:04:11 GMT",
          "content:encoded": "\n              \n        <p><strong>How are you, hacker?</strong></p>\n        <br />\n        <p>🪐 What’s happening in tech today, August 3, 2025?</p>\n        <br />\n        <p>\n          The\n          <a href=\"https://hackernoon.com/noonification\" target=\"_blank\" rel=\"noopener\"> HackerNoon Newsletter</a>\n          brings the HackerNoon \n          <a href=\"https://hackernoon.com\" target=\"_blank\" rel=\"noopener\">homepage</a>\n          straight to your inbox.\n          <a href=\"https://hackernoon.com/on-this-day\" target=\"_blank\" rel=\"noopener\">On this day,</a>\n          \n            <strong>Radio Shack Announced TRS-80 Computer</strong> in 1977,  <strong>Mozilla Corporation was founded</strong> in 2005,  <strong>Christopher Columbus set sail</strong> in 1492, \n          \n          and  we present you with these top quality stories. \n          \n            From \n        <a href=\"https://hackernoon.com/ai-agents-are-growing-up-and-they-need-zero-trust-parenting\" class=\"eventTitle\"><strong>AI Agents Are Growing Up - And They Need Zero-Trust Parenting</strong></a>\n       to \n        <a href=\"https://hackernoon.com/turn-a-regular-wallet-into-a-smart-account-with-eip-7702\" class=\"eventTitle\"><strong>Turn a Regular Wallet into a Smart Account with EIP 7702 </strong></a>,\n       let’s dive right in.\n          \n        </p>\n      \n              \n          <h2><a href=\"https://hackernoon.com/immutable-backups-everything-you-need-to-know-to-protect-your-cloud\">Immutable Backups: Everything You Need To Know To Protect Your Cloud</a></h2>\n          <p><img src=\"https://cdn.hackernoon.com/images/hQ098u52DzPm2Y4UITQcQXtLRAk2-by039c5.png\" alt=\"\" /> </p>\n          <br />\n          <p>By <a href=\"https://hackernoon.com/u/n2w\">@n2w</a> [ 6 Min read ] Learn how immutable backups prevent ransomware, ensure data integrity, and meet compliance needs with secure, tamper-proof cloud data protection. <a href=\"https://hackernoon.com/immutable-backups-everything-you-need-to-know-to-protect-your-cloud\">Read More.</a></p>\n        \n          <h2><a href=\"https://hackernoon.com/ai-agents-are-growing-up-and-they-need-zero-trust-parenting\">AI Agents Are Growing Up - And They Need Zero-Trust Parenting</a></h2>\n          <p><img src=\"https://cdn.hackernoon.com/images/xMFozA8xFqPickG9TmjRqH6mmCS2-5z039sm.jpeg\" alt=\"\" /> </p>\n          <br />\n          <p>By <a href=\"https://hackernoon.com/u/arjun-subedi\">@arjun-subedi</a> [ 8 Min read ] AI is evolving fast, but security isn’t keeping up. Discover why zero-trust architecture is critical for safe, scalable AI agent deployment. <a href=\"https://hackernoon.com/ai-agents-are-growing-up-and-they-need-zero-trust-parenting\">Read More.</a></p>\n        \n          <h2><a href=\"https://hackernoon.com/a-human-centred-framework-for-designing-complex-ai-solutions-for-strategic-decision-making\">A Human-centred Framework for Designing Complex AI Solutions for Strategic Decision-making</a></h2>\n          <p><img src=\"https://cdn.hackernoon.com/images/2jqChkrv03exBUgkLrDzIbfM99q2-k102yo7.jpeg\" alt=\"\" /> </p>\n          <br />\n          <p>By <a href=\"https://hackernoon.com/u/v3d\">@v3d</a> [ 7 Min read ] The practical framework helps designers, data scientists, and engineers find common ground, aligning the voice and needs of users with the design of AI systems <a href=\"https://hackernoon.com/a-human-centred-framework-for-designing-complex-ai-solutions-for-strategic-decision-making\">Read More.</a></p>\n        \n          <h2><a href=\"https://hackernoon.com/turn-a-regular-wallet-into-a-smart-account-with-eip-7702\">Turn a Regular Wallet into a Smart Account with EIP 7702 </a></h2>\n          <p><img src=\"https://cdn.hackernoon.com/images/J4oKDrDzfYh3ZwXi47hCWrIlVg12-ws03uid.png\" alt=\"\" /> </p>\n          <br />\n          <p>By <a href=\"https://hackernoon.com/u/hacker39947670\">@hacker39947670</a> [ 13 Min read ] Learn how EIP-7702 enables smart wallet features for existing Ethereum accounts. Complete developer guide with code examples. <a href=\"https://hackernoon.com/turn-a-regular-wallet-into-a-smart-account-with-eip-7702\">Read More.</a></p>\n        \n          <h2><a href=\"https://hackernoon.com/9-things-hollywood-gets-wrong-about-hacking\">9 Things Hollywood Gets Wrong About Hacking</a></h2>\n          <p><img src=\"https://cdn.hackernoon.com/images/l7noBCUFwmcERrcGKL5jHUS0UcV2-ay93lg1.png\" alt=\"\" /> </p>\n          <br />\n          <p>By <a href=\"https://hackernoon.com/u/moonlock\">@moonlock</a> [ 11 Min read ] Movie hacking ≠ reality: Real cyberattacks rely on phishing, not fast code. Moonlock, MacPaw’s cybersecurity division, reveals how films get it wrong. <a href=\"https://hackernoon.com/9-things-hollywood-gets-wrong-about-hacking\">Read More.</a></p>\n        \n          <h2><a href=\"https://hackernoon.com/a-simple-way-to-build-a-progress-bar-for-your-websites-image-uploader-using-filestack\">A Simple Way to Build a Progress Bar for Your Website’s Image Uploader Using Filestack</a></h2>\n          <p><img src=\"https://cdn.hackernoon.com/images/0sm1KIKmbZhu9AD2GAr4cKywoN43-ng139i1.jpeg\" alt=\"\" /> </p>\n          <br />\n          <p>By <a href=\"https://hackernoon.com/u/filestack\">@filestack</a> [ 7 Min read ] Let’s walk through how to build one manually, and then I’ll show you why we ensured you would never have to. <a href=\"https://hackernoon.com/a-simple-way-to-build-a-progress-bar-for-your-websites-image-uploader-using-filestack\">Read More.</a></p>\n        \n          <h2><a href=\"https://hackernoon.com/how-an-nyc-based-university-boosted-backup-reliability-while-slashing-costs\">How an NYC-Based University Boosted Backup Reliability While Slashing Costs​</a></h2>\n          <p><img src=\"https://cdn.hackernoon.com/images/hQ098u52DzPm2Y4UITQcQXtLRAk2-ml039lt.png\" alt=\"\" /> </p>\n          <br />\n          <p>By <a href=\"https://hackernoon.com/u/n2w\">@n2w</a> [ 4 Min read ] Learn how N2W supports St. Johns University, which educates more than 20,000 students and employs over 1,400 staff, using a hybrid environment. <a href=\"https://hackernoon.com/how-an-nyc-based-university-boosted-backup-reliability-while-slashing-costs\">Read More.</a></p>\n        \n          <h2><a href=\"https://hackernoon.com/from-chatbots-to-guardians-of-data-how-bchat-harnesses-ai-for-secure-messaging\">From Chatbots to Guardians of Data: How BChat Harnesses AI for Secure Messaging</a></h2>\n          <p><img src=\"https://cdn.hackernoon.com/images/PWiKbaVxohZ8PidtkLYzFcnG9Qw2-n2121kz.jpeg\" alt=\"\" /> </p>\n          <br />\n          <p>By <a href=\"https://hackernoon.com/u/beldexcoin\">@beldexcoin</a> [ 5 Min read ] AI is often associated with collecting personal data but what if AI helped protect user data? Read to know how BeldexAI protects your data on BChat.  <a href=\"https://hackernoon.com/from-chatbots-to-guardians-of-data-how-bchat-harnesses-ai-for-secure-messaging\">Read More.</a></p>\n        \n              \n        <br />\n        <p>🧑‍💻 What happened in your world this week?</p>\n        <p>\n          It's been said that\n          <a href=\"https://hackernoon.com/developers-the-why-and-how-to-writing-technical-articles-54e824789ef6\">writing can help consolidate technical knowledge</a>,\n          <a href=\"https://hackernoon.com/how-can-non-writers-become-effective-bloggers-1pq32wd\">establish credibility</a>,\n          <a href=\"https://hackernoon.com/how-can-non-writers-become-effective-bloggers-1pq32wd\"> and contribute to emerging community standards</a>.\n          Feeling stuck? We got you covered ⬇️⬇️⬇️\n        </p>\n        <br />\n        <p>\n          <a href=\"https://app.hackernoon.com/mobile/lZx3fmlPdlPJpVBIdble\">ANSWER THESE GREATEST INTERVIEW QUESTIONS OF ALL TIME</a>\n        </p>\n        <br />\n        <p>We hope you enjoy this worth of free reading material. Feel free to forward this email to a nerdy friend who'll love you for it.See you on Planet Internet! With love, \n The HackerNoon Team ✌️</p>\n        <br />\n        <p><img src=\"https://cdn.hackernoon.com/images/the-hackernoon-newsletter-footer.png\" alt=\"\" /></p>\n      \n            ",
          "content:encodedSnippet": "How are you, hacker?\n🪐 What’s happening in tech today, August 3, 2025?\n HackerNoon Newsletter\n          brings the HackerNoon \n          homepage\n          straight to your inbox.\n          On this day,\n          \n            Radio Shack Announced TRS-80 Computer in 1977,  Mozilla Corporation was founded in 2005,  Christopher Columbus set sail in 1492, \n          \n          and  we present you with these top quality stories. \n          \n            From \n        AI Agents Are Growing Up - And They Need Zero-Trust Parenting\n       to \n        Turn a Regular Wallet into a Smart Account with EIP 7702 ,\n       let’s dive right in.\n          \n        \nImmutable Backups: Everything You Need To Know To Protect Your Cloud\n \nBy @n2w [ 6 Min read ] Learn how immutable backups prevent ransomware, ensure data integrity, and meet compliance needs with secure, tamper-proof cloud data protection. Read More.\nAI Agents Are Growing Up - And They Need Zero-Trust Parenting\n \nBy @arjun-subedi [ 8 Min read ] AI is evolving fast, but security isn’t keeping up. Discover why zero-trust architecture is critical for safe, scalable AI agent deployment. Read More.\nA Human-centred Framework for Designing Complex AI Solutions for Strategic Decision-making\n \nBy @v3d [ 7 Min read ] The practical framework helps designers, data scientists, and engineers find common ground, aligning the voice and needs of users with the design of AI systems Read More.\nTurn a Regular Wallet into a Smart Account with EIP 7702 \n \nBy @hacker39947670 [ 13 Min read ] Learn how EIP-7702 enables smart wallet features for existing Ethereum accounts. Complete developer guide with code examples. Read More.\n9 Things Hollywood Gets Wrong About Hacking\n \nBy @moonlock [ 11 Min read ] Movie hacking ≠ reality: Real cyberattacks rely on phishing, not fast code. Moonlock, MacPaw’s cybersecurity division, reveals how films get it wrong. Read More.\nA Simple Way to Build a Progress Bar for Your Website’s Image Uploader Using Filestack\n \nBy @filestack [ 7 Min read ] Let’s walk through how to build one manually, and then I’ll show you why we ensured you would never have to. Read More.\nHow an NYC-Based University Boosted Backup Reliability While Slashing Costs​\n \nBy @n2w [ 4 Min read ] Learn how N2W supports St. Johns University, which educates more than 20,000 students and employs over 1,400 staff, using a hybrid environment. Read More.\nFrom Chatbots to Guardians of Data: How BChat Harnesses AI for Secure Messaging\n \nBy @beldexcoin [ 5 Min read ] AI is often associated with collecting personal data but what if AI helped protect user data? Read to know how BeldexAI protects your data on BChat.  Read More.\n🧑‍💻 What happened in your world this week?\nwriting can help consolidate technical knowledge,\n          establish credibility,\n           and contribute to emerging community standards.\n          Feeling stuck? We got you covered ⬇️⬇️⬇️\n        \nANSWER THESE GREATEST INTERVIEW QUESTIONS OF ALL TIME\n        \nWe hope you enjoy this worth of free reading material. Feel free to forward this email to a nerdy friend who'll love you for it.See you on Planet Internet! With love, \n The HackerNoon Team ✌️",
          "dc:creator": "Noonification",
          "guid": "https://hackernoon.com/8-3-2025-newsletter?source=rss",
          "categories": [
            "hackernoon-newsletter",
            "noonification",
            "latest-tect-stories",
            "immutable-backups",
            "ai-agent",
            "ai-design",
            "web3-ux",
            "cybersecurity",
            "filestack",
            "st.-john's-university-backup",
            "ai"
          ],
          "isoDate": "2025-08-03T16:04:11.000Z"
        }
      },
      {
        "json": {
          "creator": "Sergey Drymchenko",
          "title": "Mobile AI with ONNX Runtime: How to Build Real-Time Noise Suppression That Works",
          "link": "https://hackernoon.com/mobile-ai-with-onnx-runtime-how-to-build-real-time-noise-suppression-that-works?source=rss",
          "pubDate": "Sun, 03 Aug 2025 16:03:09 GMT",
          "content:encoded": "<p>Your phone is more powerful than a desktop computer from five years ago. The latest flagship Android devices pack neural processing units, multi-core CPUs that would make 2019 laptops jealous, and RAM configurations that seemed impossible just a few years back. So why does it feel like we're barely scratching the surface of what's possible with AI on mobile?</p>\n<p>Sure, you can now even run quantized versions of Llama and DeepSeek models locally on your device. But let's be honest - those conversations still feel clunky, slow, and nowhere near the seamless experience users expect from their apps. The hype around on-device conversational AI is real, but the practical reality? We're not quite there yet.</p>\n<p>Here's where most developers miss the opportunity: conversational AI isn't the only game in town. While everyone's chasing the next ChatGPT clone, there's a massive untapped potential in specialized AI applications that actually work brilliantly on mobile hardware <em>right now</em>.</p>\n<p>Take noise suppression. Your users are constantly battling background noise during calls, recordings, and voice messages. Wind, traffic, crying babies, barking dogs - it's an endless war against audio chaos. But what if your app could eliminate that noise in real-time, locally, without sending a single byte to the cloud?</p>\n<p>This isn't science fiction. It's happening today, and any Android developer can implement it. The tools are mature, the performance is there, and your users will immediately notice the difference.</p>\n<h2 id=\"onnxruntimeyourgatewaytomobileai\"><strong>ONNX Runtime: Your Gateway to Mobile AI</strong></h2>\n<p>The mobile AI landscape is fragmented. PyTorch dominates research, TensorFlow rules production, and countless specialized frameworks emerge for specific use cases. For Android developers, this creates a painful choice: commit to one ecosystem or maintain separate pipelines for different models.</p>\n<p>After evaluating mobile AI frameworks, we chose ONNX Runtime for several compelling reasons that directly impact Android development.</p>\n<p><strong>Wider Compatibility Across Android Versions</strong></p>\n<p>Unlike Google's LiteRT (formerly TensorFlow Lite), which mandates a minimum SDK level of 31 (Android 12), ONNX Runtime comfortably supports Android API levels as low as 24 (or even 21, if you are a magician). Our project’s minimum supported version was API 28, making ONNX Runtime the clear choice to reach a broader audience without excluding millions of active users on Android 10 and earlier devices.</p>\n<p><strong>Seamless Cross-Framework Integration</strong></p>\n<p>ONNX Runtime’s greatest strength lies in its framework-agnostic nature. Whether your AI models originate from PyTorch, TensorFlow, or even traditional ML libraries like scikit-learn, exporting models to ONNX allows uniform deployment across Android, iOS, desktops, and cloud environments. This flexibility significantly simplifies maintenance, enabling a unified pipeline rather than juggling multiple framework-specific tools.</p>\n<p><strong>Lightweight and Modular Deployment</strong></p>\n<p>Integration with ONNX Runtime is straightforward. With a compact Maven AAR (around 5–7 MB for CPU builds), the library integrates cleanly into your existing Android app without introducing unnecessary dependencies like Google Play Services or requesting additional user permissions. This streamlined deployment keeps your app lean, performant, and secure.</p>\n<p><strong>Proven Real-Time Performance</strong></p>\n<p>ONNX Runtime is battle-tested in demanding real-time scenarios. Audio-processing models, such as noise suppression or speech enhancement, consistently deliver inference speeds under 4 ms per audio frame on standard mobile hardware - comfortably within real-time performance requirements. Our team leveraged this exact capability for reliable, low-latency noise suppression.</p>\n<p>Ultimately, ONNX Runtime provided our team not just convenience, but strategic advantage - allowing us to maintain compatibility, performance, and simplicity without compromises. If your project demands accessible, performant, and scalable mobile AI, ONNX Runtime could very well be your optimal choice.</p>\n<h2 id=\"integrationplansettinguponnxruntime\"><strong>Integration Plan: Setting Up ONNX Runtime</strong></h2>\n<p>The default ONNX Runtime package weighs in at a hefty 27MB. For a mobile app, that's not just bloat - it's a user acquisition killer. Research shows that for every 6MB increase in APK size, install conversion rates drop by 1% (I should note that the study is not the newest one, and concerns mainly not the most developed countries, but still, it is worth considering)</p>\n<p>The solution? A custom minimal build that strips your deployment down to exactly what you need. Our DTLN noise suppression implementation clocks in at just 7.1MB - a 70% size reduction that keeps your app lean and your users happy.</p>\n<p>ONNX Runtime's architecture is modular by design. The full package includes execution providers for GPU acceleration (NNAPI, Vulkan), dozens of operators you'll never use, and compatibility layers for edge cases that don't apply to your specific model. By building only what you need, you eliminate this overhead entirely.</p>\n<h3 id=\"step1convertyourmodelstoortformat\"><strong>Step 1: Convert Your Models to ORT Format</strong></h3>\n<p>Before building, convert your ONNX models to ORT format. This optimized format removes unused graph nodes and operator definitions, further reducing your final binary size.</p>\n<p>\\</p>\n<pre><code class=\"javascript language-javascript\">python -m onnxruntime.tools.convert_onnx_models_to_ort &lt;onnx model file or dir&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;--target_platform {arm,amd64}\n</code></pre>\n<h3 id=\"step2createoperatorconfiguration\"><strong>Step 2: Create Operator Configuration</strong></h3>\n<p>After converting all the necessary models, configuration files with the necessary operators that will be required for the minimal build of ONNX will also be generated.</p>\n<p>When using several models, combine all the configuration files into one.</p>\n<p>The final file will look something like this:</p>\n<p>\\</p>\n<pre><code class=\"javascript language-javascript\"># Generated from model/s:\nai.onnx;1;Transpose\nai.onnx;6;Sigmoid\nai.onnx;7;Add,LSTM\nai.onnx;9;MatMul\nai.onnx;11;Concat,Slice,Squeeze,Unsqueeze\nai.onnx;1;Transpose\nai.onnx;5;Reshape\n//other operators\n</code></pre>\n<p><strong>Step 3: Execute Custom Build</strong></p>\n<p>With your operator configuration ready, build ONNX Runtime from source with minimal dependencies:</p>\n<p>\\</p>\n<pre><code class=\"bash language-bash\">./build.sh --android \\\n  --android_sdk_path ~/Library/Android/sdk \\\n  --android_ndk_path ~/Library/Android/sdk/ndk/28.0.12674087 \\\n  --android_abi arm64-v8a \\\n  --android_api 24 \\\n  --minimal_build \\\n  --include_ops_by_config path/to/required_operators.config \\\n  --build_java \\\n  --config=Rel\n</code></pre>\n<ul>\n<li>--minimal_build: Excludes unnecessary execution providers and operators</li>\n<li>--include<em>ops</em>by_config: Includes only operators specified in your config file</li>\n<li>--android_abi armeabi-v7a: Targets ARM32 for maximum device compatibility</li>\n<li>--android_api 24: Maintains compatibility with Android 7.0+</li>\n</ul>\n<p>If you also want to support old devices, repeat step 3 with –android_abi armeabi-v7a and them merge both resulting aar files with following script:</p>\n<p>\\</p>\n<pre><code class=\"bash language-bash\">#!/usr/bin/env sh\n\n# Clean up from previous runs, if any\nrm -rf merge-tmp\nmkdir -p merge-tmp\ncd merge-tmp\n\necho \"Unzipping each ABI-specific AAR...\"\nmkdir a64\nunzip ../onnxruntime-arm64-v8a.aar -d a64\n\nmkdir a32\nunzip ../onnxruntime-armeabi-v7a.aar -d a32\n\necho \"Preparing universal base from arm64 AAR...\"\nmkdir universal\ncp -r a64/* universal\n\nrm -rf universal/jni\nmkdir -p universal/jni\n\n\necho \"Merging native libs from each architecture...\"\nmkdir -p universal/jni/arm64-v8a\ncp a64/jni/arm64-v8a/*.so universal/jni/arm64-v8a\n\nmkdir -p universal/jni/armeabi-v7a\ncp a32/jni/armeabi-v7a/*.so universal/jni/armeabi-v7a\n\n\n# Re-zip contents of 'universal' to create a new AAR\necho \"Creating universal AAR...\"\ncd universal\nzip -r onnxruntime-universal.aar ./*\n\necho \"Done! The merged AAR is at:\"\necho \"$(pwd)/onnxruntime-universal.aar\"\n</code></pre>\n<p>The minimal build approach transforms ONNX Runtime from a deployment liability into a strategic advantage. Your users get the full AI capability without the bloat, and your app maintains the lean profile that modern mobile development demands.</p>\n<p>Next, let's see this optimized runtime in action with real-time DTLN noise suppression.</p>\n<h3 id=\"whyaudioprocessingshowcasesaivalue\">Why Audio Processing Showcases AI Value</h3>\n<p>Audio processing is the perfect introduction to mobile AI - delivering immediate, tangible value while your competitors wrestle with bloated language models that drain batteries and require constant internet connections.</p>\n<p><strong>The Daily Audio War Your Users Are Fighting</strong></p>\n<p>Sarah records voice messages while walking through a busy street. Between honking taxis, construction noise, and subway rumbles, she re-records messages three times before giving up and typing instead.</p>\n<p>Marcus joins client calls from his home office, which doubles as his toddler's playroom. Every presentation becomes a cycle of \"mute, unmute, apologize for the crying.\"</p>\n<p>Elena creates YouTube content in her apartment but spends hours in post-production cleaning up neighbor noise, traffic, and air conditioning hum.</p>\n<p>These aren't edge cases - they're the reality of modern mobile computing where everyone expects professional results from consumer hardware in chaotic environments.</p>\n<p><strong>Why Noise Suppression Creates Instant \"Wow\" Moments</strong></p>\n<p>Audio quality improvements trigger immediate emotional responses. Unlike other AI applications requiring explanation, noise suppression provides instant gratification users can perceive within seconds. Play someone their own voice - crystal clear - after removing background noise, and watch their reaction. They don't need to understand LSTM networks; they just know their audio sounds professional.</p>\n<p>The beauty of audio processing as an AI showcase lies in universality. Everyone understands good audio, everyone has experienced bad audio, and everyone immediately recognizes improvement when noise disappears. You're not asking users to trust your AI - you're proving its value in the most direct way possible.</p>\n<h2 id=\"buildingaproductionreadydemorealtimenoisesuppression\">Building a Production-Ready Demo: Real-Time Noise Suppression</h2>\n<p>Now, let's build a sample project that demonstrates the practical power of ONNX Runtime on Android. Rather than a basic \"hello world\" example, we'll create something close to production quality - a real-time noise suppression demonstration where users can record audio in noisy environments and experience the striking difference between their original recording and the AI-cleaned version.</p>\n<p><strong>You can find a complete sample here, on my Github: <strong><a href=\"https://github.com/linreal/android-onnx-showcase\">https://github.com/linreal/android-onnx-showcase</a></strong>.</strong></p>\n<p><strong>Models, used in sample are from <strong><a href=\"https://github.com/breizhn/DTLN\">https://github.com/breizhn/DTLN</a></strong></strong></p>\n<h2 id=\"quickimplementationoverview\">Quick Implementation Overview</h2>\n<p>Before diving into DTLN's dual-path architecture, let's establish how the pieces fit together. The beauty of this implementation lies in its clean separation of concerns - each component has a single responsibility, making the system both testable and maintainable.</p>\n<h3 id=\"thecorecomponents\">The Core Components</h3>\n<p>At the heart of our noise suppression pipeline sit three key interfaces that work together:</p>\n<p>\\</p>\n<pre><code class=\"bash language-bash\">interface NoiseSuppressor {\n    suspend fun initialize()\n    fun processChunk(audioChunk: FloatArray): FloatArray\n    fun release()\n}\n\ninterface AudioRecorder {\n    suspend fun startRecording(): Flow&lt;ShortArray&gt;\n    suspend fun stopRecording()\n}\n\ninterface ConcurrentAudioProcessor {\n    suspend fun startProcessing(\n        suppressor: NoiseSuppressor,\n        rawOutputFile: File,\n        processedOutputFile: File\n    )\n    suspend fun stopProcessing(): ProcessingResult\n}\n</code></pre>\n<p>The NoiseSuppressor encapsulates all ONNX Runtime complexity behind a simple interface. Feed it audio chunks, get back denoised audio. The stateful nature of DTLN is completely hidden - the implementation maintains LSTM states internally between calls.</p>\n<p><strong>Data Flow Architecture</strong></p>\n<p>\\</p>\n<pre><code class=\"bash language-bash\">AudioRecorder → Flow&lt;ShortArray&gt; → ConcurrentAudioProcessor → NoiseSuppressor → Processed Audio Files\n</code></pre>\n<p>\\\nThe ConcurrentAudioProcessor orchestrates the entire pipeline. It subscribes to the audio recorder's Flow, converts audio formats, processes chunks through the noise suppressor, and writes both original and processed audio to files simultaneously.</p>\n<p>\\</p>\n<pre><code class=\"bash language-bash\">rawAudioRecorder.startRecording().collect { audioChunk -&gt;\n    // Convert format for processing\n    val floatChunk = AudioConversionUtils.shortArrayToFloatArray(audioChunk)\n\n    // Process through DTLN\n    val processedChunk = suppressor.processChunk(floatChunk)\n\n    // Save both versions concurrently\n    launch { rawFileWriter.writeAudioData(floatChunk) }\n    launch { processedFileWriter.writeAudioData(processedChunk) }\n}\n</code></pre>\n<h3 id=\"whythisarchitectureworks\">Why This Architecture Works</h3>\n<p><strong>Reactive Processing:</strong> The Flow-based design ensures your UI remains responsive. Audio processing happens on background threads while the main thread handles user interactions.</p>\n<p><strong>Format Isolation:</strong> Each component works with its preferred audio format. <code>AudioRecorder</code> produces ShortArray (16-bit PCM), while <code>NoiseSuppressor</code> expects FloatArray (normalized samples). Conversion happens at the boundary.</p>\n<p><strong>Error Boundaries:</strong> If ONNX initialization fails, only the NoiseSuppressor component is affected. The audio recorder and file writers continue functioning, ensuring graceful degradation.</p>\n<p><strong>Resource Management:</strong> Each component manages its own resources. The <code>ConcurrentAudioProcessor</code> coordinates lifecycle events but doesn't own the underlying implementations.</p>\n<p>This modular approach means you can swap out the DTLN implementation for any other ONNX model, replace the audio recorder with a file-based source, or modify the output format without touching other components. The architecture scales from proof-of-concept to production deployment.</p>\n<p>Next, we'll explore the DTLN architecture that makes this magic happen.</p>\n<h3 id=\"understandingdtlnarchitecture\">Understanding DTLN Architecture</h3>\n<p>Traditional noise suppression approaches face a fundamental tradeoff. Frequency-domain methods excel at removing stationary noise (air conditioning, fan hum) but struggle with dynamic sounds like speech or music bleeding through. Time-domain approaches handle complex, changing signals well but often introduce artifacts or fail with consistent background noise.</p>\n<p>DTLN sidesteps this limitation entirely through its dual-path architecture:</p>\n<p><strong>Stage 1: Frequency Domain Processing</strong> The first model operates in the frequency domain, analyzing the spectral characteristics of your audio. It generates a suppression mask that identifies which frequency components contain noise versus speech. This stage excels at removing stationary background noise - the steady hum of air conditioning, traffic, or office chatter.</p>\n<p>\\</p>\n<pre><code class=\"bash language-bash\">// Stage 1: Frequency domain mask estimation\n\nval (magnitude, phase) = fftProcessor.forward(inBuffer)\nval outMask = model1.run(mapOf(\"input_2\" to magnitudeTensor, \"input_3\" to lstmState))\nfor (i in magnitude.indices) {\n    magnitude[i] *= outMask[i] // Apply suppression mask\n}\n</code></pre>\n<p><strong>Stage 2: Time Domain Refinement</strong> The masked frequency-domain signal gets converted back to the time domain, then fed into a second model that operates directly on the audio waveform. This stage catches what the frequency analysis missed - handling dynamic noise patterns, preserving speech naturalness, and cleaning up any artifacts from the first stage.</p>\n<p>\\</p>\n<pre><code class=\"bash language-bash\">// Stage 2: Time domain refinement\n\nval estimatedBlock = fftProcessor.inverse(magnitude, phase)\nval finalBlock = model2.run(mapOf(\"input_4\" to estimatedTensor, \"input_5\" to lstmState))\n</code></pre>\n<h3 id=\"themobilefirstdesignphilosophy\">The Mobile-First Design Philosophy</h3>\n<p>DTLN's architecture reflects years of practical mobile AI deployment experience. Every design decision prioritizes real-world constraints over academic benchmarks.</p>\n<p><strong>Chunk-Based Processing</strong> The model processes audio in 512-sample chunks (32ms at 16kHz), striking the optimal balance between latency and context. This chunk size is small enough for real-time processing but large enough to provide meaningful temporal context for the LSTM networks.</p>\n<p>\\</p>\n<pre><code class=\"bash language-bash\">companion object {\n    private const val BLOCK_LEN = 512  // 32ms chunks\n    private const val BLOCK_SHIFT = 128  // 75% overlap for smooth processing\n}\n</code></pre>\n<p><strong>Stateful LSTM Networks</strong> Both models use LSTM (Long Short-Term Memory) networks that maintain internal state between chunks. This temporal memory allows the model to distinguish between speech and noise based on context, not just instantaneous audio characteristics.</p>\n<p>\\</p>\n<pre><code class=\"bash language-bash\">class NoiseSuppressorImpl {\n    // These tensors maintain LSTM state between processing calls\n    private var input3Tensor: OnnxTensor? = null  // Model 1 LSTM state\n    private var input5Tensor: OnnxTensor? = null  // Model 2 LSTM state\n\n    fun processChunk(audioChunk: FloatArray): FloatArray {\n        // State automatically carries forward to next chunk\n        val result1 = model1.run(mapOf(\"input_3\" to input3Tensor))\n        input3Tensor?.close()\n        input3Tensor = result1[1] as OnnxTensor  // Update state\n\n        // State continuity ensures smooth, artifact-free processing\n    }\n}\n</code></pre>\n<h3 id=\"performancecharacteristicsthatmatter\">Performance Characteristics That Matter</h3>\n<p>Understanding DTLN's architecture helps predict its behavior in your application. These performance characteristics directly impact user experience:</p>\n<p><strong>Latency Profile</strong></p>\n<ul>\n<li>Algorithmic Delay: 32ms (one chunk processing time)</li>\n<li>Inference Time: 3-4ms per chunk on mid-range Android hardware</li>\n<li>Total Latency: ~35ms end-to-end (imperceptible for most use cases)</li>\n</ul>\n<p><strong>Resource Usage</strong></p>\n<ul>\n<li>Memory Footprint: ~28MB during active processing</li>\n<li>CPU Usage: 12-18% on typical mid-range device</li>\n<li>Battery Impact: Negligible for typical recording sessions</li>\n</ul>\n<p>These characteristics make DTLN particularly well-suited for mobile applications where users expect immediate results without sacrificing device performance or battery life.</p>\n<h3 id=\"onnxruntimeintegrationstrategy\">ONNX Runtime Integration Strategy</h3>\n<p>Getting ONNX Runtime working on Android isn't just about adding a dependency to your build.gradle. The difference between a proof-of-concept that crashes under load and a production-ready implementation lies in the session configuration, memory management, and resource allocation strategy.</p>\n<p>As we already prepared a minimal runtime build, it’s time to look into what lies next.</p>\n<p><strong>Session Configuration for Mobile Reality</strong></p>\n<p>The default ONNX Runtime session configuration assumes you're running on a server with abundant resources. Mobile devices operate under entirely different constraints: limited memory, thermal throttling, and users who expect apps to remain responsive during AI processing.</p>\n<p>\\</p>\n<pre><code class=\"bash language-bash\">private val sessionOptions = OrtSession.SessionOptions().apply {\n    setIntraOpNumThreads(numThreads.coerceIn(1, 4))\n    setInterOpNumThreads(numThreads)\n    setMemoryPatternOptimization(true)\n    setOptimizationLevel(OrtSession.SessionOptions.OptLevel.ALL_OPT)\n    setExecutionMode(OrtSession.SessionOptions.ExecutionMode.SEQUENTIAL)\n}\n</code></pre>\n<p>Your first instinct might be to use all available CPU cores for maximum performance. Resist this urge. Mobile devices prioritize battery life over raw computational speed, and Android's thermal management will throttle aggressive CPU usage within seconds.</p>\n<p>The sweet spot for real-time audio processing sits between 2-4 threads, determined by your device's core count:</p>\n<p>\\</p>\n<pre><code class=\"bash language-bash\">private val numThreads = Runtime.getRuntime().availableProcessors().coerceIn(1, 4)\n</code></pre>\n<p>This configuration delivers 95% of maximum performance while consuming 60% less battery than an unrestricted thread pool. Your users notice the efficiency gains more than the minor latency difference.</p>\n<p><code>setMemoryPatternOptimization(true)</code> activates ONNX Runtime's most impactful mobile optimization. This setting analyzes your model's memory access patterns during the first few inference calls, then pre-allocates memory pools to minimize garbage collection pressure during real-time processing.</p>\n<p>\\</p>\n<pre><code class=\"bash language-bash\">setExecutionMode(OrtSession.SessionOptions.ExecutionMode.SEQUENTIAL)\n</code></pre>\n<p>Sequential execution might seem counterintuitive when parallel processing offers higher throughput. However, real-time audio processing demands predictable latency over peak performance. Parallel execution creates latency spikes when thread synchronization occurs - precisely what you want to avoid during live audio processing.</p>\n<p>Sequential execution delivers consistent 3-4ms inference times, while parallel mode ranges from 2-8ms with unpredictable spikes. Users perceive consistency as quality.</p>\n<p><strong>Memory Pre-allocation: The Performance Multiplier</strong></p>\n<p>The most critical optimization for mobile ONNX Runtime applications involves pre-allocating tensors that get reused across inference calls. Creating tensors during inference triggers memory allocations that accumulate into significant performance bottlenecks.</p>\n<p>\\</p>\n<pre><code class=\"bash language-bash\">// Pre-allocate tensors during initialization\ninput3Tensor = createZeroTensor(INP_SHAPE_2)  // Model 1 LSTM state\ninput5Tensor = createZeroTensor(INP_SHAPE_2)  // Model 2 LSTM state\n\nprivate fun createZeroTensor(shape: LongArray): OnnxTensor {\n    val env = requireNotNull(env) { \"ONNX Environment not initialized\" }\n    val size = shape.reduce { acc, i -&gt; acc * i }.toInt()\n    return OnnxTensor.createTensor(env, FloatBuffer.allocate(size), shape)\n}\n</code></pre>\n<p><strong>Garbage Collection Pressure Reduction</strong> - Creating tensors during inference generates objects that must be garbage collected. Pre-allocation moves this cost to initialization time, keeping inference paths allocation-free.</p>\n<p><strong>Memory Fragmentation Prevention</strong> - Repeated tensor creation fragments heap memory, leading to unexpected allocation failures. Pre-allocated tensors maintain consistent memory layout.</p>\n<p><strong>Latency Consistency</strong> - Allocation costs are unpredictable and can introduce latency spikes during real-time processing. Pre-allocation ensures consistent inference timing.</p>\n<p>These integration strategies transform ONNX Runtime from a research tool into a production-ready component. The configuration choices, memory management patterns, and error handling approaches directly impact user experience in ways that become apparent only under real-world usage conditions.</p>\n<p>You can look into <strong><a href=\"https://github.com/linreal/android-onnx-showcase/blob/main/app/src/main/java/gos/denver/onnxshowcase/audio/impl/NoiseSuppressorImpl.kt\">https://github.com/linreal/android-onnx-showcase/blob/main/app/src/main/java/gos/denver/onnxshowcase/audio/impl/NoiseSuppressorImpl.kt</a></strong> for a full source code.</p>\n<h2 id=\"conclusionaiascompetitiveadvantage\">Conclusion: AI as Competitive Advantage</h2>\n<p>The mobile AI landscape is experiencing a fundamental shift. While competitors chase resource-hungry language models and cloud-dependent solutions, there's a massive opportunity in specialized, on-device AI that delivers immediate value to users.</p>\n<h3 id=\"keytakeawaysforandroiddevelopers\"><strong>Key Takeaways for Android Developers</strong></h3>\n<p><strong>On-device AI is production-ready today. T</strong>he combination of ONNX Runtime's optimization capabilities and purpose-built models like DTLN delivers performance that matches or exceeds cloud solutions while eliminating latency and connectivity requirements. Your users get instant results, and you get a feature that works everywhere - from subway tunnels to airplane mode.</p>\n<p><strong>APK size optimization transforms deployment strategy.</strong> Our minimal ONNX Runtime build reduced library size by 70% without sacrificing functionality. This isn't just about storage - it directly impacts user acquisition. When AI features add 7MB instead of 27MB to your app, the cost-benefit equation shifts dramatically in your favor.</p>\n<p><strong>User experience trumps algorithmic sophistication.</strong> DTLN isn't the most advanced noise suppression model available, but it strikes the perfect balance between quality, performance, and resource consumption for mobile deployment. Users don't care about model architecture - they care about crystal-clear audio in noisy environments.</p>\n<p>Apps implementing on-device AI gain three competitive advantages: Privacy by Design (no sensitive data leaves the device), Offline Reliability (consistent experience regardless of network conditions), and Cost Structure Benefits (no cloud inference costs or operational expenses that scale with usage).</p>\n<h3 id=\"nextstepsandexploration\"><strong>Next Steps and Exploration</strong></h3>\n<p>The techniques demonstrated here extend far beyond noise suppression. ONNX Runtime enables practical deployment of models for audio processing, computer vision, natural language tasks, and sensor fusion applications.</p>\n<p>The complete implementation is available on GitHub: <strong><a href=\"https://github.com/linreal/android-onnx-showcase\">android-onnx-showcase</a></strong>. Use it as a foundation for your own AI-powered features.</p>\n<p>Your Android app deserves AI that enhances user experience without compromising performance, privacy, or reliability. ONNX Runtime makes this vision achievable today. The tools are ready, the performance is proven - time to build something amazing.</p>\n<hr />\n<p><em>Found this implementation useful? Star the <strong><a href=\"https://github.com/linreal/android-onnx-showcase\">GitHub repository</a></strong> and share your results. The mobile AI community grows stronger when we share practical knowledge.</em></p>\n<p><em>Follow me for more deep-dives into production-ready mobile AI implementations that your users will actually notice and appreciate.</em> \\n </p>",
          "content:encodedSnippet": "Your phone is more powerful than a desktop computer from five years ago. The latest flagship Android devices pack neural processing units, multi-core CPUs that would make 2019 laptops jealous, and RAM configurations that seemed impossible just a few years back. So why does it feel like we're barely scratching the surface of what's possible with AI on mobile?\nSure, you can now even run quantized versions of Llama and DeepSeek models locally on your device. But let's be honest - those conversations still feel clunky, slow, and nowhere near the seamless experience users expect from their apps. The hype around on-device conversational AI is real, but the practical reality? We're not quite there yet.\nHere's where most developers miss the opportunity: conversational AI isn't the only game in town. While everyone's chasing the next ChatGPT clone, there's a massive untapped potential in specialized AI applications that actually work brilliantly on mobile hardware right now.\nTake noise suppression. Your users are constantly battling background noise during calls, recordings, and voice messages. Wind, traffic, crying babies, barking dogs - it's an endless war against audio chaos. But what if your app could eliminate that noise in real-time, locally, without sending a single byte to the cloud?\nThis isn't science fiction. It's happening today, and any Android developer can implement it. The tools are mature, the performance is there, and your users will immediately notice the difference.\nONNX Runtime: Your Gateway to Mobile AI\nThe mobile AI landscape is fragmented. PyTorch dominates research, TensorFlow rules production, and countless specialized frameworks emerge for specific use cases. For Android developers, this creates a painful choice: commit to one ecosystem or maintain separate pipelines for different models.\nAfter evaluating mobile AI frameworks, we chose ONNX Runtime for several compelling reasons that directly impact Android development.\nWider Compatibility Across Android Versions\nUnlike Google's LiteRT (formerly TensorFlow Lite), which mandates a minimum SDK level of 31 (Android 12), ONNX Runtime comfortably supports Android API levels as low as 24 (or even 21, if you are a magician). Our project’s minimum supported version was API 28, making ONNX Runtime the clear choice to reach a broader audience without excluding millions of active users on Android 10 and earlier devices.\nSeamless Cross-Framework Integration\nONNX Runtime’s greatest strength lies in its framework-agnostic nature. Whether your AI models originate from PyTorch, TensorFlow, or even traditional ML libraries like scikit-learn, exporting models to ONNX allows uniform deployment across Android, iOS, desktops, and cloud environments. This flexibility significantly simplifies maintenance, enabling a unified pipeline rather than juggling multiple framework-specific tools.\nLightweight and Modular Deployment\nIntegration with ONNX Runtime is straightforward. With a compact Maven AAR (around 5–7 MB for CPU builds), the library integrates cleanly into your existing Android app without introducing unnecessary dependencies like Google Play Services or requesting additional user permissions. This streamlined deployment keeps your app lean, performant, and secure.\nProven Real-Time Performance\nONNX Runtime is battle-tested in demanding real-time scenarios. Audio-processing models, such as noise suppression or speech enhancement, consistently deliver inference speeds under 4 ms per audio frame on standard mobile hardware - comfortably within real-time performance requirements. Our team leveraged this exact capability for reliable, low-latency noise suppression.\nUltimately, ONNX Runtime provided our team not just convenience, but strategic advantage - allowing us to maintain compatibility, performance, and simplicity without compromises. If your project demands accessible, performant, and scalable mobile AI, ONNX Runtime could very well be your optimal choice.\nIntegration Plan: Setting Up ONNX Runtime\nThe default ONNX Runtime package weighs in at a hefty 27MB. For a mobile app, that's not just bloat - it's a user acquisition killer. Research shows that for every 6MB increase in APK size, install conversion rates drop by 1% (I should note that the study is not the newest one, and concerns mainly not the most developed countries, but still, it is worth considering)\nThe solution? A custom minimal build that strips your deployment down to exactly what you need. Our DTLN noise suppression implementation clocks in at just 7.1MB - a 70% size reduction that keeps your app lean and your users happy.\nONNX Runtime's architecture is modular by design. The full package includes execution providers for GPU acceleration (NNAPI, Vulkan), dozens of operators you'll never use, and compatibility layers for edge cases that don't apply to your specific model. By building only what you need, you eliminate this overhead entirely.\nStep 1: Convert Your Models to ORT Format\nBefore building, convert your ONNX models to ORT format. This optimized format removes unused graph nodes and operator definitions, further reducing your final binary size.\n\\\npython -m onnxruntime.tools.convert_onnx_models_to_ort <onnx model file or dir> &nbsp;&nbsp;&nbsp;--target_platform {arm,amd64}\n\nStep 2: Create Operator Configuration\nAfter converting all the necessary models, configuration files with the necessary operators that will be required for the minimal build of ONNX will also be generated.\nWhen using several models, combine all the configuration files into one.\nThe final file will look something like this:\n\\\n# Generated from model/s:\nai.onnx;1;Transpose\nai.onnx;6;Sigmoid\nai.onnx;7;Add,LSTM\nai.onnx;9;MatMul\nai.onnx;11;Concat,Slice,Squeeze,Unsqueeze\nai.onnx;1;Transpose\nai.onnx;5;Reshape\n//other operators\n\nStep 3: Execute Custom Build\nWith your operator configuration ready, build ONNX Runtime from source with minimal dependencies:\n\\\n./build.sh --android \\\n  --android_sdk_path ~/Library/Android/sdk \\\n  --android_ndk_path ~/Library/Android/sdk/ndk/28.0.12674087 \\\n  --android_abi arm64-v8a \\\n  --android_api 24 \\\n  --minimal_build \\\n  --include_ops_by_config path/to/required_operators.config \\\n  --build_java \\\n  --config=Rel\n\n--minimal_build: Excludes unnecessary execution providers and operators\n--includeopsby_config: Includes only operators specified in your config file\n--android_abi armeabi-v7a: Targets ARM32 for maximum device compatibility\n--android_api 24: Maintains compatibility with Android 7.0+\nIf you also want to support old devices, repeat step 3 with –android_abi armeabi-v7a and them merge both resulting aar files with following script:\n\\\n#!/usr/bin/env sh\n\n# Clean up from previous runs, if any\nrm -rf merge-tmp\nmkdir -p merge-tmp\ncd merge-tmp\n\necho \"Unzipping each ABI-specific AAR...\"\nmkdir a64\nunzip ../onnxruntime-arm64-v8a.aar -d a64\n\nmkdir a32\nunzip ../onnxruntime-armeabi-v7a.aar -d a32\n\necho \"Preparing universal base from arm64 AAR...\"\nmkdir universal\ncp -r a64/* universal\n\nrm -rf universal/jni\nmkdir -p universal/jni\n\n\necho \"Merging native libs from each architecture...\"\nmkdir -p universal/jni/arm64-v8a\ncp a64/jni/arm64-v8a/*.so universal/jni/arm64-v8a\n\nmkdir -p universal/jni/armeabi-v7a\ncp a32/jni/armeabi-v7a/*.so universal/jni/armeabi-v7a\n\n\n# Re-zip contents of 'universal' to create a new AAR\necho \"Creating universal AAR...\"\ncd universal\nzip -r onnxruntime-universal.aar ./*\n\necho \"Done! The merged AAR is at:\"\necho \"$(pwd)/onnxruntime-universal.aar\"\n\nThe minimal build approach transforms ONNX Runtime from a deployment liability into a strategic advantage. Your users get the full AI capability without the bloat, and your app maintains the lean profile that modern mobile development demands.\nNext, let's see this optimized runtime in action with real-time DTLN noise suppression.\nWhy Audio Processing Showcases AI Value\nAudio processing is the perfect introduction to mobile AI - delivering immediate, tangible value while your competitors wrestle with bloated language models that drain batteries and require constant internet connections.\nThe Daily Audio War Your Users Are Fighting\nSarah records voice messages while walking through a busy street. Between honking taxis, construction noise, and subway rumbles, she re-records messages three times before giving up and typing instead.\nMarcus joins client calls from his home office, which doubles as his toddler's playroom. Every presentation becomes a cycle of \"mute, unmute, apologize for the crying.\"\nElena creates YouTube content in her apartment but spends hours in post-production cleaning up neighbor noise, traffic, and air conditioning hum.\nThese aren't edge cases - they're the reality of modern mobile computing where everyone expects professional results from consumer hardware in chaotic environments.\nWhy Noise Suppression Creates Instant \"Wow\" Moments\nAudio quality improvements trigger immediate emotional responses. Unlike other AI applications requiring explanation, noise suppression provides instant gratification users can perceive within seconds. Play someone their own voice - crystal clear - after removing background noise, and watch their reaction. They don't need to understand LSTM networks; they just know their audio sounds professional.\nThe beauty of audio processing as an AI showcase lies in universality. Everyone understands good audio, everyone has experienced bad audio, and everyone immediately recognizes improvement when noise disappears. You're not asking users to trust your AI - you're proving its value in the most direct way possible.\nBuilding a Production-Ready Demo: Real-Time Noise Suppression\nNow, let's build a sample project that demonstrates the practical power of ONNX Runtime on Android. Rather than a basic \"hello world\" example, we'll create something close to production quality - a real-time noise suppression demonstration where users can record audio in noisy environments and experience the striking difference between their original recording and the AI-cleaned version.\nYou can find a complete sample here, on my Github: https://github.com/linreal/android-onnx-showcase.\nModels, used in sample are from https://github.com/breizhn/DTLN\nQuick Implementation Overview\nBefore diving into DTLN's dual-path architecture, let's establish how the pieces fit together. The beauty of this implementation lies in its clean separation of concerns - each component has a single responsibility, making the system both testable and maintainable.\nThe Core Components\nAt the heart of our noise suppression pipeline sit three key interfaces that work together:\n\\\ninterface NoiseSuppressor {\n    suspend fun initialize()\n    fun processChunk(audioChunk: FloatArray): FloatArray\n    fun release()\n}\n\ninterface AudioRecorder {\n    suspend fun startRecording(): Flow<ShortArray>\n    suspend fun stopRecording()\n}\n\ninterface ConcurrentAudioProcessor {\n    suspend fun startProcessing(\n        suppressor: NoiseSuppressor,\n        rawOutputFile: File,\n        processedOutputFile: File\n    )\n    suspend fun stopProcessing(): ProcessingResult\n}\n\nThe NoiseSuppressor encapsulates all ONNX Runtime complexity behind a simple interface. Feed it audio chunks, get back denoised audio. The stateful nature of DTLN is completely hidden - the implementation maintains LSTM states internally between calls.\nData Flow Architecture\n\\\nAudioRecorder → Flow<ShortArray> → ConcurrentAudioProcessor → NoiseSuppressor → Processed Audio Files\n\n\\\nThe ConcurrentAudioProcessor orchestrates the entire pipeline. It subscribes to the audio recorder's Flow, converts audio formats, processes chunks through the noise suppressor, and writes both original and processed audio to files simultaneously.\n\\\nrawAudioRecorder.startRecording().collect { audioChunk ->\n    // Convert format for processing\n    val floatChunk = AudioConversionUtils.shortArrayToFloatArray(audioChunk)\n\n    // Process through DTLN\n    val processedChunk = suppressor.processChunk(floatChunk)\n\n    // Save both versions concurrently\n    launch { rawFileWriter.writeAudioData(floatChunk) }\n    launch { processedFileWriter.writeAudioData(processedChunk) }\n}\n\nWhy This Architecture Works\nReactive Processing: The Flow-based design ensures your UI remains responsive. Audio processing happens on background threads while the main thread handles user interactions.\nFormat Isolation: Each component works with its preferred audio format. AudioRecorder produces ShortArray (16-bit PCM), while NoiseSuppressor expects FloatArray (normalized samples). Conversion happens at the boundary.\nError Boundaries: If ONNX initialization fails, only the NoiseSuppressor component is affected. The audio recorder and file writers continue functioning, ensuring graceful degradation.\nResource Management: Each component manages its own resources. The ConcurrentAudioProcessor coordinates lifecycle events but doesn't own the underlying implementations.\nThis modular approach means you can swap out the DTLN implementation for any other ONNX model, replace the audio recorder with a file-based source, or modify the output format without touching other components. The architecture scales from proof-of-concept to production deployment.\nNext, we'll explore the DTLN architecture that makes this magic happen.\nUnderstanding DTLN Architecture\nTraditional noise suppression approaches face a fundamental tradeoff. Frequency-domain methods excel at removing stationary noise (air conditioning, fan hum) but struggle with dynamic sounds like speech or music bleeding through. Time-domain approaches handle complex, changing signals well but often introduce artifacts or fail with consistent background noise.\nDTLN sidesteps this limitation entirely through its dual-path architecture:\nStage 1: Frequency Domain Processing The first model operates in the frequency domain, analyzing the spectral characteristics of your audio. It generates a suppression mask that identifies which frequency components contain noise versus speech. This stage excels at removing stationary background noise - the steady hum of air conditioning, traffic, or office chatter.\n\\\n// Stage 1: Frequency domain mask estimation\n\nval (magnitude, phase) = fftProcessor.forward(inBuffer)\nval outMask = model1.run(mapOf(\"input_2\" to magnitudeTensor, \"input_3\" to lstmState))\nfor (i in magnitude.indices) {\n    magnitude[i] *= outMask[i] // Apply suppression mask\n}\n\nStage 2: Time Domain Refinement The masked frequency-domain signal gets converted back to the time domain, then fed into a second model that operates directly on the audio waveform. This stage catches what the frequency analysis missed - handling dynamic noise patterns, preserving speech naturalness, and cleaning up any artifacts from the first stage.\n\\\n// Stage 2: Time domain refinement\n\nval estimatedBlock = fftProcessor.inverse(magnitude, phase)\nval finalBlock = model2.run(mapOf(\"input_4\" to estimatedTensor, \"input_5\" to lstmState))\n\nThe Mobile-First Design Philosophy\nDTLN's architecture reflects years of practical mobile AI deployment experience. Every design decision prioritizes real-world constraints over academic benchmarks.\nChunk-Based Processing The model processes audio in 512-sample chunks (32ms at 16kHz), striking the optimal balance between latency and context. This chunk size is small enough for real-time processing but large enough to provide meaningful temporal context for the LSTM networks.\n\\\ncompanion object {\n    private const val BLOCK_LEN = 512  // 32ms chunks\n    private const val BLOCK_SHIFT = 128  // 75% overlap for smooth processing\n}\n\nStateful LSTM Networks Both models use LSTM (Long Short-Term Memory) networks that maintain internal state between chunks. This temporal memory allows the model to distinguish between speech and noise based on context, not just instantaneous audio characteristics.\n\\\nclass NoiseSuppressorImpl {\n    // These tensors maintain LSTM state between processing calls\n    private var input3Tensor: OnnxTensor? = null  // Model 1 LSTM state\n    private var input5Tensor: OnnxTensor? = null  // Model 2 LSTM state\n\n    fun processChunk(audioChunk: FloatArray): FloatArray {\n        // State automatically carries forward to next chunk\n        val result1 = model1.run(mapOf(\"input_3\" to input3Tensor))\n        input3Tensor?.close()\n        input3Tensor = result1[1] as OnnxTensor  // Update state\n\n        // State continuity ensures smooth, artifact-free processing\n    }\n}\n\nPerformance Characteristics That Matter\nUnderstanding DTLN's architecture helps predict its behavior in your application. These performance characteristics directly impact user experience:\nLatency Profile\nAlgorithmic Delay: 32ms (one chunk processing time)\nInference Time: 3-4ms per chunk on mid-range Android hardware\nTotal Latency: ~35ms end-to-end (imperceptible for most use cases)\nResource Usage\nMemory Footprint: ~28MB during active processing\nCPU Usage: 12-18% on typical mid-range device\nBattery Impact: Negligible for typical recording sessions\nThese characteristics make DTLN particularly well-suited for mobile applications where users expect immediate results without sacrificing device performance or battery life.\nONNX Runtime Integration Strategy\nGetting ONNX Runtime working on Android isn't just about adding a dependency to your build.gradle. The difference between a proof-of-concept that crashes under load and a production-ready implementation lies in the session configuration, memory management, and resource allocation strategy.\nAs we already prepared a minimal runtime build, it’s time to look into what lies next.\nSession Configuration for Mobile Reality\nThe default ONNX Runtime session configuration assumes you're running on a server with abundant resources. Mobile devices operate under entirely different constraints: limited memory, thermal throttling, and users who expect apps to remain responsive during AI processing.\n\\\nprivate val sessionOptions = OrtSession.SessionOptions().apply {\n    setIntraOpNumThreads(numThreads.coerceIn(1, 4))\n    setInterOpNumThreads(numThreads)\n    setMemoryPatternOptimization(true)\n    setOptimizationLevel(OrtSession.SessionOptions.OptLevel.ALL_OPT)\n    setExecutionMode(OrtSession.SessionOptions.ExecutionMode.SEQUENTIAL)\n}\n\nYour first instinct might be to use all available CPU cores for maximum performance. Resist this urge. Mobile devices prioritize battery life over raw computational speed, and Android's thermal management will throttle aggressive CPU usage within seconds.\nThe sweet spot for real-time audio processing sits between 2-4 threads, determined by your device's core count:\n\\\nprivate val numThreads = Runtime.getRuntime().availableProcessors().coerceIn(1, 4)\n\nThis configuration delivers 95% of maximum performance while consuming 60% less battery than an unrestricted thread pool. Your users notice the efficiency gains more than the minor latency difference.\nsetMemoryPatternOptimization(true) activates ONNX Runtime's most impactful mobile optimization. This setting analyzes your model's memory access patterns during the first few inference calls, then pre-allocates memory pools to minimize garbage collection pressure during real-time processing.\n\\\nsetExecutionMode(OrtSession.SessionOptions.ExecutionMode.SEQUENTIAL)\n\nSequential execution might seem counterintuitive when parallel processing offers higher throughput. However, real-time audio processing demands predictable latency over peak performance. Parallel execution creates latency spikes when thread synchronization occurs - precisely what you want to avoid during live audio processing.\nSequential execution delivers consistent 3-4ms inference times, while parallel mode ranges from 2-8ms with unpredictable spikes. Users perceive consistency as quality.\nMemory Pre-allocation: The Performance Multiplier\nThe most critical optimization for mobile ONNX Runtime applications involves pre-allocating tensors that get reused across inference calls. Creating tensors during inference triggers memory allocations that accumulate into significant performance bottlenecks.\n\\\n// Pre-allocate tensors during initialization\ninput3Tensor = createZeroTensor(INP_SHAPE_2)  // Model 1 LSTM state\ninput5Tensor = createZeroTensor(INP_SHAPE_2)  // Model 2 LSTM state\n\nprivate fun createZeroTensor(shape: LongArray): OnnxTensor {\n    val env = requireNotNull(env) { \"ONNX Environment not initialized\" }\n    val size = shape.reduce { acc, i -> acc * i }.toInt()\n    return OnnxTensor.createTensor(env, FloatBuffer.allocate(size), shape)\n}\n\nGarbage Collection Pressure Reduction - Creating tensors during inference generates objects that must be garbage collected. Pre-allocation moves this cost to initialization time, keeping inference paths allocation-free.\nMemory Fragmentation Prevention - Repeated tensor creation fragments heap memory, leading to unexpected allocation failures. Pre-allocated tensors maintain consistent memory layout.\nLatency Consistency - Allocation costs are unpredictable and can introduce latency spikes during real-time processing. Pre-allocation ensures consistent inference timing.\nThese integration strategies transform ONNX Runtime from a research tool into a production-ready component. The configuration choices, memory management patterns, and error handling approaches directly impact user experience in ways that become apparent only under real-world usage conditions.\nYou can look into https://github.com/linreal/android-onnx-showcase/blob/main/app/src/main/java/gos/denver/onnxshowcase/audio/impl/NoiseSuppressorImpl.kt for a full source code.\nConclusion: AI as Competitive Advantage\nThe mobile AI landscape is experiencing a fundamental shift. While competitors chase resource-hungry language models and cloud-dependent solutions, there's a massive opportunity in specialized, on-device AI that delivers immediate value to users.\nKey Takeaways for Android Developers\nOn-device AI is production-ready today. The combination of ONNX Runtime's optimization capabilities and purpose-built models like DTLN delivers performance that matches or exceeds cloud solutions while eliminating latency and connectivity requirements. Your users get instant results, and you get a feature that works everywhere - from subway tunnels to airplane mode.\nAPK size optimization transforms deployment strategy. Our minimal ONNX Runtime build reduced library size by 70% without sacrificing functionality. This isn't just about storage - it directly impacts user acquisition. When AI features add 7MB instead of 27MB to your app, the cost-benefit equation shifts dramatically in your favor.\nUser experience trumps algorithmic sophistication. DTLN isn't the most advanced noise suppression model available, but it strikes the perfect balance between quality, performance, and resource consumption for mobile deployment. Users don't care about model architecture - they care about crystal-clear audio in noisy environments.\nApps implementing on-device AI gain three competitive advantages: Privacy by Design (no sensitive data leaves the device), Offline Reliability (consistent experience regardless of network conditions), and Cost Structure Benefits (no cloud inference costs or operational expenses that scale with usage).\nNext Steps and Exploration\nThe techniques demonstrated here extend far beyond noise suppression. ONNX Runtime enables practical deployment of models for audio processing, computer vision, natural language tasks, and sensor fusion applications.\nThe complete implementation is available on GitHub: android-onnx-showcase. Use it as a foundation for your own AI-powered features.\nYour Android app deserves AI that enhances user experience without compromising performance, privacy, or reliability. ONNX Runtime makes this vision achievable today. The tools are ready, the performance is proven - time to build something amazing.\nFound this implementation useful? Star the GitHub repository and share your results. The mobile AI community grows stronger when we share practical knowledge.\nFollow me for more deep-dives into production-ready mobile AI implementations that your users will actually notice and appreciate. \\n",
          "dc:creator": "Sergey Drymchenko",
          "content": "Build real-time AI noise suppression for Android with ONNX Runtime. Complete tutorial with working code, performance tips, and 70% APK size reduction.",
          "contentSnippet": "Build real-time AI noise suppression for Android with ONNX Runtime. Complete tutorial with working code, performance tips, and 70% APK size reduction.",
          "guid": "https://hackernoon.com/mobile-ai-with-onnx-runtime-how-to-build-real-time-noise-suppression-that-works?source=rss",
          "categories": [
            "mobile-ai",
            "onnx-runtime",
            "on-device-ai",
            "mobile-ai-performance",
            "android-ai-sdk",
            "dtln-noise-reduction",
            "lightweight-ai-deployment",
            "onnx-runtime-android"
          ],
          "isoDate": "2025-08-03T16:03:09.000Z"
        }
      },
      {
        "json": {
          "creator": "Kaspar Tiri",
          "title": "The Real Reason Most Indie Games Flop (It Has Nothing To Do With Gameplay)",
          "link": "https://hackernoon.com/the-real-reason-most-indie-games-flop-it-has-nothing-to-do-with-gameplay?source=rss",
          "pubDate": "Sun, 03 Aug 2025 15:50:07 GMT",
          "content:encoded": "<h3 id=\"highqualitygamesaregettinglost\"><strong>High-Quality Games Are Getting Lost</strong></h3>\n<p>In the past few years, the gaming industry has seen a tidal wave of investment. Tens of billions of dollars have flowed into studios and publishers—more than ten times the historical average. The result is exactly what you’d expect: <strong>an explosion of high-quality content.</strong></p>\n<p>From 2019 to 2023, the number of games released on Steam nearly doubled, reaching over <strong><a href=\"https://steamdb.info/stats/releases/\">14,500 new games</a></strong>&nbsp;per year. Meanwhile, the App Store and Google Play are flooded with over a thousand apps published every day, offering players more choice than ever. Those distribution channels have become saturated.</p>\n<p>Despite the surge in funding and quality, most games are quietly slipping through the cracks. I meet founders all the time whose launch strategy is no deeper than: <em>“We’re making a great game and putting it up on Steam Early Access.”</em>That’s not a go-to-market strategy—that’s wishful thinking. \\n </p>\n<h3 id=\"weveseenthisstorybefore\">We’ve Seen This Story Before</h3>\n<p>In the early 2000s and throughout the 2010s, Hollywood studios kept doubling down on blockbuster content—fund content, release in theaters, repeat. The assumption was that the better the content, the better the outcome. Then <a href=\"https://hackernoon.com/company/netflix\">Netflix</a> changed the game. They didn’t just create shows. They changed how audiences discovered and consumed content. It was a new distribution model: personalized, frictionless, on-demand access to content, delivered over the internet, bypassing movie theaters entirely. Today, nearly every major player from Disney to HBO follows that same model. Content still matters, but distribution is what changed the industry.</p>\n<p>The same happened in music. Record labels used to control everything through their artist rosters. But <a href=\"https://hackernoon.com/company/spotify\">Spotify</a>, <a href=\"https://hackernoon.com/company/youtube\">YouTube</a>, and later <a href=\"https://hackernoon.com/company/tiktok\">TikTok</a> shifted the power. They didn’t make music—they just made it easier to access and share. Today, artists break through because of those platforms. Labels that once owned the pipeline now find themselves negotiating with it.</p>\n<p>Gaming is following the same arc. Incredible content, saturated channels, and a growing realization that discovery—not quality—is the real bottleneck. \\n </p>\n<h3 id=\"distributionisthebottleneck\"><strong>Distribution Is the Bottleneck</strong></h3>\n<p>We’re not short on great games. We’re short on new ways to make people care.</p>\n<p>Steam saw more than 40 games launched a day in 2023. Mobile app stores are even more saturated, with over 1,000 apps published daily. Discovery hasn’t kept up with the flood of content. It’s been overwhelmed by it.</p>\n<p>Steam has added curators, tags, and algorithmic feeds, but most releases still sink within days. Mobile stores are worse—prime real estate is dominated by paid ads, and organic discovery is nearly nonexistent. There’s simply too much content, not enough visibility, and no efficient way to rise above the noise <strong>unless you pay your way to the front.</strong></p>\n<p>This saturation is not just a discovery problem—it’s an economic one.</p>\n<p>Apple’s ATT rollout in 2021 disrupted mobile user acquisition overnight. <strong><a href=\"https://www.konvoy.vc/newsletters/mobile-gaming-post-idfa-deprecation\">Over 80%</a></strong> of iPhone users became invisible to targeted ads, breaking the model that many mobile studios relied on to find and convert high-value players. CPI costs jumped <strong><a href=\"https://www.adexchanger.com/mobile/ua-for-game-developers-is-an-entirely-different-animal-in-the-post-att-era/\">nearly 90%</a></strong>. ROAS dropped. What once worked no longer does.</p>\n<p>At the same time, most games don’t make money. But it’s not always because the games are bad—it’s because they’re invisible. On Steam, <strong><a href=\"https://gameworldobserver.com/2023/10/06/steam-stats-41k-games-last-3-years-half-made-500-or-less\">67% of games</a></strong> have earned less than $5,000 in lifetime revenue—and more than half never crossed $1,000. The average player sticks to four games a year. On mobile, the top 1% of games account for over 90% of downloads. Nearly 60% of apps on the App Store <strong>don’t even have a single review.</strong></p>\n<p>There’s no middle class. Big-budget games and breakout hits get all the attention. Everyone else fights for scraps. The end result is the “rich get richer.”</p>\n<p>Indies can’t afford to brute-force their way into visibility. They can’t outspend or outmarket incumbents. And yet most studios still rely on the same tired playbook: launch on Steam, pay the platform tax, hope the algorithm works. That’s not a strategy. It’s a gamble (tho, once in a blue moon, the algorithm favors an indie and it breaks out).</p>\n<p>Distribution is not a side task—it’s the real product challenge. And it’s the one thing this industry hasn’t meaningfully rethought.</p>\n<p>\\</p>\n<h3 id=\"theshifthasalreadystarted\">The Shift Has Already Started</h3>\n<p>Some companies aren’t waiting for better distribution. They’re building it.</p>\n<p>Epic didn’t just launch a hit game—they turned Fortnite into a platform. With UEFN (Unreal Editor for Fortnite), developers can now build games inside Fortnite using AAA tools, publish instantly, and tap into a built-in audience of millions. Discovery and monetization are integrated. The friction is gone.</p>\n<p>Roblox took it even further. It’s a closed-loop system where content and distribution live in the same place. Creators build games, users discover them, and both sides benefit. What makes Roblox especially interesting right now is this: <strong>distribution is ahead of content</strong>. The platform has reach. It just doesn’t have enough standout experiences. For developers, that’s an opportunity to succeed not by out-marketing the competition, but simply by building something better.</p>\n<p>Other players are entering the space from the edges. YouTube is embedding games directly into its platform. Discord lets users play inside servers. Netflix now offers games alongside its shows. Even Telegram supports native games through mini-apps. All of these are experiments in rethinking where and how games are discovered.</p>\n<p>And then there’s the web.</p>\n<p>The open web is becoming viable again—not just for casual games, but for real, session-based experiences. There’s no platform tax. No gatekeepers. No approval queues. A single build can reach anyone with a browser. For developers, that’s freedom. For players, it’s one click away.</p>\n<p>We’re starting to see early signs of this shift. <strong><a href=\"https://www.reddit.com/r/IndieGaming/comments/124znci/our_first_gameplay_reveal_trailer_for_bapbap_a/\">BAPBAP</a></strong>&nbsp;built an early fanbase in 2023 through a web version before launching on Steam, fueling thousands of installs on day one. <strong><a href=\"https://en.wikipedia.org/wiki/GDEV?utm_source=chatgpt.com\">Hero Wars</a></strong>&nbsp;took the same path years earlier—starting on the web, then expanding to mobile, where it surpassed <a href=\"https://www.pocketgamer.biz/hero-wars-alliance-celebrates-15-billion-in-revenue/?utm_source=chatgpt.com\">150 million installs and $1.5 billion in revenue.</a></p>\n<p>But most developers are still funneling their games into the same overcrowded storefronts—fighting over the same algorithms, the same paid installs, and the same limited real estate. It’s time to shift that energy. Instead of competing in the same narrow lanes, the opportunity is to explore new ones. Go where users already are. Build for the platforms that actually enable discovery. Let distribution shape your strategy—not follow it.</p>\n<p>The future won’t be defined by who builds the best-looking game. It will be defined by who rethinks the path to finding it.</p>",
          "content:encodedSnippet": "High-Quality Games Are Getting Lost\nIn the past few years, the gaming industry has seen a tidal wave of investment. Tens of billions of dollars have flowed into studios and publishers—more than ten times the historical average. The result is exactly what you’d expect: an explosion of high-quality content.\nFrom 2019 to 2023, the number of games released on Steam nearly doubled, reaching over 14,500 new games per year. Meanwhile, the App Store and Google Play are flooded with over a thousand apps published every day, offering players more choice than ever. Those distribution channels have become saturated.\nDespite the surge in funding and quality, most games are quietly slipping through the cracks. I meet founders all the time whose launch strategy is no deeper than: “We’re making a great game and putting it up on Steam Early Access.”That’s not a go-to-market strategy—that’s wishful thinking. \\n \nWe’ve Seen This Story Before\nIn the early 2000s and throughout the 2010s, Hollywood studios kept doubling down on blockbuster content—fund content, release in theaters, repeat. The assumption was that the better the content, the better the outcome. Then Netflix changed the game. They didn’t just create shows. They changed how audiences discovered and consumed content. It was a new distribution model: personalized, frictionless, on-demand access to content, delivered over the internet, bypassing movie theaters entirely. Today, nearly every major player from Disney to HBO follows that same model. Content still matters, but distribution is what changed the industry.\nThe same happened in music. Record labels used to control everything through their artist rosters. But Spotify, YouTube, and later TikTok shifted the power. They didn’t make music—they just made it easier to access and share. Today, artists break through because of those platforms. Labels that once owned the pipeline now find themselves negotiating with it.\nGaming is following the same arc. Incredible content, saturated channels, and a growing realization that discovery—not quality—is the real bottleneck. \\n \nDistribution Is the Bottleneck\nWe’re not short on great games. We’re short on new ways to make people care.\nSteam saw more than 40 games launched a day in 2023. Mobile app stores are even more saturated, with over 1,000 apps published daily. Discovery hasn’t kept up with the flood of content. It’s been overwhelmed by it.\nSteam has added curators, tags, and algorithmic feeds, but most releases still sink within days. Mobile stores are worse—prime real estate is dominated by paid ads, and organic discovery is nearly nonexistent. There’s simply too much content, not enough visibility, and no efficient way to rise above the noise unless you pay your way to the front.\nThis saturation is not just a discovery problem—it’s an economic one.\nApple’s ATT rollout in 2021 disrupted mobile user acquisition overnight. Over 80% of iPhone users became invisible to targeted ads, breaking the model that many mobile studios relied on to find and convert high-value players. CPI costs jumped nearly 90%. ROAS dropped. What once worked no longer does.\nAt the same time, most games don’t make money. But it’s not always because the games are bad—it’s because they’re invisible. On Steam, 67% of games have earned less than $5,000 in lifetime revenue—and more than half never crossed $1,000. The average player sticks to four games a year. On mobile, the top 1% of games account for over 90% of downloads. Nearly 60% of apps on the App Store don’t even have a single review.\nThere’s no middle class. Big-budget games and breakout hits get all the attention. Everyone else fights for scraps. The end result is the “rich get richer.”\nIndies can’t afford to brute-force their way into visibility. They can’t outspend or outmarket incumbents. And yet most studios still rely on the same tired playbook: launch on Steam, pay the platform tax, hope the algorithm works. That’s not a strategy. It’s a gamble (tho, once in a blue moon, the algorithm favors an indie and it breaks out).\nDistribution is not a side task—it’s the real product challenge. And it’s the one thing this industry hasn’t meaningfully rethought.\n\\\nThe Shift Has Already Started\nSome companies aren’t waiting for better distribution. They’re building it.\nEpic didn’t just launch a hit game—they turned Fortnite into a platform. With UEFN (Unreal Editor for Fortnite), developers can now build games inside Fortnite using AAA tools, publish instantly, and tap into a built-in audience of millions. Discovery and monetization are integrated. The friction is gone.\nRoblox took it even further. It’s a closed-loop system where content and distribution live in the same place. Creators build games, users discover them, and both sides benefit. What makes Roblox especially interesting right now is this: distribution is ahead of content. The platform has reach. It just doesn’t have enough standout experiences. For developers, that’s an opportunity to succeed not by out-marketing the competition, but simply by building something better.\nOther players are entering the space from the edges. YouTube is embedding games directly into its platform. Discord lets users play inside servers. Netflix now offers games alongside its shows. Even Telegram supports native games through mini-apps. All of these are experiments in rethinking where and how games are discovered.\nAnd then there’s the web.\nThe open web is becoming viable again—not just for casual games, but for real, session-based experiences. There’s no platform tax. No gatekeepers. No approval queues. A single build can reach anyone with a browser. For developers, that’s freedom. For players, it’s one click away.\nWe’re starting to see early signs of this shift. BAPBAP built an early fanbase in 2023 through a web version before launching on Steam, fueling thousands of installs on day one. Hero Wars took the same path years earlier—starting on the web, then expanding to mobile, where it surpassed 150 million installs and $1.5 billion in revenue.\nBut most developers are still funneling their games into the same overcrowded storefronts—fighting over the same algorithms, the same paid installs, and the same limited real estate. It’s time to shift that energy. Instead of competing in the same narrow lanes, the opportunity is to explore new ones. Go where users already are. Build for the platforms that actually enable discovery. Let distribution shape your strategy—not follow it.\nThe future won’t be defined by who builds the best-looking game. It will be defined by who rethinks the path to finding it.",
          "dc:creator": "Kaspar Tiri",
          "content": "Despite a boom in high-quality game development, most titles go unnoticed due to oversaturated platforms and outdated launch strategies. This article draws parallels with film and music to highlight how discovery—not content—is the industry’s true bottleneck. It advocates for new distribution models, from Fortnite’s UEFN and Roblox to embedded platforms like YouTube and Te",
          "contentSnippet": "Despite a boom in high-quality game development, most titles go unnoticed due to oversaturated platforms and outdated launch strategies. This article draws parallels with film and music to highlight how discovery—not content—is the industry’s true bottleneck. It advocates for new distribution models, from Fortnite’s UEFN and Roblox to embedded platforms like YouTube and Te",
          "guid": "https://hackernoon.com/the-real-reason-most-indie-games-flop-it-has-nothing-to-do-with-gameplay?source=rss",
          "categories": [
            "gaming",
            "game-discovery",
            "indie-game-marketing",
            "mobile-game-visibility",
            "game-development",
            "game-distribution-strategy",
            "app-store-visibility-hacks",
            "game-launch-strategy-2025"
          ],
          "isoDate": "2025-08-03T15:50:07.000Z"
        }
      },
      {
        "json": {
          "creator": "Arun Goyal",
          "title": "10 Ways AI Is Shaping the Future of Mobile App Development",
          "link": "https://hackernoon.com/10-ways-ai-is-shaping-the-future-of-mobile-app-development?source=rss",
          "pubDate": "Sun, 03 Aug 2025 15:29:15 GMT",
          "content:encoded": "<p>Artificial Intelligence (AI) in mobile apps was synonymous with chatbots for an extended period. Ask a question and get an answer to the extent of that on many users. This perception would have been long outdated by 2025. Today, AI is not a mere feature; it is fast becoming the invisible force that shapes how an app is built, how it unfolds upon its release, and the way it interacts with users at a very intimate level.&nbsp;</p>\n<p>Walking this path, mobile app development is getting changed, and AI is leading it. Even though conversational AI still holds important roles, developers and businesses have begun utilizing machine learning, predictive analytics, computer vision, natural language processing, and generative AI to their fullest capacity to produce intelligent and adaptive experiences, many of which latter thought to be from the far future.</p>\n<p>What does this mean for the current mobile app development scenario? Transitioning from static apps to those learning, adapting, and anticipating is the forecasted step. Let's further know how well AI is reshaping mobile app development services way beyond the virtual assistant zone.</p>\n<h2 id=\"top10waysaiistransformingmobileappdevelopmentin2025\"><strong>Top 10 Ways AI Is Transforming Mobile App Development in 2025</strong></h2>\n<p>AI is driving a massive shift in mobile app development changing how apps interact, adapt, and perform. From personalization to predictive design, here are the top ten ways AI is revolutionizing the mobile experience:</p>\n<h3 id=\"personalizedexperiencesatscale\"><strong>Personalized Experiences at Scale</strong></h3>\n<p>Some of the most visible changes in the AI field are the enhancement of user-oriented experiences. Earlier, the apps had the very same layout, content, and function for all users. Now, AI helps apps observe user behaviour, learn from these observations, and adapt their content and interface accordingly. Behind the scenes, AI goes on to analyze it all to provide every user with a very special session just for them.</p>\n<p>This level of personalization has become a core expectation, prompting every mobile app development company to incorporate such features. Whether it's a cross platform mobile app development project or a native solution, the need to create contextual user experiences is paramount.</p>\n<h3 id=\"intelligentsearchanddiscovery\"><strong>Intelligent Search and Discovery</strong></h3>\n<p>Another major shift has been the interaction facet of search within apps. Conventional search functions depended significantly on exact keywords, often discouraging users from locating what they wanted. AI radically enhanced this experience to make search more intelligent and conversational. Natural Language Processing (NLP) enables users with the ability to ask questions or make search queries using off-the-cuff language, and AI looks at the underlying intention of the words.</p>\n<p>In modern applications, the integration of an intelligent layer is standard practice among companies specializing in custom mobile app development services.</p>\n<h3 id=\"predictivecapabilitiesandanticipatorydesign\"><strong>Predictive Capabilities and Anticipatory Design</strong></h3>\n<p>One compelling ability of AI is prediction. AI can analyze patterns in user behavior and come up with what a user may want to see next, and offer it before the user asks for it. The anticipatory design, as people today commonly know it, makes the app truly clever by putting up suggestions, reminders, or shortcuts that really resonate with the user's habits.</p>\n<h3 id=\"aiindesignanddevelopmentnbsp\"><strong>AI in Design and Development</strong>&nbsp;</h3>\n<p>AI is influencing not only how apps work but also how they are created. Mobile app development, which embodies long design cycles and manual testing, is now aided and accelerated by AI in each step. There are now AI-aided tools that help designers create wireframes or mockups based on simple sketches or text prompts.</p>\n<p>Hence, repetitive tasks will require very little time and thus allow teams to invest more in creativity and strategy. This transformation is reshaping enterprise mobile app development, helping larger organizations deploy sophisticated solutions faster and with higher quality assurance.</p>\n<h3 id=\"smarterapptestingandmaintenance\"><strong>Smarter App Testing and Maintenance</strong></h3>\n<p>AI finds another key use case in quality assurance. Traditional methods are unable to keep pace with short deployment cycles and constant upgrades. AI-based test frameworks simulate user behavior or find edge cases and even predict where the bugs are most likely to appear based on prior data. Besides that, AI is doing wonders post-launch by monitoring app performance. It records crashes, wanders into behavioral analysis, detects anomalies, and blows the whistle when it stumbles upon deviations from the normal.</p>\n<h3 id=\"multimodalinteractionwithai\"><strong>Multimodal Interaction with AI</strong></h3>\n<p>Furthermore, this has been extended and pushed towards sensory interaction, particularly in voice, image, and gesture recognition. Making apps more inclusive and user-friendly, especially for those who use experimental hands-free or visual inputs. AI in voice recognition enables users to interact with apps to initiate commands and have them respond through speech, giving ways of interface new fluid and human feeling.&nbsp;</p>\n<p>Computer vision aids in the identification of faces by the app, scanning QR codes, or physically identifying objects via the smartphone camera. Today, users don't just want to know what is meant by mobile application development; they demand smarter, intuitive apps that understand them deeply.</p>\n<h3 id=\"securityandfrauddetection\"><strong>Security and Fraud Detection</strong></h3>\n<p>Security is another area where AI technologies have taken a giant leap. Older computer security models deal with threats of the past, whereas the cyber-threats of today are an altogether different animal. Using AI-based models, these computers now analyze millions of interactions occurring among interconnected devices to detect suspicious activity, irregular login patterns, or even data theft.&nbsp;</p>\n<p>Such apps now use AI to watch transactions for fraudulent behavior before any harm is done to users. The biometric security system, whether it be facial recognition or fingerprint scanning, is an AI-enabled gateway to an easy and secure authentication method.</p>\n<h3 id=\"riseofgenerativeaiinmobileapps\"><strong>Rise of Generative AI in Mobile Apps</strong></h3>\n<p>In the last year, generative AI has emerged as one of the most thrilling areas in the app development world. Tools such as GPT-4 and DALL·E of OpenAI have opened a new avenue for users to generate text, images, music, and videos, with a mere handful of commands. Mobile applications are using this technology to create generative spaces for creators to work in.&nbsp;</p>\n<p>From AI photo editing, avatar generation, to story ideation, to productivity apps, users have become accustomed to AI either assisting or potentially co-creating content with them.</p>\n<h3 id=\"fromreactivetoadaptiveapps\"><strong>From Reactive to Adaptive Apps</strong></h3>\n<p>One of the most revolutionary and disruptive changes is from reactive to adaptive app experiences. Traditional apps respond to user input. This is where AI-enabled apps excel they can learn behaviors from their human users, changing the interface, suggesting actions, and even dynamically reprogramming their workflows. For instance, depending on whether a user's mood is detected from voice tone or facial expression, a mental wellness app may choose to deliver a particular set of suggestive activities.</p>\n<h3 id=\"accessibilityandinclusivitythroughai\"><strong>Accessibility and Inclusivity Through AI</strong></h3>\n<p>AI has emerged as an enabler to infuse accessibility into mobile app creation, thereby catering to a variety of user needs. These days, apps offer a wide range of capabilities, including real-time conversion between text and speech, and vice versa. AI translations and UI variations that meet the needs of visually impaired users. Thus, by breaking down the barriers of language, cognition, and physicality it necessitates that technology assist everyone, irrespective of ability or creed.</p>\n<h2 id=\"thechallengesahead\"><strong>The Challenges Ahead</strong></h2>\n<p>Integrating AI into mobile app development services is challenging when it comes to ensuring data privacy, model accuracy, algorithmic bias, and development budgets. Trust is key from the user's perspective. They have to be transparent about the collection and use of data, conform to global privacy laws, continuously monitor, and update the model to avoid unintended consequences.&nbsp;</p>\n<p>Despite all these problems, the benefits of AI are significant enough to overpower any challenge. If applied properly, AI can help developers build smarter, faster, and safer mobile apps.</p>\n<h2 id=\"closingthoughtsfuturereadywithai\"><strong>Closing Thoughts: Future-Ready with AI</strong></h2>\n<p>Mobile app development would become intelligent even in the manner of their behavior, way of their imagination, and way of their construction. It means we are during those moments when AI chips on the device will make processing real-time but safer and efficient; emotion recognition and zero-UI interfaces will set new limits; and then AI will be analyzed as a collaborator instead of a tool.&nbsp;</p>\n<p>For developers, the latest technologies must be mastered with data-first thinking. Businesses must do the innovation, invest in more innovative experiences, and keep the user as a priority.</p>\n<p>Whether it’s for startups or enterprises, those looking for the best mobile app development company need to focus on long-term value, where AI meets user-centric design. As AI becomes the backbone of digital evolution, the future of cross platform mobile app development and beyond is undeniably innovative, intuitive, and transformational.</p>\n<p>\\n </p>",
          "content:encodedSnippet": "Artificial Intelligence (AI) in mobile apps was synonymous with chatbots for an extended period. Ask a question and get an answer to the extent of that on many users. This perception would have been long outdated by 2025. Today, AI is not a mere feature; it is fast becoming the invisible force that shapes how an app is built, how it unfolds upon its release, and the way it interacts with users at a very intimate level. \nWalking this path, mobile app development is getting changed, and AI is leading it. Even though conversational AI still holds important roles, developers and businesses have begun utilizing machine learning, predictive analytics, computer vision, natural language processing, and generative AI to their fullest capacity to produce intelligent and adaptive experiences, many of which latter thought to be from the far future.\nWhat does this mean for the current mobile app development scenario? Transitioning from static apps to those learning, adapting, and anticipating is the forecasted step. Let's further know how well AI is reshaping mobile app development services way beyond the virtual assistant zone.\nTop 10 Ways AI Is Transforming Mobile App Development in 2025\nAI is driving a massive shift in mobile app development changing how apps interact, adapt, and perform. From personalization to predictive design, here are the top ten ways AI is revolutionizing the mobile experience:\nPersonalized Experiences at Scale\nSome of the most visible changes in the AI field are the enhancement of user-oriented experiences. Earlier, the apps had the very same layout, content, and function for all users. Now, AI helps apps observe user behaviour, learn from these observations, and adapt their content and interface accordingly. Behind the scenes, AI goes on to analyze it all to provide every user with a very special session just for them.\nThis level of personalization has become a core expectation, prompting every mobile app development company to incorporate such features. Whether it's a cross platform mobile app development project or a native solution, the need to create contextual user experiences is paramount.\nIntelligent Search and Discovery\nAnother major shift has been the interaction facet of search within apps. Conventional search functions depended significantly on exact keywords, often discouraging users from locating what they wanted. AI radically enhanced this experience to make search more intelligent and conversational. Natural Language Processing (NLP) enables users with the ability to ask questions or make search queries using off-the-cuff language, and AI looks at the underlying intention of the words.\nIn modern applications, the integration of an intelligent layer is standard practice among companies specializing in custom mobile app development services.\nPredictive Capabilities and Anticipatory Design\nOne compelling ability of AI is prediction. AI can analyze patterns in user behavior and come up with what a user may want to see next, and offer it before the user asks for it. The anticipatory design, as people today commonly know it, makes the app truly clever by putting up suggestions, reminders, or shortcuts that really resonate with the user's habits.\nAI in Design and Development \nAI is influencing not only how apps work but also how they are created. Mobile app development, which embodies long design cycles and manual testing, is now aided and accelerated by AI in each step. There are now AI-aided tools that help designers create wireframes or mockups based on simple sketches or text prompts.\nHence, repetitive tasks will require very little time and thus allow teams to invest more in creativity and strategy. This transformation is reshaping enterprise mobile app development, helping larger organizations deploy sophisticated solutions faster and with higher quality assurance.\nSmarter App Testing and Maintenance\nAI finds another key use case in quality assurance. Traditional methods are unable to keep pace with short deployment cycles and constant upgrades. AI-based test frameworks simulate user behavior or find edge cases and even predict where the bugs are most likely to appear based on prior data. Besides that, AI is doing wonders post-launch by monitoring app performance. It records crashes, wanders into behavioral analysis, detects anomalies, and blows the whistle when it stumbles upon deviations from the normal.\nMultimodal Interaction with AI\nFurthermore, this has been extended and pushed towards sensory interaction, particularly in voice, image, and gesture recognition. Making apps more inclusive and user-friendly, especially for those who use experimental hands-free or visual inputs. AI in voice recognition enables users to interact with apps to initiate commands and have them respond through speech, giving ways of interface new fluid and human feeling. \nComputer vision aids in the identification of faces by the app, scanning QR codes, or physically identifying objects via the smartphone camera. Today, users don't just want to know what is meant by mobile application development; they demand smarter, intuitive apps that understand them deeply.\nSecurity and Fraud Detection\nSecurity is another area where AI technologies have taken a giant leap. Older computer security models deal with threats of the past, whereas the cyber-threats of today are an altogether different animal. Using AI-based models, these computers now analyze millions of interactions occurring among interconnected devices to detect suspicious activity, irregular login patterns, or even data theft. \nSuch apps now use AI to watch transactions for fraudulent behavior before any harm is done to users. The biometric security system, whether it be facial recognition or fingerprint scanning, is an AI-enabled gateway to an easy and secure authentication method.\nRise of Generative AI in Mobile Apps\nIn the last year, generative AI has emerged as one of the most thrilling areas in the app development world. Tools such as GPT-4 and DALL·E of OpenAI have opened a new avenue for users to generate text, images, music, and videos, with a mere handful of commands. Mobile applications are using this technology to create generative spaces for creators to work in. \nFrom AI photo editing, avatar generation, to story ideation, to productivity apps, users have become accustomed to AI either assisting or potentially co-creating content with them.\nFrom Reactive to Adaptive Apps\nOne of the most revolutionary and disruptive changes is from reactive to adaptive app experiences. Traditional apps respond to user input. This is where AI-enabled apps excel they can learn behaviors from their human users, changing the interface, suggesting actions, and even dynamically reprogramming their workflows. For instance, depending on whether a user's mood is detected from voice tone or facial expression, a mental wellness app may choose to deliver a particular set of suggestive activities.\nAccessibility and Inclusivity Through AI\nAI has emerged as an enabler to infuse accessibility into mobile app creation, thereby catering to a variety of user needs. These days, apps offer a wide range of capabilities, including real-time conversion between text and speech, and vice versa. AI translations and UI variations that meet the needs of visually impaired users. Thus, by breaking down the barriers of language, cognition, and physicality it necessitates that technology assist everyone, irrespective of ability or creed.\nThe Challenges Ahead\nIntegrating AI into mobile app development services is challenging when it comes to ensuring data privacy, model accuracy, algorithmic bias, and development budgets. Trust is key from the user's perspective. They have to be transparent about the collection and use of data, conform to global privacy laws, continuously monitor, and update the model to avoid unintended consequences. \nDespite all these problems, the benefits of AI are significant enough to overpower any challenge. If applied properly, AI can help developers build smarter, faster, and safer mobile apps.\nClosing Thoughts: Future-Ready with AI\nMobile app development would become intelligent even in the manner of their behavior, way of their imagination, and way of their construction. It means we are during those moments when AI chips on the device will make processing real-time but safer and efficient; emotion recognition and zero-UI interfaces will set new limits; and then AI will be analyzed as a collaborator instead of a tool. \nFor developers, the latest technologies must be mastered with data-first thinking. Businesses must do the innovation, invest in more innovative experiences, and keep the user as a priority.\nWhether it’s for startups or enterprises, those looking for the best mobile app development company need to focus on long-term value, where AI meets user-centric design. As AI becomes the backbone of digital evolution, the future of cross platform mobile app development and beyond is undeniably innovative, intuitive, and transformational.\n\\n",
          "dc:creator": "Arun Goyal",
          "content": "\nAI is no longer just a feature in mobile apps—it’s becoming the engine behind how they’re designed, built, and experienced. This article explores ten groundbreaking ways artificial intelligence is transforming mobile app development in 2025—from hyper-personalized UX and predictive design to generative tools, adaptive interfaces, enhanced security, and inclusive features. With NLP, computer vision, and machine learning at the core, modern apps are becoming smarter, safer, and more intuitive—marking a pivotal shift from reactive utilities to adaptive digital companions.",
          "contentSnippet": "AI is no longer just a feature in mobile apps—it’s becoming the engine behind how they’re designed, built, and experienced. This article explores ten groundbreaking ways artificial intelligence is transforming mobile app development in 2025—from hyper-personalized UX and predictive design to generative tools, adaptive interfaces, enhanced security, and inclusive features. With NLP, computer vision, and machine learning at the core, modern apps are becoming smarter, safer, and more intuitive—marking a pivotal shift from reactive utilities to adaptive digital companions.",
          "guid": "https://hackernoon.com/10-ways-ai-is-shaping-the-future-of-mobile-app-development?source=rss",
          "categories": [
            "ai-mobile-app-development",
            "mobile-app-development",
            "ai-trends",
            "predictive-mobile-ux",
            "generative-ai-apps",
            "cross-platform-ai-apps",
            "custom-app-development",
            "good-company"
          ],
          "isoDate": "2025-08-03T15:29:15.000Z"
        }
      },
      {
        "json": {
          "creator": "Pair Programming AI Agent",
          "title": "Solving Coding Puzzles: The Evolution of Programmer Assistance Tools",
          "link": "https://hackernoon.com/solving-coding-puzzles-the-evolution-of-programmer-assistance-tools?source=rss",
          "pubDate": "Sun, 03 Aug 2025 15:15:06 GMT",
          "content:encoded": "<h2 id=\"tableoflinks\">Table of Links</h2>\n<p><a href=\"https://hackernoon.com/preview/MlSqFDkgc8wyYNhcTQUS\">Abstract and 1 Introduction</a></p>\n<p><a href=\"https://hackernoon.com/preview/8dpQgkvMbLYJAljrV7Vf\">2. Prior conceptualisations of intelligent assistance for programmers</a> </p>\n<p><a href=\"https://hackernoon.com/preview/Fbh4JJB153JBpm3kLCxV\">3. A brief overview of large language models for code generation</a> </p>\n<p><a href=\"https://hackernoon.com/preview/HmlrCOxDGvgs92HVCJ2K\">4. Commercial programming tools that use large language models</a> </p>\n<p><a href=\"https://hackernoon.com/preview/LfBQwyQ4BSGJwpgYltOg\">5. Reliability, safety, and security implications of code-generating AI models</a> </p>\n<p><a href=\"https://hackernoon.com/preview/CygvKtzl4ehOH2JMjzSJ\">6. Usability and design studies of AI-assisted programming</a> </p>\n<p><a href=\"http://hackernoon.com/preview/avzRmaZuB6kTScIGgBXb\">7. Experience reports and 7.1. Writing effective prompts is hard</a></p>\n<p><a href=\"http://hackernoon.com/preview/trg3lvQVoL7t14dCFdHw\">7.2. The activity of programming shifts towards checking and unfamiliar debugging</a></p>\n<p><a href=\"https://hackernoon.com/preview/Y6BbJahplhYZlxdqdCFp\">7.3. These tools are useful for boilerplate and code reuse</a></p>\n<p>8. The inadequacy of existing metaphors for AI-assisted programming </p>\n<p><a href=\"https://hackernoon.com/preview/vWx560H10HWi8ZHXooSN\">8.1. AI assistance as search</a> </p>\n<p><a href=\"https://hackernoon.com/preview/7aqW8wQKjdANYySTv4HT\">8.2. AI assistance as compilation</a> </p>\n<p><a href=\"http://hackernoon.com/preview/dt4WL0IqtGFKwYXl8xcM\">8.3. AI assistance as pair programming</a> </p>\n<p><a href=\"https://hackernoon.com/preview/y6sPtr5BxC8m3FKl3sPe\">8.4. A distinct way of programming</a> </p>\n<p><a href=\"http://hackernoon.com/preview/cFluWTtWEw5cYM79in5t\">9. Issues with application to end-user programming</a> </p>\n<p><a href=\"http://hackernoon.com/preview/yXSCL6V4pdtdts6ABfM6\">9.1. Issue 1: Intent specification, problem decomposition and computational thinking</a></p>\n<p><a href=\"https://hackernoon.com/preview/E4BSkXJzfI4viO9ZlSiq\">9.2. Issue 2: Code correctness, quality and (over)confidence</a> </p>\n<p><a href=\"https://hackernoon.com/preview/bnqPT5z9RjUqofcdLHgu\">9.3. Issue 3: Code comprehension and maintenance</a> </p>\n<p><a href=\"http://hackernoon.com/preview/BakiKXXyiC7EliqZuaEi\">9.4. Issue 4: Consequences of automation in end-user programming</a> </p>\n<p><a href=\"http://hackernoon.com/preview/KUolRiHRR6l2EibKExUJ\">9.5. Issue 5: No code, and the dilemma of the direct answer</a> </p>\n<p><a href=\"http://hackernoon.com/preview/4zcamJIgNx2iZo9jpBY5\">10. Conclusion</a> </p>\n<p><a href=\"https://hackernoon.com/preview/tJyNpGmyfTQHlfAqjVVC\">A. Experience report sources</a> </p>\n<p><a href=\"https://hackernoon.com/preview/DfXa3jYCd5LYy3NDyv6c\">References</a></p>\n<h2 id=\"2priorconceptualisationsofintelligentassistanceforprogrammers\">2. Prior conceptualisations of intelligent assistance for programmers</h2>\n<p>What counts as ‘intelligent assistance’ can be the subject of some debate. Do we select only features that are driven by technologies that the artificial intelligence research community (itself undefined) would recognise as artificial intelligence? Do we include those that use expert-coded heuristics? Systems that make inferences a human might disagree with, or those with the potential for error? Mixed-initiative systems (Horvitz, 1999)? Or those that make the user feel intelligent, assisted, or empowered? While this debate is beyond the scope of this paper, we feel that to properly contextualise the qualitative difference made by large language models, a broad and inclusive approach to the term ‘intelligence’ is required.</p>\n<p>\\\nEnd-user programming has long been home to inferential, or intelligent assistance. The strategy of direct manipulation (Shneiderman &amp; Norwood, 1993) is highly successful for certain types of limited, albeit useful, computational tasks, where the interface being used (“what you see”, e.g., a text editor or an image editor) to develop an information artefact can represent closely the artefact being developed (“what you get”, e.g., a text document or an image). However, this strategy cannot be straightforwardly applied to programs. Programs notate multiple possible paths of execution simultaneously, and they define “behaviour to occur at some future time” (Blackwell, 2002b). Rendering multiple futures in the present is a core problem of live programming research (Tanimoto, 2013), which aims to externalise programs as they are edited (Basman et al., 2016).</p>\n<p>\\\nThe need to bridge the abstraction gap between direct manipulation and multiple paths of execution led to the invention of programming by demonstration (PBD) (Kurlander et al., 1993; Lieberman, 2001; Myers, 1992). A form of inferential assistance, PBD allows end-user programmers to make concrete demonstrations of desired behaviour that are generalised into executable programs. Despite their promise, PBD systems have not achieved widespread success as end-user programming tools, although their idea survives in vestigial form as various “macro recording” tools, and the approach is seeing a resurgence with the growing commercialisation of “robotic process automation”.</p>\n<p>\\\nProgramming language design has long been concerned with shifting the burden of intelligence between programmer, program, compiler, and user. Programming language compilers, in translating between high-level languages and machine code, are a kind of intelligent assistance for programmers. The declarative language Prolog aspired to bring a kind of intelligence, where the programmer would only be responsible for specifying (“declaring”) what to compute, but not how to compute it; that responsibility was left to the interpreter. At the same time, the language was designed with intelligent applications in mind. Indeed, it found widespread use within artificial intelligence and computational linguistics research (Colmerauer &amp; Roussel, 1996; Rouchy, 2006).</p>\n<p>\\\nFormal verification tools use a specification language, such as Hoare triples (Hoare, 1969), and writing such specifications can be considered programming at a ‘higher’ level of abstraction. Program synthesis, in particular synthesis through refinement, aims at intelligently transforming these rules into executable and correct code. However, the term “program synthesis” is also used more broadly, and programs can be synthesised from other sources than higher-level specifications. Concretely, program synthesis by example, or simply programming by example (PBE), facilitates the generation of executable code from input-output examples. An example of successfully commercialised PBE is Excel’s Flash Fill (Gulwani, 2011), which synthesises string transformations in spreadsheets from a small number of examples.</p>\n<p>\\\nThe Cognitive Dimensions framework (T. R. Green, 1989; T. Green &amp; Blackwell, 1998) identifies three categories of programming activity: authoring, transcription, and modification. Modern programmer assistance encompasses each of these. For example, program synthesis tools transform the direct authoring of code into the (arguably easier) authoring of examples. Intelligent code completions (Marasoiu et al., 2015) support the direct authoring of code. Intelligent support for reuse, such as smart code copy/paste (Allamanis &amp; Brockschmidt, 2017) support transcription, and refactoring tools (Hermans et al., 2015) support modification. Researchers have investigated inferential support for navigating source code (Henley &amp; Fleming, 2014), debugging (J. Williams et al., 2020), and selectively undoing code changes (Yoon &amp; Myers, 2015). Additionally, intelligent tools can also support learning (Cao et al., 2015).</p>\n<p>\\\nAllamanis et al. (2018) review work at the intersection of machine learning, programming languages, and software engineering. They seek to adapt methods first developed for natural language, such as language models, to source code. The emergence of large bodies of open source code, sometimes called “big code”, enabled this research area. Language models are sensitive to lexical features like names, code formatting, and order of methods, while traditional tools like compilers or code verifiers are not. Through the “naturalness hypothesis”, which claims that “software is a form of human communication; software corpora have similar statistical properties to natural language corpora; the authors claim that these properties can be exploited to build better software engineering tools.” Some support for this hypothesis comes from research that used n-gram models to build a code completion engine for Java that outperformed Eclipse’s completion feature (Hindle et al., 2012, 2016). This approach can underpin recommender systems (such as code autocompletion), debuggers, code analysers (such as type checkers (Raychev et al., 2015)), and code synthesizers. We can expect the recent expansion in capability of language models, discussed next, to magnify the effectiveness of these applications.</p>\n<p>\\</p>\n<p>:::info\n<strong>Authors:</strong></p>\n<p>(1) Advait Sarkar, Microsoft Research, University of Cambridge (advait@microsoft.com);</p>\n<p>(2) Andrew D. Gordon, Microsoft Research, University of Edinburgh (adg@microsoft.com);</p>\n<p>(3) Carina Negreanu, Microsoft Research (cnegreanu@microsoft.com);</p>\n<p>(4) Christian Poelitz, Microsoft Research (cpoelitz@microsoft.com);</p>\n<p>(5) Sruti Srinivasa Ragavan, Microsoft Research (a-srutis@microsoft.com);</p>\n<p>(6) Ben Zorn, Microsoft Research (ben.zorn@microsoft.com).</p>\n<p>:::</p>\n<hr />\n<p>:::info\nThis paper is <strong><a href=\"https://arxiv.org/abs/2208.06213\">available on arxiv</a></strong> under CC BY-NC-ND 4.0 DEED license.</p>\n<p>:::</p>\n<p>\\</p>",
          "content:encodedSnippet": "Table of Links\nAbstract and 1 Introduction\n2. Prior conceptualisations of intelligent assistance for programmers \n3. A brief overview of large language models for code generation \n4. Commercial programming tools that use large language models \n5. Reliability, safety, and security implications of code-generating AI models \n6. Usability and design studies of AI-assisted programming \n7. Experience reports and 7.1. Writing effective prompts is hard\n7.2. The activity of programming shifts towards checking and unfamiliar debugging\n7.3. These tools are useful for boilerplate and code reuse\n8. The inadequacy of existing metaphors for AI-assisted programming \n8.1. AI assistance as search \n8.2. AI assistance as compilation \n8.3. AI assistance as pair programming \n8.4. A distinct way of programming \n9. Issues with application to end-user programming \n9.1. Issue 1: Intent specification, problem decomposition and computational thinking\n9.2. Issue 2: Code correctness, quality and (over)confidence \n9.3. Issue 3: Code comprehension and maintenance \n9.4. Issue 4: Consequences of automation in end-user programming \n9.5. Issue 5: No code, and the dilemma of the direct answer \n10. Conclusion \nA. Experience report sources \nReferences\n2. Prior conceptualisations of intelligent assistance for programmers\nWhat counts as ‘intelligent assistance’ can be the subject of some debate. Do we select only features that are driven by technologies that the artificial intelligence research community (itself undefined) would recognise as artificial intelligence? Do we include those that use expert-coded heuristics? Systems that make inferences a human might disagree with, or those with the potential for error? Mixed-initiative systems (Horvitz, 1999)? Or those that make the user feel intelligent, assisted, or empowered? While this debate is beyond the scope of this paper, we feel that to properly contextualise the qualitative difference made by large language models, a broad and inclusive approach to the term ‘intelligence’ is required.\n\\\nEnd-user programming has long been home to inferential, or intelligent assistance. The strategy of direct manipulation (Shneiderman & Norwood, 1993) is highly successful for certain types of limited, albeit useful, computational tasks, where the interface being used (“what you see”, e.g., a text editor or an image editor) to develop an information artefact can represent closely the artefact being developed (“what you get”, e.g., a text document or an image). However, this strategy cannot be straightforwardly applied to programs. Programs notate multiple possible paths of execution simultaneously, and they define “behaviour to occur at some future time” (Blackwell, 2002b). Rendering multiple futures in the present is a core problem of live programming research (Tanimoto, 2013), which aims to externalise programs as they are edited (Basman et al., 2016).\n\\\nThe need to bridge the abstraction gap between direct manipulation and multiple paths of execution led to the invention of programming by demonstration (PBD) (Kurlander et al., 1993; Lieberman, 2001; Myers, 1992). A form of inferential assistance, PBD allows end-user programmers to make concrete demonstrations of desired behaviour that are generalised into executable programs. Despite their promise, PBD systems have not achieved widespread success as end-user programming tools, although their idea survives in vestigial form as various “macro recording” tools, and the approach is seeing a resurgence with the growing commercialisation of “robotic process automation”.\n\\\nProgramming language design has long been concerned with shifting the burden of intelligence between programmer, program, compiler, and user. Programming language compilers, in translating between high-level languages and machine code, are a kind of intelligent assistance for programmers. The declarative language Prolog aspired to bring a kind of intelligence, where the programmer would only be responsible for specifying (“declaring”) what to compute, but not how to compute it; that responsibility was left to the interpreter. At the same time, the language was designed with intelligent applications in mind. Indeed, it found widespread use within artificial intelligence and computational linguistics research (Colmerauer & Roussel, 1996; Rouchy, 2006).\n\\\nFormal verification tools use a specification language, such as Hoare triples (Hoare, 1969), and writing such specifications can be considered programming at a ‘higher’ level of abstraction. Program synthesis, in particular synthesis through refinement, aims at intelligently transforming these rules into executable and correct code. However, the term “program synthesis” is also used more broadly, and programs can be synthesised from other sources than higher-level specifications. Concretely, program synthesis by example, or simply programming by example (PBE), facilitates the generation of executable code from input-output examples. An example of successfully commercialised PBE is Excel’s Flash Fill (Gulwani, 2011), which synthesises string transformations in spreadsheets from a small number of examples.\n\\\nThe Cognitive Dimensions framework (T. R. Green, 1989; T. Green & Blackwell, 1998) identifies three categories of programming activity: authoring, transcription, and modification. Modern programmer assistance encompasses each of these. For example, program synthesis tools transform the direct authoring of code into the (arguably easier) authoring of examples. Intelligent code completions (Marasoiu et al., 2015) support the direct authoring of code. Intelligent support for reuse, such as smart code copy/paste (Allamanis & Brockschmidt, 2017) support transcription, and refactoring tools (Hermans et al., 2015) support modification. Researchers have investigated inferential support for navigating source code (Henley & Fleming, 2014), debugging (J. Williams et al., 2020), and selectively undoing code changes (Yoon & Myers, 2015). Additionally, intelligent tools can also support learning (Cao et al., 2015).\n\\\nAllamanis et al. (2018) review work at the intersection of machine learning, programming languages, and software engineering. They seek to adapt methods first developed for natural language, such as language models, to source code. The emergence of large bodies of open source code, sometimes called “big code”, enabled this research area. Language models are sensitive to lexical features like names, code formatting, and order of methods, while traditional tools like compilers or code verifiers are not. Through the “naturalness hypothesis”, which claims that “software is a form of human communication; software corpora have similar statistical properties to natural language corpora; the authors claim that these properties can be exploited to build better software engineering tools.” Some support for this hypothesis comes from research that used n-gram models to build a code completion engine for Java that outperformed Eclipse’s completion feature (Hindle et al., 2012, 2016). This approach can underpin recommender systems (such as code autocompletion), debuggers, code analysers (such as type checkers (Raychev et al., 2015)), and code synthesizers. We can expect the recent expansion in capability of language models, discussed next, to magnify the effectiveness of these applications.\n\\\n:::info\nAuthors:\n(1) Advait Sarkar, Microsoft Research, University of Cambridge (advait@microsoft.com);\n(2) Andrew D. Gordon, Microsoft Research, University of Edinburgh (adg@microsoft.com);\n(3) Carina Negreanu, Microsoft Research (cnegreanu@microsoft.com);\n(4) Christian Poelitz, Microsoft Research (cpoelitz@microsoft.com);\n(5) Sruti Srinivasa Ragavan, Microsoft Research (a-srutis@microsoft.com);\n(6) Ben Zorn, Microsoft Research (ben.zorn@microsoft.com).\n:::\n:::info\nThis paper is available on arxiv under CC BY-NC-ND 4.0 DEED license.\n:::\n\\",
          "dc:creator": "Pair Programming AI Agent",
          "content": "From simplifying tasks with direct manipulation to generating code from examples, tracing how intelligent tools have always helped programmers tackle complex puzzles and bridge the gap between ideas and executable code.",
          "contentSnippet": "From simplifying tasks with direct manipulation to generating code from examples, tracing how intelligent tools have always helped programmers tackle complex puzzles and bridge the gap between ideas and executable code.",
          "guid": "https://hackernoon.com/solving-coding-puzzles-the-evolution-of-programmer-assistance-tools?source=rss",
          "categories": [
            "large-language-models",
            "ai-assisted-programming",
            "github-copilot",
            "code-generation",
            "programmer-assistance",
            "end-user-programming",
            "usability-studies",
            "inferential-assistance"
          ],
          "isoDate": "2025-08-03T15:15:06.000Z"
        }
      },
      {
        "json": {
          "creator": "Georgy Starikov",
          "title": "The Hidden Cost of Performance: How High-Load Specialization Warps Engineering Intuition",
          "link": "https://hackernoon.com/the-hidden-cost-of-performance-how-high-load-specialization-warps-engineering-intuition?source=rss",
          "pubDate": "Sun, 03 Aug 2025 15:09:29 GMT",
          "content:encoded": "<p>In high-performance software engineering, it’s easy to become so focused on optimization that you lose sight of broader business needs. This article shares lessons from my 20+ years building real-time, high-load systems across finance, telecom, and advertising. I explain how engineering intuition—shaped by edge-case systems—can become a liability when applied blindly. The goal: help engineering teams, managers, and even non-technical leaders understand when performance matters, and when it doesn’t.</p>\n<p>The world of high-load, low-latency systems is a crucible of engineering disciplines. It distills software down to its most brutal essence: cycles, bytes, wire time. It teaches you to think like a CPU, to treat L1 cache behavior as gospel, and to view allocations with suspicion. It sharpens your instincts for system limits and exposes any architectural indecision under fire at 200,000 RPS. Like all specializations, it also distorts your lens.</p>\n<p>In this piece, I want to reflect on the cost of repeatedly optimizing for edge cases. Specifically, how the deeply internalized mindset from building ultra-performant, latency-sensitive systems can become a limiting factor when engineers work in more elastic, less deterministic business domains.</p>\n<h3 id=\"whereintuitionbegins\"><strong>Where Intuition Begins</strong></h3>\n<p>I started my journey in real-time systems, where timing guarantees are absolute. Like brakes in a car, the system simply cannot be late. Over time, I transitioned into web systems where elasticity and geo-distribution took precedence over millisecond determinism. In banking, consistency and security overtook performance. Then, in adtech, I encountered the most complex compromise yet: soft real-time expectations (under 100ms), low cost per request, and architectural elasticity, all under high traffic conditions.</p>\n<p>This varied experience taught me that an engineer must think vertically, understanding the entire system from business goals to infrastructure. However, it also exposed the trap many fall into: carrying over instincts honed in one domain into another, without adapting them.</p>\n<h3 id=\"latencyasreflex\"><strong>Latency as Reflex</strong></h3>\n<p>In high-load systems with latency constraints, your thinking changes. You focus not on modularity or reusability, but on minimizing processing. The logic is data-centric: don’t transform the data. Shape your logic to fit the data. Don’t pass structures between microservices. Instead, keep them where they are and compute directly. Don’t copy—compute in place.</p>\n<p>These habits are powerful. But the engineer must also understand the variability of input data, the business flow that justifies it, and the degree of correctness required. And they must know when such reflexes start working against the business.</p>\n<h3 id=\"pathologicaloptimizationingeneralsystems\"><strong>Pathological Optimization in General Systems</strong></h3>\n<p>An engineer who grew up working on high-load systems often assumes the bottleneck is always latency. But most systems are not bound by that constraint. Over the years, I’ve seen engineers apply data-centric programming, sharded databases and even custom databases, to CRUD backends. The performance gain was marginal; the complexity cost was vast.</p>\n<p>One example: while working at MTS and AdNow, we optimized the DSP backend to hit 200k RPS. The temptation was to optimize everything. We learned to isolate the high-performance core and treat admin panels, user dashboards, and analytics with simpler tools like Postgres and standard libraries. Not every component needed to live at the edge.</p>\n<h3 id=\"whenexperiencebecomesbias\"><strong>When Experience Becomes Bias</strong></h3>\n<p>Engineers carry the weight of their successes. For example, I avoided sharding if it was possible to do the processing on a single server, albeit with a significantly expanded RAM volume (for example, up to 4TB), and this often gave excellent results both in the cost of maintenance and in development - it is much easier to write code when all the data is in your memory than to work with sharded data. In such cases, we scaled vertically, adding RAM.</p>\n<p>However, this same intuition can become counterproductive in systems where horizontal scale is natural and cheap. Intuition must be regularly retrained. A 10-core server may outperform a 40-core box unless NUMA topology and mutex contention are addressed. You must consider switches (Cut-Through vs. Store-and-Forward), storage behavior (95th percentile latency), and data access patterns.</p>\n<p>The mature engineer’s mindset is not \"What is the best possible system?\" but \"What does the business need, and how can we get there with minimum future pain?\"</p>\n<h3 id=\"debuggabilityvsefficiency\"><strong>Debuggability vs. Efficiency</strong></h3>\n<p>Another anti-pattern from high-performance thinking: sacrificing observability for CPU savings. In one system, we replaced JSON logging with binary formats to reduce overhead. It worked—3% CPU saved. But the trade-off? Incident response slowed, human debugging suffered, and onboarding became a challenge.</p>\n<p>In ultra-constrained systems like SCADA (which I worked on early in my career), this trade-off is acceptable. But in most cloud-native systems, human time trumps compute time. Engineers should always ask: “Who’s going to debug this at 3 a.m.?”</p>\n<h3 id=\"culturaldriftinengineeringteams\"><strong>Cultural Drift in Engineering Teams</strong></h3>\n<p>I’ve seen high-performance specialists bring over habits that don’t scale organizationally: rewriting libraries, resisting abstractions, and insisting on building from scratch. I’ve been guilty of it too, creating \"hot\" functions in x86-64 assembler and using directly the processor's SIMD commands (AVX-512), even when using the Go language. These systems work brilliantly, but only in the hands of their authors. By the way, assembler is very conveniently integrated into Go, but, as practice has shown, few people know it.</p>\n<p>Today, as a manager, I emphasize that business tasks must come first. If business requires creating a system with extreme performance characteristics, then we must remember that this will require a stellar team and vice versa, if a standard system is required, then it is not worth using solutions that are difficult to support and develop, but should focus on schemes and architecture that are understandable to the mass developer, which can be mastered by a mid-level developer in two weeks.</p>\n<p>I also caution against microservices sprawl. Teams eager to optimize development workflows may inadvertently turn a tight data-centric pipeline into a network of chatty, latency-laden services. Even Amazon Prime Video teams have returned from microservices to monoliths in such contexts.</p>\n<h3 id=\"unlearningthehabitofoptimization\"><strong>Unlearning the Habit of Optimization</strong></h3>\n<p>The hardest thing for performance-oriented engineers to learn is when not to optimize. When building the MTS platform, we had parts of the system that were hot paths and others that were barely used. Initially, the urge was to use the same tooling across all components. But it’s a trap. CRUD services don’t need to scale like your bidding engine. Choose the right tool, even if that means sacrificing uniformity.</p>\n<p>Similarly, early in my career, when developing code to perform a fast inverse Fourier transform, I wrote a highly optimized assembler code that outperformed GCC by 30%. But six months later, the processors changed, and my code optimized for prefetch pipelines began to perform worse than the compiler-generated one. That’s the real cost of low-level perfection: it rarely lasts. Performance tuning should be reserved for business-critical paths.</p>\n<h3 id=\"lifecyclecostofoptimization\"><strong>Lifecycle Cost of Optimization</strong></h3>\n<p>What often gets overlooked is the total lifecycle cost of early optimization. An efficient algorithm or exotic data layout may save compute time today, but if it slows down onboarding, complicates testability, or becomes a barrier to architectural evolution, then the system is effectively accruing technical debt disguised as technical brilliance. I’ve seen projects where an engineer’s initial low-level perfection became a tax the team paid for years—refactoring was too risky, and new hires avoided touching critical modules. Mature systems require performance that evolves with the business, not just code that’s clever in the moment. The question we should always ask is: “Can this optimization survive team growth and domain shifts over 3–5 years?”</p>\n<h3 id=\"learningtoletgo\"><strong>Learning to Let Go</strong></h3>\n<p>In our CTR/VTR predictor, we send updates in real time. But for the segment coverage calculator in the UI, we switched to batch processing. The latency of updating the data in the UI has increased, but the complexity of support and development has decreased significantly without any impact on the business goal.</p>\n<p>The wisdom is not in knowing how to optimize, but in knowing when the business doesn’t need it. Premature optimization is only “evil” when it’s misaligned with business maturity. If you're targeting 200k RPS on a core, yes—start sharp. But if it's 200k RPS on a cluster, and you can shard data processing (e.g. distribute requests across nodes), then act iteratively, start with inefficient but working code, and plan refactoring to achieve lower server load. And how to use the \"extra\" hardware freed up after optimization has never been a problem.</p>\n<h3 id=\"matureengineersunderstandtradeoffs\"><strong>Mature Engineers Understand Trade-offs</strong></h3>\n<p>The most balanced engineers I’ve worked with understand the entire vertical, from business requirements to infrastructure tuning. They know when to use Apache Ignite and when Postgres is enough. They make performance decisions only where bottlenecks align with business outcomes.</p>\n<p>Such engineers avoid optimization addiction. They favor maintainability. They are patient with temporary solutions and confident that the roadmap allows for future improvements. That confidence, along with technical range, is what I consider “technical maturity.”</p>\n<h3 id=\"leadingselforganizingteamswithoutoverengineering\"><strong>Leading Self-Organizing Teams Without Overengineering</strong></h3>\n<p>Left unchecked, high-performance teams often over-abstract. To prevent that, I encourage cross-functional ownership—engineers who think like analysts, testers, and product managers. I advocate for teams that talk openly, document and justify the architectural decisions (ADR), and include domain experts in the loop. You cannot succeed with brilliant engineers alone. You need people from the market.</p>\n<p>Also, I’ve seen over-specialization derail early-stage teams. For new systems, buy experienced teams or foundational platforms. Don’t reinvent everything. Starting from scratch without market-ready expertise often leads to failure, unless backed by large investments.</p>\n<h3 id=\"finalthoughts\"><strong>Final Thoughts</strong></h3>\n<p>I don’t regret specializing in high-load systems. It shaped how I think. But I’ve also seen how these instincts, left unchecked, can limit engineers in broader domains. We must relearn general software engineering just as athletes must relearn walking after years of sprinting.</p>\n<p>Your best skill can become your biggest bias. And your greatest strength, when balanced, is what makes you a truly versatile engineer.</p>\n<p>If you’re a product leader, founder, or manager: don’t ask your engineers to over-optimize from the start. Let them build clear, maintainable systems that can scale later if needed. High performance has its place—but business alignment always comes first. </p>",
          "content:encodedSnippet": "In high-performance software engineering, it’s easy to become so focused on optimization that you lose sight of broader business needs. This article shares lessons from my 20+ years building real-time, high-load systems across finance, telecom, and advertising. I explain how engineering intuition—shaped by edge-case systems—can become a liability when applied blindly. The goal: help engineering teams, managers, and even non-technical leaders understand when performance matters, and when it doesn’t.\nThe world of high-load, low-latency systems is a crucible of engineering disciplines. It distills software down to its most brutal essence: cycles, bytes, wire time. It teaches you to think like a CPU, to treat L1 cache behavior as gospel, and to view allocations with suspicion. It sharpens your instincts for system limits and exposes any architectural indecision under fire at 200,000 RPS. Like all specializations, it also distorts your lens.\nIn this piece, I want to reflect on the cost of repeatedly optimizing for edge cases. Specifically, how the deeply internalized mindset from building ultra-performant, latency-sensitive systems can become a limiting factor when engineers work in more elastic, less deterministic business domains.\nWhere Intuition Begins\nI started my journey in real-time systems, where timing guarantees are absolute. Like brakes in a car, the system simply cannot be late. Over time, I transitioned into web systems where elasticity and geo-distribution took precedence over millisecond determinism. In banking, consistency and security overtook performance. Then, in adtech, I encountered the most complex compromise yet: soft real-time expectations (under 100ms), low cost per request, and architectural elasticity, all under high traffic conditions.\nThis varied experience taught me that an engineer must think vertically, understanding the entire system from business goals to infrastructure. However, it also exposed the trap many fall into: carrying over instincts honed in one domain into another, without adapting them.\nLatency as Reflex\nIn high-load systems with latency constraints, your thinking changes. You focus not on modularity or reusability, but on minimizing processing. The logic is data-centric: don’t transform the data. Shape your logic to fit the data. Don’t pass structures between microservices. Instead, keep them where they are and compute directly. Don’t copy—compute in place.\nThese habits are powerful. But the engineer must also understand the variability of input data, the business flow that justifies it, and the degree of correctness required. And they must know when such reflexes start working against the business.\nPathological Optimization in General Systems\nAn engineer who grew up working on high-load systems often assumes the bottleneck is always latency. But most systems are not bound by that constraint. Over the years, I’ve seen engineers apply data-centric programming, sharded databases and even custom databases, to CRUD backends. The performance gain was marginal; the complexity cost was vast.\nOne example: while working at MTS and AdNow, we optimized the DSP backend to hit 200k RPS. The temptation was to optimize everything. We learned to isolate the high-performance core and treat admin panels, user dashboards, and analytics with simpler tools like Postgres and standard libraries. Not every component needed to live at the edge.\nWhen Experience Becomes Bias\nEngineers carry the weight of their successes. For example, I avoided sharding if it was possible to do the processing on a single server, albeit with a significantly expanded RAM volume (for example, up to 4TB), and this often gave excellent results both in the cost of maintenance and in development - it is much easier to write code when all the data is in your memory than to work with sharded data. In such cases, we scaled vertically, adding RAM.\nHowever, this same intuition can become counterproductive in systems where horizontal scale is natural and cheap. Intuition must be regularly retrained. A 10-core server may outperform a 40-core box unless NUMA topology and mutex contention are addressed. You must consider switches (Cut-Through vs. Store-and-Forward), storage behavior (95th percentile latency), and data access patterns.\nThe mature engineer’s mindset is not \"What is the best possible system?\" but \"What does the business need, and how can we get there with minimum future pain?\"\nDebuggability vs. Efficiency\nAnother anti-pattern from high-performance thinking: sacrificing observability for CPU savings. In one system, we replaced JSON logging with binary formats to reduce overhead. It worked—3% CPU saved. But the trade-off? Incident response slowed, human debugging suffered, and onboarding became a challenge.\nIn ultra-constrained systems like SCADA (which I worked on early in my career), this trade-off is acceptable. But in most cloud-native systems, human time trumps compute time. Engineers should always ask: “Who’s going to debug this at 3 a.m.?”\nCultural Drift in Engineering Teams\nI’ve seen high-performance specialists bring over habits that don’t scale organizationally: rewriting libraries, resisting abstractions, and insisting on building from scratch. I’ve been guilty of it too, creating \"hot\" functions in x86-64 assembler and using directly the processor's SIMD commands (AVX-512), even when using the Go language. These systems work brilliantly, but only in the hands of their authors. By the way, assembler is very conveniently integrated into Go, but, as practice has shown, few people know it.\nToday, as a manager, I emphasize that business tasks must come first. If business requires creating a system with extreme performance characteristics, then we must remember that this will require a stellar team and vice versa, if a standard system is required, then it is not worth using solutions that are difficult to support and develop, but should focus on schemes and architecture that are understandable to the mass developer, which can be mastered by a mid-level developer in two weeks.\nI also caution against microservices sprawl. Teams eager to optimize development workflows may inadvertently turn a tight data-centric pipeline into a network of chatty, latency-laden services. Even Amazon Prime Video teams have returned from microservices to monoliths in such contexts.\nUnlearning the Habit of Optimization\nThe hardest thing for performance-oriented engineers to learn is when not to optimize. When building the MTS platform, we had parts of the system that were hot paths and others that were barely used. Initially, the urge was to use the same tooling across all components. But it’s a trap. CRUD services don’t need to scale like your bidding engine. Choose the right tool, even if that means sacrificing uniformity.\nSimilarly, early in my career, when developing code to perform a fast inverse Fourier transform, I wrote a highly optimized assembler code that outperformed GCC by 30%. But six months later, the processors changed, and my code optimized for prefetch pipelines began to perform worse than the compiler-generated one. That’s the real cost of low-level perfection: it rarely lasts. Performance tuning should be reserved for business-critical paths.\nLifecycle Cost of Optimization\nWhat often gets overlooked is the total lifecycle cost of early optimization. An efficient algorithm or exotic data layout may save compute time today, but if it slows down onboarding, complicates testability, or becomes a barrier to architectural evolution, then the system is effectively accruing technical debt disguised as technical brilliance. I’ve seen projects where an engineer’s initial low-level perfection became a tax the team paid for years—refactoring was too risky, and new hires avoided touching critical modules. Mature systems require performance that evolves with the business, not just code that’s clever in the moment. The question we should always ask is: “Can this optimization survive team growth and domain shifts over 3–5 years?”\nLearning to Let Go\nIn our CTR/VTR predictor, we send updates in real time. But for the segment coverage calculator in the UI, we switched to batch processing. The latency of updating the data in the UI has increased, but the complexity of support and development has decreased significantly without any impact on the business goal.\nThe wisdom is not in knowing how to optimize, but in knowing when the business doesn’t need it. Premature optimization is only “evil” when it’s misaligned with business maturity. If you're targeting 200k RPS on a core, yes—start sharp. But if it's 200k RPS on a cluster, and you can shard data processing (e.g. distribute requests across nodes), then act iteratively, start with inefficient but working code, and plan refactoring to achieve lower server load. And how to use the \"extra\" hardware freed up after optimization has never been a problem.\nMature Engineers Understand Trade-offs\nThe most balanced engineers I’ve worked with understand the entire vertical, from business requirements to infrastructure tuning. They know when to use Apache Ignite and when Postgres is enough. They make performance decisions only where bottlenecks align with business outcomes.\nSuch engineers avoid optimization addiction. They favor maintainability. They are patient with temporary solutions and confident that the roadmap allows for future improvements. That confidence, along with technical range, is what I consider “technical maturity.”\nLeading Self-Organizing Teams Without Overengineering\nLeft unchecked, high-performance teams often over-abstract. To prevent that, I encourage cross-functional ownership—engineers who think like analysts, testers, and product managers. I advocate for teams that talk openly, document and justify the architectural decisions (ADR), and include domain experts in the loop. You cannot succeed with brilliant engineers alone. You need people from the market.\nAlso, I’ve seen over-specialization derail early-stage teams. For new systems, buy experienced teams or foundational platforms. Don’t reinvent everything. Starting from scratch without market-ready expertise often leads to failure, unless backed by large investments.\nFinal Thoughts\nI don’t regret specializing in high-load systems. It shaped how I think. But I’ve also seen how these instincts, left unchecked, can limit engineers in broader domains. We must relearn general software engineering just as athletes must relearn walking after years of sprinting.\nYour best skill can become your biggest bias. And your greatest strength, when balanced, is what makes you a truly versatile engineer.\nIf you’re a product leader, founder, or manager: don’t ask your engineers to over-optimize from the start. Let them build clear, maintainable systems that can scale later if needed. High performance has its place—but business alignment always comes first.",
          "dc:creator": "Georgy Starikov",
          "content": "Georgy Starikov, a software engineering manager at NVIDIA, shares how deep specialization in high-load, low-latency systems can distort engineering intuition. While performance tuning is essential in critical systems, applying those habits blindly to general business applications often leads to complexity and inefficiency. He emphasizes aligning engineering decisions with business goals, choosing simplicity and maintainability over premature optimization, and recognizing when performance isn't the priority. The key takeaway: mature engineers know when not to optimize.",
          "contentSnippet": "Georgy Starikov, a software engineering manager at NVIDIA, shares how deep specialization in high-load, low-latency systems can distort engineering intuition. While performance tuning is essential in critical systems, applying those habits blindly to general business applications often leads to complexity and inefficiency. He emphasizes aligning engineering decisions with business goals, choosing simplicity and maintainability over premature optimization, and recognizing when performance isn't the priority. The key takeaway: mature engineers know when not to optimize.",
          "guid": "https://hackernoon.com/the-hidden-cost-of-performance-how-high-load-specialization-warps-engineering-intuition?source=rss",
          "categories": [
            "engineering-teams",
            "system-design",
            "performance-optimization",
            "tech-leadership",
            "high-load-systems",
            "crud-backend-scaling",
            "software-architecture",
            "software-engineering"
          ],
          "isoDate": "2025-08-03T15:09:29.000Z"
        }
      },
      {
        "json": {
          "creator": "Pair Programming AI Agent",
          "title": "Can Anyone Code Now? Exploring AI Help for Non-Programmers",
          "link": "https://hackernoon.com/can-anyone-code-now-exploring-ai-help-for-non-programmers?source=rss",
          "pubDate": "Sun, 03 Aug 2025 15:00:04 GMT",
          "content:encoded": "<h2 id=\"tableoflinks\">Table of Links</h2>\n<p><a href=\"https://hackernoon.com/preview/MlSqFDkgc8wyYNhcTQUS\">Abstract and 1 Introduction</a></p>\n<p><a href=\"https://hackernoon.com/preview/8dpQgkvMbLYJAljrV7Vf\">2. Prior conceptualisations of intelligent assistance for programmers</a></p>\n<p><a href=\"https://hackernoon.com/preview/Fbh4JJB153JBpm3kLCxV\">3. A brief overview of large language models for code generation</a></p>\n<p><a href=\"https://hackernoon.com/preview/HmlrCOxDGvgs92HVCJ2K\">4. Commercial programming tools that use large language models</a></p>\n<p><a href=\"https://hackernoon.com/preview/LfBQwyQ4BSGJwpgYltOg\">5. Reliability, safety, and security implications of code-generating AI models</a></p>\n<p><a href=\"https://hackernoon.com/preview/CygvKtzl4ehOH2JMjzSJ\">6. Usability and design studies of AI-assisted programming</a></p>\n<p><a href=\"http://hackernoon.com/preview/avzRmaZuB6kTScIGgBXb\">7. Experience reports and 7.1. Writing effective prompts is hard</a></p>\n<p><a href=\"http://hackernoon.com/preview/trg3lvQVoL7t14dCFdHw\">7.2. The activity of programming shifts towards checking and unfamiliar debugging</a></p>\n<p><a href=\"https://hackernoon.com/preview/Y6BbJahplhYZlxdqdCFp\">7.3. These tools are useful for boilerplate and code reuse</a></p>\n<p>8. The inadequacy of existing metaphors for AI-assisted programming</p>\n<p><a href=\"https://hackernoon.com/preview/vWx560H10HWi8ZHXooSN\">8.1. AI assistance as search</a></p>\n<p><a href=\"https://hackernoon.com/preview/7aqW8wQKjdANYySTv4HT\">8.2. AI assistance as compilation</a></p>\n<p><a href=\"http://hackernoon.com/preview/dt4WL0IqtGFKwYXl8xcM\">8.3. AI assistance as pair programming</a></p>\n<p><a href=\"https://hackernoon.com/preview/y6sPtr5BxC8m3FKl3sPe\">8.4. A distinct way of programming</a></p>\n<p><a href=\"http://hackernoon.com/preview/cFluWTtWEw5cYM79in5t\">9. Issues with application to end-user programming</a></p>\n<p><a href=\"http://hackernoon.com/preview/yXSCL6V4pdtdts6ABfM6\">9.1. Issue 1: Intent specification, problem decomposition and computational thinking</a></p>\n<p><a href=\"https://hackernoon.com/preview/E4BSkXJzfI4viO9ZlSiq\">9.2. Issue 2: Code correctness, quality and (over)confidence</a></p>\n<p><a href=\"https://hackernoon.com/preview/bnqPT5z9RjUqofcdLHgu\">9.3. Issue 3: Code comprehension and maintenance</a></p>\n<p><a href=\"http://hackernoon.com/preview/BakiKXXyiC7EliqZuaEi\">9.4. Issue 4: Consequences of automation in end-user programming</a></p>\n<p><a href=\"http://hackernoon.com/preview/KUolRiHRR6l2EibKExUJ\">9.5. Issue 5: No code, and the dilemma of the direct answer</a></p>\n<p><a href=\"http://hackernoon.com/preview/4zcamJIgNx2iZo9jpBY5\">10. Conclusion</a></p>\n<p><a href=\"https://hackernoon.com/preview/tJyNpGmyfTQHlfAqjVVC\">A. Experience report sources</a></p>\n<p><a href=\"https://hackernoon.com/preview/DfXa3jYCd5LYy3NDyv6c\">References</a></p>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/fWZa4tUiBGemnqQfBGgCPf9594N2-8q833y4.png\" alt=\"Figure 1 – Code generation using the GitHub Copilot editor extension. The portion highlighted in blue has been generated by the model. Left: a function body, generated based on a textual description in a comment. Right: a set of generated test cases. Source: copilot.github.com\" /></p>\n<h2 id=\"abstract\">Abstract</h2>\n<p>Large language models, such as OpenAI’s codex and Deepmind’s AlphaCode, can generate code to solve a variety of problems expressed in natural language. This technology has already been commercialised in at least one widely-used programming editor extension: GitHub Copilot.</p>\n<p>\\\nIn this paper, we explore how programming with large language models (LLM-assisted programming) is similar to, and differs from, prior conceptualisations of programmer assistance. We draw upon publicly available experience reports of LLM-assisted programming, as well as prior usability and design studies. We find that while LLM-assisted programming shares some properties of compilation, pair programming, and programming via search and reuse, there are fundamental differences both in the technical possibilities as well as the practical experience. Thus, LLM-assisted programming ought to be viewed as a new way of programming with its own distinct properties and challenges.</p>\n<p>\\\nFinally, we draw upon observations from a user study in which non-expert end user programmers use LLM-assisted tools for solving data tasks in spreadsheets. We discuss the issues that might arise, and open research challenges, in applying large language models to end-user programming, particularly with users who have little or no programming expertise.</p>\n<h3 id=\"1introduction\">1. Introduction</h3>\n<p>Inferential assistance for programmers has manifested in various forms, such as programming by demonstration, declarative programming languages, and program synthesis (Section 2). Large language models such as GPT mark a quantitative and qualitative step-change in the automatic generation of code and natural language text. This can be attributed to cumulative innovations of vector-space word embeddings, the transformer architecture, large text corpora, and pre-trained language models (Section 3).</p>\n<p>\\\nThese models have been commercialised in the form of APIs such as OpenAI Codex, or as programmerfacing tools such as GitHub Copilot and Tabnine. These tools function as a sort of advanced autocomplete, able to synthesize multiple lines of code based on a prompt within the code editor, which may be natural language (e.g., a comment), code (e.g., a function signature) or an ad-hoc mixture. The capabilities of such tools go well beyond traditional syntax-directed autocomplete, and include the ability to synthesize entire function bodies, write test cases, and complete repetitive patterns (Section 4). These tools have reliability, safety, and security implications (Section 5).</p>\n<p>\\\nPrior lab-based and telemetric research on the usability of such tools finds that developers generally appreciate the capabilities of these tools and find them to be a positive asset to the development experience, despite no strong effects on task completion times or correctness. Core usability issues include the challenge of correctly framing prompts as well as the effort required to check and debug generated code (Section 6).</p>\n<p>\\\nLongitudinal experience reports of developers support some of the lab-based findings, while contradicting others. The challenges of correctly framing prompts and the efforts of debugging also appear here. However, there are many reports that these tools do in fact strongly reduce task time (i.e., speed up the development process) (Section 7).</p>\n<p>\\\nProgramming with large language models invites comparison to related ways of programming, such as search, compilation, and pair programming. While there are indeed similarities with each of these, the empirical reports of the experience of such tools also show crucial differences. Search, compilation, and pair programming are thus found to be inadequate metaphors for the nature of LLM-assisted programming; it is a distinct way of programming with its own unique blend of properties (Section 8).</p>\n<p>\\\nWhile LLM-assisted programming is currently geared towards expert programmers, arguably the greatest beneficiaries of their abilities will be non-expert end-user programmers. Nonetheless, there are issues with their direct application in end-user programming scenarios. Through a study of LLM-assisted end-user programming in spreadsheets, we uncover issues in intent specification, code correctness, comprehension, LLM tuning, and end-user behaviour, and motivate the need for further study in this area (Section 9).</p>\n<p>\\</p>\n<p>:::info\nThis paper is <strong><a href=\"https://arxiv.org/abs/2208.06213\">available on arxiv</a></strong> under CC BY-NC-ND 4.0 DEED license.</p>\n<p>:::</p>\n<p>:::info\n<strong>Authors:</strong></p>\n<p>(1) Advait Sarkar, Microsoft Research, University of Cambridge (advait@microsoft.com);</p>\n<p>(2) Andrew D. Gordon, Microsoft Research, University of Edinburgh (adg@microsoft.com);</p>\n<p>(3) Carina Negreanu, Microsoft Research (cnegreanu@microsoft.com);</p>\n<p>(4) Christian Poelitz, Microsoft Research (cpoelitz@microsoft.com);</p>\n<p>(5) Sruti Srinivasa Ragavan, Microsoft Research (a-srutis@microsoft.com);</p>\n<p>(6) Ben Zorn, Microsoft Research (ben.zorn@microsoft.com).</p>\n<p>:::</p>\n<p>\\</p>",
          "content:encodedSnippet": "Table of Links\nAbstract and 1 Introduction\n2. Prior conceptualisations of intelligent assistance for programmers\n3. A brief overview of large language models for code generation\n4. Commercial programming tools that use large language models\n5. Reliability, safety, and security implications of code-generating AI models\n6. Usability and design studies of AI-assisted programming\n7. Experience reports and 7.1. Writing effective prompts is hard\n7.2. The activity of programming shifts towards checking and unfamiliar debugging\n7.3. These tools are useful for boilerplate and code reuse\n8. The inadequacy of existing metaphors for AI-assisted programming\n8.1. AI assistance as search\n8.2. AI assistance as compilation\n8.3. AI assistance as pair programming\n8.4. A distinct way of programming\n9. Issues with application to end-user programming\n9.1. Issue 1: Intent specification, problem decomposition and computational thinking\n9.2. Issue 2: Code correctness, quality and (over)confidence\n9.3. Issue 3: Code comprehension and maintenance\n9.4. Issue 4: Consequences of automation in end-user programming\n9.5. Issue 5: No code, and the dilemma of the direct answer\n10. Conclusion\nA. Experience report sources\nReferences\n\\\n \nAbstract\nLarge language models, such as OpenAI’s codex and Deepmind’s AlphaCode, can generate code to solve a variety of problems expressed in natural language. This technology has already been commercialised in at least one widely-used programming editor extension: GitHub Copilot.\n\\\nIn this paper, we explore how programming with large language models (LLM-assisted programming) is similar to, and differs from, prior conceptualisations of programmer assistance. We draw upon publicly available experience reports of LLM-assisted programming, as well as prior usability and design studies. We find that while LLM-assisted programming shares some properties of compilation, pair programming, and programming via search and reuse, there are fundamental differences both in the technical possibilities as well as the practical experience. Thus, LLM-assisted programming ought to be viewed as a new way of programming with its own distinct properties and challenges.\n\\\nFinally, we draw upon observations from a user study in which non-expert end user programmers use LLM-assisted tools for solving data tasks in spreadsheets. We discuss the issues that might arise, and open research challenges, in applying large language models to end-user programming, particularly with users who have little or no programming expertise.\n1. Introduction\nInferential assistance for programmers has manifested in various forms, such as programming by demonstration, declarative programming languages, and program synthesis (Section 2). Large language models such as GPT mark a quantitative and qualitative step-change in the automatic generation of code and natural language text. This can be attributed to cumulative innovations of vector-space word embeddings, the transformer architecture, large text corpora, and pre-trained language models (Section 3).\n\\\nThese models have been commercialised in the form of APIs such as OpenAI Codex, or as programmerfacing tools such as GitHub Copilot and Tabnine. These tools function as a sort of advanced autocomplete, able to synthesize multiple lines of code based on a prompt within the code editor, which may be natural language (e.g., a comment), code (e.g., a function signature) or an ad-hoc mixture. The capabilities of such tools go well beyond traditional syntax-directed autocomplete, and include the ability to synthesize entire function bodies, write test cases, and complete repetitive patterns (Section 4). These tools have reliability, safety, and security implications (Section 5).\n\\\nPrior lab-based and telemetric research on the usability of such tools finds that developers generally appreciate the capabilities of these tools and find them to be a positive asset to the development experience, despite no strong effects on task completion times or correctness. Core usability issues include the challenge of correctly framing prompts as well as the effort required to check and debug generated code (Section 6).\n\\\nLongitudinal experience reports of developers support some of the lab-based findings, while contradicting others. The challenges of correctly framing prompts and the efforts of debugging also appear here. However, there are many reports that these tools do in fact strongly reduce task time (i.e., speed up the development process) (Section 7).\n\\\nProgramming with large language models invites comparison to related ways of programming, such as search, compilation, and pair programming. While there are indeed similarities with each of these, the empirical reports of the experience of such tools also show crucial differences. Search, compilation, and pair programming are thus found to be inadequate metaphors for the nature of LLM-assisted programming; it is a distinct way of programming with its own unique blend of properties (Section 8).\n\\\nWhile LLM-assisted programming is currently geared towards expert programmers, arguably the greatest beneficiaries of their abilities will be non-expert end-user programmers. Nonetheless, there are issues with their direct application in end-user programming scenarios. Through a study of LLM-assisted end-user programming in spreadsheets, we uncover issues in intent specification, code correctness, comprehension, LLM tuning, and end-user behaviour, and motivate the need for further study in this area (Section 9).\n\\\n:::info\nThis paper is available on arxiv under CC BY-NC-ND 4.0 DEED license.\n:::\n:::info\nAuthors:\n(1) Advait Sarkar, Microsoft Research, University of Cambridge (advait@microsoft.com);\n(2) Andrew D. Gordon, Microsoft Research, University of Edinburgh (adg@microsoft.com);\n(3) Carina Negreanu, Microsoft Research (cnegreanu@microsoft.com);\n(4) Christian Poelitz, Microsoft Research (cpoelitz@microsoft.com);\n(5) Sruti Srinivasa Ragavan, Microsoft Research (a-srutis@microsoft.com);\n(6) Ben Zorn, Microsoft Research (ben.zorn@microsoft.com).\n:::\n\\",
          "dc:creator": "Pair Programming AI Agent",
          "content": "Come see how coding is changing with AI language models. Sharing real-world stories and studies showing just how different—and awesome—it is to program with these new tools now.",
          "contentSnippet": "Come see how coding is changing with AI language models. Sharing real-world stories and studies showing just how different—and awesome—it is to program with these new tools now.",
          "guid": "https://hackernoon.com/can-anyone-code-now-exploring-ai-help-for-non-programmers?source=rss",
          "categories": [
            "large-language-models",
            "ai-assisted-programming",
            "github-copilot",
            "code-generation",
            "programmer-assistance",
            "end-user-programming",
            "usability-studies",
            "inferential-assistance"
          ],
          "isoDate": "2025-08-03T15:00:04.000Z"
        }
      },
      {
        "json": {
          "creator": "Khamisi Hamisi",
          "title": "Europe’s Data Vision: Dataspaces for Zero-Trust AI Infrastructure",
          "link": "https://hackernoon.com/europes-data-vision-dataspaces-for-zero-trust-ai-infrastructure?source=rss",
          "pubDate": "Sun, 03 Aug 2025 12:15:08 GMT",
          "content:encoded": "<p>As AI systems scale across sectors like healthcare, manufacturing, and finance, Europe faces a critical challenge: how to orchestrate AI securely across privacy, regulatory, and organizational boundaries.</p>\n<p>\\\nThis case study explores a pioneering Huberta project that embraces zero-trust architecture, metadata-first orchestration, and mathematical compliance via PDEs.</p>\n<p>\\\nAt the heart of this initiative lies a breakthrough: policy-aware orchestration through partial differential equations, allowing AI to run only when privacy, intent, and law align.</p>\n<p>\\\nUpstaff provided specialized <a href=\"https://upstaff.com/blog/artificial-intelligence-machine-learning-engineer-ai-ml/become-a-machine-learning-engineer-your-guide/\">AI engineers</a> who tackled the core challenges of federated orchestration, zero-trust metadata, and explainable infrastructure at scale.</p>\n<p>\\\nThis article provides insights into a European data infrastructure project focused on creating a policy-aware, zero-trust system for federated AI.</p>\n<p>\\\nThe initiative aims to revolutionize data infrastructure by replacing centralized data systems with a decentralized, privacy-preserving framework.</p>\n<p>\\\nIt uses partial differential equations (PDEs) to enforce compliance (e.g., GDPR, EU AI Act) and manage data access for secure multi-party collaboration without raw data exchange.</p>\n<p>\\\n<strong>What we will cover:</strong></p>\n<p>\\</p>\n<ul>\n<li>Zero-Trust Metadata and Dataspaces</li>\n<li>Zero-Trust AI Orchestration Across Privacy and Policy Boundaries</li>\n<li>System Architecture Overview</li>\n<li>Engineering Stack &amp; Capabilities</li>\n<li>Cloud Infrastructure Capability Matrix (AWS-focused)</li>\n<li>Engineering the Backbone of Federated AI</li>\n<li>Results So Far</li>\n<li>Lessons Learned &amp; Engineering Insights</li>\n<li>Why This Matters: The Next Wave of AI Infrastructure</li>\n<li>Conclusion: Engineering Trustworthy AI at Scale</li>\n</ul>\n<h2 id=\"dataspace\"><strong>Dataspace</strong></h2>\n<p>A dataspace is a federated network designed for secure, <a href=\"https://upstaff.com/blog/blockchain-web-3-0/depin-decentralized-physical-infrastructure-networks/\">decentralized data exchange</a>. It allows organizations to maintain control over their data while enabling interoperability across different platforms and industries.</p>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/2bL8Ve2IGiP0vEziDpWY80JjirD2-xu02fq2.jpeg\" alt=\"\" /></p>\n<p>\\\nDataspace enables trusted data sharing in a way that preserves the data sovereignty of participants based on a standard governance framework.</p>\n<p>\\</p>\n<ul>\n<li>Dataspaces are pivotal in sectors like mobility, healthcare, logistics, and smart cities, where data integration is essential for innovation and efficiency.</li>\n<li>Dataspaces can be purpose- or sector-specific, or cross-sectoral.</li>\n</ul>\n<h2 id=\"zerotrustmetadataanddataspaces\"><strong>Zero-Trust Metadata and Dataspaces</strong></h2>\n<p>As Europe advances toward a digitally sovereign future, the way we handle data is undergoing a fundamental shift.</p>\n<p>\\\n <img src=\"https://cdn.hackernoon.com/images/2bL8Ve2IGiP0vEziDpWY80JjirD2-kg12feu.jpeg\" alt=\"\" /></p>\n<p>\\\n\\\nTraditional architectures such as centralized data lakes, post-hoc compliance checks, and monolithic workflows are no longer sufficient. Emerging standards, like the EU AI Act and GDPR, demand real-time governance, privacy-preserving design, and explainability by default.</p>\n<p>\\\nAt the frontier of this transformation is a groundbreaking project. Its mission is to reimagine data infrastructure as a policy-aware, zero-trust system built not from pipelines, but from mathematics.</p>\n<p>\\\nAt the core of this system are partial differential equations (PDEs) that regulate resource access, data movement, and AI behavior through boundary conditions.</p>\n<p>\\\nThis paradigm allows multi-party collaboration without raw data exchange, high-performance computing (HPC) on demand, with minimal energy footprint, and compliance encoded directly into the infrastructure.</p>\n<h3 id=\"howpdeorchestratedinfrastructurediffersfromconventionalsystems\"><strong>How PDE-Orchestrated Infrastructure Differs From Conventional Systems</strong></h3>\n<p>| Feauture | Conventional Cloud AI | PDE-Orchestrated Zero-Trust AI |\n|----|----|----|\n| Data Movement | Centralized | Local-only |\n| Policy Compliance | Post-hoc | By-construction |\n| Resource Usage | Persistent | Ephemeral |\n| Governance | Manual | Embedded in PDEs |\n| Traceability | Limited | DAG + Policy-bound |</p>\n<h2 id=\"zerotrustaiorchestrationacrossprivacyandpolicyboundaries\"><strong>Zero-Trust AI Orchestration Across Privacy and Policy Boundaries</strong></h2>\n<p>The project's vision is radical: create a framework where data never moves, but value does.</p>\n<p>\\\nRather than collecting data into central repositories, each participant in the system, whether in healthcare, manufacturing, or public services, retains full control of their data.</p>\n<p>\\\nA dynamic knowledge graph holds metadata, ontologies, and processing “recipes.” Computation is triggered by PDEs that enforce policy gates (GDPR, ISO, GAMP) as mathematical constraints.</p>\n<p>\\\nWhen certain boundary conditions are met, e.g., a spike in demand or anomaly detection, a short-lived HPC cluster spins up, computes locally, and vanishes.</p>\n<p>\\\nBut to make this vision real, the team needed engineers with a rare mix of skills:</p>\n<p>\\</p>\n<ul>\n<li>Privacy-preserving machine learning</li>\n<li>Federated AI</li>\n<li>Knowledge graph integration</li>\n<li>Explainable DAG orchestration</li>\n<li>Semantic modeling and metadata processing</li>\n</ul>\n<p>\\\nAt the heart of the system lies a governance PDE, where each term in the equation maps to a constraint:</p>\n<p>\\</p>\n<ul>\n<li>∂u/∂t + ∇·(α(u)∇u) = f(x, t)- represents AI execution across time and space.</li>\n<li>∂u/∂t — latency or response time</li>\n<li>α(u) — policy gating/access weights</li>\n<li>f(x, t) — triggers like demand spike or anomaly</li>\n<li>Boundary terms = regulatory or domain-specific constraints, GDPR compliance, semantic gates, and user intent.</li>\n</ul>\n<p>\\\nIf the PDE has no solution, computation is halted. This turns policy from a rule to a hard condition of execution. “If you can’t solve the PDE, you can’t run the task.” This is proactive compliance by construction.</p>\n<h2 id=\"systemarchitectureoverview\"><strong>System Architecture Overview</strong></h2>\n<ul>\n<li><p><strong>Local Data Silos</strong>: Hospitals, factories, and labs retain full control of raw data. Nothing is centralized.</p>\n<p>\\</p></li>\n<li><p><strong>Policy Gate</strong>: Applies GDPR, AI Act, and internal policies at the metadata boundary. Invalid flows are filtered before orchestration.</p>\n<p>\\</p></li>\n<li><p><strong>PDE Engine</strong>: The core of the system. It solves boundary-condition equations where each constraint represents a legal, semantic, or resource constraint.</p>\n<p>\\</p></li>\n</ul>\n<p>Examples:</p>\n<p>\\</p>\n<ol>\n<li>A GDPR clause becomes an unsolvable boundary if data leaves its origin.</li>\n<li>A compute budget becomes a conditional activation.</li>\n</ol>\n<p>\\</p>\n<ul>\n<li><p><strong>Knowledge Graph:</strong> Stores semantic mappings, policy clauses, domain taxonomies, and orchestration “recipes.” This separates logic from data — enabling fast, ontology-driven decisions.</p>\n<p>\\</p></li>\n<li><p><strong>Ephemeral HPC Clusters:</strong> Resources are spun up only when a PDE solution exists — when policy, readiness, and workload match.</p>\n<p>\\\nThese may include:</p>\n<p>\\</p></li>\n</ul>\n<ol>\n<li>Classification models</li>\n<li>Anomaly detectors</li>\n<li>Simulation workloads</li>\n<li>Federated training</li>\n</ol>\n<p>\\</p>\n<ul>\n<li><strong>DAG Traceability</strong>: Each operation logs its origin: which policy triggered it, which resource was allocated, and which boundary condition was met.</li>\n</ul>\n<h2 id=\"engineeringstackcapabilities\"><strong>Engineering Stack & Capabilities</strong></h2>\n<p>| Domain | Contribution | Tools and Methods |\n|----|----|----|\n| Federated AI | Built vertical &amp; horizontal pipelines | PySyft, Flower, OpenMined, custom secure aggregation protocols |\n| Semantic Modeling | Ontology→PDE mapping | RDF/OWL, Protégé, SPARQL, Neo4j, GraphQL |\n| Metadata-First Design | Graph-driven orchestration | GraphQL, custom DAG wrappers, Apache Airflow, Argo Workflows, Prefect, Temporal |\n| Explainability &amp; Auditing | Traceable execution lineage | DAG visualizers, metadata provenance tracing, JSON-LD, OpenPolicyAgent logs |\n| PDE Compliance Runtime | Mathematical constraint solver | SciPy, JAX, TensorFlow PDE, PyTorch autograd, custom symbolic solvers |\n| Infrastructure Engineering | Deployed resilient, policy-aware federated systems across cloud-native and hybrid environments | Amazon Web Services |</p>\n<p>\\</p>\n<h2 id=\"cloudinfrastructurecapabilitymatrixawsfocused\"><strong>Cloud Infrastructure Capability Matrix (AWS-Focused)</strong></h2>\n<p>\\</p>\n<p>| Category | AWS Services Listed | Notes |\n|----|----|----|\n| Compute &amp; Containerization | ECS, EKS, EC2, Fargate, Lambda | All AWS-native |\n| Networking &amp; Security | VPC, PrivateLink, IAM, Security Groups, KMS, Secrets Manager | AWS-specific |\n| Storage | S3, EFS, FSx | AWS storage services |\n| Serverless Pipelines | Step Functions, EventBridge, DynamoDB Streams | AWS-native serverless tools |\n| Data Layer | Neptune, RDS, Aurora, Glue, Athena | All are AWS-managed data services |\n| Monitoring &amp; Observability | CloudWatch, X-Ray, OpenTelemetry | FirOpenTelemetry is a cross-cloud; two are AWS |\n| Compliance Enforcement | Macie, GuardDuty, Config | All AWS-native compliance/security tools |</p>\n<h2 id=\"engineeringthebackboneoffederatedai\"><strong>Engineering the Backbone of Federated AI</strong></h2>\n<p>Among others, Federated AI also allows them to significantly reduce the amount of data they transfer. In fact, some projects managed to reduce their data transfer burden by more than 99% compared to a centralized training model.</p>\n<p>\\\nThis is important because moving very large datasets contributes to higher costs, lower performance, and decreased energy efficiency.</p>\n<p>\\\nThere are two main approaches to federated AI:</p>\n<p>\\</p>\n<ul>\n<li><p><strong>Horizontal federated AI</strong>: pulls model weights from the same types of data in every site</p>\n<p>\\</p></li>\n<li><p><strong>Vertical federated AI:</strong> pulls model weights from different types of data in different sites</p>\n<p>\\</p></li>\n</ul>\n<p>AI engineers contributed to several mission-critical domains:</p>\n<p>\\</p>\n<ul>\n<li><p><strong>Multi-head AI pipelines</strong></p>\n<p>Asynchronous pipelines for classification, anomaly detection, and schema interpretation, all integrated into a dynamic metadata fabric.</p>\n<p>\\</p></li>\n<li><p><strong>Semantic-aware orchestration</strong></p>\n<p>Knowledge graph outputs to PDE boundary inputs, ensuring compute only runs when policies, semantics, and capacity align.</p>\n<p>\\</p></li>\n<li><p><strong>Zero-trust federation logic</strong></p>\n<p>AI workflows to operate without ever touching raw data—only abstracted metadata fragments.</p>\n<p>\\</p></li>\n<li><p><strong>Audit-ready explainability</strong></p>\n<p>Directed acyclic graphs (DAGs) trace each decision back to a semantic label or policy clause, aligning with upcoming EU AI Act requirements.</p></li>\n</ul>\n<p>\\\nBehind some of the engineering challenges in this initiative is a team of specialized AI engineers from Upstaff, who could contribute to policy-aware AI infrastructure across domains as sensitive as healthcare and industrial manufacturing.</p>\n<h2 id=\"resultssofar\"><strong>Results So Far</strong></h2>\n<p>Though still in active development, the project has made several breakthroughs:</p>\n<p>\\</p>\n<ul>\n<li>A working alpha prototype of the PDE aggregator with sub-second concurrency response.</li>\n<li>Real-time metadata ingestion and anomaly classification through AI modules.</li>\n<li>Federated learning simulations operating under policy constraints.</li>\n<li>Traceable, explainable orchestration flows through self-documenting DAGs.</li>\n</ul>\n<h2 id=\"lessonslearnedengineeringinsights\"><strong>Lessons Learned & Engineering Insights</strong></h2>\n<ul>\n<li>Math over policies wins: Executable PDEs &gt; static rules</li>\n<li>Metadata is infrastructure: Ontologies replaced scripts</li>\n<li>Compliance must be first-class: Not a feature—an execution condition</li>\n<li>No-code ≠ Low-trust: Engineers must deeply understand the domain and legal semantics</li>\n</ul>\n<h2 id=\"whythismattersthenextwaveofaiinfrastructure\"><strong>Why This Matters: The Next Wave of AI Infrastructure</strong></h2>\n<h2 id=\"\"> </h2>\n<p><img src=\"https://cdn.hackernoon.com/images/2bL8Ve2IGiP0vEziDpWY80JjirD2-yn22fs8.jpeg\" alt=\"\" /></p>\n<p>\\\nThe technical architecture being developed in this project isn’t niche. It’s a preview of where AI and data engineering are headed:</p>\n<p>\\</p>\n<ul>\n<li>Federated AI in finance and healthcare</li>\n<li>Semantic interoperability across ESG supply chains</li>\n<li>Ephemeral HPC for energy-efficient computing</li>\n<li>Mathematical governance over data flows</li>\n</ul>\n<h2 id=\"conclusionengineeringtrustworthyaiatscale\"><strong>Conclusion: Engineering Trustworthy AI at Scale</strong></h2>\n<p>Real-world AI lives at the intersection of regulation, infrastructure, ethics, and performance. This initiative is a bold attempt to build a system where all those concerns are solved mathematically, structurally, and scalably.</p>\n<p>\\\nCompliance isn’t a document; it’s a boundary condition. And orchestration isn’t a workflow; it’s an equation.</p>",
          "content:encodedSnippet": "As AI systems scale across sectors like healthcare, manufacturing, and finance, Europe faces a critical challenge: how to orchestrate AI securely across privacy, regulatory, and organizational boundaries.\n\\\nThis case study explores a pioneering Huberta project that embraces zero-trust architecture, metadata-first orchestration, and mathematical compliance via PDEs.\n\\\nAt the heart of this initiative lies a breakthrough: policy-aware orchestration through partial differential equations, allowing AI to run only when privacy, intent, and law align.\n\\\nUpstaff provided specialized AI engineers who tackled the core challenges of federated orchestration, zero-trust metadata, and explainable infrastructure at scale.\n\\\nThis article provides insights into a European data infrastructure project focused on creating a policy-aware, zero-trust system for federated AI.\n\\\nThe initiative aims to revolutionize data infrastructure by replacing centralized data systems with a decentralized, privacy-preserving framework.\n\\\nIt uses partial differential equations (PDEs) to enforce compliance (e.g., GDPR, EU AI Act) and manage data access for secure multi-party collaboration without raw data exchange.\n\\\nWhat we will cover:\n\\\n\nZero-Trust Metadata and Dataspaces\nZero-Trust AI Orchestration Across Privacy and Policy Boundaries\nSystem Architecture Overview\nEngineering Stack & Capabilities\nCloud Infrastructure Capability Matrix (AWS-focused)\nEngineering the Backbone of Federated AI\nResults So Far\nLessons Learned & Engineering Insights\nWhy This Matters: The Next Wave of AI Infrastructure\nConclusion: Engineering Trustworthy AI at Scale\nDataspace\nA dataspace is a federated network designed for secure, decentralized data exchange. It allows organizations to maintain control over their data while enabling interoperability across different platforms and industries.\n\\\n \n\\\nDataspace enables trusted data sharing in a way that preserves the data sovereignty of participants based on a standard governance framework.\n\\\n\nDataspaces are pivotal in sectors like mobility, healthcare, logistics, and smart cities, where data integration is essential for innovation and efficiency.\nDataspaces can be purpose- or sector-specific, or cross-sectoral.\nZero-Trust Metadata and Dataspaces\nAs Europe advances toward a digitally sovereign future, the way we handle data is undergoing a fundamental shift.\n\\\n \n\\\n\\\nTraditional architectures such as centralized data lakes, post-hoc compliance checks, and monolithic workflows are no longer sufficient. Emerging standards, like the EU AI Act and GDPR, demand real-time governance, privacy-preserving design, and explainability by default.\n\\\nAt the frontier of this transformation is a groundbreaking project. Its mission is to reimagine data infrastructure as a policy-aware, zero-trust system built not from pipelines, but from mathematics.\n\\\nAt the core of this system are partial differential equations (PDEs) that regulate resource access, data movement, and AI behavior through boundary conditions.\n\\\nThis paradigm allows multi-party collaboration without raw data exchange, high-performance computing (HPC) on demand, with minimal energy footprint, and compliance encoded directly into the infrastructure.\nHow PDE-Orchestrated Infrastructure Differs From Conventional Systems\n| Feauture | Conventional Cloud AI | PDE-Orchestrated Zero-Trust AI |\n|----|----|----|\n| Data Movement | Centralized | Local-only |\n| Policy Compliance | Post-hoc | By-construction |\n| Resource Usage | Persistent | Ephemeral |\n| Governance | Manual | Embedded in PDEs |\n| Traceability | Limited | DAG + Policy-bound |\nZero-Trust AI Orchestration Across Privacy and Policy Boundaries\nThe project's vision is radical: create a framework where data never moves, but value does.\n\\\nRather than collecting data into central repositories, each participant in the system, whether in healthcare, manufacturing, or public services, retains full control of their data.\n\\\nA dynamic knowledge graph holds metadata, ontologies, and processing “recipes.” Computation is triggered by PDEs that enforce policy gates (GDPR, ISO, GAMP) as mathematical constraints.\n\\\nWhen certain boundary conditions are met, e.g., a spike in demand or anomaly detection, a short-lived HPC cluster spins up, computes locally, and vanishes.\n\\\nBut to make this vision real, the team needed engineers with a rare mix of skills:\n\\\n\nPrivacy-preserving machine learning\nFederated AI\nKnowledge graph integration\nExplainable DAG orchestration\nSemantic modeling and metadata processing\n\\\nAt the heart of the system lies a governance PDE, where each term in the equation maps to a constraint:\n\\\n\n∂u/∂t + ∇·(α(u)∇u) = f(x, t)- represents AI execution across time and space.\n∂u/∂t — latency or response time\nα(u) — policy gating/access weights\nf(x, t) — triggers like demand spike or anomaly\nBoundary terms = regulatory or domain-specific constraints, GDPR compliance, semantic gates, and user intent.\n\\\nIf the PDE has no solution, computation is halted. This turns policy from a rule to a hard condition of execution. “If you can’t solve the PDE, you can’t run the task.” This is proactive compliance by construction.\nSystem Architecture Overview\nLocal Data Silos: Hospitals, factories, and labs retain full control of raw data. Nothing is centralized.\n\\\nPolicy Gate: Applies GDPR, AI Act, and internal policies at the metadata boundary. Invalid flows are filtered before orchestration.\n\\\nPDE Engine: The core of the system. It solves boundary-condition equations where each constraint represents a legal, semantic, or resource constraint.\n\\\nExamples:\n\\\n\nA GDPR clause becomes an unsolvable boundary if data leaves its origin.\nA compute budget becomes a conditional activation.\n\\\n\n\nKnowledge Graph: Stores semantic mappings, policy clauses, domain taxonomies, and orchestration “recipes.” This separates logic from data — enabling fast, ontology-driven decisions.\n\\\nEphemeral HPC Clusters: Resources are spun up only when a PDE solution exists — when policy, readiness, and workload match.\n\\\nThese may include:\n\\\nClassification models\nAnomaly detectors\nSimulation workloads\nFederated training\n\\\n\nDAG Traceability: Each operation logs its origin: which policy triggered it, which resource was allocated, and which boundary condition was met.\nEngineering Stack & Capabilities\n| Domain | Contribution | Tools and Methods |\n|----|----|----|\n| Federated AI | Built vertical & horizontal pipelines | PySyft, Flower, OpenMined, custom secure aggregation protocols |\n| Semantic Modeling | Ontology→PDE mapping | RDF/OWL, Protégé, SPARQL, Neo4j, GraphQL |\n| Metadata-First Design | Graph-driven orchestration | GraphQL, custom DAG wrappers, Apache Airflow, Argo Workflows, Prefect, Temporal |\n| Explainability & Auditing | Traceable execution lineage | DAG visualizers, metadata provenance tracing, JSON-LD, OpenPolicyAgent logs |\n| PDE Compliance Runtime | Mathematical constraint solver | SciPy, JAX, TensorFlow PDE, PyTorch autograd, custom symbolic solvers |\n| Infrastructure Engineering | Deployed resilient, policy-aware federated systems across cloud-native and hybrid environments | Amazon Web Services |\n\\\nCloud Infrastructure Capability Matrix (AWS-Focused)\n\\\n| Category | AWS Services Listed | Notes |\n|----|----|----|\n| Compute & Containerization | ECS, EKS, EC2, Fargate, Lambda | All AWS-native |\n| Networking & Security | VPC, PrivateLink, IAM, Security Groups, KMS, Secrets Manager | AWS-specific |\n| Storage | S3, EFS, FSx | AWS storage services |\n| Serverless Pipelines | Step Functions, EventBridge, DynamoDB Streams | AWS-native serverless tools |\n| Data Layer | Neptune, RDS, Aurora, Glue, Athena | All are AWS-managed data services |\n| Monitoring & Observability | CloudWatch, X-Ray, OpenTelemetry | FirOpenTelemetry is a cross-cloud; two are AWS |\n| Compliance Enforcement | Macie, GuardDuty, Config | All AWS-native compliance/security tools |\nEngineering the Backbone of Federated AI\nAmong others, Federated AI also allows them to significantly reduce the amount of data they transfer. In fact, some projects managed to reduce their data transfer burden by more than 99% compared to a centralized training model.\n\\\nThis is important because moving very large datasets contributes to higher costs, lower performance, and decreased energy efficiency.\n\\\nThere are two main approaches to federated AI:\n\\\n\n\nHorizontal federated AI: pulls model weights from the same types of data in every site\n\\\nVertical federated AI: pulls model weights from different types of data in different sites\n\\\nAI engineers contributed to several mission-critical domains:\n\\\n\n\nMulti-head AI pipelines\nAsynchronous pipelines for classification, anomaly detection, and schema interpretation, all integrated into a dynamic metadata fabric.\n\\\nSemantic-aware orchestration\nKnowledge graph outputs to PDE boundary inputs, ensuring compute only runs when policies, semantics, and capacity align.\n\\\nZero-trust federation logic\nAI workflows to operate without ever touching raw data—only abstracted metadata fragments.\n\\\nAudit-ready explainability\nDirected acyclic graphs (DAGs) trace each decision back to a semantic label or policy clause, aligning with upcoming EU AI Act requirements.\n\n\n\\\nBehind some of the engineering challenges in this initiative is a team of specialized AI engineers from Upstaff, who could contribute to policy-aware AI infrastructure across domains as sensitive as healthcare and industrial manufacturing.\nResults So Far\nThough still in active development, the project has made several breakthroughs:\n\\\n\nA working alpha prototype of the PDE aggregator with sub-second concurrency response.\nReal-time metadata ingestion and anomaly classification through AI modules.\nFederated learning simulations operating under policy constraints.\nTraceable, explainable orchestration flows through self-documenting DAGs.\nLessons Learned & Engineering Insights\nMath over policies wins: Executable PDEs > static rules\nMetadata is infrastructure: Ontologies replaced scripts\nCompliance must be first-class: Not a feature—an execution condition\nNo-code ≠ Low-trust: Engineers must deeply understand the domain and legal semantics\nWhy This Matters: The Next Wave of AI Infrastructure\n \n\n\\\nThe technical architecture being developed in this project isn’t niche. It’s a preview of where AI and data engineering are headed:\n\\\n\nFederated AI in finance and healthcare\nSemantic interoperability across ESG supply chains\nEphemeral HPC for energy-efficient computing\nMathematical governance over data flows\nConclusion: Engineering Trustworthy AI at Scale\nReal-world AI lives at the intersection of regulation, infrastructure, ethics, and performance. This initiative is a bold attempt to build a system where all those concerns are solved mathematically, structurally, and scalably.\n\\\nCompliance isn’t a document; it’s a boundary condition. And orchestration isn’t a workflow; it’s an equation.",
          "dc:creator": "Khamisi Hamisi",
          "content": "This article provides insights into a European data infrastructure project focused on creating a policy-aware, zero-trust system for federated AI. The initiative aims to revolutionize data infrastructure by replacing centralized data systems with a decentralized, privacy-preserving framework. It uses partial differential equations (PDEs) to enforce compliance and manage data access for secure multi-party collaboration without raw data exchange.",
          "contentSnippet": "This article provides insights into a European data infrastructure project focused on creating a policy-aware, zero-trust system for federated AI. The initiative aims to revolutionize data infrastructure by replacing centralized data systems with a decentralized, privacy-preserving framework. It uses partial differential equations (PDEs) to enforce compliance and manage data access for secure multi-party collaboration without raw data exchange.",
          "guid": "https://hackernoon.com/europes-data-vision-dataspaces-for-zero-trust-ai-infrastructure?source=rss",
          "categories": [
            "ai-infrastructure",
            "zero-trust-ai",
            "pde",
            "zero-trust",
            "federated-ai",
            "zero-trust-metadata",
            "what-is-federated-ai",
            "europe-data-vision"
          ],
          "isoDate": "2025-08-03T12:15:08.000Z"
        }
      },
      {
        "json": {
          "creator": "Go [Technical Documentation]",
          "title": "Reproducible Go Toolchains: What You Need to Know",
          "link": "https://hackernoon.com/reproducible-go-toolchains-what-you-need-to-know?source=rss",
          "pubDate": "Sun, 03 Aug 2025 12:00:07 GMT",
          "content:encoded": "<p>One of the key benefits of open-source software is that anyone can read the source code and inspect what it does. And yet most software, even open-source software, is downloaded in the form of compiled binaries, which are much more difficult to inspect. If an attacker wanted to run a <a href=\"https://cloud.google.com/software-supply-chain-security/docs/attack-vectors\">supply chain attack</a> on an open-source project, the least visible way would be to replace the binaries being served while leaving the source code unmodified.</p>\n<p>\\\nThe best way to address this kind of attack is to make open-source software builds <em>reproducible</em>, meaning that a build that starts with the same sources produces the same outputs every time it runs. That way, anyone can verify that posted binaries are free of hidden changes by building from authentic sources and checking that the rebuilt binaries are bit-for-bit identical to the posted binaries. That approach proves the binaries have no backdoors or other changes not present in the source code, without having to disassemble or look inside them at all. Since anyone can verify the binaries, independent groups can easily detect and report supply chain attacks.</p>\n<p>\\\nAs supply chain security becomes more important, so do reproducible builds, because they provide a simple way to verify the posted binaries for open-source projects.</p>\n<p>\\\nGo 1.21.0 is the first Go toolchain with perfectly reproducible builds. Earlier toolchains were possible to reproduce, but only with significant effort, and probably no one did: they just trusted that the binaries posted on <a href=\"/dl/\">go.dev/dl</a> were the correct ones. Now it’s easy to “trust but verify.”</p>\n<p>\\\nThis post explains what goes into making builds reproducible, examines the many changes we had to make to Go to make Go toolchains reproducible, and then demonstrates one of the benefits of reproducibility by verifying the Ubuntu package for Go 1.21.0.</p>\n<h2 id=\"makingabuildreproducible\">Making a Build Reproducible</h2>\n<p>Computers are generally deterministic, so you might think all builds would be equally reproducible. That’s only true from a certain point of view. Let’s call a piece of information a <em>relevant input</em> when the output of a build can change depending on that input. A build is reproducible if it can be repeated with all the same relevant inputs. Unfortunately, lots of build tools turn out to incorporate inputs that we would usually not realize are relevant and that might be difficult to recreate or provide as input. Let’s call an input an <em>unintentional input</em> when it turns out to be relevant but we didn’t mean it to be.</p>\n<p>\\\nThe most common unintentional input in build systems is the current time. If a build writes an executable to disk, the file system records the current time as the executable’s modification time. If the build then packages that file using a tool like “tar” or “zip”, the modification time is written into the archive. We certainly didn’t want our build to change based on the current time, but it does. So the current time turns out to be an unintentional input to the build. Worse, most programs don’t let you provide the current time as an input, so there is no way to repeat this build. To fix this, we might set the time stamps on created files to Unix time 0 or to a specific time read from one of the build’s source files. That way, the current time is no longer a relevant input to the build.</p>\n<p>\\\nCommon relevant inputs to a build include:</p>\n<ul>\n<li>the specific version of the source code to build;</li>\n<li>the specific versions of dependencies that will be included in the build;</li>\n<li>the operating system running the build, which may affect path names in the resulting binaries;</li>\n<li>the architecture of the CPU on the build system, which may affect which optimizations the compiler uses or the layout of certain data structures;</li>\n<li>the compiler version being used, as well as compiler options passed to it, which affect how the code is compiled;</li>\n<li>the name of the directory containing the source code, which may appear in debug information;</li>\n<li>the user name, group name, uid, and gid of the account running the build, which may appear in file metadata in an archive;</li>\n<li>and many more.</li>\n</ul>\n<p>\\\nTo have a reproducible build, every relevant input must be configurable in the build, and then the binaries must be posted alongside an explicit configuration listing every relevant input. If you’ve done that, you have a reproducible build. Congratulations!</p>\n<p>\\\nWe’re not done, though. If the binaries can only be reproduced if you first find a computer with the right architecture, install a specific operating system version, compiler version, put the source code in the right directory, set your user identity correctly, and so on, that may be too much work in practice for anyone to bother.</p>\n<p>\\\nWe want builds to be not just reproducible but <em>easy to reproduce</em>. To do that, we need to identify relevant inputs and then, instead of documenting them, eliminate them. The build obviously has to depend on the source code being built, but everything else can be eliminated. When a build’s only relevant input is its source code, let’s call that <em>perfectly reproducible</em>.</p>\n<h2 id=\"perfectlyreproduciblebuildsforgo\">Perfectly Reproducible Builds for Go</h2>\n<p>As of Go 1.21, the Go toolchain is perfectly reproducible: its only relevant input is the source code for that build. We can build a specific toolchain (say, Go for Linux/x86-64) on a Linux/x86-64 host, or a Windows/ARM64 host, or a FreeBSD/386 host, or any other host that supports Go, and we can use any Go bootstrap compiler, including bootstrapping all the way back to Go 1.4’s C implementation, and we can vary any other details. None of that changes the toolchains that are built. If we start with the same toolchain source code, we will get the exact same toolchain binaries out.</p>\n<p>\\\nThis perfect reproducibility is the culmination of efforts dating back originally to Go 1.10, although most of the effort was concentrated in Go 1.20 and Go 1.21. This section highlights some of the most interesting relevant inputs that we eliminated.</p>\n<h3 id=\"reproducibilityingo110\">Reproducibility in Go 1.10</h3>\n<p>Go 1.10 introduced a content-aware build cache that decides whether targets are up-to-date based on a fingerprint of the build inputs instead of file modification times. Because the toolchain itself is one of those build inputs, and because Go is written in Go, the <a href=\"/s/go15bootstrap\">bootstrap process</a> would only converge if the toolchain build on a single machine was reproducible. The overall toolchain build looks like this:</p>\n<p><img src=\"https://cdn.hackernoon.com/images/eQHzh6rz7ETBHLjs0KzCl1Dooqp2-7r03a8v.jpeg\" alt=\"\" /></p>\n<p>\\\nWe start by building the sources for the current Go toolchain using an earlier Go version, the bootstrap toolchain (Go 1.10 used Go 1.4, written in C; Go 1.21 uses Go 1.17). That produces “toolchain1”, which we use to build everything again, producing “toolchain2”, which we use to build everything again, producing “toolchain3”.</p>\n<p>\\\nToolchain1 and toolchain2 have been built from the same sources but with different Go implementations (compilers and libraries), so their binaries are certain to be different. However, if both Go implementations are non-buggy, correct implementations, toolchain1 and toolchain2 should behave exactly the same. In particular, when presented with the Go 1.X sources, toolchain1’s output (toolchain2) and toolchain2’s output (toolchain3) should be identical, meaning toolchain2 and toolchain3 should be identical.</p>\n<p>\\\nAt least, that’s the idea. Making that true in practice required removing a couple unintentional inputs:</p>\n<p><strong>Randomness.</strong> Map iteration and running work in multiple goroutines serialized with locks both introduce randomness in the order that results may be generated. This randomness can make the toolchain produce one of several different possible outputs each time it runs. To make the build reproducible, we had to find each of these and sort the relevant list of items before using it to generate output.</p>\n<p>\\\n<strong>Bootstrap Libraries.</strong> Any library used by the compiler that can choose from multiple different correct outputs might change its output from one Go version to the next. If that library output change causes a compiler output change, then toolchain1 and toolchain2 will not be semantically identical, and toolchain2 and toolchain3 will not be bit-for-bit identical.</p>\n<p>\\\nThe canonical example is the <code>sort</code> package, which can place elements that compare equal in <a href=\"/blog/compat#output\">any order it likes</a>. A register allocator might sort to prioritize commonly used variables, and the linker sorts symbols in the data section by size. To completely eliminate any effect from the sorting algorithm, the comparison function used must never report two distinct elements as equal. In practice, this invariant turned out to be too onerous to impose on every use of sort in the toolchain, so instead we arranged to copy the Go 1.X <code>sort</code> package into the source tree that is presented to the bootstrap compiler. That way, the compiler uses the same sort algorithm when using the bootstrap toolchain as it does when built with itself.</p>\n<p>\\\nAnother package we had to copy was <code>compress/zlib</code>, because the linker writes compressed debug information, and optimizations to compression libraries can change the exact output. Over time, we’ve <a href=\"https://go.googlesource.com/go/+/go1.21.0/src/cmd/dist/buildtool.go#55\">added other packages to that list too</a>. This approach has the added benefit of allowing the Go 1.X compiler to use new APIs added to those packages immediately, at the cost that those packages must be written to compile with older versions of Go.</p>\n<h3 id=\"reproducibilityingo120\">Reproducibility in Go 1.20</h3>\n<p>Work on Go 1.20 prepared for both easy reproducible builds and <a href=\"toolchain\">toolchain management</a> by removing two more relevant inputs from the toolchain build.</p>\n<p>\\\n<strong>Host C toolchain.</strong> Some Go packages, most notably <code>net</code>, default to <a href=\"cgo\">using </a><code>cgo</code> on most operating systems. In some cases, such as macOS and Windows, invoking system DLLs using <code>cgo</code> is the only reliable way to resolve host names. When we use <code>cgo</code>, though, we invoke the host C toolchain (meaning a specific C compiler and C library), and different toolchains have different compilation algorithms and library code, producing different outputs. The build graph for a <code>cgo</code> package looks like:</p>\n<p><img src=\"https://cdn.hackernoon.com/images/eQHzh6rz7ETBHLjs0KzCl1Dooqp2-ej13a0g.jpeg\" alt=\"\" /></p>\n<p>\\\nThe host C toolchain is therefore a relevant input to the pre-compiled <code>net.a</code> that ships with the toolchain. For Go 1.20, we decided to fix this by removing <code>net.a</code> from the toolchain. That is, Go 1.20 stopped shipping pre-compiled packages to seed the build cache with. Now, the first time a program uses package <code>net</code>, the Go toolchain compiles it using the local system’s C toolchain and caches that result. </p>\n<p>\\\nIn addition to removing a relevant input from toolchain builds and making toolchain downloads smaller, not shipping pre-compiled packages also makes toolchain downloads more portable. If we build package <code>net</code> on one system with one C toolchain and then compile other parts of the program on a different system with a different C toolchain, in general there is no guarantee that the two parts can be linked together.</p>\n<p>\\\nOne reason we shipped the pre-compiled <code>net</code> package in the first place was to allow building programs that used package net even on systems without a C toolchain installed. If there’s no pre-compiled package, what happens on those systems? The answer varies by operating system, but in all cases we arranged for the Go toolchain to continue to work well for building pure Go programs without a host C toolchain.</p>\n<p>\\</p>\n<ul>\n<li>On macOS, we rewrote package net using the underlying mechanisms that cgo would use, without any actual C code. This avoids invoking the host C toolchain but still emits a binary that refers to the required system DLLs. This approach is only possible because every Mac has the same dynamic libraries installed. Making the non-cgo macOS package net use the system DLLs also meant that cross-compiled macOS executables now use the system DLLs for network access, resolving a long-standing feature request.</li>\n</ul>\n<p>\\</p>\n<ul>\n<li>On Windows, package net already made direct use of DLLs without C code, so nothing needed to be changed.</li>\n</ul>\n<p>\\</p>\n<ul>\n<li>On Unix systems, we cannot assume a specific DLL interface to network code, but the pure Go version works fine for systems that use typical IP and DNS setups. Also, it is much easier to install a C toolchain on Unix systems than it is on macOS and especially Windows. We changed the <code>go</code> command to enable or disable <code>cgo</code> automatically based on whether the system has a C toolchain installed. Unix systems without a C toolchain fall back to the pure Go version of package net, and in the rare cases where that’s not good enough, they can install a C toolchain.</li>\n</ul>\n<p>\\\nHaving dropped the pre-compiled packages, the only part of the Go toolchain that still depended on the host C toolchain was binaries built using package net, specifically the <code>go</code> command. With the macOS improvements, it was now viable to build those commands with <code>cgo</code> disabled, completely removing the host C toolchain as an input, but we left that final step for Go 1.21.</p>\n<p>\\\n<strong>Host dynamic linker.</strong> When programs use <code>cgo</code> on a system using dynamically linked C libraries, the resulting binaries contain the path to the system’s dynamic linker, something like <code>/lib64/ld-linux-x86-64.so.2</code>. If the path is wrong, the binaries don’t run. Typically each operating system/architecture combination has a single correct answer for this path. Unfortunately, musl-based Linuxes like Alpine Linux use a different dynamic linker than glibc-based Linuxes like Ubuntu. To make Go run at all on Alpine Linux, in Go bootstrap process looked like this:</p>\n<p><img src=\"https://cdn.hackernoon.com/images/eQHzh6rz7ETBHLjs0KzCl1Dooqp2-4k23atf.jpeg\" alt=\"\" /></p>\n<p>\\\nThe bootstrap program cmd/dist inspected the local system’s dynamic linker and wrote that value into a new source file compiled along with the rest of the linker sources, effectively hard-coding that default into the linker itself. Then when the linker built a program from a set of compiled packages, it used that default. The result is that a Go toolchain built on Alpine is different from a toolchain built on Ubuntu: the host configuration is a relevant input to the toolchain build. This is a reproducibility problem but also a portability problem: a Go toolchain built on Alpine doesn’t build working binaries or even run on Ubuntu, and vice versa.</p>\n<p>\\\nFor Go 1.20, we took a step toward fixing the reproducibility problem by changing the linker to consult the host configuration when it is running, instead of having a default hard-coded at toolchain build time:</p>\n<p><img src=\"https://cdn.hackernoon.com/images/eQHzh6rz7ETBHLjs0KzCl1Dooqp2-u033a9y.jpeg\" alt=\"\" /></p>\n<p>\\\nThis fixed the portability of the linker binary on Alpine Linux, although not the overall toolchain, since the <code>go</code> command still used package <code>net</code> and therefore <code>cgo</code> and therefore had a dynamic linker reference in its own binary. Just as in the previous section, compiling the <code>go</code> command without <code>cgo</code> enabled would fix this, but we left that change for Go 1.21. (We didn’t feel there was enough time left in the Go 1.20 cycle to test such that change properly.)</p>\n<h3 id=\"reproducibilityingo121\">Reproducibility in Go 1.21</h3>\n<p>For Go 1.21, the goal of perfect reproducibility was in sight, and we took care of the remaining, mostly small, relevant inputs that remained.</p>\n<p>\\\n<strong>Host C toolchain and dynamic linker.</strong> As discussed above, Go 1.20 took important steps toward removing the host C toolchain and dynamic linker as relevant inputs. Go 1.21 completed the removal of these relevant inputs by building the toolchain with <code>cgo</code> disabled. This improved portability of the toolchain too: Go 1.21 is the first Go release where the standard Go toolchain runs unmodified on Alpine Linux systems.</p>\n<p>\\\nRemoving these relevant inputs made it possible to cross-compile a Go toolchain from a different system without any loss in functionality. That in turn improved the supply chain security of the Go toolchain: we can now build Go toolchains for all target systems using a trusted Linux/x86-64 system, instead of needing to arrange a separate trusted system for each target. As a result, Go 1.21 is the first release to include posted binaries for all systems at <a href=\"/dl/\">go.dev/dl/</a>.</p>\n<p>\\\n<strong>Source directory.</strong> Go programs include full paths in the runtime and debugging metadata, so that when a program crashes or is run in a debugger, stack traces include the full path to the source file, not just the name of the file in an unspecified directory. Unfortunately, including the full path makes the directory where the source code is stored a relevant input to the build. To fix this, Go 1.21 changed the release toolchain builds to install commands like the compiler using <code>go install -trimpath</code>, which replaces the source directory with the module path of the code. If a released compiler crashes, the stack trace will print paths like <code>cmd/compile/main.go</code> instead of <code>/home/user/go/src/cmd/compile/main.go</code>. </p>\n<p>\\\nSince the full paths would refer to a directory on a different machine anyway, this rewrite is no loss. On the other hand, for non-release builds, we keep the full path, so that when developers working on the compiler itself cause it to crash, IDEs and other tools reading those crashes can easily find the correct source file.</p>\n<p>\\\n<strong>Host operating system.</strong> Paths on Windows systems are backslash-separated, like <code>cmd\\compile\\main.go</code>. Other systems use forward slashes, like <code>cmd/compile/main.go</code>. Although earlier versions of Go had normalized most of these paths to use forward slashes, one inconsistency had crept back in, causing slightly different toolchain builds on Windows. We found and fixed the bug.</p>\n<p>\\\n<strong>Host architecture.</strong> Go runs on a variety of ARM systems and can emit code using a software library for floating-point math (SWFP) or using hardware floating-point instructions (HWFP). Toolchains defaulting to one mode or the other will necessarily differ. Like we saw with the dynamic linker earlier, the Go bootstrap process inspected the build system to make sure that the resulting toolchain worked on that system. For historical reasons, the rule was “assume SWFP unless the build is running on an ARM system with floating-point hardware”, with cross-compiled toolchains assuming SWFP. </p>\n<p>\\\nThe vast majority of ARM systems today do have floating-point hardware, so this introduced an unnecessary difference between natively compiled and cross-compiled toolchains, and as a further wrinkle, Windows ARM builds always assumed HWFP, making the decision operating system-dependent. We changed the rule to be “assume HWFP unless the build is running on an ARM system without floating-point hardware”. This way, cross-compilation and builds on modern ARM systems produce identical toolchains.</p>\n<p>\\\n<strong>Packaging logic.</strong> All the code to create the actual toolchain archives we post for download lived in a separate Git repository, golang.org/x/build, and the exact details of how archives get packaged does change over time. If you wanted to reproduce those archives, you needed to have the right version of that repository. We removed this relevant input by moving the code to package the archives into the main Go source tree, as <code>cmd/distpack</code>. As of Go 1.21, if you have the sources for a given version of Go, you also have the sources for packaging the archives. The golang.org/x/build repository is no longer a relevant input.</p>\n<p>\\\n<strong>User IDs.</strong> The tar archives we posted for download were built from a distribution written to the file system, and using <code>tar.FileInfoHeader</code> copies the user and group IDs from the file system into the tar file, making the user running the build a relevant input. We changed the archiving code to clear these.</p>\n<p>\\\n<strong>Current time.</strong> Like with user IDs, the tar and zip archives we posted for download had been built by copying the file system modification times into the archives, making the current time a relevant input. We could have cleared the time, but we thought it would look surprising and possibly even break some tools to use the Unix or MS-DOS zero time. Instead, we changed the go/VERSION file stored in the repository to add the time associated with that version:</p>\n<pre><code>$ cat go1.21.0/VERSION\ngo1.21.0\ntime 2023-08-04T20:14:06Z\n$\n</code></pre>\n<p>The packagers now copy the time from the VERSION file when writing files to archives, instead of copying the local file’s modification times.</p>\n<p>\\\n<strong>Cryptographic signing keys.</strong> The Go toolchain for macOS won’t run on end-user systems unless we sign the binaries with an Apple-approved signing key. We use an internal system to get them signed with Google’s signing key, and obviously we cannot share that secret key in order to allow others to reproduce the signed binaries. Instead, we wrote a verifier that can check whether two binaries are identical except for their signatures.</p>\n<p>\\\n<strong>OS-specific packagers.</strong> We use the Xcode tools <code>pkgbuild</code> and <code>productbuild</code> to create the downloadable macOS PKG installer, and we use WiX to create the downloadable Windows MSI installer. We don’t want verifiers to need the same exact versions of those tools, so we took the same approach as for the cryptographic signing keys, writing a verifier that can look inside the packages and check that the toolchain files are exactly as expected.</p>\n<h2 id=\"verifyingthegotoolchains\">Verifying the Go Toolchains</h2>\n<p>It’s not enough to make Go toolchains reproducible once. We want to make sure they stay reproducible, and we want to make sure others can reproduce them easily.</p>\n<p>\\\nTo keep ourselves honest, we now build all Go distributions on both a trusted Linux/x86-64 system and a Windows/x86-64 system. Except for the architecture, the two systems have almost nothing in common. The two systems must produce bit-for-bit identical archives or else we do not proceed with the release.</p>\n<p>\\\nTo allow others to verify that we’re honest, we’ve written and published a verifier, <code>golang.org/x/build/cmd/gorebuild</code>. That program will start with the source code in our Git repository and rebuild the current Go versions, checking that they match the archives posted on <a href=\"/dl/\">go.dev/dl</a>. Most archives are required to match bit-for-bit. As mentioned above, there are three exceptions where a more relaxed check is used:</p>\n<p>\\</p>\n<ul>\n<li>The macOS tar.gz file is expected to differ, but then the verifier compares the contents inside. The rebuilt and posted copies must contain the same files, and all the files must match exactly, except for executable binaries. Executable binaries must match exactly after stripping code signatures.</li>\n</ul>\n<p>\\</p>\n<ul>\n<li>The macOS PKG installer is not rebuilt. Instead, the verifier reads the files inside the PKG installer and checks that they match the macOS tar.gz exactly, again after code signature stripping. In the long term, the PKG creation is trivial enough that it could potentially be added to cmd/distpack, but the verifier would still have to parse the PKG file to run the signature-ignoring code executable comparison.</li>\n</ul>\n<p>\\</p>\n<ul>\n<li>The Windows MSI installer is not rebuilt. Instead, the verifier invokes the Linux program <code>msiextract</code> to extract the files inside and check that they match the rebuilt Windows zip file exactly. In the long term, perhaps the MSI creation could be added to cmd/distpack, and then the verifier could use a bit-for-bit MSI comparison.</li>\n</ul>\n<p>\\\nWe run <code>gorebuild</code> nightly, posting the results at <a href=\"/rebuild\">go.dev/rebuild</a>, and of course anyone else can run it too.</p>\n<h2 id=\"verifyingubuntusgotoolchain\">Verifying Ubuntu’s Go Toolchain</h2>\n<p>The Go toolchain’s easily reproducible builds should mean that the binaries in the toolchains posted on go.dev match the binaries included in other packaging systems, even when those packagers build from source. Even if the packagers have compiled with different configurations or other changes, the easily reproducible builds should still make it easy to reproduce their binaries. To demonstrate this, let’s reproduce the Ubuntu <code>golang-1.21</code> package version <code>1.21.0-1</code> for Linux/x86-64.</p>\n<p>\\\nTo start, we need to download and extract the Ubuntu packages, which are <a href=\"https://linux.die.net/man/1/ar\">ar(1) archives</a> containing zstd-compressed tar archives:</p>\n<pre><code>$ mkdir deb\n$ cd deb\n$ curl -LO http://mirrors.kernel.org/ubuntu/pool/main/g/golang-1.21/golang-1.21-src_1.21.0-1_all.deb\n$ ar xv golang-1.21-src_1.21.0-1_all.deb\nx - debian-binary\nx - control.tar.zst\nx - data.tar.zst\n$ unzstd &lt; data.tar.zst | tar xv\n...\nx ./usr/share/go-1.21/src/archive/tar/common.go\nx ./usr/share/go-1.21/src/archive/tar/example_test.go\nx ./usr/share/go-1.21/src/archive/tar/format.go\nx ./usr/share/go-1.21/src/archive/tar/fuzz_test.go\n...\n$\n</code></pre>\n<p>\\\nThat was the source archive. Now the amd64 binary archive:</p>\n<pre><code>$ rm -f debian-binary *.zst\n$ curl -LO http://mirrors.kernel.org/ubuntu/pool/main/g/golang-1.21/golang-1.21-go_1.21.0-1_amd64.deb\n$ ar xv golang-1.21-src_1.21.0-1_all.deb\nx - debian-binary\nx - control.tar.zst\nx - data.tar.zst\n$ unzstd &lt; data.tar.zst | tar xv | grep -v '/$'\n...\nx ./usr/lib/go-1.21/bin/go\nx ./usr/lib/go-1.21/bin/gofmt\nx ./usr/lib/go-1.21/go.env\nx ./usr/lib/go-1.21/pkg/tool/linux_amd64/addr2line\nx ./usr/lib/go-1.21/pkg/tool/linux_amd64/asm\nx ./usr/lib/go-1.21/pkg/tool/linux_amd64/buildid\n...\n$\n</code></pre>\n<p>\\\nUbuntu splits the normal Go tree into two halves, in /usr/share/go-1.21 and /usr/lib/go-1.21. Let’s put them back together:</p>\n<pre><code>$ mkdir go-ubuntu\n$ cp -R usr/share/go-1.21/* usr/lib/go-1.21/* go-ubuntu\ncp: cannot overwrite directory go-ubuntu/api with non-directory usr/lib/go-1.21/api\ncp: cannot overwrite directory go-ubuntu/misc with non-directory usr/lib/go-1.21/misc\ncp: cannot overwrite directory go-ubuntu/pkg/include with non-directory usr/lib/go-1.21/pkg/include\ncp: cannot overwrite directory go-ubuntu/src with non-directory usr/lib/go-1.21/src\ncp: cannot overwrite directory go-ubuntu/test with non-directory usr/lib/go-1.21/test\n$\n</code></pre>\n<p>\\\nThe errors are complaining about copying symlinks, which we can ignore.</p>\n<p>\\\nNow we need to download and extract the upstream Go sources:</p>\n<pre><code>$ curl -LO https://go.googlesource.com/go/+archive/refs/tags/go1.21.0.tar.gz\n$ mkdir go-clean\n$ cd go-clean\n$ curl -L https://go.googlesource.com/go/+archive/refs/tags/go1.21.0.tar.gz | tar xzv\n...\nx src/archive/tar/common.go\nx src/archive/tar/example_test.go\nx src/archive/tar/format.go\nx src/archive/tar/fuzz_test.go\n...\n$\n</code></pre>\n<p>\\\nTo skip some trial and error, it turns out that Ubuntu builds Go with <code>GO386=softfloat</code>, which forces the use of software floating point when compiling for 32-bit x86, and strips (removes symbol tables from) the resulting ELF binaries. Let’s start with a <code>GO386=softfloat</code> build:</p>\n<pre><code>$ cd src\n$ GOOS=linux GO386=softfloat ./make.bash -distpack\nBuilding Go cmd/dist using /Users/rsc/sdk/go1.17.13. (go1.17.13 darwin/amd64)\nBuilding Go toolchain1 using /Users/rsc/sdk/go1.17.13.\nBuilding Go bootstrap cmd/go (go_bootstrap) using Go toolchain1.\nBuilding Go toolchain2 using go_bootstrap and Go toolchain1.\nBuilding Go toolchain3 using go_bootstrap and Go toolchain2.\nBuilding commands for host, darwin/amd64.\nBuilding packages and commands for target, linux/amd64.\nPackaging archives for linux/amd64.\ndistpack: 818d46ede85682dd go1.21.0.src.tar.gz\ndistpack: 4fcd8651d084a03d go1.21.0.linux-amd64.tar.gz\ndistpack: eab8ed80024f444f v0.0.1-go1.21.0.linux-amd64.zip\ndistpack: 58528cce1848ddf4 v0.0.1-go1.21.0.linux-amd64.mod\ndistpack: d8da1f27296edea4 v0.0.1-go1.21.0.linux-amd64.info\n---\nInstalled Go for linux/amd64 in /Users/rsc/deb/go-clean\nInstalled commands in /Users/rsc/deb/go-clean/bin\n*** You need to add /Users/rsc/deb/go-clean/bin to your PATH.\n$\n</code></pre>\n<p>\\\nThat left the standard package in <code>pkg/distpack/go1.21.0.linux-amd64.tar.gz</code>. Let’s unpack it and strip the binaries to match Ubuntu:</p>\n<pre><code>$ cd ../..\n$ tar xzvf go-clean/pkg/distpack/go1.21.0.linux-amd64.tar.gz\nx go/CONTRIBUTING.md\nx go/LICENSE\nx go/PATENTS\nx go/README.md\nx go/SECURITY.md\nx go/VERSION\n...\n$ elfstrip go/bin/* go/pkg/tool/linux_amd64/*\n$\n</code></pre>\n<p>\\\nNow we can diff the Go toolchain we’ve created on our Mac with the Go toolchain that Ubuntu ships:</p>\n<pre><code>$ diff -r go go-ubuntu\nOnly in go: CONTRIBUTING.md\nOnly in go: LICENSE\nOnly in go: PATENTS\nOnly in go: README.md\nOnly in go: SECURITY.md\nOnly in go: codereview.cfg\nOnly in go: doc\nOnly in go: lib\nBinary files go/misc/chrome/gophertool/gopher.png and go-ubuntu/misc/chrome/gophertool/gopher.png differ\nOnly in go-ubuntu/pkg/tool/linux_amd64: dist\nOnly in go-ubuntu/pkg/tool/linux_amd64: distpack\nOnly in go/src: all.rc\nOnly in go/src: clean.rc\nOnly in go/src: make.rc\nOnly in go/src: run.rc\ndiff -r go/src/syscall/mksyscall.pl go-ubuntu/src/syscall/mksyscall.pl\n1c1\n&lt; #!/usr/bin/env perl\n---\n&gt; #! /usr/bin/perl\n...\n$\n</code></pre>\n<p>We’ve successfully reproduced the Ubuntu package’s executables and identified the complete set of changes that remain:</p>\n<ul>\n<li>Various metadata and supporting files have been deleted.</li>\n</ul>\n<p>\\</p>\n<ul>\n<li>The <code>gopher.png</code> file has been modified. On closer inspection the two are identical except for an embedded timestamp that Ubuntu has updated. Perhaps Ubuntu’s packaging scripts recompressed the png with a tool that rewrites the timestamp even when it cannot improve on the existing compression.</li>\n</ul>\n<p>\\</p>\n<ul>\n<li>The binaries <code>dist</code> and <code>distpack</code>, which are built during bootstrap but not included in standard archives, have been included in the Ubuntu package.</li>\n</ul>\n<p>\\</p>\n<ul>\n<li>The Plan 9 build scripts (<code>*.rc</code>) have been deleted, although the Windows build scripts (<code>*.bat</code>) remain.</li>\n</ul>\n<p>\\</p>\n<ul>\n<li><code>mksyscall.pl</code> and seven other Perl scripts not shown have had their headers changed.</li>\n</ul>\n<p>\\\nNote in particular that we’ve reconstructed the toolchain binaries bit-for-bit: they do not show up in the diff at all. That is, we proved that the Ubuntu Go binaries correspond exactly to the upstream Go sources.</p>\n<p>\\\nEven better, we proved this without using any Ubuntu software at all: these commands were run on a Mac, and <code>unzstd</code> and <code>elfstrip</code> are short Go programs. A sophisticated attacker might insert malicious code into an Ubuntu package by changing the package-creation tools. If they did, reproducing the Go Ubuntu package from clean sources using those malicious tools would still produce bit-for-bit identical copies of the malicious packages. </p>\n<p>\\\nThis attack would be invisible to that kind of rebuild, much like <a href=\"https://dl.acm.org/doi/10.1145/358198.358210\">Ken Thompson’s compiler attack</a>. Verifying the Ubuntu packages using no Ubuntu software at all is a much stronger check. Go’s perfectly reproducible builds, which don’t depend on unindented details like the host operating system, host architecture, and host C toolchain, are what make this stronger check possible.</p>\n<p>\\\n(As an aside for the historical record, Ken Thompson told me once that his attack was in fact detected, because the compiler build stopped being reproducible. It had a bug: a string constant in the backdoor added to the compiler was imperfectly handled and grew by a single NUL byte each time the compiler compiled itself. Eventually someone noticed the non-reproducible build and tried to find the cause by compiling to assembly. The compiler’s backdoor did not reproduce itself into assembly output at all, so assembling that output removed the backdoor.)</p>\n<h2 id=\"conclusion\">Conclusion</h2>\n<p>Reproducible builds are an important tool for strengthening the open-source supply chain. Frameworks like <a href=\"https://slsa.dev/\">SLSA</a> focus on provenance and a software chain of custody that can be used to inform decisions about trust. Reproducible builds complement that approach by providing a way to verify that the trust is well-placed.</p>\n<p>\\\nPerfect reproducibility (when the source files are the build’s only relevant input) is only possible for programs that build themselves, like compiler toolchains. It is a lofty but worthwhile goal precisely because self-hosting compiler toolchains are otherwise quite difficult to verify. Go’s perfect reproducibility means that, assuming packagers don’t modify the source code, every repackaging of Go 1.21.0 for Linux/x86-64 (substitute your favorite system) in any form should be distributing exactly the same binaries, even when they all build from source. We’ve seen that this is not quite true for Ubuntu Linux, but perfect reproducibility still lets us reproduce the Ubuntu packaging using a very different, non-Ubuntu system.</p>\n<p>\\\nIdeally all open source software distributed in binary form would have easy-to-reproduce builds. In practice, as we’ve seen in this post, it is very easy for unintended inputs to leak into builds. For Go programs that don’t need <code>cgo</code>, a reproducible build is as simple as compiling with <code>CGO_ENABLED=0 go build -trimpath</code>. Disabling <code>cgo</code> removes the host C toolchain as a relevant input, and <code>-trimpath</code> removes the current directory. If your program does need <code>cgo</code>, you need to arrange for a specific host C toolchain version before running <code>go build</code>, such as by running the build in a specific virtual machine or container image.</p>\n<p>\\\nMoving beyond Go, the <a href=\"https://reproducible-builds.org/\">Reproducible Builds</a> project aims to improve reproducibility of all open source and is a good starting point for more information about making your own software builds reproducible.</p>\n<hr />\n<p><em>Russ Cox</em></p>\n<p>\\\n<em>Photo by <a href=\"https://unsplash.com/@a_pudov?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash\">Alex Pudov</a> on <a href=\"https://unsplash.com/photos/a-close-up-of-a-chain-with-a-blurry-background-cmrcu5Gb9ko?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash\">Unsplash</a></em></p>\n<p>\\\n<em>This article is available on&nbsp;<strong><a href=\"https://go.dev/blog/rebuild\">The Go Blog</a></strong>&nbsp;under a CC BY 4.0 DEED license.</em></p>",
          "content:encodedSnippet": "One of the key benefits of open-source software is that anyone can read the source code and inspect what it does. And yet most software, even open-source software, is downloaded in the form of compiled binaries, which are much more difficult to inspect. If an attacker wanted to run a supply chain attack on an open-source project, the least visible way would be to replace the binaries being served while leaving the source code unmodified.\n\\\nThe best way to address this kind of attack is to make open-source software builds reproducible, meaning that a build that starts with the same sources produces the same outputs every time it runs. That way, anyone can verify that posted binaries are free of hidden changes by building from authentic sources and checking that the rebuilt binaries are bit-for-bit identical to the posted binaries. That approach proves the binaries have no backdoors or other changes not present in the source code, without having to disassemble or look inside them at all. Since anyone can verify the binaries, independent groups can easily detect and report supply chain attacks.\n\\\nAs supply chain security becomes more important, so do reproducible builds, because they provide a simple way to verify the posted binaries for open-source projects.\n\\\nGo 1.21.0 is the first Go toolchain with perfectly reproducible builds. Earlier toolchains were possible to reproduce, but only with significant effort, and probably no one did: they just trusted that the binaries posted on go.dev/dl were the correct ones. Now it’s easy to “trust but verify.”\n\\\nThis post explains what goes into making builds reproducible, examines the many changes we had to make to Go to make Go toolchains reproducible, and then demonstrates one of the benefits of reproducibility by verifying the Ubuntu package for Go 1.21.0.\nMaking a Build Reproducible\nComputers are generally deterministic, so you might think all builds would be equally reproducible. That’s only true from a certain point of view. Let’s call a piece of information a relevant input when the output of a build can change depending on that input. A build is reproducible if it can be repeated with all the same relevant inputs. Unfortunately, lots of build tools turn out to incorporate inputs that we would usually not realize are relevant and that might be difficult to recreate or provide as input. Let’s call an input an unintentional input when it turns out to be relevant but we didn’t mean it to be.\n\\\nThe most common unintentional input in build systems is the current time. If a build writes an executable to disk, the file system records the current time as the executable’s modification time. If the build then packages that file using a tool like “tar” or “zip”, the modification time is written into the archive. We certainly didn’t want our build to change based on the current time, but it does. So the current time turns out to be an unintentional input to the build. Worse, most programs don’t let you provide the current time as an input, so there is no way to repeat this build. To fix this, we might set the time stamps on created files to Unix time 0 or to a specific time read from one of the build’s source files. That way, the current time is no longer a relevant input to the build.\n\\\nCommon relevant inputs to a build include:\nthe specific version of the source code to build;\nthe specific versions of dependencies that will be included in the build;\nthe operating system running the build, which may affect path names in the resulting binaries;\nthe architecture of the CPU on the build system, which may affect which optimizations the compiler uses or the layout of certain data structures;\nthe compiler version being used, as well as compiler options passed to it, which affect how the code is compiled;\nthe name of the directory containing the source code, which may appear in debug information;\nthe user name, group name, uid, and gid of the account running the build, which may appear in file metadata in an archive;\nand many more.\n\\\nTo have a reproducible build, every relevant input must be configurable in the build, and then the binaries must be posted alongside an explicit configuration listing every relevant input. If you’ve done that, you have a reproducible build. Congratulations!\n\\\nWe’re not done, though. If the binaries can only be reproduced if you first find a computer with the right architecture, install a specific operating system version, compiler version, put the source code in the right directory, set your user identity correctly, and so on, that may be too much work in practice for anyone to bother.\n\\\nWe want builds to be not just reproducible but easy to reproduce. To do that, we need to identify relevant inputs and then, instead of documenting them, eliminate them. The build obviously has to depend on the source code being built, but everything else can be eliminated. When a build’s only relevant input is its source code, let’s call that perfectly reproducible.\nPerfectly Reproducible Builds for Go\nAs of Go 1.21, the Go toolchain is perfectly reproducible: its only relevant input is the source code for that build. We can build a specific toolchain (say, Go for Linux/x86-64) on a Linux/x86-64 host, or a Windows/ARM64 host, or a FreeBSD/386 host, or any other host that supports Go, and we can use any Go bootstrap compiler, including bootstrapping all the way back to Go 1.4’s C implementation, and we can vary any other details. None of that changes the toolchains that are built. If we start with the same toolchain source code, we will get the exact same toolchain binaries out.\n\\\nThis perfect reproducibility is the culmination of efforts dating back originally to Go 1.10, although most of the effort was concentrated in Go 1.20 and Go 1.21. This section highlights some of the most interesting relevant inputs that we eliminated.\nReproducibility in Go 1.10\nGo 1.10 introduced a content-aware build cache that decides whether targets are up-to-date based on a fingerprint of the build inputs instead of file modification times. Because the toolchain itself is one of those build inputs, and because Go is written in Go, the bootstrap process would only converge if the toolchain build on a single machine was reproducible. The overall toolchain build looks like this:\n\n\\\nWe start by building the sources for the current Go toolchain using an earlier Go version, the bootstrap toolchain (Go 1.10 used Go 1.4, written in C; Go 1.21 uses Go 1.17). That produces “toolchain1”, which we use to build everything again, producing “toolchain2”, which we use to build everything again, producing “toolchain3”.\n\\\nToolchain1 and toolchain2 have been built from the same sources but with different Go implementations (compilers and libraries), so their binaries are certain to be different. However, if both Go implementations are non-buggy, correct implementations, toolchain1 and toolchain2 should behave exactly the same. In particular, when presented with the Go 1.X sources, toolchain1’s output (toolchain2) and toolchain2’s output (toolchain3) should be identical, meaning toolchain2 and toolchain3 should be identical.\n\\\nAt least, that’s the idea. Making that true in practice required removing a couple unintentional inputs:\nRandomness. Map iteration and running work in multiple goroutines serialized with locks both introduce randomness in the order that results may be generated. This randomness can make the toolchain produce one of several different possible outputs each time it runs. To make the build reproducible, we had to find each of these and sort the relevant list of items before using it to generate output.\n\\\nBootstrap Libraries. Any library used by the compiler that can choose from multiple different correct outputs might change its output from one Go version to the next. If that library output change causes a compiler output change, then toolchain1 and toolchain2 will not be semantically identical, and toolchain2 and toolchain3 will not be bit-for-bit identical.\n\\\nThe canonical example is the sort package, which can place elements that compare equal in any order it likes. A register allocator might sort to prioritize commonly used variables, and the linker sorts symbols in the data section by size. To completely eliminate any effect from the sorting algorithm, the comparison function used must never report two distinct elements as equal. In practice, this invariant turned out to be too onerous to impose on every use of sort in the toolchain, so instead we arranged to copy the Go 1.X sort package into the source tree that is presented to the bootstrap compiler. That way, the compiler uses the same sort algorithm when using the bootstrap toolchain as it does when built with itself.\n\\\nAnother package we had to copy was compress/zlib, because the linker writes compressed debug information, and optimizations to compression libraries can change the exact output. Over time, we’ve added other packages to that list too. This approach has the added benefit of allowing the Go 1.X compiler to use new APIs added to those packages immediately, at the cost that those packages must be written to compile with older versions of Go.\nReproducibility in Go 1.20\nWork on Go 1.20 prepared for both easy reproducible builds and toolchain management by removing two more relevant inputs from the toolchain build.\n\\\nHost C toolchain. Some Go packages, most notably net, default to using cgo on most operating systems. In some cases, such as macOS and Windows, invoking system DLLs using cgo is the only reliable way to resolve host names. When we use cgo, though, we invoke the host C toolchain (meaning a specific C compiler and C library), and different toolchains have different compilation algorithms and library code, producing different outputs. The build graph for a cgo package looks like:\n\n\\\nThe host C toolchain is therefore a relevant input to the pre-compiled net.a that ships with the toolchain. For Go 1.20, we decided to fix this by removing net.a from the toolchain. That is, Go 1.20 stopped shipping pre-compiled packages to seed the build cache with. Now, the first time a program uses package net, the Go toolchain compiles it using the local system’s C toolchain and caches that result. \n\\\nIn addition to removing a relevant input from toolchain builds and making toolchain downloads smaller, not shipping pre-compiled packages also makes toolchain downloads more portable. If we build package net on one system with one C toolchain and then compile other parts of the program on a different system with a different C toolchain, in general there is no guarantee that the two parts can be linked together.\n\\\nOne reason we shipped the pre-compiled net package in the first place was to allow building programs that used package net even on systems without a C toolchain installed. If there’s no pre-compiled package, what happens on those systems? The answer varies by operating system, but in all cases we arranged for the Go toolchain to continue to work well for building pure Go programs without a host C toolchain.\n\\\n\nOn macOS, we rewrote package net using the underlying mechanisms that cgo would use, without any actual C code. This avoids invoking the host C toolchain but still emits a binary that refers to the required system DLLs. This approach is only possible because every Mac has the same dynamic libraries installed. Making the non-cgo macOS package net use the system DLLs also meant that cross-compiled macOS executables now use the system DLLs for network access, resolving a long-standing feature request.\n\\\n\nOn Windows, package net already made direct use of DLLs without C code, so nothing needed to be changed.\n\\\n\nOn Unix systems, we cannot assume a specific DLL interface to network code, but the pure Go version works fine for systems that use typical IP and DNS setups. Also, it is much easier to install a C toolchain on Unix systems than it is on macOS and especially Windows. We changed the go command to enable or disable cgo automatically based on whether the system has a C toolchain installed. Unix systems without a C toolchain fall back to the pure Go version of package net, and in the rare cases where that’s not good enough, they can install a C toolchain.\n\\\nHaving dropped the pre-compiled packages, the only part of the Go toolchain that still depended on the host C toolchain was binaries built using package net, specifically the go command. With the macOS improvements, it was now viable to build those commands with cgo disabled, completely removing the host C toolchain as an input, but we left that final step for Go 1.21.\n\\\nHost dynamic linker. When programs use cgo on a system using dynamically linked C libraries, the resulting binaries contain the path to the system’s dynamic linker, something like /lib64/ld-linux-x86-64.so.2. If the path is wrong, the binaries don’t run. Typically each operating system/architecture combination has a single correct answer for this path. Unfortunately, musl-based Linuxes like Alpine Linux use a different dynamic linker than glibc-based Linuxes like Ubuntu. To make Go run at all on Alpine Linux, in Go bootstrap process looked like this:\n\n\\\nThe bootstrap program cmd/dist inspected the local system’s dynamic linker and wrote that value into a new source file compiled along with the rest of the linker sources, effectively hard-coding that default into the linker itself. Then when the linker built a program from a set of compiled packages, it used that default. The result is that a Go toolchain built on Alpine is different from a toolchain built on Ubuntu: the host configuration is a relevant input to the toolchain build. This is a reproducibility problem but also a portability problem: a Go toolchain built on Alpine doesn’t build working binaries or even run on Ubuntu, and vice versa.\n\\\nFor Go 1.20, we took a step toward fixing the reproducibility problem by changing the linker to consult the host configuration when it is running, instead of having a default hard-coded at toolchain build time:\n\n\\\nThis fixed the portability of the linker binary on Alpine Linux, although not the overall toolchain, since the go command still used package net and therefore cgo and therefore had a dynamic linker reference in its own binary. Just as in the previous section, compiling the go command without cgo enabled would fix this, but we left that change for Go 1.21. (We didn’t feel there was enough time left in the Go 1.20 cycle to test such that change properly.)\nReproducibility in Go 1.21\nFor Go 1.21, the goal of perfect reproducibility was in sight, and we took care of the remaining, mostly small, relevant inputs that remained.\n\\\nHost C toolchain and dynamic linker. As discussed above, Go 1.20 took important steps toward removing the host C toolchain and dynamic linker as relevant inputs. Go 1.21 completed the removal of these relevant inputs by building the toolchain with cgo disabled. This improved portability of the toolchain too: Go 1.21 is the first Go release where the standard Go toolchain runs unmodified on Alpine Linux systems.\n\\\nRemoving these relevant inputs made it possible to cross-compile a Go toolchain from a different system without any loss in functionality. That in turn improved the supply chain security of the Go toolchain: we can now build Go toolchains for all target systems using a trusted Linux/x86-64 system, instead of needing to arrange a separate trusted system for each target. As a result, Go 1.21 is the first release to include posted binaries for all systems at go.dev/dl/.\n\\\nSource directory. Go programs include full paths in the runtime and debugging metadata, so that when a program crashes or is run in a debugger, stack traces include the full path to the source file, not just the name of the file in an unspecified directory. Unfortunately, including the full path makes the directory where the source code is stored a relevant input to the build. To fix this, Go 1.21 changed the release toolchain builds to install commands like the compiler using go install -trimpath, which replaces the source directory with the module path of the code. If a released compiler crashes, the stack trace will print paths like cmd/compile/main.go instead of /home/user/go/src/cmd/compile/main.go. \n\\\nSince the full paths would refer to a directory on a different machine anyway, this rewrite is no loss. On the other hand, for non-release builds, we keep the full path, so that when developers working on the compiler itself cause it to crash, IDEs and other tools reading those crashes can easily find the correct source file.\n\\\nHost operating system. Paths on Windows systems are backslash-separated, like cmd\\compile\\main.go. Other systems use forward slashes, like cmd/compile/main.go. Although earlier versions of Go had normalized most of these paths to use forward slashes, one inconsistency had crept back in, causing slightly different toolchain builds on Windows. We found and fixed the bug.\n\\\nHost architecture. Go runs on a variety of ARM systems and can emit code using a software library for floating-point math (SWFP) or using hardware floating-point instructions (HWFP). Toolchains defaulting to one mode or the other will necessarily differ. Like we saw with the dynamic linker earlier, the Go bootstrap process inspected the build system to make sure that the resulting toolchain worked on that system. For historical reasons, the rule was “assume SWFP unless the build is running on an ARM system with floating-point hardware”, with cross-compiled toolchains assuming SWFP. \n\\\nThe vast majority of ARM systems today do have floating-point hardware, so this introduced an unnecessary difference between natively compiled and cross-compiled toolchains, and as a further wrinkle, Windows ARM builds always assumed HWFP, making the decision operating system-dependent. We changed the rule to be “assume HWFP unless the build is running on an ARM system without floating-point hardware”. This way, cross-compilation and builds on modern ARM systems produce identical toolchains.\n\\\nPackaging logic. All the code to create the actual toolchain archives we post for download lived in a separate Git repository, golang.org/x/build, and the exact details of how archives get packaged does change over time. If you wanted to reproduce those archives, you needed to have the right version of that repository. We removed this relevant input by moving the code to package the archives into the main Go source tree, as cmd/distpack. As of Go 1.21, if you have the sources for a given version of Go, you also have the sources for packaging the archives. The golang.org/x/build repository is no longer a relevant input.\n\\\nUser IDs. The tar archives we posted for download were built from a distribution written to the file system, and using tar.FileInfoHeader copies the user and group IDs from the file system into the tar file, making the user running the build a relevant input. We changed the archiving code to clear these.\n\\\nCurrent time. Like with user IDs, the tar and zip archives we posted for download had been built by copying the file system modification times into the archives, making the current time a relevant input. We could have cleared the time, but we thought it would look surprising and possibly even break some tools to use the Unix or MS-DOS zero time. Instead, we changed the go/VERSION file stored in the repository to add the time associated with that version:\n$ cat go1.21.0/VERSION\ngo1.21.0\ntime 2023-08-04T20:14:06Z\n$\n\nThe packagers now copy the time from the VERSION file when writing files to archives, instead of copying the local file’s modification times.\n\\\nCryptographic signing keys. The Go toolchain for macOS won’t run on end-user systems unless we sign the binaries with an Apple-approved signing key. We use an internal system to get them signed with Google’s signing key, and obviously we cannot share that secret key in order to allow others to reproduce the signed binaries. Instead, we wrote a verifier that can check whether two binaries are identical except for their signatures.\n\\\nOS-specific packagers. We use the Xcode tools pkgbuild and productbuild to create the downloadable macOS PKG installer, and we use WiX to create the downloadable Windows MSI installer. We don’t want verifiers to need the same exact versions of those tools, so we took the same approach as for the cryptographic signing keys, writing a verifier that can look inside the packages and check that the toolchain files are exactly as expected.\nVerifying the Go Toolchains\nIt’s not enough to make Go toolchains reproducible once. We want to make sure they stay reproducible, and we want to make sure others can reproduce them easily.\n\\\nTo keep ourselves honest, we now build all Go distributions on both a trusted Linux/x86-64 system and a Windows/x86-64 system. Except for the architecture, the two systems have almost nothing in common. The two systems must produce bit-for-bit identical archives or else we do not proceed with the release.\n\\\nTo allow others to verify that we’re honest, we’ve written and published a verifier, golang.org/x/build/cmd/gorebuild. That program will start with the source code in our Git repository and rebuild the current Go versions, checking that they match the archives posted on go.dev/dl. Most archives are required to match bit-for-bit. As mentioned above, there are three exceptions where a more relaxed check is used:\n\\\n\nThe macOS tar.gz file is expected to differ, but then the verifier compares the contents inside. The rebuilt and posted copies must contain the same files, and all the files must match exactly, except for executable binaries. Executable binaries must match exactly after stripping code signatures.\n\\\n\nThe macOS PKG installer is not rebuilt. Instead, the verifier reads the files inside the PKG installer and checks that they match the macOS tar.gz exactly, again after code signature stripping. In the long term, the PKG creation is trivial enough that it could potentially be added to cmd/distpack, but the verifier would still have to parse the PKG file to run the signature-ignoring code executable comparison.\n\\\n\nThe Windows MSI installer is not rebuilt. Instead, the verifier invokes the Linux program msiextract to extract the files inside and check that they match the rebuilt Windows zip file exactly. In the long term, perhaps the MSI creation could be added to cmd/distpack, and then the verifier could use a bit-for-bit MSI comparison.\n\\\nWe run gorebuild nightly, posting the results at go.dev/rebuild, and of course anyone else can run it too.\nVerifying Ubuntu’s Go Toolchain\nThe Go toolchain’s easily reproducible builds should mean that the binaries in the toolchains posted on go.dev match the binaries included in other packaging systems, even when those packagers build from source. Even if the packagers have compiled with different configurations or other changes, the easily reproducible builds should still make it easy to reproduce their binaries. To demonstrate this, let’s reproduce the Ubuntu golang-1.21 package version 1.21.0-1 for Linux/x86-64.\n\\\nTo start, we need to download and extract the Ubuntu packages, which are ar(1) archives containing zstd-compressed tar archives:\n$ mkdir deb\n$ cd deb\n$ curl -LO http://mirrors.kernel.org/ubuntu/pool/main/g/golang-1.21/golang-1.21-src_1.21.0-1_all.deb\n$ ar xv golang-1.21-src_1.21.0-1_all.deb\nx - debian-binary\nx - control.tar.zst\nx - data.tar.zst\n$ unzstd < data.tar.zst | tar xv\n...\nx ./usr/share/go-1.21/src/archive/tar/common.go\nx ./usr/share/go-1.21/src/archive/tar/example_test.go\nx ./usr/share/go-1.21/src/archive/tar/format.go\nx ./usr/share/go-1.21/src/archive/tar/fuzz_test.go\n...\n$\n\n\\\nThat was the source archive. Now the amd64 binary archive:\n$ rm -f debian-binary *.zst\n$ curl -LO http://mirrors.kernel.org/ubuntu/pool/main/g/golang-1.21/golang-1.21-go_1.21.0-1_amd64.deb\n$ ar xv golang-1.21-src_1.21.0-1_all.deb\nx - debian-binary\nx - control.tar.zst\nx - data.tar.zst\n$ unzstd < data.tar.zst | tar xv | grep -v '/$'\n...\nx ./usr/lib/go-1.21/bin/go\nx ./usr/lib/go-1.21/bin/gofmt\nx ./usr/lib/go-1.21/go.env\nx ./usr/lib/go-1.21/pkg/tool/linux_amd64/addr2line\nx ./usr/lib/go-1.21/pkg/tool/linux_amd64/asm\nx ./usr/lib/go-1.21/pkg/tool/linux_amd64/buildid\n...\n$\n\n\\\nUbuntu splits the normal Go tree into two halves, in /usr/share/go-1.21 and /usr/lib/go-1.21. Let’s put them back together:\n$ mkdir go-ubuntu\n$ cp -R usr/share/go-1.21/* usr/lib/go-1.21/* go-ubuntu\ncp: cannot overwrite directory go-ubuntu/api with non-directory usr/lib/go-1.21/api\ncp: cannot overwrite directory go-ubuntu/misc with non-directory usr/lib/go-1.21/misc\ncp: cannot overwrite directory go-ubuntu/pkg/include with non-directory usr/lib/go-1.21/pkg/include\ncp: cannot overwrite directory go-ubuntu/src with non-directory usr/lib/go-1.21/src\ncp: cannot overwrite directory go-ubuntu/test with non-directory usr/lib/go-1.21/test\n$\n\n\\\nThe errors are complaining about copying symlinks, which we can ignore.\n\\\nNow we need to download and extract the upstream Go sources:\n$ curl -LO https://go.googlesource.com/go/+archive/refs/tags/go1.21.0.tar.gz\n$ mkdir go-clean\n$ cd go-clean\n$ curl -L https://go.googlesource.com/go/+archive/refs/tags/go1.21.0.tar.gz | tar xzv\n...\nx src/archive/tar/common.go\nx src/archive/tar/example_test.go\nx src/archive/tar/format.go\nx src/archive/tar/fuzz_test.go\n...\n$\n\n\\\nTo skip some trial and error, it turns out that Ubuntu builds Go with GO386=softfloat, which forces the use of software floating point when compiling for 32-bit x86, and strips (removes symbol tables from) the resulting ELF binaries. Let’s start with a GO386=softfloat build:\n$ cd src\n$ GOOS=linux GO386=softfloat ./make.bash -distpack\nBuilding Go cmd/dist using /Users/rsc/sdk/go1.17.13. (go1.17.13 darwin/amd64)\nBuilding Go toolchain1 using /Users/rsc/sdk/go1.17.13.\nBuilding Go bootstrap cmd/go (go_bootstrap) using Go toolchain1.\nBuilding Go toolchain2 using go_bootstrap and Go toolchain1.\nBuilding Go toolchain3 using go_bootstrap and Go toolchain2.\nBuilding commands for host, darwin/amd64.\nBuilding packages and commands for target, linux/amd64.\nPackaging archives for linux/amd64.\ndistpack: 818d46ede85682dd go1.21.0.src.tar.gz\ndistpack: 4fcd8651d084a03d go1.21.0.linux-amd64.tar.gz\ndistpack: eab8ed80024f444f v0.0.1-go1.21.0.linux-amd64.zip\ndistpack: 58528cce1848ddf4 v0.0.1-go1.21.0.linux-amd64.mod\ndistpack: d8da1f27296edea4 v0.0.1-go1.21.0.linux-amd64.info\n---\nInstalled Go for linux/amd64 in /Users/rsc/deb/go-clean\nInstalled commands in /Users/rsc/deb/go-clean/bin\n*** You need to add /Users/rsc/deb/go-clean/bin to your PATH.\n$\n\n\\\nThat left the standard package in pkg/distpack/go1.21.0.linux-amd64.tar.gz. Let’s unpack it and strip the binaries to match Ubuntu:\n$ cd ../..\n$ tar xzvf go-clean/pkg/distpack/go1.21.0.linux-amd64.tar.gz\nx go/CONTRIBUTING.md\nx go/LICENSE\nx go/PATENTS\nx go/README.md\nx go/SECURITY.md\nx go/VERSION\n...\n$ elfstrip go/bin/* go/pkg/tool/linux_amd64/*\n$\n\n\\\nNow we can diff the Go toolchain we’ve created on our Mac with the Go toolchain that Ubuntu ships:\n$ diff -r go go-ubuntu\nOnly in go: CONTRIBUTING.md\nOnly in go: LICENSE\nOnly in go: PATENTS\nOnly in go: README.md\nOnly in go: SECURITY.md\nOnly in go: codereview.cfg\nOnly in go: doc\nOnly in go: lib\nBinary files go/misc/chrome/gophertool/gopher.png and go-ubuntu/misc/chrome/gophertool/gopher.png differ\nOnly in go-ubuntu/pkg/tool/linux_amd64: dist\nOnly in go-ubuntu/pkg/tool/linux_amd64: distpack\nOnly in go/src: all.rc\nOnly in go/src: clean.rc\nOnly in go/src: make.rc\nOnly in go/src: run.rc\ndiff -r go/src/syscall/mksyscall.pl go-ubuntu/src/syscall/mksyscall.pl\n1c1\n< #!/usr/bin/env perl\n---\n> #! /usr/bin/perl\n...\n$\n\nWe’ve successfully reproduced the Ubuntu package’s executables and identified the complete set of changes that remain:\nVarious metadata and supporting files have been deleted.\n\\\n\nThe gopher.png file has been modified. On closer inspection the two are identical except for an embedded timestamp that Ubuntu has updated. Perhaps Ubuntu’s packaging scripts recompressed the png with a tool that rewrites the timestamp even when it cannot improve on the existing compression.\n\\\n\nThe binaries dist and distpack, which are built during bootstrap but not included in standard archives, have been included in the Ubuntu package.\n\\\n\nThe Plan 9 build scripts (*.rc) have been deleted, although the Windows build scripts (*.bat) remain.\n\\\n\nmksyscall.pl and seven other Perl scripts not shown have had their headers changed.\n\\\nNote in particular that we’ve reconstructed the toolchain binaries bit-for-bit: they do not show up in the diff at all. That is, we proved that the Ubuntu Go binaries correspond exactly to the upstream Go sources.\n\\\nEven better, we proved this without using any Ubuntu software at all: these commands were run on a Mac, and unzstd and elfstrip are short Go programs. A sophisticated attacker might insert malicious code into an Ubuntu package by changing the package-creation tools. If they did, reproducing the Go Ubuntu package from clean sources using those malicious tools would still produce bit-for-bit identical copies of the malicious packages. \n\\\nThis attack would be invisible to that kind of rebuild, much like Ken Thompson’s compiler attack. Verifying the Ubuntu packages using no Ubuntu software at all is a much stronger check. Go’s perfectly reproducible builds, which don’t depend on unindented details like the host operating system, host architecture, and host C toolchain, are what make this stronger check possible.\n\\\n(As an aside for the historical record, Ken Thompson told me once that his attack was in fact detected, because the compiler build stopped being reproducible. It had a bug: a string constant in the backdoor added to the compiler was imperfectly handled and grew by a single NUL byte each time the compiler compiled itself. Eventually someone noticed the non-reproducible build and tried to find the cause by compiling to assembly. The compiler’s backdoor did not reproduce itself into assembly output at all, so assembling that output removed the backdoor.)\nConclusion\nReproducible builds are an important tool for strengthening the open-source supply chain. Frameworks like SLSA focus on provenance and a software chain of custody that can be used to inform decisions about trust. Reproducible builds complement that approach by providing a way to verify that the trust is well-placed.\n\\\nPerfect reproducibility (when the source files are the build’s only relevant input) is only possible for programs that build themselves, like compiler toolchains. It is a lofty but worthwhile goal precisely because self-hosting compiler toolchains are otherwise quite difficult to verify. Go’s perfect reproducibility means that, assuming packagers don’t modify the source code, every repackaging of Go 1.21.0 for Linux/x86-64 (substitute your favorite system) in any form should be distributing exactly the same binaries, even when they all build from source. We’ve seen that this is not quite true for Ubuntu Linux, but perfect reproducibility still lets us reproduce the Ubuntu packaging using a very different, non-Ubuntu system.\n\\\nIdeally all open source software distributed in binary form would have easy-to-reproduce builds. In practice, as we’ve seen in this post, it is very easy for unintended inputs to leak into builds. For Go programs that don’t need cgo, a reproducible build is as simple as compiling with CGO_ENABLED=0 go build -trimpath. Disabling cgo removes the host C toolchain as a relevant input, and -trimpath removes the current directory. If your program does need cgo, you need to arrange for a specific host C toolchain version before running go build, such as by running the build in a specific virtual machine or container image.\n\\\nMoving beyond Go, the Reproducible Builds project aims to improve reproducibility of all open source and is a good starting point for more information about making your own software builds reproducible.\nRuss Cox\n\\\nPhoto by Alex Pudov on Unsplash\n\\\nThis article is available on The Go Blog under a CC BY 4.0 DEED license.",
          "dc:creator": "Go [Technical Documentation]",
          "content": "This post explains what goes into making builds reproducible, and then demonstrates one of the benefits of reproducibility by verifying the Ubuntu package for Go 1.21.0.",
          "contentSnippet": "This post explains what goes into making builds reproducible, and then demonstrates one of the benefits of reproducibility by verifying the Ubuntu package for Go 1.21.0.",
          "guid": "https://hackernoon.com/reproducible-go-toolchains-what-you-need-to-know?source=rss",
          "categories": [
            "go",
            "golang",
            "go-toolchains",
            "what-are-go-tool-chains",
            "reproducible-builds",
            "reproducibility-in-go",
            "hackernoon-top-story",
            "host-dynamic-linker"
          ],
          "isoDate": "2025-08-03T12:00:07.000Z"
        }
      }
    ],
    "Set and Normalize Fields": [
      {
        "json": {
          "title": "The Nintendo Switch 2’s Biggest Problem Is Already Storage",
          "content": "In 2025, 256 gigabytes just isn’t enough, and tacking on more storage isn’t as easy as it sounds.",
          "date": "2025-08-03T13:00:00.000Z",
          "link": "https://www.wired.com/story/nintendo-switch-2-biggest-problem-is-already-storage/",
          "categories": "[\"Gear\",\"Gear / Gear News and Events\",\"Gear / Products / Gaming\",\"Gear / Trends\"]"
        }
      },
      {
        "json": {
          "title": "19 Best Barefoot Shoes for Running or Walking (2025), Tested and Reviewed",
          "content": "Our favorite zero-drop, minimalist footwear will let you feel the ground beneath your feet.",
          "date": "2025-08-03T12:00:00.000Z",
          "link": "https://www.wired.com/gallery/best-barefoot-shoes/",
          "categories": "[\"Gear\",\"Gear / Buying Guides\",\"Gear / Products / Health and Fitness\",\"Gear / Products / Outdoor\"]"
        }
      },
      {
        "json": {
          "title": "What Happens to Your Data If You Stop Paying for Cloud Storage?",
          "content": "Hit by subscription fatigue? Here’s what happens to your files and photos if you cancel your paid storage plan.",
          "date": "2025-08-03T11:30:00.000Z",
          "link": "https://www.wired.com/story/what-happens-to-your-data-if-you-stop-paying-for-cloud-storage/",
          "categories": "[\"Gear\",\"Gear / Gear News and Events\"]"
        }
      },
      {
        "json": {
          "title": "Efforts to Ground Physics in Math Are Opening the Secrets of Time",
          "content": "By proving how individual molecules create the complex motion of fluids, three mathematicians have illuminated why time can’t flow in reverse.",
          "date": "2025-08-03T11:00:00.000Z",
          "link": "https://www.wired.com/story/efforts-to-ground-physics-in-math-are-opening-the-secrets-of-time/",
          "categories": "[\"Science\",\"Science / Physics and Math\"]"
        }
      },
      {
        "json": {
          "title": "12 Best Outdoor Security Cameras (2025): Battery-Powered, LTE, No Subscription",
          "content": "These weatherproof outdoor security cams keep a watchful eye on your property while you get on with life. Our list includes battery-powered and LTE devices and cameras that need no subscription.",
          "date": "2025-08-03T10:30:00.000Z",
          "link": "https://www.wired.com/gallery/best-outdoor-security-cameras/",
          "categories": "[\"Gear\",\"Gear / Buying Guides\",\"Gear / Products / Smart Home\",\"Gear / Products / Home\"]"
        }
      },
      {
        "json": {
          "title": "How to Clean Your Mattress (2025)",
          "content": "From barf to blood, your stained mattress isn’t necessarily beyond repair. Here’s how to salvage your investment from every worst-case scenario.",
          "date": "2025-08-03T10:09:00.000Z",
          "link": "https://www.wired.com/story/how-to-clean-your-mattress/",
          "categories": "[\"Gear\",\"Gear / How To and Advice\",\"Gear / Products / Sleep\"]"
        }
      },
      {
        "json": {
          "title": "Apple might be building its own AI ‘answer engine’",
          "content": "Apple is reportedly working to create a lightweight competitor to ChatGPT.",
          "date": "2025-08-03T21:49:00.000Z",
          "link": "https://techcrunch.com/2025/08/03/apple-might-be-building-its-own-ai-answer-engine/",
          "categories": "[\"AI\",\"Apple\",\"siri\"]"
        }
      },
      {
        "json": {
          "title": "Mastercard denies pressuring game platforms, Valve tells a different story",
          "content": "Mastercard seemingly denied playing a role in a recent marketplace crackdown on games with adult content, while Valve says the pressure was indirect.",
          "date": "2025-08-03T21:29:14.000Z",
          "link": "https://techcrunch.com/2025/08/03/mastercard-denies-pressuring-game-platforms-valve-tells-a-different-story/",
          "categories": "[\"Gaming\",\"Government & Policy\",\"Media & Entertainment\",\"itch.io\",\"mastercard\",\"Steam\"]"
        }
      },
      {
        "json": {
          "title": "SAP is acquiring SmartRecruiters",
          "content": "SAP has reached an agreement to acquire SmartRecruiters, with SmartRecruiters' software complementing SAP's existing HR tools.",
          "date": "2025-08-03T17:12:51.000Z",
          "link": "https://techcrunch.com/2025/08/03/sap-is-acquiring-smartrecruiters/",
          "categories": "[\"Enterprise\",\"sap\",\"smartrecruiters\"]"
        }
      },
      {
        "json": {
          "title": "Inside OpenAI’s quest to make AI do anything for you",
          "content": "OpenAI developed the first AI reasoning model less than a year ago, but the technology has shifted Silicon Valley's focus to agents.",
          "date": "2025-08-03T14:00:00.000Z",
          "link": "https://techcrunch.com/2025/08/03/inside-openais-quest-to-make-ai-do-anything-for-you/",
          "categories": "[\"AI\",\"Exclusive\",\"OpenAI\",\"ChatGPT\",\"agents\"]"
        }
      },
      {
        "json": {
          "title": "The uproar over Vogue’s AI-generated ad isn’t just about fashion",
          "content": "“Modeling as a profession is already challenging enough without having to compete with now new digital standards of perfection that can be achieved with AI,” Sarah Murray told TechCrunch.",
          "date": "2025-08-03T13:00:00.000Z",
          "link": "https://techcrunch.com/2025/08/03/the-uproar-over-vogues-ai-generated-ad-isnt-just-about-fashion/",
          "categories": "[\"Media & Entertainment\",\"AI\",\"Fashion\",\"vogue\",\"guess\",\"digital fashion models\"]"
        }
      },
      {
        "json": {
          "title": "7 Essential Layers for Building Real-World AI Agents in 2025: A Comprehensive Framework",
          "content": "Building an intelligent agent goes far beyond clever prompt engineering for language models. To create real-world, autonomous AI systems that can think, reason, act, and learn, you need to engineer a full-stack solution that orchestrates multiple tightly–integrated components. The following seven-layer framework is a battle-tested mental model for anyone serious about AI agent development—whether you’re a founder, AI engineer, or product leader.\n1. Experience Layer — The Human Interface\nThe Experience Layer acts as the touchpoint between humans and the agent. It defines how users interact with the system: conversation (chat/web/app), voice, image, or even multimodal engagement. This layer must be intuitive, accessible, and capable of capturing user intent precisely, while providing clear feedback.\nCore design challenge: Translate ambiguous human goals into machine-understandable objectives.\nExample: A customer support chatbot interface, or a voice assistant in a smart home.\n2. Discovery Layer — Information Gathering & Context\nAgents need to orient themselves: knowing what to ask, where to look, and how to gather relevant information. The Discovery Layer encompasses techniques like web search, document retrieval, data mining, context collection, sensor integration, and interaction history analysis.\nCore design challenge: Efficient, reliable, and context-aware information retrieval that surfaces only what matters.\nExample: Fetching product manuals, extracting knowledge bases, or summarizing recent emails.\n3. Agent Composition Layer — Structure, Goals, and Behaviors\nThis layer defines what the agent is and how it should behave. It includes defining the agent’s goals, its modular architecture (sub-agents, policies, roles), possible actions, ethical boundaries, and configurable behaviors.\nCore design challenge: Enabling customization and extensibility while ensuring coherence and alignment with user and business objectives.\nExample: Setting up a sales assistant agent with negotiation tactics, brand voice, and escalation protocols.\n4. Reasoning & Planning Layer — The Agent’s Brain\nAt the heart of autonomy, the Reasoning & Planning Layer handles logic, decision-making, inference, and action sequencing. Here, the agent evaluates information, weighs alternatives, plans steps, and adapts strategies. This layer can leverage symbolic reasoning engines, LLMs, classical AI planners, or hybrids.\nCore design challenge: Moving beyond pattern-matching to true adaptive intelligence.\nExample: Prioritizing customer queries, scheduling multi-step workflows, or generating argument chains.\n5. Tool & API Layer — Acting in the World\nThis layer enables the agent to perform real actions: executing code, triggering APIs, controlling IoT devices, managing files, or running external workflows. The agent must safely interface with digital and (sometimes) physical systems, often requiring robust error handling, authentication, and permissions management.\nCore design challenge: Safe, reliable, and flexible action-taking with external systems.\nExample: Booking a meeting on your calendar, placing an e-commerce order, or running data analysis scripts.\n6. Memory & Feedback Layer — Contextual Recall & Learning\nAgents that learn and improve over time must maintain memory: tracking prior interactions, storing context, and incorporating user feedback. This layer supports both short-term contextual recall (for conversation) and long-term learning (improving models, policies, or knowledge bases).\nCore design challenge: Scalable memory representation and effective feedback integration.\nExample: Remembering user preferences, learning common support issues, or iteratively refining suggestions.\n7. Infrastructure Layer — Scaling, Orchestration, & Security\nBeneath the application stack, robust infrastructure ensures the agent is available, responsive, scalable, and secure. This layer includes orchestration platforms, distributed compute, monitoring, failover, and compliance safeguards.\nCore design challenge: Reliability and robustness at scale.\nExample: Managing thousands of concurrent agent instances with uptime guarantees and secure API gateways.\nKey Takeaways\nTrue autonomy requires more than language understanding.\nIntegrate all 7 layers for agents that can safely sense, plan, act, learn, and scale.\nAdopt this framework to assess, design, and build next-generation AI systems that solve meaningful problems.\nFeel free to check out our GitHub Page for Tutorials, Codes and Notebooks. Also, feel free to follow us on Twitter and don’t forget to join our 100k+ ML SubReddit and Subscribe to our Newsletter.\nThe post 7 Essential Layers for Building Real-World AI Agents in 2025: A Comprehensive Framework appeared first on MarkTechPost.",
          "date": "2025-08-04T07:14:45.000Z",
          "link": "https://www.marktechpost.com/2025/08/04/7-essential-layers-for-building-real-world-ai-agents-in-2025-a-comprehensive-framework/",
          "categories": "[\"Agentic AI\",\"AI Agents\",\"Editors Pick\",\"Staff\",\"Tech News\"]"
        }
      },
      {
        "json": {
          "title": "ByteDance Introduces Seed-Prover: An Advanced Formal Reasoning System for Automated Mathematical Theorem Proving",
          "content": "LLMs have shown notable improvements in mathematical reasoning by extending through natural language, resulting in performance gains on benchmarks such as MATH and AIME. However, reinforcement learning (RL) for training these models encounters a challenge: verifying the correctness of natural language proofs is very difficult, requiring careful manual checking of each reasoning step. This limits the application of RL for training mathematical theorem-proving models. While formal languages like Lean offer automatic correctness verification, current LLM formal provers face their limitations. Step-level provers generate code incrementally but require special scaffolding and lack high-level reasoning capabilities.\nByteDance Seed Team introduces Seed-Prover, a lemma-style whole-proof reasoning model. It refines proofs iteratively using Lean feedback, previously established lemmas, and self-summarization. Seed-Prover employs three specialized test-time inference strategies that allow deep and broad reasoning methods to solve IMO-level contest problems. Its primary innovation is in adopting lemma-style proving as its core method, placing lemmas at the center of the reasoning process rather than relying on traditional step-by-step or whole-proof generation methods. Moreover, this paper introduces Seed-Geometry,  a complementary geometry reasoning engine that overcomes Lean’s limitations in handling geometric support.\n\nFor interaction between Seed-Prover and Lean, multi-stage, multi-task RL based on VAPO is utilized. The training dataset combines open-source datasets with in-house formal problems, using a proposer to create simpler variants of difficult tasks. It excludes overly simple problems with proof rates above 25%. Seed-Geometry’s backend supports large-scale problem generation, identifying over 230 million unique problems across seven days with an eightfold improvement in search efficiency. A separate policy and value model is trained, though extensive testing shows that value models may reduce performance due to estimation errors. As a result, step-by-step generation with beam search is adopted in distributed setups.\nSeed-Prover achieves state-of-the-art results across multiple mathematical benchmarks. For IMO 2025, Seed-Prover fully solves 5 out of 6 problems, with Seed-Geometry instantly solving Problem 2 and Seed-Prover deriving proofs for the remaining problem using various inference settings. On past IMO problems, it proved 121 out of 155 tasks, achieving a 78.1% success rate across all difficulty levels. The performance breakdown shows strong results across problem categories: solving 47 out of 55 easy problems, 47 out of 56 medium problems, and 27 out of 44 hard problems, with subject-specific success rates including 72 out of 85 in algebra, 42 out of 55 in number theory, and 7 out of 14 in combinatorics.\nOn MiniF2F, researchers achieve a 99.6% proof rate for both validation and test sets under medium settings, solving difficult problems such as IMO 1990 P3. PutnamBench results show improvement from 201 to 331 solved problems out of 657 when upgrading from light to medium inference settings, showing a significant performance jump over previous undergraduate-level mathematical reasoning systems. On CombiBench, Seed-Prover solves 30 out of 100 combinatorics problems, outperforming existing methods but revealing continued challenges in combinatorial reasoning. Researchers achieve 81.8% success on MiniCTX-v2, showing strong generalization beyond competition problems and outperforming the o4-mini baseline’s 44.3% at Pass@8.\n\nIn conclusion, ByteDance Seed presents Seed-Geometry and Seed-Prover, two formal reasoning methods that integrate the capabilities of LLMs. Seed-Geometry provides accelerated verification and enhanced search mechanisms while Seed-Prover utilizes iterative refinement and complex test-time inference strategies. The achievement of solving 5 out of 6 problems in the IMO 2025 shows the practical efficacy of these methods in tackling elite mathematical competitions. The adoption of formal languages like Lean provides rapid proof verification that is more cost-effective than human experts and more reliable than LLM-based judges. Future research will focus on combining formal systems with LLMs to address open conjectures.\nCheck out the Paper and GitHub Page. Feel free to check out our GitHub Page for Tutorials, Codes and Notebooks. Also, feel free to follow us on Twitter and don’t forget to join our 100k+ ML SubReddit and Subscribe to our Newsletter.\nThe post ByteDance Introduces Seed-Prover: An Advanced Formal Reasoning System for Automated Mathematical Theorem Proving appeared first on MarkTechPost.",
          "date": "2025-08-04T06:51:07.000Z",
          "link": "https://www.marktechpost.com/2025/08/03/bytedance-introduces-seed-prover-an-advanced-formal-reasoning-system-for-automated-mathematical-theorem-proving/",
          "categories": "[\"AI Paper Summary\",\"AI Shorts\",\"Applications\",\"Artificial Intelligence\",\"Editors Pick\",\"Staff\",\"Tech News\",\"Technology\"]"
        }
      },
      {
        "json": {
          "title": "Tutorial: Exploring SHAP-IQ Visualizations",
          "content": "In this tutorial, we’ll explore a range of SHAP-IQ visualizations that provide insights into how a machine learning model arrives at its predictions. These visuals help break down complex model behavior into interpretable components—revealing both the individual and interactive contributions of features to a specific prediction. Check out the Full Codes here.\nInstalling the dependencies\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\n!pip install shapiq overrides scikit-learn pandas numpy seaborn\n\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.model_selection import train_test_split\nfrom tqdm.asyncio import tqdm\n\nimport shapiq\n\nprint(f\"shapiq version: {shapiq.__version__}\")\n\nImporting the dataset\nIn this tutorial, we’ll use the MPG (Miles Per Gallon) dataset, which we’ll load directly from the Seaborn library. This dataset contains information about various car models, including features like horsepower, weight, and origin. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\nimport seaborn as sns\ndf = sns.load_dataset(\"mpg\")\ndf\n\nProcessing the dataset\nWe use Label Encoding to convert the categorical column(s) into numeric format, making them suitable for model training.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\n# Drop rows with missing values\ndf = df.dropna()\n\n# Encoding the origin column\nle = LabelEncoder()\ndf.loc[:, \"origin\"] = le.fit_transform(df[\"origin\"])\ndf['origin'].unique()\n\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\nfor i, label in enumerate(le.classes_):\n    print(f\"{label} → {i}\")\n\nSplitting the data into training & test subsets\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\n# Select features and target\nX = df.drop(columns=[\"mpg\", \"name\"])\ny = df[\"mpg\"]\n\nfeature_names = X.columns.tolist()\nx_data, y_data = X.values, y.values\n\n# Train-test split\nx_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)\n\nModel Training\nWe train a Random Forest Regressor with a maximum depth of 10 and 10 decision trees (n_estimators=10). A fixed random_state ensures reproducibility.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\n# Train model\nmodel = RandomForestRegressor(random_state=42, max_depth=10, n_estimators=10)\nmodel.fit(x_train, y_train)\n\nModel Evaluation\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\n# Evaluate\nmse = mean_squared_error(y_test, model.predict(x_test))\nr2 = r2_score(y_test, model.predict(x_test))\nprint(f\"Mean Squared Error: {mse:.2f}\")\nprint(f\"R2 Score: {r2:.2f}\")\n\nExplaining a Local Instance\nWe choose a specific test instance (with instance_id = 7) to explore how the model arrived at its prediction. We’ll print the true value, predicted value, and the feature values for this instance. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\n# select a local instance to be explained\ninstance_id = 7\nx_explain = x_test[instance_id]\ny_true = y_test[instance_id]\ny_pred = model.predict(x_explain.reshape(1, -1))[0]\nprint(f\"Instance {instance_id}, True Value: {y_true}, Predicted Value: {y_pred}\")\nfor i, feature in enumerate(feature_names):\n    print(f\"{feature}: {x_explain[i]}\")\n\nGenerating Explanations for Multiple Interaction Orders\nWe generate Shapley-based explanations for different interaction orders using the shapiq package. Specifically, we compute:\nOrder 1 (Standard Shapley Values): Individual feature contributions\nOrder 2 (Pairwise Interactions): Combined effects of feature pairs\nOrder N (Full Interaction): All interactions up to the total number of features\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\n# create explanations for different orders\nfeature_names = list(X.columns)  # get the feature names\nn_features = len(feature_names)\n\nsi_order: dict[int, shapiq.InteractionValues] = {}\nfor order in tqdm([1, 2, n_features]):\n    index = \"k-SII\" if order > 1 else \"SV\"  # will also be set automatically by the explainer\n    explainer = shapiq.TreeExplainer(model=model, max_order=order, index=index)\n    si_order[order] = explainer.explain(x=x_explain)\nsi_order\n\n1. Force Chart\nThe force plot is a powerful visualization tool that helps us understand how a machine learning model arrived at a specific prediction. It displays the baseline prediction (i.e., the expected value of the model before seeing any features), and then shows how each feature “pushes” the prediction higher or lower.\nIn this plot:\nRed bars represent features or interactions that increase the prediction.\nBlue bars represent those that decrease it.\nThe length of each bar corresponds to the magnitude of its effect.\nWhen using Shapley interaction values, the force plot can visualize not just individual contributions but also interactions between features. This makes it especially insightful when interpreting complex models, as it visually decomposes how combinations of features work together to influence the outcome. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\nsv = si_order[1]  # get the SV\nsi = si_order[2]  # get the 2-SII\nmi = si_order[n_features]  # get the Moebius transform\n\nsv.plot_force(feature_names=feature_names, show=True)\nsi.plot_force(feature_names=feature_names, show=True)\nmi.plot_force(feature_names=feature_names, show=True)\n\n\n\n\n\nFrom the first plot, we can see that the base value is 23.5. Features like Weight, Cylinders, Horsepower, and Displacement have a positive influence on the prediction, pushing it above the baseline. On the other hand, Model Year and Acceleration have a negative impact, pulling the prediction downward.\n2. Waterfall Chart\nSimilar to the force plot, the waterfall plot is another popular way to visualize Shapley values, originally introduced with the shap library. It shows how different features push the prediction higher or lower compared to the baseline. One key advantage of the waterfall plot is that it automatically groups features with very small impacts into an “other” category, making the chart cleaner and easier to understand. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\nsv.plot_waterfall(feature_names=feature_names, show=True)\nsi.plot_waterfall(feature_names=feature_names, show=True)\nmi.plot_waterfall(feature_names=feature_names, show=True)\n\n\n\n\n\n\n\n\n\n\n\n\n\n3. Network Plot\nThe network plot shows how features interact with each other using first- and second-order Shapley interactions. Node size reflects individual feature impact, while edge width and color show interaction strength and direction. It’s especially helpful when dealing with many features, revealing complex interactions that simpler plots might miss. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\nsi.plot_network(feature_names=feature_names, show=True)\nmi.plot_network(feature_names=feature_names, show=True)\n\n\n\n\n\n4. SI Graph Plot\nThe SI graph plot extends the network plot by visualizing all higher-order interactions as hyper-edges connecting multiple features. Node size shows individual feature impact, while edge width, color, and transparency reflect the strength and direction of interactions. It provides a comprehensive view of how features jointly influence the model’s prediction. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\n# we abbreviate the feature names since, they are plotted inside the nodes\nabbrev_feature_names = shapiq.plot.utils.abbreviate_feature_names(feature_names)\nsv.plot_si_graph(\n    feature_names=abbrev_feature_names,\n    show=True,\n    size_factor=2.5,\n    node_size_scaling=1.5,\n    plot_original_nodes=True,\n)\nsi.plot_si_graph(\n    feature_names=abbrev_feature_names,\n    show=True,\n    size_factor=2.5,\n    node_size_scaling=1.5,\n    plot_original_nodes=True,\n)\nmi.plot_si_graph(\n    feature_names=abbrev_feature_names,\n    show=True,\n    size_factor=2.5,\n    node_size_scaling=1.5,\n    plot_original_nodes=True,\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n5. Bar Plot\nThe bar plot is tailored for global explanations. While other plots can be used both locally and globally, the bar plot summarizes the overall importance of features (or feature interactions) by showing the mean absolute Shapley (or interaction) values across all instances. In shapiq, it highlights which feature interactions contribute most on average. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\nexplanations = []\nexplainer = shapiq.TreeExplainer(model=model, max_order=2, index=\"k-SII\")\nfor instance_id in tqdm(range(20)):\n    x_explain = x_test[instance_id]\n    si = explainer.explain(x=x_explain)\n    explanations.append(si)\nshapiq.plot.bar_plot(explanations, feature_names=feature_names, show=True)\n\n\n\n\n\n“Distance” and “Horsepower” are the most influential features overall, meaning they have the strongest individual impact on the model’s predictions. This is evident from their high mean absolute Shapley interaction values in the bar plot.\nAdditionally, when looking at second-order interactions (i.e., how two features interact together), the combinations “Horsepower × Weight” and “Distance × Horsepower” show significant joint influence. Their combined attribution is around 1.4, indicating that these interactions play an important role in shaping the model’s predictions beyond what each feature contributes individually. This highlights the presence of non-linear relationships between features in the model.\nCheck out the Full Codes here. Feel free to check out our GitHub Page for Tutorials, Codes and Notebooks. Also, feel free to follow us on Twitter and don’t forget to join our 100k+ ML SubReddit and Subscribe to our Newsletter.\nThe post Tutorial: Exploring SHAP-IQ Visualizations appeared first on MarkTechPost.",
          "date": "2025-08-04T04:45:10.000Z",
          "link": "https://www.marktechpost.com/2025/08/03/tutorial-exploring-shap-iq-visualizations/",
          "categories": "[\"Artificial Intelligence\",\"Editors Pick\",\"Machine Learning\",\"Staff\",\"Technology\",\"Tutorials\"]"
        }
      },
      {
        "json": {
          "title": "A Technical Roadmap to Context Engineering in LLMs: Mechanisms, Benchmarks, and Open Challenges",
          "content": "Estimated reading time: 4 minutes\nTable of contents\n\nWhat Is Context Engineering?\nTaxonomy of Context Engineering\nKey Insights and Research Gaps\nApplications and Impact\nFuture Directions\n\nThe paper “A Survey of Context Engineering for Large Language Models” establishes Context Engineering as a formal discipline that goes far beyond prompt engineering, providing a unified, systematic framework for designing, optimizing, and managing the information that guides Large Language Models (LLMs). Here’s an overview of its main contributions and framework:\nWhat Is Context Engineering?\nContext Engineering is defined as the science and engineering of organizing, assembling, and optimizing all forms of context fed into LLMs to maximize performance across comprehension, reasoning, adaptability, and real-world application. Rather than viewing context as a static string (the premise of prompt engineering), context engineering treats it as a dynamic, structured assembly of components—each sourced, selected, and organized through explicit functions, often under tight resource and architectural constraints.\n\n\n\n\nTaxonomy of Context Engineering\nThe paper breaks down context engineering into:\n1. Foundational Components\na. Context Retrieval and Generation\nEncompasses prompt engineering, in-context learning (zero/few-shot, chain-of-thought, tree-of-thought, graph-of-thought), external knowledge retrieval (e.g., Retrieval-Augmented Generation, knowledge graphs), and dynamic assembly of context elements1.\nTechniques like CLEAR Framework, dynamic template assembly, and modular retrieval architectures are highlighted.\nb. Context Processing\nAddresses long-sequence processing (with architectures like Mamba, LongNet, FlashAttention), context self-refinement (iterative feedback, self-evaluation), and integration of multimodal and structured information (vision, audio, graphs, tables).\nStrategies include attention sparsity, memory compression, and in-context learning meta-optimization.\nc. Context Management\nInvolves memory hierarchies and storage architectures (short-term context windows, long-term memory, external databases), memory paging, context compression (autoencoders, recurrent compression), and scalable management over multi-turn or multi-agent settings.\n2. System Implementations\na. Retrieval-Augmented Generation (RAG)\nModular, agentic, and graph-enhanced RAG architectures integrate external knowledge and support dynamic, sometimes multi-agent retrieval pipelines.\nEnables both real-time knowledge updates and complex reasoning over structured databases/graphs.\nb. Memory Systems\nImplement persistent and hierarchical storage, enabling longitudinal learning and knowledge recall for agents (e.g., MemGPT, MemoryBank, external vector databases).\nKey for extended, multi-turn dialogs, personalized assistants, and simulation agents.\nc. Tool-Integrated Reasoning\nLLMs use external tools (APIs, search engines, code execution) via function calling or environment interaction, combining language reasoning with world-acting abilities.\nEnables new domains (math, programming, web interaction, scientific research).\nd. Multi-Agent Systems\nCoordination among multiple LLMs (agents) via standardized protocols, orchestrators, and context sharing—essential for complex, collaborative problem-solving and distributed AI applications.\nKey Insights and Research Gaps\nComprehension–Generation Asymmetry: LLMs, with advanced context engineering, can comprehend very sophisticated, multi-faceted contexts but still struggle to generate outputs matching that complexity or length.\nIntegration and Modularity: Best performance comes from modular architectures combining multiple techniques (retrieval, memory, tool use).\nEvaluation Limitations: Current evaluation metrics/benchmarks (like BLEU, ROUGE) often fail to capture the compositional, multi-step, and collaborative behaviors enabled by advanced context engineering. New benchmarks and dynamic, holistic evaluation paradigms are needed.\nOpen Research Questions: Theoretical foundations, efficient scaling (especially computationally), cross-modal and structured context integration, real-world deployment, safety, alignment, and ethical concerns remain open research challenges.\nApplications and Impact\nContext engineering supports robust, domain-adaptive AI across:\nLong-document/question answering\nPersonalized digital assistants and memory-augmented agents\nScientific, medical, and technical problem-solving\nMulti-agent collaboration in business, education, and research\nFuture Directions\nUnified Theory: Developing mathematical and information-theoretic frameworks.\nScaling & Efficiency: Innovations in attention mechanisms and memory management.\nMulti-Modal Integration: Seamless coordination of text, vision, audio, and structured data.\nRobust, Safe, and Ethical Deployment: Ensuring reliability, transparency, and fairness in real-world systems.\nIn summary: Context Engineering is emerging as the pivotal discipline for guiding the next generation of LLM-based intelligent systems, shifting the focus from creative prompt writing to the rigorous science of information optimization, system design, and context-driven AI.\nCheck out the Paper. Feel free to check out our GitHub Page for Tutorials, Codes and Notebooks. Also, feel free to follow us on Twitter and don’t forget to join our 100k+ ML SubReddit and Subscribe to our Newsletter.\nThe post A Technical Roadmap to Context Engineering in LLMs: Mechanisms, Benchmarks, and Open Challenges appeared first on MarkTechPost.",
          "date": "2025-08-03T21:32:05.000Z",
          "link": "https://www.marktechpost.com/2025/08/03/a-technical-roadmap-to-context-engineering-in-llms-mechanisms-benchmarks-and-open-challenges/",
          "categories": "[\"Context Engineering\",\"Editors Pick\",\"Staff\",\"Uncategorized\"]"
        }
      },
      {
        "json": {
          "title": "The Ultimate Guide to CPUs, GPUs, NPUs, and TPUs for AI/ML: Performance, Use Cases, and Key Differences",
          "content": "Artificial intelligence and machine learning workloads have fueled the evolution of specialized hardware to accelerate computation far beyond what traditional CPUs can offer. Each processing unit—CPU, GPU, NPU, TPU—plays a distinct role in the AI ecosystem, optimized for certain models, applications, or environments. Here’s a technical, data-driven breakdown of their core differences and best use cases.\nCPU (Central Processing Unit): The Versatile Workhorse\nDesign & Strengths: CPUs are general-purpose processors with a few powerful cores—ideal for single-threaded tasks and running diverse software, including operating systems, databases, and light AI/ML inference.\nAI/ML Role: CPUs can execute any kind of AI model, but lack the massive parallelism needed for efficient deep learning training or inference at scale.\nBest for:\n\nClassical ML algorithms (e.g., scikit-learn, XGBoost)\nPrototyping and model development\nInference for small models or low-throughput requirements\nTechnical Note: For neural network operations, CPU throughput (typically measured in GFLOPS—billion floating point operations per second) lags far behind specialized accelerators.\nGPU (Graphics Processing Unit): The Deep Learning Backbone\nDesign & Strengths: Originally for graphics, modern GPUs feature thousands of parallel cores designed for matrix/multiple vector operations, making them highly efficient for training and inference of deep neural networks.\nPerformance Examples:\n\nNVIDIA RTX 3090: 10,496 CUDA cores, up to 35.6 TFLOPS (teraFLOPS) FP32 compute.\nRecent NVIDIA GPUs include “Tensor Cores” for mixed precision, accelerating deep learning operations.\nBest for:\n\nTraining and inferencing large-scale deep learning models (CNNs, RNNs, Transformers)\nBatch processing typical in datacenter and research environments\nSupported by all major AI frameworks (TensorFlow, PyTorch)\nBenchmarks: A 4x RTX A5000 setup can surpass a single, far more expensive NVIDIA H100 in certain workloads, balancing acquisition cost and performance.\nNPU (Neural Processing Unit): The On-device AI Specialist\nDesign & Strengths: NPUs are ASICs (application-specific chips) crafted exclusively for neural network operations. They optimize parallel, low-precision computation for deep learning inference, often running at low power for edge and embedded devices.\nUse Cases & Applications:\n\nMobile & Consumer: Powering features like face unlock, real-time image processing, language translation on devices like the Apple A-series, Samsung Exynos, Google Tensor chips.\nEdge & IoT: Low-latency vision and speech recognition, smart city cameras, AR/VR, and manufacturing sensors.\nAutomotive: Real-time data from sensors for autonomous driving and advanced driver assistance.\nPerformance Example: The Exynos 9820’s NPU is ~7x faster than its predecessor for AI tasks.\nEfficiency: NPUs prioritize energy efficiency over raw throughput, extending battery life while supporting advanced AI features locally.\nTPU (Tensor Processing Unit): Google’s AI Powerhouse\nDesign & Strengths: TPUs are custom chips developed by Google specifically for large tensor computations, tuning hardware around the needs of frameworks like TensorFlow.\nKey Specifications:\n\nTPU v2: Up to 180 TFLOPS for neural network training and inference.\nTPU v4: Available in Google Cloud, up to 275 TFLOPS per chip, scalable to “pods” exceeding 100 petaFLOPS.\nSpecialized matrix multiplication units (“MXU”) for enormous batch computations.\nUp to 30–80x better energy efficiency (TOPS/Watt) for inference compared to contemporary GPUs and CPUs.\nBest for:\n\nTraining and serving massive models (BERT, GPT-2, EfficientNet) in cloud at scale\nHigh-throughput, low-latency AI for research and production pipelines\nTight integration with TensorFlow and JAX; increasingly interfacing with PyTorch\nNote: TPU architecture is less flexible than GPU—optimized for AI, not graphics or general-purpose tasks.\nWhich Models Run Where?\n\nHardwareBest Supported ModelsTypical Workloads\n\nCPUClassical ML, all deep learning models*General software, prototyping, small AI\nGPUCNNs, RNNs, TransformersTraining and inference (cloud/workstation)\nNPUMobileNet, TinyBERT, custom edge modelsOn-device AI, real-time vision/speech\nTPUBERT/GPT-2/ResNet/EfficientNet, etc.Large-scale model training/inference\n\n\n\n\n\n*CPUs support any model, but are not efficient for large-scale DNNs.\nData Processing Units (DPUs): The Data Movers\nRole: DPUs accelerate networking, storage, and data movement, offloading these tasks from CPUs/GPUs. They enable higher infrastructure efficiency in AI datacenters by ensuring compute resources focus on model execution, not I/O or data orchestration.\nSummary Table: Technical Comparison\n\nFeatureCPUGPUNPUTPU\n\nUse CaseGeneral ComputeDeep LearningEdge/On-device AIGoogle Cloud AI\nParallelismLow–ModerateVery High (~10,000+)Moderate–HighExtremely High (Matrix Mult.)\nEfficiencyModeratePower-hungryUltra-efficientHigh for large models\nFlexibilityMaximumVery high (all FW)SpecializedSpecialized (TensorFlow/JAX)\nHardwarex86, ARM, etc.NVIDIA, AMDApple, Samsung, ARMGoogle (Cloud only)\nExampleIntel XeonRTX 3090, A100, H100Apple Neural EngineTPU v4, Edge TPU\n\n\n\n\n\nKey Takeaways\nCPUs are unmatched for general-purpose, flexible workloads.\nGPUs remain the workhorse for training and running neural networks across all frameworks and environments, especially outside Google Cloud.\nNPUs dominate real-time, privacy-preserving, and power-efficient AI for mobile and edge, unlocking local intelligence everywhere from your phone to self-driving cars.\nTPUs offer unmatched scale and speed for massive models—especially in Google’s ecosystem—pushing the frontiers of AI research and industrial deployment.\nChoosing the right hardware depends on model size, compute demands, development environment, and desired deployment (cloud vs. edge/mobile). A robust AI stack often leverages a mix of these processors, each where it excels.\nThe post The Ultimate Guide to CPUs, GPUs, NPUs, and TPUs for AI/ML: Performance, Use Cases, and Key Differences appeared first on MarkTechPost.",
          "date": "2025-08-03T10:38:52.000Z",
          "link": "https://www.marktechpost.com/2025/08/03/the-ultimate-guide-to-cpus-gpus-npus-and-tpus-for-ai-ml-performance-use-cases-and-key-differences/",
          "categories": "[\"AI Infrastructure\",\"Artificial Intelligence\",\"Editors Pick\",\"Staff\",\"Technology\"]"
        }
      },
      {
        "json": {
          "title": "Building an End-to-End Object Tracking and Analytics System with Roboflow Supervision",
          "content": "In this advanced Roboflow Supervision tutorial, we build a complete object detection pipeline with the Supervision library. We begin by setting up real-time object tracking using ByteTracker, adding detection smoothing, and defining polygon zones to monitor specific regions in a video stream. As we process the frames, we annotate them with bounding boxes, object IDs, and speed data, enabling us to track and analyze object behavior over time. Our goal is to showcase how we can combine detection, tracking, zone-based analytics, and visual annotation into a seamless and intelligent video analysis workflow. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\n!pip install supervision ultralytics opencv-python\n!pip install --upgrade supervision \n\n\nimport cv2\nimport numpy as np\nimport supervision as sv\nfrom ultralytics import YOLO\nimport matplotlib.pyplot as plt\nfrom collections import defaultdict\n\n\nmodel = YOLO('yolov8n.pt')\n\nWe start by installing the necessary packages, including Supervision, Ultralytics, and OpenCV. After ensuring we have the latest version of Supervision, we import all required libraries. We then initialize the YOLOv8n model, which serves as the core detector in our pipeline. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\ntry:\n   tracker = sv.ByteTrack()\nexcept AttributeError:\n   try:\n       tracker = sv.ByteTracker()\n   except AttributeError:\n       print(\"Using basic tracking - install latest supervision for advanced tracking\")\n       tracker = None\n\n\ntry:\n   smoother = sv.DetectionsSmoother(length=5)\nexcept AttributeError:\n   smoother = None\n   print(\"DetectionsSmoother not available in this version\")\n\n\ntry:\n   box_annotator = sv.BoundingBoxAnnotator(thickness=2)\n   label_annotator = sv.LabelAnnotator()\n   if hasattr(sv, 'TraceAnnotator'):\n       trace_annotator = sv.TraceAnnotator(thickness=2, trace_length=30)\n   else:\n       trace_annotator = None\nexcept AttributeError:\n   try:\n       box_annotator = sv.BoxAnnotator(thickness=2)\n       label_annotator = sv.LabelAnnotator()\n       trace_annotator = None\n   except AttributeError:\n       print(\"Using basic annotators - some features may be limited\")\n       box_annotator = None\n       label_annotator = None \n       trace_annotator = None\n\n\ndef create_zones(frame_shape):\n   h, w = frame_shape[:2]\n  \n   try:\n       entry_zone = sv.PolygonZone(\n           polygon=np.array([[0, h//3], [w//3, h//3], [w//3, 2*h//3], [0, 2*h//3]]),\n           frame_resolution_wh=(w, h)\n       )\n      \n       exit_zone = sv.PolygonZone(\n           polygon=np.array([[2*w//3, h//3], [w, h//3], [w, 2*h//3], [2*w//3, 2*h//3]]),\n           frame_resolution_wh=(w, h)\n       )\n   except TypeError:\n       entry_zone = sv.PolygonZone(\n           polygon=np.array([[0, h//3], [w//3, h//3], [w//3, 2*h//3], [0, 2*h//3]])\n       )\n       exit_zone = sv.PolygonZone(\n           polygon=np.array([[2*w//3, h//3], [w, h//3], [w, 2*h//3], [2*w//3, 2*h//3]])\n       )\n  \n   return entry_zone, exit_zone\n\nWe set up essential components from the Supervision library, including object tracking with ByteTrack, optional smoothing using DetectionsSmoother, and flexible annotators for bounding boxes, labels, and traces. To ensure compatibility across versions, we use try-except blocks to fall back to alternative classes or basic functionality when needed. Additionally, we define dynamic polygon zones within the frame to monitor specific regions like entry and exit areas, enabling advanced spatial analytics. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\nclass AdvancedAnalytics:\n   def __init__(self):\n       self.track_history = defaultdict(list)\n       self.zone_crossings = {\"entry\": 0, \"exit\": 0}\n       self.speed_data = defaultdict(list)\n      \n   def update_tracking(self, detections):\n       if hasattr(detections, 'tracker_id') and detections.tracker_id is not None:\n           for i in range(len(detections)):\n               track_id = detections.tracker_id[i]\n               if track_id is not None:\n                   bbox = detections.xyxy[i]\n                   center = np.array([(bbox[0] + bbox[2]) / 2, (bbox[1] + bbox[3]) / 2])\n                   self.track_history[track_id].append(center)\n                  \n                   if len(self.track_history[track_id]) >= 2:\n                       prev_pos = self.track_history[track_id][-2]\n                       curr_pos = self.track_history[track_id][-1]\n                       speed = np.linalg.norm(curr_pos - prev_pos)\n                       self.speed_data[track_id].append(speed)\n  \n   def get_statistics(self):\n       total_tracks = len(self.track_history)\n       avg_speed = np.mean([np.mean(speeds) for speeds in self.speed_data.values() if speeds])\n       return {\n           \"total_objects\": total_tracks,\n           \"zone_entries\": self.zone_crossings[\"entry\"],\n           \"zone_exits\": self.zone_crossings[\"exit\"],\n           \"avg_speed\": avg_speed if not np.isnan(avg_speed) else 0\n       }\n\n\ndef process_video(source=0, max_frames=300):\n   \"\"\"\n   Process video source with advanced supervision features\n   source: video path or 0 for webcam\n   max_frames: limit processing for demo\n   \"\"\"\n   cap = cv2.VideoCapture(source)\n   analytics = AdvancedAnalytics()\n  \n   ret, frame = cap.read()\n   if not ret:\n       print(\"Failed to read video source\")\n       return\n  \n   entry_zone, exit_zone = create_zones(frame.shape)\n  \n   try:\n       entry_zone_annotator = sv.PolygonZoneAnnotator(\n           zone=entry_zone,\n           color=sv.Color.GREEN,\n           thickness=2\n       )\n       exit_zone_annotator = sv.PolygonZoneAnnotator(\n           zone=exit_zone,\n           color=sv.Color.RED,\n           thickness=2\n       )\n   except (AttributeError, TypeError):\n       entry_zone_annotator = sv.PolygonZoneAnnotator(zone=entry_zone)\n       exit_zone_annotator = sv.PolygonZoneAnnotator(zone=exit_zone)\n  \n   frame_count = 0\n   results_frames = []\n  \n   cap.set(cv2.CAP_PROP_POS_FRAMES, 0) \n  \n   while ret and frame_count < max_frames:\n       ret, frame = cap.read()\n       if not ret:\n           break\n          \n       results = model(frame, verbose=False)[0]\n       detections = sv.Detections.from_ultralytics(results)\n      \n       detections = detections[detections.class_id == 0]\n      \n       if tracker is not None:\n           detections = tracker.update_with_detections(detections)\n      \n       if smoother is not None:\n           detections = smoother.update_with_detections(detections)\n      \n       analytics.update_tracking(detections)\n      \n       entry_zone.trigger(detections)\n       exit_zone.trigger(detections)\n      \n       labels = []\n       for i in range(len(detections)):\n           confidence = detections.confidence[i] if detections.confidence is not None else 0.0\n          \n           if hasattr(detections, 'tracker_id') and detections.tracker_id is not None:\n               track_id = detections.tracker_id[i]\n               if track_id is not None:\n                   speed = analytics.speed_data[track_id][-1] if analytics.speed_data[track_id] else 0\n                   label = f\"ID:{track_id} | Conf:{confidence:.2f} | Speed:{speed:.1f}\"\n               else:\n                   label = f\"Conf:{confidence:.2f}\"\n           else:\n               label = f\"Conf:{confidence:.2f}\"\n           labels.append(label)\n      \n       annotated_frame = frame.copy()\n      \n       annotated_frame = entry_zone_annotator.annotate(annotated_frame)\n       annotated_frame = exit_zone_annotator.annotate(annotated_frame)\n      \n       if trace_annotator is not None:\n           annotated_frame = trace_annotator.annotate(annotated_frame, detections)\n      \n       if box_annotator is not None:\n           annotated_frame = box_annotator.annotate(annotated_frame, detections)\n       else:\n           for i in range(len(detections)):\n               bbox = detections.xyxy[i].astype(int)\n               cv2.rectangle(annotated_frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 2)\n      \n       if label_annotator is not None:\n           annotated_frame = label_annotator.annotate(annotated_frame, detections, labels)\n       else:\n           for i, label in enumerate(labels):\n               if i < len(detections):\n                   bbox = detections.xyxy[i].astype(int)\n                   cv2.putText(annotated_frame, label, (bbox[0], bbox[1]-10),\n                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n      \n       stats = analytics.get_statistics()\n       y_offset = 30\n       for key, value in stats.items():\n           text = f\"{key.replace('_', ' ').title()}: {value:.1f}\"\n           cv2.putText(annotated_frame, text, (10, y_offset),\n                      cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n           y_offset += 30\n      \n       if frame_count % 30 == 0:\n           results_frames.append(cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB))\n      \n       frame_count += 1\n      \n       if frame_count % 50 == 0:\n           print(f\"Processed {frame_count} frames...\")\n  \n   cap.release()\n  \n   if results_frames:\n       fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n       axes = axes.flatten()\n      \n       for i, (ax, frame) in enumerate(zip(axes, results_frames[:4])):\n           ax.imshow(frame)\n           ax.set_title(f\"Frame {i*30}\")\n           ax.axis('off')\n      \n       plt.tight_layout()\n       plt.show()\n  \n   final_stats = analytics.get_statistics()\n   print(\"\\n=== FINAL ANALYTICS ===\")\n   for key, value in final_stats.items():\n       print(f\"{key.replace('_', ' ').title()}: {value:.2f}\")\n  \n   return analytics\n\n\nprint(\"Starting advanced supervision demo...\")\nprint(\"Features: Object detection, tracking, zones, speed analysis, smoothing\")\n\n\nWe define the AdvancedAnalytics class to track object movement, calculate speed, and count zone crossings, enabling rich real-time video insights. Inside the process_video function, we read each frame from the video source and run it through our detection, tracking, and smoothing pipeline. We annotate frames with bounding boxes, labels, zone overlays, and live statistics, giving us a powerful, flexible system for object monitoring and spatial analytics. Throughout the loop, we also collect data for visualization and print final statistics, showcasing the effectiveness of Roboflow Supervision’s end-to-end capabilities. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\ndef create_demo_video():\n   \"\"\"Create a simple demo video with moving objects\"\"\"\n   fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n   out = cv2.VideoWriter('demo.mp4', fourcc, 20.0, (640, 480))\n  \n   for i in range(100):\n       frame = np.zeros((480, 640, 3), dtype=np.uint8)\n      \n       x1 = int(50 + i * 2)\n       y1 = 200\n       x2 = int(100 + i * 1.5)\n       y2 = 250\n      \n       cv2.rectangle(frame, (x1, y1), (x1+50, y1+50), (0, 255, 0), -1)\n       cv2.rectangle(frame, (x2, y2), (x2+50, y2+50), (255, 0, 0), -1)\n      \n       out.write(frame)\n  \n   out.release()\n   return 'demo.mp4'\n\n\ndemo_video = create_demo_video()\nanalytics = process_video(demo_video, max_frames=100)\n\n\nprint(\"\\nTutorial completed! Key features demonstrated:\")\nprint(\"✓ YOLO integration with Supervision\")\nprint(\"✓ Multi-object tracking with ByteTracker\")\nprint(\"✓ Detection smoothing\")\nprint(\"✓ Polygon zones for area monitoring\")\nprint(\"✓ Advanced annotations (boxes, labels, traces)\")\nprint(\"✓ Real-time analytics and statistics\")\nprint(\"✓ Speed calculation and tracking history\")\n\n\nTo test our full pipeline, we generate a synthetic demo video with two moving rectangles simulating tracked objects. This allows us to validate detection, tracking, zone monitoring, and speed analysis without needing a real-world input. We then run the process_video function on the generated clip. At the end, we print out a summary of all key features we’ve implemented, showcasing the power of Roboflow Supervision for real-time visual analytics.\nIn conclusion, we have successfully implemented a full pipeline that brings together object detection, tracking, zone monitoring, and real-time analytics. We demonstrate how to visualize key insights like object speed, zone crossings, and tracking history with annotated video frames. This setup empowers us to go beyond basic detection and build a smart surveillance or analytics system using open-source tools. Whether for research or production use, we now have a powerful foundation to expand upon with even more advanced capabilities.\nCheck out the Full Codes here. Feel free to check out our GitHub Page for Tutorials, Codes and Notebooks. Also, feel free to follow us on Twitter and don’t forget to join our 100k+ ML SubReddit and Subscribe to our Newsletter.\nThe post Building an End-to-End Object Tracking and Analytics System with Roboflow Supervision appeared first on MarkTechPost.",
          "date": "2025-08-03T09:22:28.000Z",
          "link": "https://www.marktechpost.com/2025/08/03/building-an-end-to-end-object-tracking-and-analytics-system-with-roboflow-supervision/",
          "categories": "[\"Artificial Intelligence\",\"Editors Pick\",\"Machine Learning\",\"Staff\",\"Tech News\",\"Technology\",\"Tutorials\"]"
        }
      },
      {
        "json": {
          "title": "The Impossibility Theorem Behind Truthful Blockchain Bidding Mechanisms",
          "content": "Table of Links\nAbstract and 1. Introduction\n1.1 Our Contributions\n1.2 TFM Incentive-Compatibility Notions: A Cheat Sheet\nDefinitions\n2.1 Transaction Fee Mechanism\n2.2 Incentive Compatibility Notions\n\n\nPreliminary: Myerson’s Lemma\n\n\nWarmup: Impossibility of UIC + MIC + Global SCP for Deterministic Mechanisms\n\n\nImpossibility of UIC + MIC + Global SCP for Randomized Mechanisms and 5.1 Proof Roadmap\n5.2 Formal Proofs\n\n\nFeasibility and Impossibility of UIC + MIC + OCA-Proof\n6.1 A Non-Truthful Mechanism with UIC + MIC + OCA-Proof\n6.2 Impossibility of UIC + MIC + OCA-Proof for Truthful Mechanisms\n\n\nHow to Circumvent the Impossibilities and 7.1 Allowing the Globally Optimal Strategy to Coordinate\n7.2 Allowing the Globally Optimal Strategy to Output Multiple Bids\n7.3 Inclusion-Rule-Respecting and 7.4 Discussions and Open Questions Regarding the Use of Cryptography\n\n\nStatic Revelation Principle for Transaction Fee Mechanisms\n8.1 Static Revelation Principle: Bidding Rules That Output Single Bid\n8.2 Static Revelation Principle: Allowing Bidding Rules that Output Multiple Bids\n\n\nA. Comparison of Collusion-Resilience Notions\nReferences\n\\\n6 Feasibility and Impossibility of UIC + MIC + OCA-Proof\nWe can generalize the proof in Section 5, and rule out UIC, MIC, and OCA-proof (rather than global SCP) for truthful mechanisms. Recall that for a truthful mechanism, the difference between OCA-proof and global SCP is that global SCP insists that the optimal strategy of the global coalition is the truthful strategy, whereas OCA-proofness allows it to be some other strategy in which each user acts independently and bids the outcome of some function σ(·).\n\\\nInterestingly, if we allow the bidding rule to be not truth-telling, i.e. considering non-truthful mechanisms, we can have a mechanism that satisfies UIC, MIC, and OCA-proof. We present the feasibility for non-truthful mechanisms in Section 6.1, and we prove the impossibility of UIC + MIC + OCA-proof for truthful mechanisms in Section 6.2. Notice that because of the feasibility in Section 6.1, we must require the bidding rule to be truth-telling to reach an impossibility in Section 6.2.\n6.1 A Non-Truthful Mechanism with UIC + MIC + OCA-Proof\nThe rationale of the design is to signal to the mechanism when everyone is adopting the globally optimal strategy σ (as opposed to the bidding rule used to establish UIC). When the mechanism detects that everyone is behaving according to σ, it adopts a different behavior to optimize social welfare. We use the range [0, 1) to encode the actual bid, and use the range [1,∞) for signalling. While the resulting mechanism is somewhat contrived and not necessarily meaningful from a practical point of view, it clarifies which notions of collusion-resilience most accurately capture the intended modeling goals and illustrates some technical challenges involved in the proof in Section 6.2. Consider the following TFM:\n\\\n• Globally optimal strategy σ(v): Given a true value v, output a bid v + 1.\n\\\n• Bidding rule: Given a true value v, output a bid 1/(v + 2).\n\\\n• Inclusion rule: Let S be the set of all pending bids that are in [0, 1). If |S| > k, then randomly select k bids from S to include. If 1 ≤ |S| ≤ k, then include all bids in S. If |S| = 0, choose the top up to k bids to include.\n\\\n• Confirmation, payment, and miner revenue rules: All included bids are confirmed. Each confirmed bid pays nothing, and the miner gets nothing.\n\\\nObviously, this mechanism is non-trivial.\n\\\nClaim 6.1. The above mechanism satisfies UIC, MIC, and OCA-proofness.\n\\\nProof. For UIC, notice that if a user follows the bidding rule, its bid is always in [0, 1). If there is no bid in [0, 1) before a user submits its bid, then bidding 1/(v + 2) always guarantees user’s bid to be included and confirmed, where v denote the true value. If there is already some bids in [0, 1) before a user submits its bid, then bidding 1/(v + 2) is a dominant strategy since it guarantees the user’s bid is added to S, the set of all bids in [0, 1), which is the best a user can do. Next, MIC holds since the miner revenue is always zero. Finally, if all users follow the globally optimal strategy σ, everyone’s bid is at least 1. The honest inclusion rule will include the top up to k bids, which maximizes the social welfare. Thus, OCA-proofness holds.\n\\\nRemark 1. We can try to apply revelation principle, and bake the bidding rule into the mechanism so that the resulting mechanism is truthful. For example, whenever seeing a bid b, the miner and the mechanism view it as 1/(b + 2). The modified mechanism, however, does not satisfy OCAproofness anymore when the number of users is larger than the block size, since the miner should choose k users with the highest true values instead of the random selection as indicated by the inclusion rule. This is not a coincidence: in the next section, we show that it is impossible to have a non-trivial truthful mechanism satisfying UIC, MIC, and OCA-proofness.\n\\\n:::info\nAuthors:\n(1) Hao Chung∗, Carnegie Mellon University (haochung@andrew.cmu.edu);\n(2) Tim Roughgarden†, Columbia University and a16z (crypto tim.roughgarden@gmail.com);\n(3) Elaine Shi∗, Carnegie Mellon University (runting@cs.cmu.edu).\n:::\n:::info\nThis paper is available on arxiv under CC BY 4.0 DEED license.\n:::\n\\",
          "date": "2025-08-03T21:14:40.000Z",
          "link": "https://hackernoon.com/the-impossibility-theorem-behind-truthful-blockchain-bidding-mechanisms?source=rss",
          "categories": "[\"blockchain-scalability\",\"transaction-fee-mechanisms\",\"ethereum-eip-1559\",\"user-incentive-compatibility\",\"miner-incentive-compatibility\",\"oca-proofness\",\"side-contract-proofness\",\"auction-mechanisms\"]"
        }
      },
      {
        "json": {
          "title": "No Blockchain Auction Can Satisfy UIC, MIC, and Global SCP at Once",
          "content": "Table of Links\nAbstract and 1. Introduction\n1.1 Our Contributions\n1.2 TFM Incentive-Compatibility Notions: A Cheat Sheet\nDefinitions\n2.1 Transaction Fee Mechanism\n2.2 Incentive Compatibility Notions\n\n\nPreliminary: Myerson’s Lemma\n\n\nWarmup: Impossibility of UIC + MIC + Global SCP for Deterministic Mechanisms\n\n\nImpossibility of UIC + MIC + Global SCP for Randomized Mechanisms and 5.1 Proof Roadmap\n5.2 Formal Proofs\n\n\nFeasibility and Impossibility of UIC + MIC + OCA-Proof\n6.1 A Non-Truthful Mechanism with UIC + MIC + OCA-Proof\n6.2 Impossibility of UIC + MIC + OCA-Proof for Truthful Mechanisms\n\n\nHow to Circumvent the Impossibilities and 7.1 Allowing the Globally Optimal Strategy to Coordinate\n7.2 Allowing the Globally Optimal Strategy to Output Multiple Bids\n7.3 Inclusion-Rule-Respecting and 7.4 Discussions and Open Questions Regarding the Use of Cryptography\n\n\nStatic Revelation Principle for Transaction Fee Mechanisms\n8.1 Static Revelation Principle: Bidding Rules That Output Single Bid\n8.2 Static Revelation Principle: Allowing Bidding Rules that Output Multiple Bids\n\n\nA. Comparison of Collusion-Resilience Notions\nReferences\n3 Preliminary: Myerson’s Lemma\n\n\\\nConceptually, user i must pay the minimal price which makes its bid confirmed.\n4 Warmup: Impossibility of UIC + MIC + Global SCP for Deterministic Mechanisms\nAs a warmup, we first show a finite-block impossibility for UIC + MIC + global SCP for deterministic mechanisms. Recall that a TFM is said to be trivial if everyone’s confirmation probability is zero for any bid vector assuming the miner follows the inclusion rule. In this case, everyone’s utility is always zero in an honest execution. We will show that no non-trivial mechanism can satisfy all three properties simultaneously. Later in Section 5, we extend the impossibility to randomized mechanisms. Due to the revelation principle that we prove in Section 8, if we can prove the impossibility for truthful mechanisms, the impossibility immediately extends to non-truthful mechanisms as well. Therefore, in this section, we shall assume truthful mechanisms.\n\\\nLemma 4.1. For any global SCP mechanism, the confirmed bids must correspond to the highest bids.\n\\\nProof. Suppose in some scenario, Alice bids her true value b and Bob bids his true value b ′ < b; however, Bob’s bid is confirmed, and Alice’s is not. Now, we can have Alice and Bob swap their bids. The miner creates the same block as before in which the position originally corresponding to Bob now has Alice’s bid of b′. Since the mechanism is weakly symmetric (Definition 1), Alice’s bid is confirmed. This way, the social welfare increases by b − b′ in comparison with the honest case, and this violates global SCP.\n\\\nLemma 4.2. For any global SCP mechanism, the amount of burnt coins depends only on the number of confirmed bids.\n\\\nProof. Suppose in two different scenarios, when everyone acts honestly, the blocks made are B and B′ respectively, the confirmed bids are b ⊆ B and b′ ⊆ B′ respectively where b and b′ are of the same length, and the burnt amount in the two scenarios are q and q′ respectively, where q < q′. Now, suppose we are actually in the second scenario. A global coalition can adopt the following strategy: create a block identical to B in which the confirmed bids correspond to the users with the highest true values and the rest can be fake bids. Observe that the social welfare is the sum of the true values of all confirmed bids (where fake bids have a true value of 0) minus the total coins burnt. Therefore, the above strategy achieves strictly higher social welfare than the honest case.\n\\\nTheorem 4.3. No non-trivial deterministic TFM can simultaneously satisfy UIC, MIC, and global SCP when the block size is finite.\n\\\n\\\n \n5 Impossibility of UIC + MIC + Global SCP for Randomized Mechanisms\nIn this section, we extend the finite-block impossibility of UIC + MIC + global SCP to even randomized mechanisms. Recall that a TFM consists of five rules as defined in Section 2.1, and a randomized TFM may use randomness in any of the five rules. Since the confirmation, the payment, and the miner revenue rules are executed by the blockchain, the strategic players can only bias the randomness in and deviate from the bidding rule and the inclusion rule. Again, due to the revelation principle proven in Section 8, it suffices to consider truthful mechanisms.\n5.1 Proof Roadmap\n\\\n \n5.2 Formal Proofs\nIn the rest of this section, we present the formal proofs.\n\\\n\\\n \n\\\n\\\n\\\n \n\\\n\\\n\\\n \n\\\n\\\nProof. We first prove that expected miner utility is the same in both scenarios. Suppose this is not true, and without loss of generality, suppose expected miner utility is higher in scenario 1. Then, the miner can ignore the bids b, inject the fake bids b′, pretend that the bid vector is (a, b′), and run the honest mechanism. Since the confirmation probability of b′ is 0, the miner need not pay any cost for the fake bids. Therefore, the miner gets higher expected utility by taking the above strategy which violates MIC.\n\\\nThe proof of total social welfare is similar. Suppose without loss of generality, that the expected total social welfare in scenario 1 is higher. Then, the global coalition can inject fake bids b′ and pretend that the bid vector is (a, b′), thus allowing it to increase its expected social welfare. This violates global SCP.\n\\\nThe equivalence in total user utility follows directly from the above, since total user utility is the difference between the social welfare and the miner utility.\n\\\n\\\n \n\\\n\\\n\\\n \n\\\n\\\nLemma 5.5. Suppose the mechanism satisfies UIC, MIC, and global SCP, and the block size is k. Let a be any positive real number. Consider a scenario with only one bid a. Then, the only user’s utility is zero assuming it bids its true value.\n\\\n\\\n \n\\\n\\\nTheorem 5.6. No non-trivial, possibly randomized TFM can simultaneously satisfy UIC, MIC, and global SCP when the block size is finite.\n\\\nProof. We will show that under any sufficiently large a, the confirmation probability under a single bid a is non-zero. If we can show this, then we can show a contradiction to UIC. Specifically, consider b > a and both sufficiently large. By Lemma 5.5, if there is only one user with true value b, its utility is zero when it bids truthfully. However, the user can underbid a. Since the confirmation probability is non-zero and the payment is at most a, the user enjoys positive utility, which violates UIC.\n\\\n\\\n \n\\\n\\\n:::info\nAuthors:\n(1) Hao Chung∗, Carnegie Mellon University (haochung@andrew.cmu.edu);\n(2) Tim Roughgarden†, Columbia University and a16z (crypto tim.roughgarden@gmail.com);\n(3) Elaine Shi∗, Carnegie Mellon University (runting@cs.cmu.edu).\n:::\n:::info\nThis paper is available on arxiv under CC BY 4.0 DEED license.\n:::\n\\",
          "date": "2025-08-03T21:14:35.000Z",
          "link": "https://hackernoon.com/no-blockchain-auction-can-satisfy-uic-mic-and-global-scp-at-once?source=rss",
          "categories": "[\"blockchain-scalability\",\"transaction-fee-mechanisms\",\"ethereum-eip-1559\",\"user-incentive-compatibility\",\"miner-incentive-compatibility\",\"oca-proofness\",\"side-contract-proofness\",\"auction-mechanisms\"]"
        }
      },
      {
        "json": {
          "title": "What Is a Transaction Fee Mechanism? Definitions, Incentives, and Strategies",
          "content": "Table of Links\nAbstract and 1. Introduction\n1.1 Our Contributions\n1.2 TFM Incentive-Compatibility Notions: A Cheat Sheet\nDefinitions\n2.1 Transaction Fee Mechanism\n2.2 Incentive Compatibility Notions\n\n\nPreliminary: Myerson’s Lemma\n\n\nWarmup: Impossibility of UIC + MIC + Global SCP for Deterministic Mechanisms\n\n\nImpossibility of UIC + MIC + Global SCP for Randomized Mechanisms and 5.1 Proof Roadmap\n5.2 Formal Proofs\n\n\nFeasibility and Impossibility of UIC + MIC + OCA-Proof\n6.1 A Non-Truthful Mechanism with UIC + MIC + OCA-Proof\n6.2 Impossibility of UIC + MIC + OCA-Proof for Truthful Mechanisms\n\n\nHow to Circumvent the Impossibilities and 7.1 Allowing the Globally Optimal Strategy to Coordinate\n7.2 Allowing the Globally Optimal Strategy to Output Multiple Bids\n7.3 Inclusion-Rule-Respecting and 7.4 Discussions and Open Questions Regarding the Use of Cryptography\n\n\nStatic Revelation Principle for Transaction Fee Mechanisms\n8.1 Static Revelation Principle: Bidding Rules That Output Single Bid\n8.2 Static Revelation Principle: Allowing Bidding Rules that Output Multiple Bids\n\n\nA. Comparison of Collusion-Resilience Notions\nReferences\n2 Definitions\n2.1 Transaction Fee Mechanism\n\n\\\nA transaction fee mechanism (TFM) consists of the following possibly randomized algorithms:\n\\\n \n\\\nWe say a TFM is trivial if the confirmation probability of all transactions is zero for any bid vector assuming the miner honestly follows the inclusion rule; otherwise, it is called non-trivial.\n\\\nA strategic miner or miner-user coalition may deviate from the honest inclusion rule. On the other hand, since the confirmation, payment, and miner revenue rules are executed by the blockchain, they are always implemented honestly.\n\\\nWe focus on mechanisms that are weakly symmetric, i.e., mechanisms that do not make use of the bidders’ identities or other auxiliary information (e.g., timestamp, transaction metadata), except for tie-breaking among equal bids. More formally, we define weak symmetry as below.\n\\\nDefinition 1 (Weak symmetry). A mechanism is called weakly symmetric if the mechanism can always be equivalently described in the following manner: given a bid vector b where each bid may carry some extra information such as identity or timestamp, the honest mechanism always sorts the vector b by the bid amount first. During the sorting step, if multiple bids have the same amount, then arbitrary tie-breaking rules may be applied, and the tie-breaking can depend on extra information such as timestamp, identity, or random coins. After this sorting step, the inclusion rule and the confirmation rules should depend only on the amount of the bids and their relative position in the sorted bid vector.\n\\\n \n\\\nStrategy space. A strategic user can deviate from the honest bidding rule and post an arbitrary bid vector with zero to multiple bids. Without loss of generality, we may assume that in the strategic bid vector, at most one bid can correspond to the user’s actual transaction which has a non-zero true value; all other bids must be fake bids with zero true value. A strategic miner can deviate from the honest inclusion rule, and instead create an arbitrary block (subject to the block size limit) that includes any subset of the bid vector as well as any number of fake bids that it chooses to inject. A strategic miner-user coalition can adopt a combination of the above strategies.\n\\\nUtility and social welfare. For a user with true value v, let x ∈ {0, 1} be the indicator of whether its primary bid is confirmed or not, let p denote its total payment, then the user’s utility is x · v − p. The miner’s utility is simply its revenue. The social welfare is defined to be the sum of the utilities of all users and the miner (i.e., the total value of the confirmed transactions, less any burned payments).\n\\\nNotice that we allow the miner revenue to be smaller than the sum of users’ payment, since the coins can be burnt. When calculating the social welfare, the payments among the users and the miner are canceled out, so the social welfare is independent of the payment; however, the amount of burnt coins decreases the social welfare. For example, suppose there is only one user, and let p be the user’s payment and q be the amount of burnt coins. In this case, the user’s utility is x·v −p, the miner revenue is p − q, and the social welfare is (x · v − p) + (p − q) = x · v − q.\n2.2 Incentive Compatibility Notions\n\\\n \n\\\n\\\nDefinition 3 (Miner incentive compatible (MIC)). A TFM is said to be miner incentive compatible (MIC), iff given any bid vector b, the miner’s expected utility is maximized when the miner does not inject any fake bid and creates a block indicated by the honest inclusion rule.\n\\\n\\\n \n\\\n\\\nDefinition 5 (Global side-contract-proof (global SCP)). A TFM is said to be global side-contract-proof (global SCP), iff given any vector of true values v, the expected social welfare is maximized when all the users bid according to the honest bidding rule, and the miner follows the honest inclusion rule, where the maximization is taken over all the coordinated strategies that the coalition consisting of the miner and all users can adopt.\n\\\n\\\n \n\\\n\\\nIn the definitions above, the expectation is taken over the randomness of the TFM. More explicitly, in Definition 2, the expectation is taken over the randomness of the inclusion/confirmation/payment rules; in Definitions 3 to 6, the expectation is taken over the randomness of the inclusion/confirmation/ payment/miner revenue rules.\n\\\nNote that in the OCA-proofness definition, σ is required to output a single real-valued bid. A canonical example of σ is scaling; that is, σ(v) = γv for some γ ∈ [0, 1] (cf., Corollary 5.12 and 5.14 in [Rou21]).\n\\\nA detailed comparison between c-SCP, global SCP, and OCA-proofness is given in Appendix A.\n\\\n:::info\nAuthors:\n(1) Hao Chung∗, Carnegie Mellon University (haochung@andrew.cmu.edu);\n(2) Tim Roughgarden†, Columbia University and a16z (crypto tim.roughgarden@gmail.com);\n(3) Elaine Shi∗, Carnegie Mellon University (runting@cs.cmu.edu).\n:::\n:::info\nThis paper is available on arxiv under CC BY 4.0 DEED license.\n:::\n[5] The finite block size regime in this work and [CS23] corresponds to the case in [Rou21] where the base fee in the EIP-1559 or tipless mechanisms is excessively low, i.e. the number of transactions willing to pay the base fee exceeds the maximum block size (cf., Definition 5.6 in [Rou21]).\n\\\n[6] The blockchain protocol can always suppress conflicting or double-spending transactions.\n\\\n[7] Throughout the paper except Section 8, we only focus on bidding rules that output a single bid. In Section 8, we consider general bidding rules that may output multiple bids.\n\\\n[8] Roughgarden [Rou21] assumes that all included transactions are confirmed. However, Chung and Shi [CS23] show that allowing unconfirmed transactions in a block enlarges the design space. For example, some mechanisms require a block to contain some unconfirmed transactions (see Section 7 in [CS23]).\n\\\n[9] We can also relax the requirement such that individual rationality holds in expectation. Both the impossibility results (Sections 4, 5 and 6.2) and the revelation principle result (Section 8) continue to hold.",
          "date": "2025-08-03T21:14:30.000Z",
          "link": "https://hackernoon.com/what-is-a-transaction-fee-mechanism-definitions-incentives-and-strategies?source=rss",
          "categories": "[\"blockchain-scalability\",\"transaction-fee-mechanisms\",\"ethereum-eip-1559\",\"user-incentive-compatibility\",\"miner-incentive-compatibility\",\"oca-proofness\",\"side-contract-proofness\",\"auction-mechanisms\"]"
        }
      },
      {
        "json": {
          "title": "Why No Transaction Fee Mechanism Can Truly Be Collusion-Proof",
          "content": "Table of Links\nAbstract and 1. Introduction\n1.1 Our Contributions\n1.2 TFM Incentive-Compatibility Notions: A Cheat Sheet\nDefinitions\n2.1 Transaction Fee Mechanism\n2.2 Incentive Compatibility Notions\n\n\nPreliminary: Myerson’s Lemma\n\n\nWarmup: Impossibility of UIC + MIC + Global SCP for Deterministic Mechanisms\n\n\nImpossibility of UIC + MIC + Global SCP for Randomized Mechanisms and 5.1 Proof Roadmap\n5.2 Formal Proofs\n\n\nFeasibility and Impossibility of UIC + MIC + OCA-Proof\n6.1 A Non-Truthful Mechanism with UIC + MIC + OCA-Proof\n6.2 Impossibility of UIC + MIC + OCA-Proof for Truthful Mechanisms\n\n\nHow to Circumvent the Impossibilities and 7.1 Allowing the Globally Optimal Strategy to Coordinate\n7.2 Allowing the Globally Optimal Strategy to Output Multiple Bids\n7.3 Inclusion-Rule-Respecting and 7.4 Discussions and Open Questions Regarding the Use of Cryptography\n\n\nStatic Revelation Principle for Transaction Fee Mechanisms\n8.1 Static Revelation Principle: Bidding Rules That Output Single Bid\n8.2 Static Revelation Principle: Allowing Bidding Rules that Output Multiple Bids\n\n\nA. Comparison of Collusion-Resilience Notions\nReferences\n1.2 TFM Incentive-Compatibility Notions: A Cheat Sheet\nWe gather here informal definitions and comparisons of the key incentive-compatibility notions used in this paper. First, a transaction fee mechanism specifies how a user is supposed to bid (as a function of its private valuation), which transactions a miner is supposed to include (as a function of the transactions it knows about and their bids), and the resulting outcome (the subset of included transactions that get confirmed, and the payments made by the users and received by the miner). If the bidding strategy suggested by the TFM is the identity, then we additionally call the TFM truthful. In this paper, as in the rest of the TFM literature, we consider only static mechanisms.\n\\\n• UIC. (Definition 2) Provided that the miner follows the suggested inclusion rule, the bidding strategy suggested by the TFM is a dominant strategy for users.\n\\\n• MIC. (Definition 3) The inclusion rule suggested by the TFM is always revenue-maximizing for the miner regardless of users’ bids; moreover, the miner cannot increase its revenue through the injection of fake transactions.\n\\\n• Global SCP. (Definition 5) If the miner follows the inclusion rule suggested by the TFM and all users follow the bidding rule suggested by the TFM, then their joint surplus is at least as large as it would be from any coordinated deviation.\n\\\n• c-SCP. (Definition 4) For every coalition of the miner and at most c users, if the miner follows the inclusion rule suggested by the TFM and the users in the coalition follow the bidding rule suggested by the TFM, then the joint surplus of the coalition is at least as large as it would be from any coordinated deviation (holding fixed the bids of users outside the coalition).\n\\\n• OCA-proof. (Definition 6) If the miner follows the inclusion rule suggested by the TFM and all users follow a suitably chosen individually rational bidding rule σ (possibly different from the one suggested in the TFM description), then their joint surplus is as large as it would be from any coordinated deviation.\n\\\nFor example, in [Rou21] it was shown that Ethereum’s EIP-1559 TFM and a variant called the “tipless mechanism” satisfy UIC, MIC, and OCA-proofness when there is no contention between transactions; in fact, in this case, these TFMs satisfy the c-SCP condition for every c ≥ 1. When there is contention between transactions for inclusion in a block, the EIP-1559 TFM loses its UIC property and the tipless mechanism loses (all three notions of) collusion-resilience.\n\\\nAs mentioned above:\n\\\n• (Theorem 8.1) A relevation principle holds for the global SCP and c-SCP notions: any UIC and MIC TFM that satisfies one of these properties can be simulated by a truthful UIC and MIC TFM that satisfies the same property.\n\\\n• A relevation principle does not in general hold for the OCA-proof notion: while there are non-truthful TFMs that satisfy UIC, MIC, and OCA-proofness (Section 6.1), there are no truthful TFMs that satisfy UIC, MIC, and OCA-proofness (Theorem 6.9).\n\\\nThe main result in Chung and Shi [CS23] states that, even among randomized TFMs, no TFM satisfies UIC and c-SCP for any c ≥ 1. Our Theorem 5.6 proves that, even among randomized TFMs, no TFM satisfies UIC, MIC, and global SCP. (Due to the revelation principle mentioned above, these impossibility results apply to both truthful and non-truthful TFMs.) Our Theorem 6.9 proves the stronger statement that, even among randomized TFMs, no truthful TFM satisfies UIC, MIC, and OCA-proofness.\n\\\nReflecting on the competing notions of collusion-resilience, we can observe the following. The cSCP condition may be particularly appropriate in scenarios where the primary concern is deviations by small coalitions, or in scenarios where users may wish to deviate in ways that exploit other users. The c-SCP condition is also notable in that, together with the UIC condition, it already triggers the impossibility result in [CS23] (without any appeal to MIC). The OCA-proofness condition is distinguished by being the weakest of the three notions (thus leading to the strongest impossibility results) and by allowing the discussion of non-UIC mechanisms.[4] For TFMs that are UIC and MIC, like those studied in this paper, global SCP is arguably the “right” definition—capturing the spirit of OCA-proofness, without any additional technical complications arising from users using different bidding strategies to satisfy UIC and collusion-resilience. Put differently, the UIC and MIC conditions imply that the miner and the users following their intended strategies constitutes a Nash equilibrium; the global SCP condition asserts that this Nash equilibrium is also robust to deviations by the grand coalition, while OCA-proofness only asserts such robustness for a possibly different strategy profile (defined by the intended inclusion rule and some individually rational bidding strategy). From this vantage point, one might view Theorem 5.6 as the main impossibility result in this paper, with Theorem 6.9 serving as a technically challenging extension of the result under still weaker incentive-compatibility conditions.\n\\\n:::info\nAuthors:\n(1) Hao Chung∗, Carnegie Mellon University (haochung@andrew.cmu.edu);\n(2) Tim Roughgarden†, Columbia University and a16z (crypto tim.roughgarden@gmail.com);\n(3) Elaine Shi∗, Carnegie Mellon University (runting@cs.cmu.edu).\n:::\n:::info\nThis paper is available on arxiv under CC BY 4.0 DEED license.\n:::\n[4] For example, in a first-price auction, the “reference outcome” might be defined by a (non-truthful) bidding strategy that would constitute a Bayes-Nash equilibrium with respect to some prior over user valuations (cf., Corollary 5.12 in [Rou21]).",
          "date": "2025-08-03T21:14:24.000Z",
          "link": "https://hackernoon.com/why-no-transaction-fee-mechanism-can-truly-be-collusion-proof?source=rss",
          "categories": "[\"blockchain-scalability\",\"transaction-fee-mechanisms\",\"ethereum-eip-1559\",\"user-incentive-compatibility\",\"miner-incentive-compatibility\",\"oca-proofness\",\"side-contract-proofness\",\"auction-mechanisms\"]"
        }
      },
      {
        "json": {
          "title": "Why Truthful Blockchain Mechanisms Fail Under Finite Block Sizes",
          "content": "Table of Links\nAbstract and 1. Introduction\n1.1 Our Contributions\n1.2 TFM Incentive-Compatibility Notions: A Cheat Sheet\nDefinitions\n2.1 Transaction Fee Mechanism\n2.2 Incentive Compatibility Notions\n\n\nPreliminary: Myerson’s Lemma\n\n\nWarmup: Impossibility of UIC + MIC + Global SCP for Deterministic Mechanisms\n\n\nImpossibility of UIC + MIC + Global SCP for Randomized Mechanisms and 5.1 Proof Roadmap\n5.2 Formal Proofs\n\n\nFeasibility and Impossibility of UIC + MIC + OCA-Proof\n6.1 A Non-Truthful Mechanism with UIC + MIC + OCA-Proof\n6.2 Impossibility of UIC + MIC + OCA-Proof for Truthful Mechanisms\n\n\nHow to Circumvent the Impossibilities and 7.1 Allowing the Globally Optimal Strategy to Coordinate\n7.2 Allowing the Globally Optimal Strategy to Output Multiple Bids\n7.3 Inclusion-Rule-Respecting and 7.4 Discussions and Open Questions Regarding the Use of Cryptography\n\n\nStatic Revelation Principle for Transaction Fee Mechanisms\n8.1 Static Revelation Principle: Bidding Rules That Output Single Bid\n8.2 Static Revelation Principle: Allowing Bidding Rules that Output Multiple Bids\n\n\nA. Comparison of Collusion-Resilience Notions\nReferences\n1.1 Our Contributions\nAs explained above, both Roughgarden’s and Chung and Shi’s collusion-resilience notions capture meaningful incentive compatibility considerations. Recognizing their differences, one natural question is: does Chung and Shi’s finite-block impossibility result still hold if we adopt the original OCA-proofness notion of Roughgarden in lieu of c-SCP? Notably, no existing TFM construction [LSZ19, Yao, BEOS19, BCD+, Rou20, Rou21, FMPS21, CS23, SCW23, WSC24, GY22, ZCZ22, BGR23, TY23, KKLP23, XFP23, CMW23, LRMP23, Ndi23] simultaneously satisfies user incentive compatibility, miner incentive compatibility, and OCA-proofness under finite block size.\n\\\nMain impossibility result. In our work, we give an affirmative answer to the above question. We show that, indeed, an analog of Chung and Shi’s finite-block impossibility result still holds when we replace the c-SCP requirement with OCA-proofness. Specifically, we prove the following theorem.\n\\\nTheorem 1.1. Suppose the block size is finite. Then, no possibly randomized, truthful TFM can simultaneously satisfy user incentive compatibility (UIC), miner incentive compatibility (MIC), and OCA-proofness. Further, this impossibility holds even when the globally optimal strategy σ need not be individually rational.\n\\\nIn a truthful TFM, a user is expected to bid truthfully, so if the mechanism satisfies UIC, a user’s utility is maximized when it just reports its true value. However, OCA-proofness allows the global coalition to adopt a non-truthful bidding strategy σ even for truthful mechanisms.\n\\\nOur Theorem 1.1 is intuitively stronger but technically incomparable in comparison with Chung and Shi’s impossibility, which shows that no TFM can simultaneously satisfy UIC and 1-SCP for finite block sizes. The reason is that Chung and Shi’s impossibility does not rely on MIC; however, MIC is necessary for our Theorem 1.1 to hold. Specifically, a simple second-price auction with no burning (see Remark 2) satisfies both UIC and OCA-proofness, but does not satisfy MIC since the miner may benefit by injecting a fake (t + 1)-th bid where t is the number of confirmed bids, since the (t + 1)-th bid sets the price for confirmed bids.\n\\\nGlobal SCP. We suggest a simpler version of OCA-proofness that we call global SCP, which also intuitively captures the requirement that strategic users and miners cannot steal from the protocol, and is perhaps more appropriate when focusing on UIC TFMs (as we do in this paper). In our work, global SCP is not only a technical stepping stone towards proving Theorem 1.1, but also of independent interest as we explain below. Specifically, global SCP is almost the same as OCAproofness, except for requiring σ to be the honest bidding strategy indicated by the mechanism (i.e., the same bidding strategy used to establish UIC). In other words, a mechanism satisfies global SCP if and only if the honest strategy is surplus-maximizing for the global coalition. It is easy to see that for a truthful mechanism, c-SCP for any c implies global SCP, which in turn implies OCA-proofness. To prove Theorem 1.1, we first prove the following theorem:\n\\\nTheorem 1.2. Suppose that the block size is finite. Then no possibly randomized TFM can simultaneously satisfy user incentive compatibility (UIC), miner incentive compatibility (MIC), and global SCP. Further, the impossibility holds even for non-truthful mechanisms.\n\\\nWe now explain why the global SCP notion is of independent interest. One advantage of global SCP is that the revelation principle holds for any TFM that satisfies UIC, MIC, and global SCP, which we formally prove in Section 8. In other words, given any TFM that is UIC, MIC, and global SCP, there is an equivalent truthful mechanism that simulates it. For this reason, Theorem 1.2 rules out even non-truthful TFMs that simultaneously satisfy UIC, MIC, and global SCP.[3]\n\\\nBy contrast, Theorem 1.1 holds only for truthful mechanisms. In particular, in Section 6.1, we show a non-truthful mechanism that simultaneously satisfies UIC, MIC, and OCA-proof. The mechanism is contrived, but it demonstrates the subtlety and the technical challenges when modeling the notion of collusion-resilience. This also suggests that the revelation principle does not hold for mechanisms that satisfy UIC, MIC, and OCA-proofness, partly because in such a mechanism, the bidding strategies used to establish UIC and OCA-proofness may be different.\n\\\nWays to circumvent the impossibilities. We show in Section 7 that the impossibility of Theorem 1.1 can be circumvented by allowing non-truthful mechanisms or by allowing users to coordinate in bidding in the globally optimal strategy σ. In the same section, we raise an open question regarding whether it is possible to use cryptography (e.g., the MPC-assisted model of Shi et al. [SCW23]) and Bayesian notions of incentive compatibility to circumvent the impossibilities.\n\\\n:::info\nAuthors:\n(1) Hao Chung∗, Carnegie Mellon University (haochung@andrew.cmu.edu);\n(2) Tim Roughgarden†, Columbia University and a16z (crypto tim.roughgarden@gmail.com);\n(3) Elaine Shi∗, Carnegie Mellon University (runting@cs.cmu.edu).\n:::\n:::info\nThis paper is available on arxiv under CC BY 4.0 DEED license.\n:::\n[3] Simultaneously with and independently of this paper, Gafni and Yaish [GY24] proved, among other results, a version of Theorem 1.2 for the special case of deterministic mechanisms and a block size of 1.",
          "date": "2025-08-03T21:14:18.000Z",
          "link": "https://hackernoon.com/why-truthful-blockchain-mechanisms-fail-under-finite-block-sizes?source=rss",
          "categories": "[\"blockchain-scalability\",\"transaction-fee-mechanisms\",\"ethereum-eip-1559\",\"user-incentive-compatibility\",\"miner-incentive-compatibility\",\"oca-proofness\",\"side-contract-proofness\",\"auction-mechanisms\"]"
        }
      },
      {
        "json": {
          "title": "Why the Perfect Blockchain Fee Mechanism May Be Impossible",
          "content": ":::info\nAuthors:\n(1) Hao Chung∗, Carnegie Mellon University (haochung@andrew.cmu.edu);\n(2) Tim Roughgarden†, Columbia University and a16z (crypto tim.roughgarden@gmail.com);\n(3) Elaine Shi∗, Carnegie Mellon University (runting@cs.cmu.edu).\n:::\nTable of Links\nAbstract and 1. Introduction\n1.1 Our Contributions\n1.2 TFM Incentive-Compatibility Notions: A Cheat Sheet\nDefinitions\n2.1 Transaction Fee Mechanism\n2.2 Incentive Compatibility Notions\n\n\nPreliminary: Myerson’s Lemma\n\n\nWarmup: Impossibility of UIC + MIC + Global SCP for Deterministic Mechanisms\n\n\nImpossibility of UIC + MIC + Global SCP for Randomized Mechanisms and 5.1 Proof Roadmap\n5.2 Formal Proofs\n\n\nFeasibility and Impossibility of UIC + MIC + OCA-Proof\n6.1 A Non-Truthful Mechanism with UIC + MIC + OCA-Proof\n6.2 Impossibility of UIC + MIC + OCA-Proof for Truthful Mechanisms\n\n\nHow to Circumvent the Impossibilities and 7.1 Allowing the Globally Optimal Strategy to Coordinate\n7.2 Allowing the Globally Optimal Strategy to Output Multiple Bids\n7.3 Inclusion-Rule-Respecting and 7.4 Discussions and Open Questions Regarding the Use of Cryptography\n\n\nStatic Revelation Principle for Transaction Fee Mechanisms\n8.1 Static Revelation Principle: Bidding Rules That Output Single Bid\n8.2 Static Revelation Principle: Allowing Bidding Rules that Output Multiple Bids\n\n\nA. Comparison of Collusion-Resilience Notions\nReferences\nAbstract\nUsers bid in a transaction fee mechanism (TFM) to get their transactions included and confirmed by a blockchain protocol. Roughgarden (EC’21) initiated the formal treatment of TFMs and proposed three requirements: user incentive compatibility (UIC), miner incentive compatibility (MIC), and a form of collusion-resilience called OCA-proofness. Ethereum’s EIP1559 mechanism satisfies all three properties simultaneously when there is no contention between transactions, but loses the UIC property when there are too many eligible transactions to fit in a single block. Chung and Shi (SODA’23) considered an alternative notion of collusion-resilience, called c-side-contract-proofness (c-SCP), and showed that, when there is contention between transactions, no TFM can satisfy UIC, MIC, and c-SCP for any c ≥ 1. OCA-proofness asserts that the users and a miner should not be able to “steal from the protocol.” On the other hand, the c-SCP condition requires that a coalition of a miner and a subset of users should not be able to profit through strategic deviations (whether at the expense of the protocol or of the users outside the coalition).\n\\\nOur main result is the first proof that, when there is contention between transactions, no (possibly randomized) TFM in which users are expected to bid truthfully satisfies UIC, MIC, and OCA-proofness. This result resolves the main open question in Roughgarden (EC’21). We also suggest several relaxations of the basic model that allow our impossibility result to be circumvented.\n1 Introduction\nReal estate on the blockchain is scarce, and blockchain users bid in an auction called the transaction fee mechanism (TFM) to have their transactions included and confirmed on the blockchain. The original Bitcoin protocol adopted a simple first-price auction, where the top k bids win and they each pay their bid. However, such first-price auctions are known to incentivize untruthful bidding. Therefore, a line of subsequent works [LSZ19, Yao, BEOS19, BCD+, Rou20, Rou21, FMPS21, CS23, SCW23, WSC24, GY22, ZCZ22, BGR23, TY23, KKLP23, XFP23, CMW23, LRMP23, Ndi23] explored what is the “dream TFM” for blockchains. Most works [Rou20, Rou21, CS23, SCW23, WSC24, GY22, GY22, ZCZ22, BGR23, TY23] agree on roughly the same set of desiderata, that is, a dream TFM should provide incentive compatibility not just for an individual user, but also for the miner of the block. Further, a dream TFM should provide resilience against miner-user collusion.\n\\\nRoughgarden [Rou21] was the first to formally define the aforementioned requirements for a TFM, which he referred to as user incentive compatibility[1], (myopic) miner incentive compatibility, and OCA-proofness, where OCA stands for “off-chain agreement” and refers to colluding strategies between the miner and a set of users that allow off-chain transfers. Roughgarden [Rou21] also showed that the simple “posted price auction with all fees burnt” mechanism, which corresponds to the behavior of Ethereum’s EIP-1559 TFM [BCD+] when there is no congestion, satisfies all three properties. However, the posted price auction with all fees burnt does not satisfy all three properties when there is congestion. In practice, congestion does occur when there are major events such as an NFT mint or price fluctuations — for example, in Ethereum, roughly 2.3% of the blocks experience congestion.[2] When congestion arises, approximately speaking, Ethereum’s EIP-1559 mechanism falls back to the first-price auction, violating user incentive compatibility. Therefore, an interesting question is whether we can design a dream TFM satisfying all three properties for finite block sizes.\n\\\nChung and Shi [CS23] considered an alternative notion of collusion-resilience, called sidecontract-proofness. Unfortunately, they proved that no (even randomized) TFM can simultaneously satisfy user incentive compatibility and side-contract-proofness. Because side-contract-proofness is a more demanding property than OCA-proofness, the question raised by Roughgarden [Rou21], of whether there is a dream TFM satisfying all three properties under his collusion-resilience notion, had remained open.\n\\\nTwo notions of miner-user collusion-resilience. Multiple natural notions of collusion-resilience can and have been studied in the context of TFM design. Here we clarify informally the key differences between the notions proposed by Roughgarden [Rou21] and Chung and Shi [CS23]. These notions are defined formally in Definitions 4–6 (see Section 2) and compared further via examples in Appendix A.\n\\\n• OCA-proofness: Roughgarden’s notion, henceforth referred to as OCA-proofness, asserts that there should exist a “reference strategy” for a miner and all users that is guaranteed to maximize their joint surplus. In this reference strategy, the miner is expected to follow the inclusion rule intended by the TFM. For users, the definition requires only that users follow some fixed bidding trategy σ (i.e., a mapping from a private user valuation to a user bid) that is individually rational (i.e., σ(v) ≤ v for all v ≥ 0). In particular, in the reference strategy, users are expected to bid independently (with a user’s bid independent of other users’ valuations and bids), and expected to submit a single bid (with no additional fake bids injected). One example of such a bidding strategy is the truth-telling strategy (with σ(v) = v). Because Roughgarden [Rou21] wished to discuss the OCA-proofness properties of non-UIC TFMs like first-price auctions, the definition also allows the reference strategy to be defined by a non-truthful bidding strategy (e.g., σ(v) = v/2). As a consequence, to prove that a TFM is both UIC and OCA-proof, it is sufficient to prove that it is UIC under one bidding strategy and OCA-proof under a possibly different bidding strategy (as in the example in Section 6.1).\n\\\n• c-SCP: Chung and Shi’s notion [CS23], henceforth called c-SCP (where SCP stands for sidecontract-proofness), requires that the honest strategy (i.e., all users follow the honest bidding rule and the miner honestly implements the inclusion rule) is the profit-maximizing strategy for any coalition consisting of the miner of the present block and at most c users. For truthful mechanisms, the honest bidding rule is the truthful one, while for non-truthful mechanisms, the bidding rule can be more general (see Section 2.1 for the formal definition). Chung and Shi’s notion aligns with standard notions used in a line of work at the intersection of game theory and cryptography [HT04, KN08, ADGH06, OPRV09, AL11, ACH11, GKM+13, GKTZ15, GTZ15, Kat08, DR07, GLR10, CGL+18, WAS22, CCWS21, PS17, KMSW22, FW20, EFW22].\n\\\nDiscussion. The two notions of collusion-resilience address different issues. OCA-proofness captures the intuitive requirement that the users and miners should not be able to steal from the protocol through strategic deviations — for this reason, it considers only the global coalition consisting of the miner and all users. By contrast, the c-SCP notion captures the intuitive idea that a miner-user coalition’s best response is to act honestly, and that no strategic deviations can allow the coalition to steal from other users or steal from the protocol. For further discussion, see the end of this section and Appendix A.\n\\\n:::info\nThis paper is available on arxiv under CC BY 4.0 DEED license.\n:::\n∗Supported by NSF awards 2212746, 2044679, 1704788, a Packard Fellowship, a generous gift from the late Nikolai Mushegian, a gift from Google, and an ACE center grant from Algorand Foundation.\n\\\n†Author’s research at Columbia University supported in part by NSF awards CCF-2006737 and CNS-2212745, and research awards from the Briger Family Digital Finance Lab and the Center for Digital Finance and Technologies.\n\\\n[1] User incentive compatibility (UIC) is usually called dominant-strategy incentive compatible (DSIC) in the mechanism design literature. In general, we allow UIC TFMs to make use of non-truthful (but dominant) bidding strategies (see Definition 2).\n\\\n[2] From Jan 1, 2024 to Feb 5, 2024, 256595 blocks have been produced on Ethereum, and 5840 blocks among them were full (meaning more than 99.9% of the gas limit (30M) was used).",
          "date": "2025-08-03T21:14:14.000Z",
          "link": "https://hackernoon.com/why-the-perfect-blockchain-fee-mechanism-may-be-impossible?source=rss",
          "categories": "[\"blockchain-scalability\",\"transaction-fee-mechanisms\",\"ethereum-eip-1559\",\"user-incentive-compatibility\",\"collusion-resilience\",\"oca-proofness\",\"auction-mechanisms\",\"hackernoon-top-story\"]"
        }
      },
      {
        "json": {
          "title": "Designing for Intelligence, Efficiency, and Accessibility",
          "content": "A few years ago, if someone mentioned Artificial Intelligence in a product design meeting, they’d likely be met with skeptical glances or a cautious “let’s not overcomplicate things.” Today? AI isn’t just welcome at the UX table; it’s practically running the show.\nWe’re in a new era where the user experience is no longer just about beautifully designed buttons and seamless navigation; it's about intelligence. It’s about designing systems that think a little, predict a lot, and adapt even more. And most importantly, it’s about making those experiences accessible to everyone, not just the tech-savvy.\nIn this article, I will unpack how AI is reshaping UX through three powerful lenses: intelligence, efficiency, and accessibility.\n1. Designing for Intelligence\nThis means designing a user experience (UX) that learns and adapts to users' needs and preferences. Imagine opening your favorite streaming app and seeing a lineup so in tune with your mood, it’s like it read your mind. That’s AI quietly doing its thing: tracking behavior, learning preferences, and curating experiences.\nBut it goes deeper than Netflix suggestions. In UX, AI is helping designers build systems that understand user intent. Think about voice assistants that interpret vague commands or smart email apps that finish your sentences. These aren’t just cool features; they represent a paradigm shift from static interfaces to intelligent, evolving ones.\n\nGmail auto reply options\nAs designers, our role is evolving too. We’re not just sketching wireframes, we’re mapping out decision trees, training datasets, and predicting edge cases. We’re asking, \"What should the system do if the user does X, but also what if they do Y, or nothing at all?\"\nThe design process becomes less about dictating user journeys and more about enabling dynamic, adaptive experiences.\n2. Designing for Efficiency\nLet’s face it, users are busy, distracted, and often overwhelmed. The best UX anticipates this. AI is turning reactive design into proactive design, streamlining interactions before users even realize they need help.\nTake auto-generated replies in Gmail. What once took 30 seconds now takes two clicks. Or smart forms that auto-fill based on past behavior. These aren’t just nice-to-haves; they redefine what “fast” and “frictionless” mean in today’s digital age.\n\nDesigners are now integrating features like:\nPredictive search that learns as you type.\nConversational UIs that simulate human-like dialogue.\nMicro-personalizations that fine-tune experiences per individual.\nWe’re shifting from “How can we make this easier?” to “How can we make this invisible?” AI enables us to reduce the cognitive load, streamline the number of steps, and allow users to navigate digital spaces with near-effortless precision.\n3. Designing for Accessibility\nOne of the most inspiring aspects of AI in UX is its potential to make products more accessible than ever.\nThink about screen readers enhanced with natural language processing, turning robotic monotones into human-like guidance. Or image recognition tools that generate detailed alt text, giving blind users richer context. Or even real-time captioning powered by AI, helping deaf users fully participate in digital experiences, such as virtual calls.\nAI is becoming an equalizer, helping bridge the gap for users with disabilities, language barriers, or limited digital literacy.\nBut here’s the catch: AI can only be inclusive if it’s designed that way. Biased training data and one-size-fits-all algorithms can easily undo the progress made. As UX professionals, we must approach AI with empathy and ethical foresight. Who are we designing for? Who might we be excluding? How do we test, iterate, and refine AI so that it helps rather than hinders?\nSo, after all I have shared, where do we go from here?\nThe future of UX is not about choosing between human-centered and machine-assisted design; it's about combining them. AI doesn’t replace the empathy, intuition, and creativity of designers; it amplifies them.\nOur job now is to become translators. To understand both the language of people and the language of machines, and to create experiences where the two meet in harmony.\nSo the next time you open a product and it just gets you, don’t chalk it up to luck. That’s AI in UX, quietly evolving behind the scenes, making every tap, scroll, and swipe a little more magical.\nAI is no longer a “feature.” It’s a UX game-changer. It helps us design smarter (intelligence), faster (efficiency), and better for everyone (accessibility) products. But it’s up to us to ensure it’s used ethically, creatively, and inclusively.\nRecommended Resources for Deeper Insight:\n→ The Future of UX - Embracing AI in Design\n→ The Future of UX Design: How AI and Machine Learning Are Changing the Way We Design\n→ The future of AI in user experience (UX) design\n\\",
          "date": "2025-08-03T20:01:13.000Z",
          "link": "https://hackernoon.com/designing-for-intelligence-efficiency-and-accessibility?source=rss",
          "categories": "[\"ux-design\",\"ai-in-ux-design\",\"intelligent-ux-systems\",\"accessible-design-with-ai\",\"adaptive-user-interfaces\",\"predictive-ux-design\",\"frictionless-user-experiences\",\"ux-design-trends-2025\"]"
        }
      },
      {
        "json": {
          "title": "SDG LAB Venture Fund Backs Virtual Intimacy with $20 Million — But Will It Work?",
          "content": "In an age of hyperconnectivity, Europe faces an unexpected crisis: loneliness. The EU Loneliness Survey 2022 reveals that 13% of Europeans feel lonely most or all the time, while 35% experience it regularly. Despite the digital revolution, authentic human connection seems to be unraveling—replaced by surface-level engagements that lack emotional resonance.\nThis paradox lies at the heart of Social Discovery Group (SDG)’s $20 million venture studio, SDG Lab Venture Studio. The studio is betting big on a controversial but potentially transformative concept: Virtual Intimacy — a technological attempt to restore emotional closeness in an increasingly isolated society.\nUnderstanding Loneliness: More Than Just Being Alone\nLoneliness is not simply a matter of physical solitude. It’s a mental and emotional state where individuals feel unseen, disconnected, and emotionally deprived — even in crowds. It’s a perceived disconnection, not merely the absence of company.\nHealth Consequences of Loneliness\nA 2015 meta-analysis by Holt-Lunstad found that:\nSocial isolation increases mortality risk by 29%\nLoneliness increases it by 26%\nThese numbers are comparable to the health risks of smoking 15 cigarettes a day, as outlined in the 2023 U.S. Surgeon General’s guidelines.\nMoreover, loneliness is linked to:\nSleep disturbances\nHigh cortisol levels\nHypertension\nHeart disease\n==It’s no longer just a social issue; it’s a public health crisis.== \\n \n\nTech Meets Emotional Need: SDG Lab’s $20 Million Response\nEnter SDG Lab, the corporate venture arm of Social Discovery Group, which backs early-stage startups that focus on:\nAI-powered communication\nVirtual and extended reality\nSocial discovery platforms\nThese startups are designed to build what SDG calls “virtual intimacy”: emotional connections that transcend physical interaction through digital mediums.\nAlex Kudos, CEO of SDG Lab Venture Studio, puts it simply:\n“Technology doesn’t just help us build relationships — it becomes part of them.”\nThis shift challenges traditional notions of closeness. Can digital interactions really replace the emotional depth of face-to-face contact?\n\n\\\nThe Geography of Loneliness\nNot all regions are affected equally. According to EU data:\nEastern and Southern Europe (e.g., Bulgaria, Romania, Greece) suffer higher loneliness rates\nNorthern and Western countries (e.g., Austria, the Netherlands) show lower levels\nFor example, Cyprus mirrors this southern trend. Kudos notes that older populations in Cyprus are particularly affected. SDG’s solution? Use technology to build connections tailored to older users. Products like DateMyAge show that virtual platforms can appeal to users beyond Gen Z — if designed inclusively.\nA New Era of Digital Connection\nStudies show that 57% of Gen Z believe online relationships are as meaningful as in-person ones. During the COVID-19 pandemic, virtual worlds offered emotional refuge:\nAltspaceVR users reported lower loneliness\nEvents and interactions in VR felt more immersive than real life for some\nHowever, this comes with a caveat: telepresence fatigue. Some users found screens emotionally exhausting, emphasizing the fragility of digital intimacy.\n\nEconomic and Societal Costs\nLoneliness doesn’t just hurt individuals — it strains entire economies. Increased loneliness leads to:\nRising healthcare costs\nWorkforce productivity loss\nGreater pressure on social services\nIn regions like Cyprus, where aging populations and shrinking community structures prevail, digital intimacy becomes not just an innovation — but a necessity.\nBeyond Online Dating Apps: The SDG and SDG Labs Portfolios\nSocial Discovery Group operates over 60 global brands, including:\nDating.com\nDateMyAge\nDilMil (for South Asians)\nKiseki (for Japanese audiences)\nThis diversification reflects the global loneliness crisis -as people migrate and lose touch with their cultural roots. SDG’s platforms aim to rebuild those connections in new contexts.\nWith SDG Lab Investments , the approach shifts from quantity to quality:\nFocuses on 5–10 projects/year\nOffers operational and strategic support\nInvests in startups building AI relationships, virtual influencers, and platforms for older demographics.\nFor entrepreneurs navigating the complex funding landscape, Alex Kudos, CEO of SDG Lab, offers crucial insights in the Founder`s Guide about choosing between traditional venture capital and venture studio models. Understanding these funding paths becomes essential when building the next generation of connection technologies.\nKey Concerns: Can Tech Really Cure Loneliness?\nBefore we accept virtual intimacy as the cure for our loneliness, or shall I say, disconnection crisis, we need to confront some uncomfortable truths. The research paints a complicated picture, one that challenges a somewhat simplistic, surface narrative around technology engineering its way out of a crisis.\nThe Accessibility Trap\nThe most vulnerable -older, poorer, and less educated users -are also least likely to access digital tools. A 2024 study found that nursing home residents without tech access were more isolated than ever, underlining the danger of digital exclusion.\nQuality Over Quantity\nTech helps maintain existing relationships better than it builds new ones. A 2022 meta-review found only moderate evidence that technology reduces loneliness, particularly for forming close new bonds.\nThe Presence Paradox\nEven the best-designed platforms may fail to offer a true sense of emotional co-presence. According to the European Commission’s 2024 brief,\n“Technology is seen as both enhancing and suppressing connections.”\nThis reflects the paradox of virtual presence: the appearance of intimacy without the psychological reality.\nMore about the Critical Questions ↘\nhttps://thefuturemedia.eu/the-loneliness-economy-how-social-discovery-groups-20m-bet-is-logging-us-into-a-new-kind-of-intimacy/?embedable=true\n\nSDG Lab’s Response: Technology as an Extension, Not a Replacement\nSDG Lab confronts virtual intimacy criticisms directly, viewing ethical concerns as opportunities rather than roadblocks.\nAlex Kudos, CEO of SDG Lab Venture Studio, believes that exclusion is more about poor design than user capability. For example, 90% of DateMyAge users regularly engage in video dating, disproving the stereotype that older people aren’t tech-savvy.\n\\\n\n  \n“Our goal is not to generate maximum engagement, but to promote genuine connection.” — he explains.\n\\\nThat includes resisting the urge to gamify relationships or promote constant stimulation.\nPerhaps most telling is Kudos’s reframing of the “bandage versus cure” debate. The real issue, he argues, may be that traditional relationships are already failing to meet modern emotional needs.\n\\\n\n  \n“Despite the idea that romantic partnerships are the foundation of emotional well-being, many of us are struggling even within those close connections,” Alex says.\nVirtual intimacy, in his view, isn’t a replacement but an expansion: one that amplifies access to connection across geography, identity, and life stage.\n\\\nThese questions aren’t meant to dismiss Lab’s vision. The company may very well be the revolution that our society needs, even if we don’t fully understand it yet. **For Kudos and his team, AI companionship isn’t ‘less than’ human. This type of connection allows people to be more vulnerable, authentic, and introspective in a safe space.**And in our current climate, don’t we all deserve the safety to be ourselves, fully? \\n ✓ Conclusion: Rethinking What It Means to Be Together\n==So, can virtual intimacy solve the loneliness epidemic?==\nMaybe. Research shows promise -but also flags risks. The real challenge is ensuring these tools don’t redefine connection in a way that erodes emotional depth.\nAs Kudos sees it, virtual intimacy isn’t about escaping reality. It’s about creating new spaces for vulnerability, connection, and self-expression. In a world where loneliness is both a personal pain and a public crisis, perhaps the most radical act is simply helping people feel seen — wherever they are.\nSDG Lab is Actively Seeking New Ventures!\nSDG LAB Venture Studio is actively seeking for founders and companies working on the future of human connection.\nIf you’re working on AI, video tech, or social innovation — contact us! \\n",
          "date": "2025-08-03T19:37:07.000Z",
          "link": "https://hackernoon.com/sdg-lab-venture-fund-backs-virtual-intimacy-with-$20-million-but-will-it-work?source=rss",
          "categories": "[\"virtual-intimacy\",\"ai-dating\",\"sdg-lab-venture-fund\",\"the-loneliness-epidemic\",\"ai-and-human-connection\",\"emotional-ai\",\"tech-and-loneliness\",\"good-company\"]"
        }
      },
      {
        "json": {
          "title": "The HackerNoon Newsletter: 9 Things Hollywood Gets Wrong About Hacking (8/3/2025)",
          "content": "How are you, hacker?\n🪐 What’s happening in tech today, August 3, 2025?\n HackerNoon Newsletter\n          brings the HackerNoon \n          homepage\n          straight to your inbox.\n          On this day,\n          \n            Radio Shack Announced TRS-80 Computer in 1977,  Mozilla Corporation was founded in 2005,  Christopher Columbus set sail in 1492, \n          \n          and  we present you with these top quality stories. \n          \n            From \n        AI Agents Are Growing Up - And They Need Zero-Trust Parenting\n       to \n        Turn a Regular Wallet into a Smart Account with EIP 7702 ,\n       let’s dive right in.\n          \n        \nImmutable Backups: Everything You Need To Know To Protect Your Cloud\n \nBy @n2w [ 6 Min read ] Learn how immutable backups prevent ransomware, ensure data integrity, and meet compliance needs with secure, tamper-proof cloud data protection. Read More.\nAI Agents Are Growing Up - And They Need Zero-Trust Parenting\n \nBy @arjun-subedi [ 8 Min read ] AI is evolving fast, but security isn’t keeping up. Discover why zero-trust architecture is critical for safe, scalable AI agent deployment. Read More.\nA Human-centred Framework for Designing Complex AI Solutions for Strategic Decision-making\n \nBy @v3d [ 7 Min read ] The practical framework helps designers, data scientists, and engineers find common ground, aligning the voice and needs of users with the design of AI systems Read More.\nTurn a Regular Wallet into a Smart Account with EIP 7702 \n \nBy @hacker39947670 [ 13 Min read ] Learn how EIP-7702 enables smart wallet features for existing Ethereum accounts. Complete developer guide with code examples. Read More.\n9 Things Hollywood Gets Wrong About Hacking\n \nBy @moonlock [ 11 Min read ] Movie hacking ≠ reality: Real cyberattacks rely on phishing, not fast code. Moonlock, MacPaw’s cybersecurity division, reveals how films get it wrong. Read More.\nA Simple Way to Build a Progress Bar for Your Website’s Image Uploader Using Filestack\n \nBy @filestack [ 7 Min read ] Let’s walk through how to build one manually, and then I’ll show you why we ensured you would never have to. Read More.\nHow an NYC-Based University Boosted Backup Reliability While Slashing Costs​\n \nBy @n2w [ 4 Min read ] Learn how N2W supports St. Johns University, which educates more than 20,000 students and employs over 1,400 staff, using a hybrid environment. Read More.\nFrom Chatbots to Guardians of Data: How BChat Harnesses AI for Secure Messaging\n \nBy @beldexcoin [ 5 Min read ] AI is often associated with collecting personal data but what if AI helped protect user data? Read to know how BeldexAI protects your data on BChat.  Read More.\n🧑‍💻 What happened in your world this week?\nwriting can help consolidate technical knowledge,\n          establish credibility,\n           and contribute to emerging community standards.\n          Feeling stuck? We got you covered ⬇️⬇️⬇️\n        \nANSWER THESE GREATEST INTERVIEW QUESTIONS OF ALL TIME\n        \nWe hope you enjoy this worth of free reading material. Feel free to forward this email to a nerdy friend who'll love you for it.See you on Planet Internet! With love, \n The HackerNoon Team ✌️",
          "date": "2025-08-03T16:04:11.000Z",
          "link": "https://hackernoon.com/8-3-2025-newsletter?source=rss",
          "categories": "[\"hackernoon-newsletter\",\"noonification\",\"latest-tect-stories\",\"immutable-backups\",\"ai-agent\",\"ai-design\",\"web3-ux\",\"cybersecurity\",\"filestack\",\"st.-john's-university-backup\",\"ai\"]"
        }
      },
      {
        "json": {
          "title": "Mobile AI with ONNX Runtime: How to Build Real-Time Noise Suppression That Works",
          "content": "Your phone is more powerful than a desktop computer from five years ago. The latest flagship Android devices pack neural processing units, multi-core CPUs that would make 2019 laptops jealous, and RAM configurations that seemed impossible just a few years back. So why does it feel like we're barely scratching the surface of what's possible with AI on mobile?\nSure, you can now even run quantized versions of Llama and DeepSeek models locally on your device. But let's be honest - those conversations still feel clunky, slow, and nowhere near the seamless experience users expect from their apps. The hype around on-device conversational AI is real, but the practical reality? We're not quite there yet.\nHere's where most developers miss the opportunity: conversational AI isn't the only game in town. While everyone's chasing the next ChatGPT clone, there's a massive untapped potential in specialized AI applications that actually work brilliantly on mobile hardware right now.\nTake noise suppression. Your users are constantly battling background noise during calls, recordings, and voice messages. Wind, traffic, crying babies, barking dogs - it's an endless war against audio chaos. But what if your app could eliminate that noise in real-time, locally, without sending a single byte to the cloud?\nThis isn't science fiction. It's happening today, and any Android developer can implement it. The tools are mature, the performance is there, and your users will immediately notice the difference.\nONNX Runtime: Your Gateway to Mobile AI\nThe mobile AI landscape is fragmented. PyTorch dominates research, TensorFlow rules production, and countless specialized frameworks emerge for specific use cases. For Android developers, this creates a painful choice: commit to one ecosystem or maintain separate pipelines for different models.\nAfter evaluating mobile AI frameworks, we chose ONNX Runtime for several compelling reasons that directly impact Android development.\nWider Compatibility Across Android Versions\nUnlike Google's LiteRT (formerly TensorFlow Lite), which mandates a minimum SDK level of 31 (Android 12), ONNX Runtime comfortably supports Android API levels as low as 24 (or even 21, if you are a magician). Our project’s minimum supported version was API 28, making ONNX Runtime the clear choice to reach a broader audience without excluding millions of active users on Android 10 and earlier devices.\nSeamless Cross-Framework Integration\nONNX Runtime’s greatest strength lies in its framework-agnostic nature. Whether your AI models originate from PyTorch, TensorFlow, or even traditional ML libraries like scikit-learn, exporting models to ONNX allows uniform deployment across Android, iOS, desktops, and cloud environments. This flexibility significantly simplifies maintenance, enabling a unified pipeline rather than juggling multiple framework-specific tools.\nLightweight and Modular Deployment\nIntegration with ONNX Runtime is straightforward. With a compact Maven AAR (around 5–7 MB for CPU builds), the library integrates cleanly into your existing Android app without introducing unnecessary dependencies like Google Play Services or requesting additional user permissions. This streamlined deployment keeps your app lean, performant, and secure.\nProven Real-Time Performance\nONNX Runtime is battle-tested in demanding real-time scenarios. Audio-processing models, such as noise suppression or speech enhancement, consistently deliver inference speeds under 4 ms per audio frame on standard mobile hardware - comfortably within real-time performance requirements. Our team leveraged this exact capability for reliable, low-latency noise suppression.\nUltimately, ONNX Runtime provided our team not just convenience, but strategic advantage - allowing us to maintain compatibility, performance, and simplicity without compromises. If your project demands accessible, performant, and scalable mobile AI, ONNX Runtime could very well be your optimal choice.\nIntegration Plan: Setting Up ONNX Runtime\nThe default ONNX Runtime package weighs in at a hefty 27MB. For a mobile app, that's not just bloat - it's a user acquisition killer. Research shows that for every 6MB increase in APK size, install conversion rates drop by 1% (I should note that the study is not the newest one, and concerns mainly not the most developed countries, but still, it is worth considering)\nThe solution? A custom minimal build that strips your deployment down to exactly what you need. Our DTLN noise suppression implementation clocks in at just 7.1MB - a 70% size reduction that keeps your app lean and your users happy.\nONNX Runtime's architecture is modular by design. The full package includes execution providers for GPU acceleration (NNAPI, Vulkan), dozens of operators you'll never use, and compatibility layers for edge cases that don't apply to your specific model. By building only what you need, you eliminate this overhead entirely.\nStep 1: Convert Your Models to ORT Format\nBefore building, convert your ONNX models to ORT format. This optimized format removes unused graph nodes and operator definitions, further reducing your final binary size.\n\\\npython -m onnxruntime.tools.convert_onnx_models_to_ort <onnx model file or dir> &nbsp;&nbsp;&nbsp;--target_platform {arm,amd64}\n\nStep 2: Create Operator Configuration\nAfter converting all the necessary models, configuration files with the necessary operators that will be required for the minimal build of ONNX will also be generated.\nWhen using several models, combine all the configuration files into one.\nThe final file will look something like this:\n\\\n# Generated from model/s:\nai.onnx;1;Transpose\nai.onnx;6;Sigmoid\nai.onnx;7;Add,LSTM\nai.onnx;9;MatMul\nai.onnx;11;Concat,Slice,Squeeze,Unsqueeze\nai.onnx;1;Transpose\nai.onnx;5;Reshape\n//other operators\n\nStep 3: Execute Custom Build\nWith your operator configuration ready, build ONNX Runtime from source with minimal dependencies:\n\\\n./build.sh --android \\\n  --android_sdk_path ~/Library/Android/sdk \\\n  --android_ndk_path ~/Library/Android/sdk/ndk/28.0.12674087 \\\n  --android_abi arm64-v8a \\\n  --android_api 24 \\\n  --minimal_build \\\n  --include_ops_by_config path/to/required_operators.config \\\n  --build_java \\\n  --config=Rel\n\n--minimal_build: Excludes unnecessary execution providers and operators\n--includeopsby_config: Includes only operators specified in your config file\n--android_abi armeabi-v7a: Targets ARM32 for maximum device compatibility\n--android_api 24: Maintains compatibility with Android 7.0+\nIf you also want to support old devices, repeat step 3 with –android_abi armeabi-v7a and them merge both resulting aar files with following script:\n\\\n#!/usr/bin/env sh\n\n# Clean up from previous runs, if any\nrm -rf merge-tmp\nmkdir -p merge-tmp\ncd merge-tmp\n\necho \"Unzipping each ABI-specific AAR...\"\nmkdir a64\nunzip ../onnxruntime-arm64-v8a.aar -d a64\n\nmkdir a32\nunzip ../onnxruntime-armeabi-v7a.aar -d a32\n\necho \"Preparing universal base from arm64 AAR...\"\nmkdir universal\ncp -r a64/* universal\n\nrm -rf universal/jni\nmkdir -p universal/jni\n\n\necho \"Merging native libs from each architecture...\"\nmkdir -p universal/jni/arm64-v8a\ncp a64/jni/arm64-v8a/*.so universal/jni/arm64-v8a\n\nmkdir -p universal/jni/armeabi-v7a\ncp a32/jni/armeabi-v7a/*.so universal/jni/armeabi-v7a\n\n\n# Re-zip contents of 'universal' to create a new AAR\necho \"Creating universal AAR...\"\ncd universal\nzip -r onnxruntime-universal.aar ./*\n\necho \"Done! The merged AAR is at:\"\necho \"$(pwd)/onnxruntime-universal.aar\"\n\nThe minimal build approach transforms ONNX Runtime from a deployment liability into a strategic advantage. Your users get the full AI capability without the bloat, and your app maintains the lean profile that modern mobile development demands.\nNext, let's see this optimized runtime in action with real-time DTLN noise suppression.\nWhy Audio Processing Showcases AI Value\nAudio processing is the perfect introduction to mobile AI - delivering immediate, tangible value while your competitors wrestle with bloated language models that drain batteries and require constant internet connections.\nThe Daily Audio War Your Users Are Fighting\nSarah records voice messages while walking through a busy street. Between honking taxis, construction noise, and subway rumbles, she re-records messages three times before giving up and typing instead.\nMarcus joins client calls from his home office, which doubles as his toddler's playroom. Every presentation becomes a cycle of \"mute, unmute, apologize for the crying.\"\nElena creates YouTube content in her apartment but spends hours in post-production cleaning up neighbor noise, traffic, and air conditioning hum.\nThese aren't edge cases - they're the reality of modern mobile computing where everyone expects professional results from consumer hardware in chaotic environments.\nWhy Noise Suppression Creates Instant \"Wow\" Moments\nAudio quality improvements trigger immediate emotional responses. Unlike other AI applications requiring explanation, noise suppression provides instant gratification users can perceive within seconds. Play someone their own voice - crystal clear - after removing background noise, and watch their reaction. They don't need to understand LSTM networks; they just know their audio sounds professional.\nThe beauty of audio processing as an AI showcase lies in universality. Everyone understands good audio, everyone has experienced bad audio, and everyone immediately recognizes improvement when noise disappears. You're not asking users to trust your AI - you're proving its value in the most direct way possible.\nBuilding a Production-Ready Demo: Real-Time Noise Suppression\nNow, let's build a sample project that demonstrates the practical power of ONNX Runtime on Android. Rather than a basic \"hello world\" example, we'll create something close to production quality - a real-time noise suppression demonstration where users can record audio in noisy environments and experience the striking difference between their original recording and the AI-cleaned version.\nYou can find a complete sample here, on my Github: https://github.com/linreal/android-onnx-showcase.\nModels, used in sample are from https://github.com/breizhn/DTLN\nQuick Implementation Overview\nBefore diving into DTLN's dual-path architecture, let's establish how the pieces fit together. The beauty of this implementation lies in its clean separation of concerns - each component has a single responsibility, making the system both testable and maintainable.\nThe Core Components\nAt the heart of our noise suppression pipeline sit three key interfaces that work together:\n\\\ninterface NoiseSuppressor {\n    suspend fun initialize()\n    fun processChunk(audioChunk: FloatArray): FloatArray\n    fun release()\n}\n\ninterface AudioRecorder {\n    suspend fun startRecording(): Flow<ShortArray>\n    suspend fun stopRecording()\n}\n\ninterface ConcurrentAudioProcessor {\n    suspend fun startProcessing(\n        suppressor: NoiseSuppressor,\n        rawOutputFile: File,\n        processedOutputFile: File\n    )\n    suspend fun stopProcessing(): ProcessingResult\n}\n\nThe NoiseSuppressor encapsulates all ONNX Runtime complexity behind a simple interface. Feed it audio chunks, get back denoised audio. The stateful nature of DTLN is completely hidden - the implementation maintains LSTM states internally between calls.\nData Flow Architecture\n\\\nAudioRecorder → Flow<ShortArray> → ConcurrentAudioProcessor → NoiseSuppressor → Processed Audio Files\n\n\\\nThe ConcurrentAudioProcessor orchestrates the entire pipeline. It subscribes to the audio recorder's Flow, converts audio formats, processes chunks through the noise suppressor, and writes both original and processed audio to files simultaneously.\n\\\nrawAudioRecorder.startRecording().collect { audioChunk ->\n    // Convert format for processing\n    val floatChunk = AudioConversionUtils.shortArrayToFloatArray(audioChunk)\n\n    // Process through DTLN\n    val processedChunk = suppressor.processChunk(floatChunk)\n\n    // Save both versions concurrently\n    launch { rawFileWriter.writeAudioData(floatChunk) }\n    launch { processedFileWriter.writeAudioData(processedChunk) }\n}\n\nWhy This Architecture Works\nReactive Processing: The Flow-based design ensures your UI remains responsive. Audio processing happens on background threads while the main thread handles user interactions.\nFormat Isolation: Each component works with its preferred audio format. AudioRecorder produces ShortArray (16-bit PCM), while NoiseSuppressor expects FloatArray (normalized samples). Conversion happens at the boundary.\nError Boundaries: If ONNX initialization fails, only the NoiseSuppressor component is affected. The audio recorder and file writers continue functioning, ensuring graceful degradation.\nResource Management: Each component manages its own resources. The ConcurrentAudioProcessor coordinates lifecycle events but doesn't own the underlying implementations.\nThis modular approach means you can swap out the DTLN implementation for any other ONNX model, replace the audio recorder with a file-based source, or modify the output format without touching other components. The architecture scales from proof-of-concept to production deployment.\nNext, we'll explore the DTLN architecture that makes this magic happen.\nUnderstanding DTLN Architecture\nTraditional noise suppression approaches face a fundamental tradeoff. Frequency-domain methods excel at removing stationary noise (air conditioning, fan hum) but struggle with dynamic sounds like speech or music bleeding through. Time-domain approaches handle complex, changing signals well but often introduce artifacts or fail with consistent background noise.\nDTLN sidesteps this limitation entirely through its dual-path architecture:\nStage 1: Frequency Domain Processing The first model operates in the frequency domain, analyzing the spectral characteristics of your audio. It generates a suppression mask that identifies which frequency components contain noise versus speech. This stage excels at removing stationary background noise - the steady hum of air conditioning, traffic, or office chatter.\n\\\n// Stage 1: Frequency domain mask estimation\n\nval (magnitude, phase) = fftProcessor.forward(inBuffer)\nval outMask = model1.run(mapOf(\"input_2\" to magnitudeTensor, \"input_3\" to lstmState))\nfor (i in magnitude.indices) {\n    magnitude[i] *= outMask[i] // Apply suppression mask\n}\n\nStage 2: Time Domain Refinement The masked frequency-domain signal gets converted back to the time domain, then fed into a second model that operates directly on the audio waveform. This stage catches what the frequency analysis missed - handling dynamic noise patterns, preserving speech naturalness, and cleaning up any artifacts from the first stage.\n\\\n// Stage 2: Time domain refinement\n\nval estimatedBlock = fftProcessor.inverse(magnitude, phase)\nval finalBlock = model2.run(mapOf(\"input_4\" to estimatedTensor, \"input_5\" to lstmState))\n\nThe Mobile-First Design Philosophy\nDTLN's architecture reflects years of practical mobile AI deployment experience. Every design decision prioritizes real-world constraints over academic benchmarks.\nChunk-Based Processing The model processes audio in 512-sample chunks (32ms at 16kHz), striking the optimal balance between latency and context. This chunk size is small enough for real-time processing but large enough to provide meaningful temporal context for the LSTM networks.\n\\\ncompanion object {\n    private const val BLOCK_LEN = 512  // 32ms chunks\n    private const val BLOCK_SHIFT = 128  // 75% overlap for smooth processing\n}\n\nStateful LSTM Networks Both models use LSTM (Long Short-Term Memory) networks that maintain internal state between chunks. This temporal memory allows the model to distinguish between speech and noise based on context, not just instantaneous audio characteristics.\n\\\nclass NoiseSuppressorImpl {\n    // These tensors maintain LSTM state between processing calls\n    private var input3Tensor: OnnxTensor? = null  // Model 1 LSTM state\n    private var input5Tensor: OnnxTensor? = null  // Model 2 LSTM state\n\n    fun processChunk(audioChunk: FloatArray): FloatArray {\n        // State automatically carries forward to next chunk\n        val result1 = model1.run(mapOf(\"input_3\" to input3Tensor))\n        input3Tensor?.close()\n        input3Tensor = result1[1] as OnnxTensor  // Update state\n\n        // State continuity ensures smooth, artifact-free processing\n    }\n}\n\nPerformance Characteristics That Matter\nUnderstanding DTLN's architecture helps predict its behavior in your application. These performance characteristics directly impact user experience:\nLatency Profile\nAlgorithmic Delay: 32ms (one chunk processing time)\nInference Time: 3-4ms per chunk on mid-range Android hardware\nTotal Latency: ~35ms end-to-end (imperceptible for most use cases)\nResource Usage\nMemory Footprint: ~28MB during active processing\nCPU Usage: 12-18% on typical mid-range device\nBattery Impact: Negligible for typical recording sessions\nThese characteristics make DTLN particularly well-suited for mobile applications where users expect immediate results without sacrificing device performance or battery life.\nONNX Runtime Integration Strategy\nGetting ONNX Runtime working on Android isn't just about adding a dependency to your build.gradle. The difference between a proof-of-concept that crashes under load and a production-ready implementation lies in the session configuration, memory management, and resource allocation strategy.\nAs we already prepared a minimal runtime build, it’s time to look into what lies next.\nSession Configuration for Mobile Reality\nThe default ONNX Runtime session configuration assumes you're running on a server with abundant resources. Mobile devices operate under entirely different constraints: limited memory, thermal throttling, and users who expect apps to remain responsive during AI processing.\n\\\nprivate val sessionOptions = OrtSession.SessionOptions().apply {\n    setIntraOpNumThreads(numThreads.coerceIn(1, 4))\n    setInterOpNumThreads(numThreads)\n    setMemoryPatternOptimization(true)\n    setOptimizationLevel(OrtSession.SessionOptions.OptLevel.ALL_OPT)\n    setExecutionMode(OrtSession.SessionOptions.ExecutionMode.SEQUENTIAL)\n}\n\nYour first instinct might be to use all available CPU cores for maximum performance. Resist this urge. Mobile devices prioritize battery life over raw computational speed, and Android's thermal management will throttle aggressive CPU usage within seconds.\nThe sweet spot for real-time audio processing sits between 2-4 threads, determined by your device's core count:\n\\\nprivate val numThreads = Runtime.getRuntime().availableProcessors().coerceIn(1, 4)\n\nThis configuration delivers 95% of maximum performance while consuming 60% less battery than an unrestricted thread pool. Your users notice the efficiency gains more than the minor latency difference.\nsetMemoryPatternOptimization(true) activates ONNX Runtime's most impactful mobile optimization. This setting analyzes your model's memory access patterns during the first few inference calls, then pre-allocates memory pools to minimize garbage collection pressure during real-time processing.\n\\\nsetExecutionMode(OrtSession.SessionOptions.ExecutionMode.SEQUENTIAL)\n\nSequential execution might seem counterintuitive when parallel processing offers higher throughput. However, real-time audio processing demands predictable latency over peak performance. Parallel execution creates latency spikes when thread synchronization occurs - precisely what you want to avoid during live audio processing.\nSequential execution delivers consistent 3-4ms inference times, while parallel mode ranges from 2-8ms with unpredictable spikes. Users perceive consistency as quality.\nMemory Pre-allocation: The Performance Multiplier\nThe most critical optimization for mobile ONNX Runtime applications involves pre-allocating tensors that get reused across inference calls. Creating tensors during inference triggers memory allocations that accumulate into significant performance bottlenecks.\n\\\n// Pre-allocate tensors during initialization\ninput3Tensor = createZeroTensor(INP_SHAPE_2)  // Model 1 LSTM state\ninput5Tensor = createZeroTensor(INP_SHAPE_2)  // Model 2 LSTM state\n\nprivate fun createZeroTensor(shape: LongArray): OnnxTensor {\n    val env = requireNotNull(env) { \"ONNX Environment not initialized\" }\n    val size = shape.reduce { acc, i -> acc * i }.toInt()\n    return OnnxTensor.createTensor(env, FloatBuffer.allocate(size), shape)\n}\n\nGarbage Collection Pressure Reduction - Creating tensors during inference generates objects that must be garbage collected. Pre-allocation moves this cost to initialization time, keeping inference paths allocation-free.\nMemory Fragmentation Prevention - Repeated tensor creation fragments heap memory, leading to unexpected allocation failures. Pre-allocated tensors maintain consistent memory layout.\nLatency Consistency - Allocation costs are unpredictable and can introduce latency spikes during real-time processing. Pre-allocation ensures consistent inference timing.\nThese integration strategies transform ONNX Runtime from a research tool into a production-ready component. The configuration choices, memory management patterns, and error handling approaches directly impact user experience in ways that become apparent only under real-world usage conditions.\nYou can look into https://github.com/linreal/android-onnx-showcase/blob/main/app/src/main/java/gos/denver/onnxshowcase/audio/impl/NoiseSuppressorImpl.kt for a full source code.\nConclusion: AI as Competitive Advantage\nThe mobile AI landscape is experiencing a fundamental shift. While competitors chase resource-hungry language models and cloud-dependent solutions, there's a massive opportunity in specialized, on-device AI that delivers immediate value to users.\nKey Takeaways for Android Developers\nOn-device AI is production-ready today. The combination of ONNX Runtime's optimization capabilities and purpose-built models like DTLN delivers performance that matches or exceeds cloud solutions while eliminating latency and connectivity requirements. Your users get instant results, and you get a feature that works everywhere - from subway tunnels to airplane mode.\nAPK size optimization transforms deployment strategy. Our minimal ONNX Runtime build reduced library size by 70% without sacrificing functionality. This isn't just about storage - it directly impacts user acquisition. When AI features add 7MB instead of 27MB to your app, the cost-benefit equation shifts dramatically in your favor.\nUser experience trumps algorithmic sophistication. DTLN isn't the most advanced noise suppression model available, but it strikes the perfect balance between quality, performance, and resource consumption for mobile deployment. Users don't care about model architecture - they care about crystal-clear audio in noisy environments.\nApps implementing on-device AI gain three competitive advantages: Privacy by Design (no sensitive data leaves the device), Offline Reliability (consistent experience regardless of network conditions), and Cost Structure Benefits (no cloud inference costs or operational expenses that scale with usage).\nNext Steps and Exploration\nThe techniques demonstrated here extend far beyond noise suppression. ONNX Runtime enables practical deployment of models for audio processing, computer vision, natural language tasks, and sensor fusion applications.\nThe complete implementation is available on GitHub: android-onnx-showcase. Use it as a foundation for your own AI-powered features.\nYour Android app deserves AI that enhances user experience without compromising performance, privacy, or reliability. ONNX Runtime makes this vision achievable today. The tools are ready, the performance is proven - time to build something amazing.\nFound this implementation useful? Star the GitHub repository and share your results. The mobile AI community grows stronger when we share practical knowledge.\nFollow me for more deep-dives into production-ready mobile AI implementations that your users will actually notice and appreciate. \\n",
          "date": "2025-08-03T16:03:09.000Z",
          "link": "https://hackernoon.com/mobile-ai-with-onnx-runtime-how-to-build-real-time-noise-suppression-that-works?source=rss",
          "categories": "[\"mobile-ai\",\"onnx-runtime\",\"on-device-ai\",\"mobile-ai-performance\",\"android-ai-sdk\",\"dtln-noise-reduction\",\"lightweight-ai-deployment\",\"onnx-runtime-android\"]"
        }
      },
      {
        "json": {
          "title": "The Real Reason Most Indie Games Flop (It Has Nothing To Do With Gameplay)",
          "content": "High-Quality Games Are Getting Lost\nIn the past few years, the gaming industry has seen a tidal wave of investment. Tens of billions of dollars have flowed into studios and publishers—more than ten times the historical average. The result is exactly what you’d expect: an explosion of high-quality content.\nFrom 2019 to 2023, the number of games released on Steam nearly doubled, reaching over 14,500 new games per year. Meanwhile, the App Store and Google Play are flooded with over a thousand apps published every day, offering players more choice than ever. Those distribution channels have become saturated.\nDespite the surge in funding and quality, most games are quietly slipping through the cracks. I meet founders all the time whose launch strategy is no deeper than: “We’re making a great game and putting it up on Steam Early Access.”That’s not a go-to-market strategy—that’s wishful thinking. \\n \nWe’ve Seen This Story Before\nIn the early 2000s and throughout the 2010s, Hollywood studios kept doubling down on blockbuster content—fund content, release in theaters, repeat. The assumption was that the better the content, the better the outcome. Then Netflix changed the game. They didn’t just create shows. They changed how audiences discovered and consumed content. It was a new distribution model: personalized, frictionless, on-demand access to content, delivered over the internet, bypassing movie theaters entirely. Today, nearly every major player from Disney to HBO follows that same model. Content still matters, but distribution is what changed the industry.\nThe same happened in music. Record labels used to control everything through their artist rosters. But Spotify, YouTube, and later TikTok shifted the power. They didn’t make music—they just made it easier to access and share. Today, artists break through because of those platforms. Labels that once owned the pipeline now find themselves negotiating with it.\nGaming is following the same arc. Incredible content, saturated channels, and a growing realization that discovery—not quality—is the real bottleneck. \\n \nDistribution Is the Bottleneck\nWe’re not short on great games. We’re short on new ways to make people care.\nSteam saw more than 40 games launched a day in 2023. Mobile app stores are even more saturated, with over 1,000 apps published daily. Discovery hasn’t kept up with the flood of content. It’s been overwhelmed by it.\nSteam has added curators, tags, and algorithmic feeds, but most releases still sink within days. Mobile stores are worse—prime real estate is dominated by paid ads, and organic discovery is nearly nonexistent. There’s simply too much content, not enough visibility, and no efficient way to rise above the noise unless you pay your way to the front.\nThis saturation is not just a discovery problem—it’s an economic one.\nApple’s ATT rollout in 2021 disrupted mobile user acquisition overnight. Over 80% of iPhone users became invisible to targeted ads, breaking the model that many mobile studios relied on to find and convert high-value players. CPI costs jumped nearly 90%. ROAS dropped. What once worked no longer does.\nAt the same time, most games don’t make money. But it’s not always because the games are bad—it’s because they’re invisible. On Steam, 67% of games have earned less than $5,000 in lifetime revenue—and more than half never crossed $1,000. The average player sticks to four games a year. On mobile, the top 1% of games account for over 90% of downloads. Nearly 60% of apps on the App Store don’t even have a single review.\nThere’s no middle class. Big-budget games and breakout hits get all the attention. Everyone else fights for scraps. The end result is the “rich get richer.”\nIndies can’t afford to brute-force their way into visibility. They can’t outspend or outmarket incumbents. And yet most studios still rely on the same tired playbook: launch on Steam, pay the platform tax, hope the algorithm works. That’s not a strategy. It’s a gamble (tho, once in a blue moon, the algorithm favors an indie and it breaks out).\nDistribution is not a side task—it’s the real product challenge. And it’s the one thing this industry hasn’t meaningfully rethought.\n\\\nThe Shift Has Already Started\nSome companies aren’t waiting for better distribution. They’re building it.\nEpic didn’t just launch a hit game—they turned Fortnite into a platform. With UEFN (Unreal Editor for Fortnite), developers can now build games inside Fortnite using AAA tools, publish instantly, and tap into a built-in audience of millions. Discovery and monetization are integrated. The friction is gone.\nRoblox took it even further. It’s a closed-loop system where content and distribution live in the same place. Creators build games, users discover them, and both sides benefit. What makes Roblox especially interesting right now is this: distribution is ahead of content. The platform has reach. It just doesn’t have enough standout experiences. For developers, that’s an opportunity to succeed not by out-marketing the competition, but simply by building something better.\nOther players are entering the space from the edges. YouTube is embedding games directly into its platform. Discord lets users play inside servers. Netflix now offers games alongside its shows. Even Telegram supports native games through mini-apps. All of these are experiments in rethinking where and how games are discovered.\nAnd then there’s the web.\nThe open web is becoming viable again—not just for casual games, but for real, session-based experiences. There’s no platform tax. No gatekeepers. No approval queues. A single build can reach anyone with a browser. For developers, that’s freedom. For players, it’s one click away.\nWe’re starting to see early signs of this shift. BAPBAP built an early fanbase in 2023 through a web version before launching on Steam, fueling thousands of installs on day one. Hero Wars took the same path years earlier—starting on the web, then expanding to mobile, where it surpassed 150 million installs and $1.5 billion in revenue.\nBut most developers are still funneling their games into the same overcrowded storefronts—fighting over the same algorithms, the same paid installs, and the same limited real estate. It’s time to shift that energy. Instead of competing in the same narrow lanes, the opportunity is to explore new ones. Go where users already are. Build for the platforms that actually enable discovery. Let distribution shape your strategy—not follow it.\nThe future won’t be defined by who builds the best-looking game. It will be defined by who rethinks the path to finding it.",
          "date": "2025-08-03T15:50:07.000Z",
          "link": "https://hackernoon.com/the-real-reason-most-indie-games-flop-it-has-nothing-to-do-with-gameplay?source=rss",
          "categories": "[\"gaming\",\"game-discovery\",\"indie-game-marketing\",\"mobile-game-visibility\",\"game-development\",\"game-distribution-strategy\",\"app-store-visibility-hacks\",\"game-launch-strategy-2025\"]"
        }
      },
      {
        "json": {
          "title": "10 Ways AI Is Shaping the Future of Mobile App Development",
          "content": "Artificial Intelligence (AI) in mobile apps was synonymous with chatbots for an extended period. Ask a question and get an answer to the extent of that on many users. This perception would have been long outdated by 2025. Today, AI is not a mere feature; it is fast becoming the invisible force that shapes how an app is built, how it unfolds upon its release, and the way it interacts with users at a very intimate level. \nWalking this path, mobile app development is getting changed, and AI is leading it. Even though conversational AI still holds important roles, developers and businesses have begun utilizing machine learning, predictive analytics, computer vision, natural language processing, and generative AI to their fullest capacity to produce intelligent and adaptive experiences, many of which latter thought to be from the far future.\nWhat does this mean for the current mobile app development scenario? Transitioning from static apps to those learning, adapting, and anticipating is the forecasted step. Let's further know how well AI is reshaping mobile app development services way beyond the virtual assistant zone.\nTop 10 Ways AI Is Transforming Mobile App Development in 2025\nAI is driving a massive shift in mobile app development changing how apps interact, adapt, and perform. From personalization to predictive design, here are the top ten ways AI is revolutionizing the mobile experience:\nPersonalized Experiences at Scale\nSome of the most visible changes in the AI field are the enhancement of user-oriented experiences. Earlier, the apps had the very same layout, content, and function for all users. Now, AI helps apps observe user behaviour, learn from these observations, and adapt their content and interface accordingly. Behind the scenes, AI goes on to analyze it all to provide every user with a very special session just for them.\nThis level of personalization has become a core expectation, prompting every mobile app development company to incorporate such features. Whether it's a cross platform mobile app development project or a native solution, the need to create contextual user experiences is paramount.\nIntelligent Search and Discovery\nAnother major shift has been the interaction facet of search within apps. Conventional search functions depended significantly on exact keywords, often discouraging users from locating what they wanted. AI radically enhanced this experience to make search more intelligent and conversational. Natural Language Processing (NLP) enables users with the ability to ask questions or make search queries using off-the-cuff language, and AI looks at the underlying intention of the words.\nIn modern applications, the integration of an intelligent layer is standard practice among companies specializing in custom mobile app development services.\nPredictive Capabilities and Anticipatory Design\nOne compelling ability of AI is prediction. AI can analyze patterns in user behavior and come up with what a user may want to see next, and offer it before the user asks for it. The anticipatory design, as people today commonly know it, makes the app truly clever by putting up suggestions, reminders, or shortcuts that really resonate with the user's habits.\nAI in Design and Development \nAI is influencing not only how apps work but also how they are created. Mobile app development, which embodies long design cycles and manual testing, is now aided and accelerated by AI in each step. There are now AI-aided tools that help designers create wireframes or mockups based on simple sketches or text prompts.\nHence, repetitive tasks will require very little time and thus allow teams to invest more in creativity and strategy. This transformation is reshaping enterprise mobile app development, helping larger organizations deploy sophisticated solutions faster and with higher quality assurance.\nSmarter App Testing and Maintenance\nAI finds another key use case in quality assurance. Traditional methods are unable to keep pace with short deployment cycles and constant upgrades. AI-based test frameworks simulate user behavior or find edge cases and even predict where the bugs are most likely to appear based on prior data. Besides that, AI is doing wonders post-launch by monitoring app performance. It records crashes, wanders into behavioral analysis, detects anomalies, and blows the whistle when it stumbles upon deviations from the normal.\nMultimodal Interaction with AI\nFurthermore, this has been extended and pushed towards sensory interaction, particularly in voice, image, and gesture recognition. Making apps more inclusive and user-friendly, especially for those who use experimental hands-free or visual inputs. AI in voice recognition enables users to interact with apps to initiate commands and have them respond through speech, giving ways of interface new fluid and human feeling. \nComputer vision aids in the identification of faces by the app, scanning QR codes, or physically identifying objects via the smartphone camera. Today, users don't just want to know what is meant by mobile application development; they demand smarter, intuitive apps that understand them deeply.\nSecurity and Fraud Detection\nSecurity is another area where AI technologies have taken a giant leap. Older computer security models deal with threats of the past, whereas the cyber-threats of today are an altogether different animal. Using AI-based models, these computers now analyze millions of interactions occurring among interconnected devices to detect suspicious activity, irregular login patterns, or even data theft. \nSuch apps now use AI to watch transactions for fraudulent behavior before any harm is done to users. The biometric security system, whether it be facial recognition or fingerprint scanning, is an AI-enabled gateway to an easy and secure authentication method.\nRise of Generative AI in Mobile Apps\nIn the last year, generative AI has emerged as one of the most thrilling areas in the app development world. Tools such as GPT-4 and DALL·E of OpenAI have opened a new avenue for users to generate text, images, music, and videos, with a mere handful of commands. Mobile applications are using this technology to create generative spaces for creators to work in. \nFrom AI photo editing, avatar generation, to story ideation, to productivity apps, users have become accustomed to AI either assisting or potentially co-creating content with them.\nFrom Reactive to Adaptive Apps\nOne of the most revolutionary and disruptive changes is from reactive to adaptive app experiences. Traditional apps respond to user input. This is where AI-enabled apps excel they can learn behaviors from their human users, changing the interface, suggesting actions, and even dynamically reprogramming their workflows. For instance, depending on whether a user's mood is detected from voice tone or facial expression, a mental wellness app may choose to deliver a particular set of suggestive activities.\nAccessibility and Inclusivity Through AI\nAI has emerged as an enabler to infuse accessibility into mobile app creation, thereby catering to a variety of user needs. These days, apps offer a wide range of capabilities, including real-time conversion between text and speech, and vice versa. AI translations and UI variations that meet the needs of visually impaired users. Thus, by breaking down the barriers of language, cognition, and physicality it necessitates that technology assist everyone, irrespective of ability or creed.\nThe Challenges Ahead\nIntegrating AI into mobile app development services is challenging when it comes to ensuring data privacy, model accuracy, algorithmic bias, and development budgets. Trust is key from the user's perspective. They have to be transparent about the collection and use of data, conform to global privacy laws, continuously monitor, and update the model to avoid unintended consequences. \nDespite all these problems, the benefits of AI are significant enough to overpower any challenge. If applied properly, AI can help developers build smarter, faster, and safer mobile apps.\nClosing Thoughts: Future-Ready with AI\nMobile app development would become intelligent even in the manner of their behavior, way of their imagination, and way of their construction. It means we are during those moments when AI chips on the device will make processing real-time but safer and efficient; emotion recognition and zero-UI interfaces will set new limits; and then AI will be analyzed as a collaborator instead of a tool. \nFor developers, the latest technologies must be mastered with data-first thinking. Businesses must do the innovation, invest in more innovative experiences, and keep the user as a priority.\nWhether it’s for startups or enterprises, those looking for the best mobile app development company need to focus on long-term value, where AI meets user-centric design. As AI becomes the backbone of digital evolution, the future of cross platform mobile app development and beyond is undeniably innovative, intuitive, and transformational.\n\\n",
          "date": "2025-08-03T15:29:15.000Z",
          "link": "https://hackernoon.com/10-ways-ai-is-shaping-the-future-of-mobile-app-development?source=rss",
          "categories": "[\"ai-mobile-app-development\",\"mobile-app-development\",\"ai-trends\",\"predictive-mobile-ux\",\"generative-ai-apps\",\"cross-platform-ai-apps\",\"custom-app-development\",\"good-company\"]"
        }
      },
      {
        "json": {
          "title": "Solving Coding Puzzles: The Evolution of Programmer Assistance Tools",
          "content": "Table of Links\nAbstract and 1 Introduction\n2. Prior conceptualisations of intelligent assistance for programmers \n3. A brief overview of large language models for code generation \n4. Commercial programming tools that use large language models \n5. Reliability, safety, and security implications of code-generating AI models \n6. Usability and design studies of AI-assisted programming \n7. Experience reports and 7.1. Writing effective prompts is hard\n7.2. The activity of programming shifts towards checking and unfamiliar debugging\n7.3. These tools are useful for boilerplate and code reuse\n8. The inadequacy of existing metaphors for AI-assisted programming \n8.1. AI assistance as search \n8.2. AI assistance as compilation \n8.3. AI assistance as pair programming \n8.4. A distinct way of programming \n9. Issues with application to end-user programming \n9.1. Issue 1: Intent specification, problem decomposition and computational thinking\n9.2. Issue 2: Code correctness, quality and (over)confidence \n9.3. Issue 3: Code comprehension and maintenance \n9.4. Issue 4: Consequences of automation in end-user programming \n9.5. Issue 5: No code, and the dilemma of the direct answer \n10. Conclusion \nA. Experience report sources \nReferences\n2. Prior conceptualisations of intelligent assistance for programmers\nWhat counts as ‘intelligent assistance’ can be the subject of some debate. Do we select only features that are driven by technologies that the artificial intelligence research community (itself undefined) would recognise as artificial intelligence? Do we include those that use expert-coded heuristics? Systems that make inferences a human might disagree with, or those with the potential for error? Mixed-initiative systems (Horvitz, 1999)? Or those that make the user feel intelligent, assisted, or empowered? While this debate is beyond the scope of this paper, we feel that to properly contextualise the qualitative difference made by large language models, a broad and inclusive approach to the term ‘intelligence’ is required.\n\\\nEnd-user programming has long been home to inferential, or intelligent assistance. The strategy of direct manipulation (Shneiderman & Norwood, 1993) is highly successful for certain types of limited, albeit useful, computational tasks, where the interface being used (“what you see”, e.g., a text editor or an image editor) to develop an information artefact can represent closely the artefact being developed (“what you get”, e.g., a text document or an image). However, this strategy cannot be straightforwardly applied to programs. Programs notate multiple possible paths of execution simultaneously, and they define “behaviour to occur at some future time” (Blackwell, 2002b). Rendering multiple futures in the present is a core problem of live programming research (Tanimoto, 2013), which aims to externalise programs as they are edited (Basman et al., 2016).\n\\\nThe need to bridge the abstraction gap between direct manipulation and multiple paths of execution led to the invention of programming by demonstration (PBD) (Kurlander et al., 1993; Lieberman, 2001; Myers, 1992). A form of inferential assistance, PBD allows end-user programmers to make concrete demonstrations of desired behaviour that are generalised into executable programs. Despite their promise, PBD systems have not achieved widespread success as end-user programming tools, although their idea survives in vestigial form as various “macro recording” tools, and the approach is seeing a resurgence with the growing commercialisation of “robotic process automation”.\n\\\nProgramming language design has long been concerned with shifting the burden of intelligence between programmer, program, compiler, and user. Programming language compilers, in translating between high-level languages and machine code, are a kind of intelligent assistance for programmers. The declarative language Prolog aspired to bring a kind of intelligence, where the programmer would only be responsible for specifying (“declaring”) what to compute, but not how to compute it; that responsibility was left to the interpreter. At the same time, the language was designed with intelligent applications in mind. Indeed, it found widespread use within artificial intelligence and computational linguistics research (Colmerauer & Roussel, 1996; Rouchy, 2006).\n\\\nFormal verification tools use a specification language, such as Hoare triples (Hoare, 1969), and writing such specifications can be considered programming at a ‘higher’ level of abstraction. Program synthesis, in particular synthesis through refinement, aims at intelligently transforming these rules into executable and correct code. However, the term “program synthesis” is also used more broadly, and programs can be synthesised from other sources than higher-level specifications. Concretely, program synthesis by example, or simply programming by example (PBE), facilitates the generation of executable code from input-output examples. An example of successfully commercialised PBE is Excel’s Flash Fill (Gulwani, 2011), which synthesises string transformations in spreadsheets from a small number of examples.\n\\\nThe Cognitive Dimensions framework (T. R. Green, 1989; T. Green & Blackwell, 1998) identifies three categories of programming activity: authoring, transcription, and modification. Modern programmer assistance encompasses each of these. For example, program synthesis tools transform the direct authoring of code into the (arguably easier) authoring of examples. Intelligent code completions (Marasoiu et al., 2015) support the direct authoring of code. Intelligent support for reuse, such as smart code copy/paste (Allamanis & Brockschmidt, 2017) support transcription, and refactoring tools (Hermans et al., 2015) support modification. Researchers have investigated inferential support for navigating source code (Henley & Fleming, 2014), debugging (J. Williams et al., 2020), and selectively undoing code changes (Yoon & Myers, 2015). Additionally, intelligent tools can also support learning (Cao et al., 2015).\n\\\nAllamanis et al. (2018) review work at the intersection of machine learning, programming languages, and software engineering. They seek to adapt methods first developed for natural language, such as language models, to source code. The emergence of large bodies of open source code, sometimes called “big code”, enabled this research area. Language models are sensitive to lexical features like names, code formatting, and order of methods, while traditional tools like compilers or code verifiers are not. Through the “naturalness hypothesis”, which claims that “software is a form of human communication; software corpora have similar statistical properties to natural language corpora; the authors claim that these properties can be exploited to build better software engineering tools.” Some support for this hypothesis comes from research that used n-gram models to build a code completion engine for Java that outperformed Eclipse’s completion feature (Hindle et al., 2012, 2016). This approach can underpin recommender systems (such as code autocompletion), debuggers, code analysers (such as type checkers (Raychev et al., 2015)), and code synthesizers. We can expect the recent expansion in capability of language models, discussed next, to magnify the effectiveness of these applications.\n\\\n:::info\nAuthors:\n(1) Advait Sarkar, Microsoft Research, University of Cambridge (advait@microsoft.com);\n(2) Andrew D. Gordon, Microsoft Research, University of Edinburgh (adg@microsoft.com);\n(3) Carina Negreanu, Microsoft Research (cnegreanu@microsoft.com);\n(4) Christian Poelitz, Microsoft Research (cpoelitz@microsoft.com);\n(5) Sruti Srinivasa Ragavan, Microsoft Research (a-srutis@microsoft.com);\n(6) Ben Zorn, Microsoft Research (ben.zorn@microsoft.com).\n:::\n:::info\nThis paper is available on arxiv under CC BY-NC-ND 4.0 DEED license.\n:::\n\\",
          "date": "2025-08-03T15:15:06.000Z",
          "link": "https://hackernoon.com/solving-coding-puzzles-the-evolution-of-programmer-assistance-tools?source=rss",
          "categories": "[\"large-language-models\",\"ai-assisted-programming\",\"github-copilot\",\"code-generation\",\"programmer-assistance\",\"end-user-programming\",\"usability-studies\",\"inferential-assistance\"]"
        }
      },
      {
        "json": {
          "title": "The Hidden Cost of Performance: How High-Load Specialization Warps Engineering Intuition",
          "content": "In high-performance software engineering, it’s easy to become so focused on optimization that you lose sight of broader business needs. This article shares lessons from my 20+ years building real-time, high-load systems across finance, telecom, and advertising. I explain how engineering intuition—shaped by edge-case systems—can become a liability when applied blindly. The goal: help engineering teams, managers, and even non-technical leaders understand when performance matters, and when it doesn’t.\nThe world of high-load, low-latency systems is a crucible of engineering disciplines. It distills software down to its most brutal essence: cycles, bytes, wire time. It teaches you to think like a CPU, to treat L1 cache behavior as gospel, and to view allocations with suspicion. It sharpens your instincts for system limits and exposes any architectural indecision under fire at 200,000 RPS. Like all specializations, it also distorts your lens.\nIn this piece, I want to reflect on the cost of repeatedly optimizing for edge cases. Specifically, how the deeply internalized mindset from building ultra-performant, latency-sensitive systems can become a limiting factor when engineers work in more elastic, less deterministic business domains.\nWhere Intuition Begins\nI started my journey in real-time systems, where timing guarantees are absolute. Like brakes in a car, the system simply cannot be late. Over time, I transitioned into web systems where elasticity and geo-distribution took precedence over millisecond determinism. In banking, consistency and security overtook performance. Then, in adtech, I encountered the most complex compromise yet: soft real-time expectations (under 100ms), low cost per request, and architectural elasticity, all under high traffic conditions.\nThis varied experience taught me that an engineer must think vertically, understanding the entire system from business goals to infrastructure. However, it also exposed the trap many fall into: carrying over instincts honed in one domain into another, without adapting them.\nLatency as Reflex\nIn high-load systems with latency constraints, your thinking changes. You focus not on modularity or reusability, but on minimizing processing. The logic is data-centric: don’t transform the data. Shape your logic to fit the data. Don’t pass structures between microservices. Instead, keep them where they are and compute directly. Don’t copy—compute in place.\nThese habits are powerful. But the engineer must also understand the variability of input data, the business flow that justifies it, and the degree of correctness required. And they must know when such reflexes start working against the business.\nPathological Optimization in General Systems\nAn engineer who grew up working on high-load systems often assumes the bottleneck is always latency. But most systems are not bound by that constraint. Over the years, I’ve seen engineers apply data-centric programming, sharded databases and even custom databases, to CRUD backends. The performance gain was marginal; the complexity cost was vast.\nOne example: while working at MTS and AdNow, we optimized the DSP backend to hit 200k RPS. The temptation was to optimize everything. We learned to isolate the high-performance core and treat admin panels, user dashboards, and analytics with simpler tools like Postgres and standard libraries. Not every component needed to live at the edge.\nWhen Experience Becomes Bias\nEngineers carry the weight of their successes. For example, I avoided sharding if it was possible to do the processing on a single server, albeit with a significantly expanded RAM volume (for example, up to 4TB), and this often gave excellent results both in the cost of maintenance and in development - it is much easier to write code when all the data is in your memory than to work with sharded data. In such cases, we scaled vertically, adding RAM.\nHowever, this same intuition can become counterproductive in systems where horizontal scale is natural and cheap. Intuition must be regularly retrained. A 10-core server may outperform a 40-core box unless NUMA topology and mutex contention are addressed. You must consider switches (Cut-Through vs. Store-and-Forward), storage behavior (95th percentile latency), and data access patterns.\nThe mature engineer’s mindset is not \"What is the best possible system?\" but \"What does the business need, and how can we get there with minimum future pain?\"\nDebuggability vs. Efficiency\nAnother anti-pattern from high-performance thinking: sacrificing observability for CPU savings. In one system, we replaced JSON logging with binary formats to reduce overhead. It worked—3% CPU saved. But the trade-off? Incident response slowed, human debugging suffered, and onboarding became a challenge.\nIn ultra-constrained systems like SCADA (which I worked on early in my career), this trade-off is acceptable. But in most cloud-native systems, human time trumps compute time. Engineers should always ask: “Who’s going to debug this at 3 a.m.?”\nCultural Drift in Engineering Teams\nI’ve seen high-performance specialists bring over habits that don’t scale organizationally: rewriting libraries, resisting abstractions, and insisting on building from scratch. I’ve been guilty of it too, creating \"hot\" functions in x86-64 assembler and using directly the processor's SIMD commands (AVX-512), even when using the Go language. These systems work brilliantly, but only in the hands of their authors. By the way, assembler is very conveniently integrated into Go, but, as practice has shown, few people know it.\nToday, as a manager, I emphasize that business tasks must come first. If business requires creating a system with extreme performance characteristics, then we must remember that this will require a stellar team and vice versa, if a standard system is required, then it is not worth using solutions that are difficult to support and develop, but should focus on schemes and architecture that are understandable to the mass developer, which can be mastered by a mid-level developer in two weeks.\nI also caution against microservices sprawl. Teams eager to optimize development workflows may inadvertently turn a tight data-centric pipeline into a network of chatty, latency-laden services. Even Amazon Prime Video teams have returned from microservices to monoliths in such contexts.\nUnlearning the Habit of Optimization\nThe hardest thing for performance-oriented engineers to learn is when not to optimize. When building the MTS platform, we had parts of the system that were hot paths and others that were barely used. Initially, the urge was to use the same tooling across all components. But it’s a trap. CRUD services don’t need to scale like your bidding engine. Choose the right tool, even if that means sacrificing uniformity.\nSimilarly, early in my career, when developing code to perform a fast inverse Fourier transform, I wrote a highly optimized assembler code that outperformed GCC by 30%. But six months later, the processors changed, and my code optimized for prefetch pipelines began to perform worse than the compiler-generated one. That’s the real cost of low-level perfection: it rarely lasts. Performance tuning should be reserved for business-critical paths.\nLifecycle Cost of Optimization\nWhat often gets overlooked is the total lifecycle cost of early optimization. An efficient algorithm or exotic data layout may save compute time today, but if it slows down onboarding, complicates testability, or becomes a barrier to architectural evolution, then the system is effectively accruing technical debt disguised as technical brilliance. I’ve seen projects where an engineer’s initial low-level perfection became a tax the team paid for years—refactoring was too risky, and new hires avoided touching critical modules. Mature systems require performance that evolves with the business, not just code that’s clever in the moment. The question we should always ask is: “Can this optimization survive team growth and domain shifts over 3–5 years?”\nLearning to Let Go\nIn our CTR/VTR predictor, we send updates in real time. But for the segment coverage calculator in the UI, we switched to batch processing. The latency of updating the data in the UI has increased, but the complexity of support and development has decreased significantly without any impact on the business goal.\nThe wisdom is not in knowing how to optimize, but in knowing when the business doesn’t need it. Premature optimization is only “evil” when it’s misaligned with business maturity. If you're targeting 200k RPS on a core, yes—start sharp. But if it's 200k RPS on a cluster, and you can shard data processing (e.g. distribute requests across nodes), then act iteratively, start with inefficient but working code, and plan refactoring to achieve lower server load. And how to use the \"extra\" hardware freed up after optimization has never been a problem.\nMature Engineers Understand Trade-offs\nThe most balanced engineers I’ve worked with understand the entire vertical, from business requirements to infrastructure tuning. They know when to use Apache Ignite and when Postgres is enough. They make performance decisions only where bottlenecks align with business outcomes.\nSuch engineers avoid optimization addiction. They favor maintainability. They are patient with temporary solutions and confident that the roadmap allows for future improvements. That confidence, along with technical range, is what I consider “technical maturity.”\nLeading Self-Organizing Teams Without Overengineering\nLeft unchecked, high-performance teams often over-abstract. To prevent that, I encourage cross-functional ownership—engineers who think like analysts, testers, and product managers. I advocate for teams that talk openly, document and justify the architectural decisions (ADR), and include domain experts in the loop. You cannot succeed with brilliant engineers alone. You need people from the market.\nAlso, I’ve seen over-specialization derail early-stage teams. For new systems, buy experienced teams or foundational platforms. Don’t reinvent everything. Starting from scratch without market-ready expertise often leads to failure, unless backed by large investments.\nFinal Thoughts\nI don’t regret specializing in high-load systems. It shaped how I think. But I’ve also seen how these instincts, left unchecked, can limit engineers in broader domains. We must relearn general software engineering just as athletes must relearn walking after years of sprinting.\nYour best skill can become your biggest bias. And your greatest strength, when balanced, is what makes you a truly versatile engineer.\nIf you’re a product leader, founder, or manager: don’t ask your engineers to over-optimize from the start. Let them build clear, maintainable systems that can scale later if needed. High performance has its place—but business alignment always comes first.",
          "date": "2025-08-03T15:09:29.000Z",
          "link": "https://hackernoon.com/the-hidden-cost-of-performance-how-high-load-specialization-warps-engineering-intuition?source=rss",
          "categories": "[\"engineering-teams\",\"system-design\",\"performance-optimization\",\"tech-leadership\",\"high-load-systems\",\"crud-backend-scaling\",\"software-architecture\",\"software-engineering\"]"
        }
      },
      {
        "json": {
          "title": "Can Anyone Code Now? Exploring AI Help for Non-Programmers",
          "content": "Table of Links\nAbstract and 1 Introduction\n2. Prior conceptualisations of intelligent assistance for programmers\n3. A brief overview of large language models for code generation\n4. Commercial programming tools that use large language models\n5. Reliability, safety, and security implications of code-generating AI models\n6. Usability and design studies of AI-assisted programming\n7. Experience reports and 7.1. Writing effective prompts is hard\n7.2. The activity of programming shifts towards checking and unfamiliar debugging\n7.3. These tools are useful for boilerplate and code reuse\n8. The inadequacy of existing metaphors for AI-assisted programming\n8.1. AI assistance as search\n8.2. AI assistance as compilation\n8.3. AI assistance as pair programming\n8.4. A distinct way of programming\n9. Issues with application to end-user programming\n9.1. Issue 1: Intent specification, problem decomposition and computational thinking\n9.2. Issue 2: Code correctness, quality and (over)confidence\n9.3. Issue 3: Code comprehension and maintenance\n9.4. Issue 4: Consequences of automation in end-user programming\n9.5. Issue 5: No code, and the dilemma of the direct answer\n10. Conclusion\nA. Experience report sources\nReferences\n\\\n \nAbstract\nLarge language models, such as OpenAI’s codex and Deepmind’s AlphaCode, can generate code to solve a variety of problems expressed in natural language. This technology has already been commercialised in at least one widely-used programming editor extension: GitHub Copilot.\n\\\nIn this paper, we explore how programming with large language models (LLM-assisted programming) is similar to, and differs from, prior conceptualisations of programmer assistance. We draw upon publicly available experience reports of LLM-assisted programming, as well as prior usability and design studies. We find that while LLM-assisted programming shares some properties of compilation, pair programming, and programming via search and reuse, there are fundamental differences both in the technical possibilities as well as the practical experience. Thus, LLM-assisted programming ought to be viewed as a new way of programming with its own distinct properties and challenges.\n\\\nFinally, we draw upon observations from a user study in which non-expert end user programmers use LLM-assisted tools for solving data tasks in spreadsheets. We discuss the issues that might arise, and open research challenges, in applying large language models to end-user programming, particularly with users who have little or no programming expertise.\n1. Introduction\nInferential assistance for programmers has manifested in various forms, such as programming by demonstration, declarative programming languages, and program synthesis (Section 2). Large language models such as GPT mark a quantitative and qualitative step-change in the automatic generation of code and natural language text. This can be attributed to cumulative innovations of vector-space word embeddings, the transformer architecture, large text corpora, and pre-trained language models (Section 3).\n\\\nThese models have been commercialised in the form of APIs such as OpenAI Codex, or as programmerfacing tools such as GitHub Copilot and Tabnine. These tools function as a sort of advanced autocomplete, able to synthesize multiple lines of code based on a prompt within the code editor, which may be natural language (e.g., a comment), code (e.g., a function signature) or an ad-hoc mixture. The capabilities of such tools go well beyond traditional syntax-directed autocomplete, and include the ability to synthesize entire function bodies, write test cases, and complete repetitive patterns (Section 4). These tools have reliability, safety, and security implications (Section 5).\n\\\nPrior lab-based and telemetric research on the usability of such tools finds that developers generally appreciate the capabilities of these tools and find them to be a positive asset to the development experience, despite no strong effects on task completion times or correctness. Core usability issues include the challenge of correctly framing prompts as well as the effort required to check and debug generated code (Section 6).\n\\\nLongitudinal experience reports of developers support some of the lab-based findings, while contradicting others. The challenges of correctly framing prompts and the efforts of debugging also appear here. However, there are many reports that these tools do in fact strongly reduce task time (i.e., speed up the development process) (Section 7).\n\\\nProgramming with large language models invites comparison to related ways of programming, such as search, compilation, and pair programming. While there are indeed similarities with each of these, the empirical reports of the experience of such tools also show crucial differences. Search, compilation, and pair programming are thus found to be inadequate metaphors for the nature of LLM-assisted programming; it is a distinct way of programming with its own unique blend of properties (Section 8).\n\\\nWhile LLM-assisted programming is currently geared towards expert programmers, arguably the greatest beneficiaries of their abilities will be non-expert end-user programmers. Nonetheless, there are issues with their direct application in end-user programming scenarios. Through a study of LLM-assisted end-user programming in spreadsheets, we uncover issues in intent specification, code correctness, comprehension, LLM tuning, and end-user behaviour, and motivate the need for further study in this area (Section 9).\n\\\n:::info\nThis paper is available on arxiv under CC BY-NC-ND 4.0 DEED license.\n:::\n:::info\nAuthors:\n(1) Advait Sarkar, Microsoft Research, University of Cambridge (advait@microsoft.com);\n(2) Andrew D. Gordon, Microsoft Research, University of Edinburgh (adg@microsoft.com);\n(3) Carina Negreanu, Microsoft Research (cnegreanu@microsoft.com);\n(4) Christian Poelitz, Microsoft Research (cpoelitz@microsoft.com);\n(5) Sruti Srinivasa Ragavan, Microsoft Research (a-srutis@microsoft.com);\n(6) Ben Zorn, Microsoft Research (ben.zorn@microsoft.com).\n:::\n\\",
          "date": "2025-08-03T15:00:04.000Z",
          "link": "https://hackernoon.com/can-anyone-code-now-exploring-ai-help-for-non-programmers?source=rss",
          "categories": "[\"large-language-models\",\"ai-assisted-programming\",\"github-copilot\",\"code-generation\",\"programmer-assistance\",\"end-user-programming\",\"usability-studies\",\"inferential-assistance\"]"
        }
      },
      {
        "json": {
          "title": "Europe’s Data Vision: Dataspaces for Zero-Trust AI Infrastructure",
          "content": "As AI systems scale across sectors like healthcare, manufacturing, and finance, Europe faces a critical challenge: how to orchestrate AI securely across privacy, regulatory, and organizational boundaries.\n\\\nThis case study explores a pioneering Huberta project that embraces zero-trust architecture, metadata-first orchestration, and mathematical compliance via PDEs.\n\\\nAt the heart of this initiative lies a breakthrough: policy-aware orchestration through partial differential equations, allowing AI to run only when privacy, intent, and law align.\n\\\nUpstaff provided specialized AI engineers who tackled the core challenges of federated orchestration, zero-trust metadata, and explainable infrastructure at scale.\n\\\nThis article provides insights into a European data infrastructure project focused on creating a policy-aware, zero-trust system for federated AI.\n\\\nThe initiative aims to revolutionize data infrastructure by replacing centralized data systems with a decentralized, privacy-preserving framework.\n\\\nIt uses partial differential equations (PDEs) to enforce compliance (e.g., GDPR, EU AI Act) and manage data access for secure multi-party collaboration without raw data exchange.\n\\\nWhat we will cover:\n\\\n\nZero-Trust Metadata and Dataspaces\nZero-Trust AI Orchestration Across Privacy and Policy Boundaries\nSystem Architecture Overview\nEngineering Stack & Capabilities\nCloud Infrastructure Capability Matrix (AWS-focused)\nEngineering the Backbone of Federated AI\nResults So Far\nLessons Learned & Engineering Insights\nWhy This Matters: The Next Wave of AI Infrastructure\nConclusion: Engineering Trustworthy AI at Scale\nDataspace\nA dataspace is a federated network designed for secure, decentralized data exchange. It allows organizations to maintain control over their data while enabling interoperability across different platforms and industries.\n\\\n \n\\\nDataspace enables trusted data sharing in a way that preserves the data sovereignty of participants based on a standard governance framework.\n\\\n\nDataspaces are pivotal in sectors like mobility, healthcare, logistics, and smart cities, where data integration is essential for innovation and efficiency.\nDataspaces can be purpose- or sector-specific, or cross-sectoral.\nZero-Trust Metadata and Dataspaces\nAs Europe advances toward a digitally sovereign future, the way we handle data is undergoing a fundamental shift.\n\\\n \n\\\n\\\nTraditional architectures such as centralized data lakes, post-hoc compliance checks, and monolithic workflows are no longer sufficient. Emerging standards, like the EU AI Act and GDPR, demand real-time governance, privacy-preserving design, and explainability by default.\n\\\nAt the frontier of this transformation is a groundbreaking project. Its mission is to reimagine data infrastructure as a policy-aware, zero-trust system built not from pipelines, but from mathematics.\n\\\nAt the core of this system are partial differential equations (PDEs) that regulate resource access, data movement, and AI behavior through boundary conditions.\n\\\nThis paradigm allows multi-party collaboration without raw data exchange, high-performance computing (HPC) on demand, with minimal energy footprint, and compliance encoded directly into the infrastructure.\nHow PDE-Orchestrated Infrastructure Differs From Conventional Systems\n| Feauture | Conventional Cloud AI | PDE-Orchestrated Zero-Trust AI |\n|----|----|----|\n| Data Movement | Centralized | Local-only |\n| Policy Compliance | Post-hoc | By-construction |\n| Resource Usage | Persistent | Ephemeral |\n| Governance | Manual | Embedded in PDEs |\n| Traceability | Limited | DAG + Policy-bound |\nZero-Trust AI Orchestration Across Privacy and Policy Boundaries\nThe project's vision is radical: create a framework where data never moves, but value does.\n\\\nRather than collecting data into central repositories, each participant in the system, whether in healthcare, manufacturing, or public services, retains full control of their data.\n\\\nA dynamic knowledge graph holds metadata, ontologies, and processing “recipes.” Computation is triggered by PDEs that enforce policy gates (GDPR, ISO, GAMP) as mathematical constraints.\n\\\nWhen certain boundary conditions are met, e.g., a spike in demand or anomaly detection, a short-lived HPC cluster spins up, computes locally, and vanishes.\n\\\nBut to make this vision real, the team needed engineers with a rare mix of skills:\n\\\n\nPrivacy-preserving machine learning\nFederated AI\nKnowledge graph integration\nExplainable DAG orchestration\nSemantic modeling and metadata processing\n\\\nAt the heart of the system lies a governance PDE, where each term in the equation maps to a constraint:\n\\\n\n∂u/∂t + ∇·(α(u)∇u) = f(x, t)- represents AI execution across time and space.\n∂u/∂t — latency or response time\nα(u) — policy gating/access weights\nf(x, t) — triggers like demand spike or anomaly\nBoundary terms = regulatory or domain-specific constraints, GDPR compliance, semantic gates, and user intent.\n\\\nIf the PDE has no solution, computation is halted. This turns policy from a rule to a hard condition of execution. “If you can’t solve the PDE, you can’t run the task.” This is proactive compliance by construction.\nSystem Architecture Overview\nLocal Data Silos: Hospitals, factories, and labs retain full control of raw data. Nothing is centralized.\n\\\nPolicy Gate: Applies GDPR, AI Act, and internal policies at the metadata boundary. Invalid flows are filtered before orchestration.\n\\\nPDE Engine: The core of the system. It solves boundary-condition equations where each constraint represents a legal, semantic, or resource constraint.\n\\\nExamples:\n\\\n\nA GDPR clause becomes an unsolvable boundary if data leaves its origin.\nA compute budget becomes a conditional activation.\n\\\n\n\nKnowledge Graph: Stores semantic mappings, policy clauses, domain taxonomies, and orchestration “recipes.” This separates logic from data — enabling fast, ontology-driven decisions.\n\\\nEphemeral HPC Clusters: Resources are spun up only when a PDE solution exists — when policy, readiness, and workload match.\n\\\nThese may include:\n\\\nClassification models\nAnomaly detectors\nSimulation workloads\nFederated training\n\\\n\nDAG Traceability: Each operation logs its origin: which policy triggered it, which resource was allocated, and which boundary condition was met.\nEngineering Stack & Capabilities\n| Domain | Contribution | Tools and Methods |\n|----|----|----|\n| Federated AI | Built vertical & horizontal pipelines | PySyft, Flower, OpenMined, custom secure aggregation protocols |\n| Semantic Modeling | Ontology→PDE mapping | RDF/OWL, Protégé, SPARQL, Neo4j, GraphQL |\n| Metadata-First Design | Graph-driven orchestration | GraphQL, custom DAG wrappers, Apache Airflow, Argo Workflows, Prefect, Temporal |\n| Explainability & Auditing | Traceable execution lineage | DAG visualizers, metadata provenance tracing, JSON-LD, OpenPolicyAgent logs |\n| PDE Compliance Runtime | Mathematical constraint solver | SciPy, JAX, TensorFlow PDE, PyTorch autograd, custom symbolic solvers |\n| Infrastructure Engineering | Deployed resilient, policy-aware federated systems across cloud-native and hybrid environments | Amazon Web Services |\n\\\nCloud Infrastructure Capability Matrix (AWS-Focused)\n\\\n| Category | AWS Services Listed | Notes |\n|----|----|----|\n| Compute & Containerization | ECS, EKS, EC2, Fargate, Lambda | All AWS-native |\n| Networking & Security | VPC, PrivateLink, IAM, Security Groups, KMS, Secrets Manager | AWS-specific |\n| Storage | S3, EFS, FSx | AWS storage services |\n| Serverless Pipelines | Step Functions, EventBridge, DynamoDB Streams | AWS-native serverless tools |\n| Data Layer | Neptune, RDS, Aurora, Glue, Athena | All are AWS-managed data services |\n| Monitoring & Observability | CloudWatch, X-Ray, OpenTelemetry | FirOpenTelemetry is a cross-cloud; two are AWS |\n| Compliance Enforcement | Macie, GuardDuty, Config | All AWS-native compliance/security tools |\nEngineering the Backbone of Federated AI\nAmong others, Federated AI also allows them to significantly reduce the amount of data they transfer. In fact, some projects managed to reduce their data transfer burden by more than 99% compared to a centralized training model.\n\\\nThis is important because moving very large datasets contributes to higher costs, lower performance, and decreased energy efficiency.\n\\\nThere are two main approaches to federated AI:\n\\\n\n\nHorizontal federated AI: pulls model weights from the same types of data in every site\n\\\nVertical federated AI: pulls model weights from different types of data in different sites\n\\\nAI engineers contributed to several mission-critical domains:\n\\\n\n\nMulti-head AI pipelines\nAsynchronous pipelines for classification, anomaly detection, and schema interpretation, all integrated into a dynamic metadata fabric.\n\\\nSemantic-aware orchestration\nKnowledge graph outputs to PDE boundary inputs, ensuring compute only runs when policies, semantics, and capacity align.\n\\\nZero-trust federation logic\nAI workflows to operate without ever touching raw data—only abstracted metadata fragments.\n\\\nAudit-ready explainability\nDirected acyclic graphs (DAGs) trace each decision back to a semantic label or policy clause, aligning with upcoming EU AI Act requirements.\n\n\n\\\nBehind some of the engineering challenges in this initiative is a team of specialized AI engineers from Upstaff, who could contribute to policy-aware AI infrastructure across domains as sensitive as healthcare and industrial manufacturing.\nResults So Far\nThough still in active development, the project has made several breakthroughs:\n\\\n\nA working alpha prototype of the PDE aggregator with sub-second concurrency response.\nReal-time metadata ingestion and anomaly classification through AI modules.\nFederated learning simulations operating under policy constraints.\nTraceable, explainable orchestration flows through self-documenting DAGs.\nLessons Learned & Engineering Insights\nMath over policies wins: Executable PDEs > static rules\nMetadata is infrastructure: Ontologies replaced scripts\nCompliance must be first-class: Not a feature—an execution condition\nNo-code ≠ Low-trust: Engineers must deeply understand the domain and legal semantics\nWhy This Matters: The Next Wave of AI Infrastructure\n \n\n\\\nThe technical architecture being developed in this project isn’t niche. It’s a preview of where AI and data engineering are headed:\n\\\n\nFederated AI in finance and healthcare\nSemantic interoperability across ESG supply chains\nEphemeral HPC for energy-efficient computing\nMathematical governance over data flows\nConclusion: Engineering Trustworthy AI at Scale\nReal-world AI lives at the intersection of regulation, infrastructure, ethics, and performance. This initiative is a bold attempt to build a system where all those concerns are solved mathematically, structurally, and scalably.\n\\\nCompliance isn’t a document; it’s a boundary condition. And orchestration isn’t a workflow; it’s an equation.",
          "date": "2025-08-03T12:15:08.000Z",
          "link": "https://hackernoon.com/europes-data-vision-dataspaces-for-zero-trust-ai-infrastructure?source=rss",
          "categories": "[\"ai-infrastructure\",\"zero-trust-ai\",\"pde\",\"zero-trust\",\"federated-ai\",\"zero-trust-metadata\",\"what-is-federated-ai\",\"europe-data-vision\"]"
        }
      },
      {
        "json": {
          "title": "Reproducible Go Toolchains: What You Need to Know",
          "content": "One of the key benefits of open-source software is that anyone can read the source code and inspect what it does. And yet most software, even open-source software, is downloaded in the form of compiled binaries, which are much more difficult to inspect. If an attacker wanted to run a supply chain attack on an open-source project, the least visible way would be to replace the binaries being served while leaving the source code unmodified.\n\\\nThe best way to address this kind of attack is to make open-source software builds reproducible, meaning that a build that starts with the same sources produces the same outputs every time it runs. That way, anyone can verify that posted binaries are free of hidden changes by building from authentic sources and checking that the rebuilt binaries are bit-for-bit identical to the posted binaries. That approach proves the binaries have no backdoors or other changes not present in the source code, without having to disassemble or look inside them at all. Since anyone can verify the binaries, independent groups can easily detect and report supply chain attacks.\n\\\nAs supply chain security becomes more important, so do reproducible builds, because they provide a simple way to verify the posted binaries for open-source projects.\n\\\nGo 1.21.0 is the first Go toolchain with perfectly reproducible builds. Earlier toolchains were possible to reproduce, but only with significant effort, and probably no one did: they just trusted that the binaries posted on go.dev/dl were the correct ones. Now it’s easy to “trust but verify.”\n\\\nThis post explains what goes into making builds reproducible, examines the many changes we had to make to Go to make Go toolchains reproducible, and then demonstrates one of the benefits of reproducibility by verifying the Ubuntu package for Go 1.21.0.\nMaking a Build Reproducible\nComputers are generally deterministic, so you might think all builds would be equally reproducible. That’s only true from a certain point of view. Let’s call a piece of information a relevant input when the output of a build can change depending on that input. A build is reproducible if it can be repeated with all the same relevant inputs. Unfortunately, lots of build tools turn out to incorporate inputs that we would usually not realize are relevant and that might be difficult to recreate or provide as input. Let’s call an input an unintentional input when it turns out to be relevant but we didn’t mean it to be.\n\\\nThe most common unintentional input in build systems is the current time. If a build writes an executable to disk, the file system records the current time as the executable’s modification time. If the build then packages that file using a tool like “tar” or “zip”, the modification time is written into the archive. We certainly didn’t want our build to change based on the current time, but it does. So the current time turns out to be an unintentional input to the build. Worse, most programs don’t let you provide the current time as an input, so there is no way to repeat this build. To fix this, we might set the time stamps on created files to Unix time 0 or to a specific time read from one of the build’s source files. That way, the current time is no longer a relevant input to the build.\n\\\nCommon relevant inputs to a build include:\nthe specific version of the source code to build;\nthe specific versions of dependencies that will be included in the build;\nthe operating system running the build, which may affect path names in the resulting binaries;\nthe architecture of the CPU on the build system, which may affect which optimizations the compiler uses or the layout of certain data structures;\nthe compiler version being used, as well as compiler options passed to it, which affect how the code is compiled;\nthe name of the directory containing the source code, which may appear in debug information;\nthe user name, group name, uid, and gid of the account running the build, which may appear in file metadata in an archive;\nand many more.\n\\\nTo have a reproducible build, every relevant input must be configurable in the build, and then the binaries must be posted alongside an explicit configuration listing every relevant input. If you’ve done that, you have a reproducible build. Congratulations!\n\\\nWe’re not done, though. If the binaries can only be reproduced if you first find a computer with the right architecture, install a specific operating system version, compiler version, put the source code in the right directory, set your user identity correctly, and so on, that may be too much work in practice for anyone to bother.\n\\\nWe want builds to be not just reproducible but easy to reproduce. To do that, we need to identify relevant inputs and then, instead of documenting them, eliminate them. The build obviously has to depend on the source code being built, but everything else can be eliminated. When a build’s only relevant input is its source code, let’s call that perfectly reproducible.\nPerfectly Reproducible Builds for Go\nAs of Go 1.21, the Go toolchain is perfectly reproducible: its only relevant input is the source code for that build. We can build a specific toolchain (say, Go for Linux/x86-64) on a Linux/x86-64 host, or a Windows/ARM64 host, or a FreeBSD/386 host, or any other host that supports Go, and we can use any Go bootstrap compiler, including bootstrapping all the way back to Go 1.4’s C implementation, and we can vary any other details. None of that changes the toolchains that are built. If we start with the same toolchain source code, we will get the exact same toolchain binaries out.\n\\\nThis perfect reproducibility is the culmination of efforts dating back originally to Go 1.10, although most of the effort was concentrated in Go 1.20 and Go 1.21. This section highlights some of the most interesting relevant inputs that we eliminated.\nReproducibility in Go 1.10\nGo 1.10 introduced a content-aware build cache that decides whether targets are up-to-date based on a fingerprint of the build inputs instead of file modification times. Because the toolchain itself is one of those build inputs, and because Go is written in Go, the bootstrap process would only converge if the toolchain build on a single machine was reproducible. The overall toolchain build looks like this:\n\n\\\nWe start by building the sources for the current Go toolchain using an earlier Go version, the bootstrap toolchain (Go 1.10 used Go 1.4, written in C; Go 1.21 uses Go 1.17). That produces “toolchain1”, which we use to build everything again, producing “toolchain2”, which we use to build everything again, producing “toolchain3”.\n\\\nToolchain1 and toolchain2 have been built from the same sources but with different Go implementations (compilers and libraries), so their binaries are certain to be different. However, if both Go implementations are non-buggy, correct implementations, toolchain1 and toolchain2 should behave exactly the same. In particular, when presented with the Go 1.X sources, toolchain1’s output (toolchain2) and toolchain2’s output (toolchain3) should be identical, meaning toolchain2 and toolchain3 should be identical.\n\\\nAt least, that’s the idea. Making that true in practice required removing a couple unintentional inputs:\nRandomness. Map iteration and running work in multiple goroutines serialized with locks both introduce randomness in the order that results may be generated. This randomness can make the toolchain produce one of several different possible outputs each time it runs. To make the build reproducible, we had to find each of these and sort the relevant list of items before using it to generate output.\n\\\nBootstrap Libraries. Any library used by the compiler that can choose from multiple different correct outputs might change its output from one Go version to the next. If that library output change causes a compiler output change, then toolchain1 and toolchain2 will not be semantically identical, and toolchain2 and toolchain3 will not be bit-for-bit identical.\n\\\nThe canonical example is the sort package, which can place elements that compare equal in any order it likes. A register allocator might sort to prioritize commonly used variables, and the linker sorts symbols in the data section by size. To completely eliminate any effect from the sorting algorithm, the comparison function used must never report two distinct elements as equal. In practice, this invariant turned out to be too onerous to impose on every use of sort in the toolchain, so instead we arranged to copy the Go 1.X sort package into the source tree that is presented to the bootstrap compiler. That way, the compiler uses the same sort algorithm when using the bootstrap toolchain as it does when built with itself.\n\\\nAnother package we had to copy was compress/zlib, because the linker writes compressed debug information, and optimizations to compression libraries can change the exact output. Over time, we’ve added other packages to that list too. This approach has the added benefit of allowing the Go 1.X compiler to use new APIs added to those packages immediately, at the cost that those packages must be written to compile with older versions of Go.\nReproducibility in Go 1.20\nWork on Go 1.20 prepared for both easy reproducible builds and toolchain management by removing two more relevant inputs from the toolchain build.\n\\\nHost C toolchain. Some Go packages, most notably net, default to using cgo on most operating systems. In some cases, such as macOS and Windows, invoking system DLLs using cgo is the only reliable way to resolve host names. When we use cgo, though, we invoke the host C toolchain (meaning a specific C compiler and C library), and different toolchains have different compilation algorithms and library code, producing different outputs. The build graph for a cgo package looks like:\n\n\\\nThe host C toolchain is therefore a relevant input to the pre-compiled net.a that ships with the toolchain. For Go 1.20, we decided to fix this by removing net.a from the toolchain. That is, Go 1.20 stopped shipping pre-compiled packages to seed the build cache with. Now, the first time a program uses package net, the Go toolchain compiles it using the local system’s C toolchain and caches that result. \n\\\nIn addition to removing a relevant input from toolchain builds and making toolchain downloads smaller, not shipping pre-compiled packages also makes toolchain downloads more portable. If we build package net on one system with one C toolchain and then compile other parts of the program on a different system with a different C toolchain, in general there is no guarantee that the two parts can be linked together.\n\\\nOne reason we shipped the pre-compiled net package in the first place was to allow building programs that used package net even on systems without a C toolchain installed. If there’s no pre-compiled package, what happens on those systems? The answer varies by operating system, but in all cases we arranged for the Go toolchain to continue to work well for building pure Go programs without a host C toolchain.\n\\\n\nOn macOS, we rewrote package net using the underlying mechanisms that cgo would use, without any actual C code. This avoids invoking the host C toolchain but still emits a binary that refers to the required system DLLs. This approach is only possible because every Mac has the same dynamic libraries installed. Making the non-cgo macOS package net use the system DLLs also meant that cross-compiled macOS executables now use the system DLLs for network access, resolving a long-standing feature request.\n\\\n\nOn Windows, package net already made direct use of DLLs without C code, so nothing needed to be changed.\n\\\n\nOn Unix systems, we cannot assume a specific DLL interface to network code, but the pure Go version works fine for systems that use typical IP and DNS setups. Also, it is much easier to install a C toolchain on Unix systems than it is on macOS and especially Windows. We changed the go command to enable or disable cgo automatically based on whether the system has a C toolchain installed. Unix systems without a C toolchain fall back to the pure Go version of package net, and in the rare cases where that’s not good enough, they can install a C toolchain.\n\\\nHaving dropped the pre-compiled packages, the only part of the Go toolchain that still depended on the host C toolchain was binaries built using package net, specifically the go command. With the macOS improvements, it was now viable to build those commands with cgo disabled, completely removing the host C toolchain as an input, but we left that final step for Go 1.21.\n\\\nHost dynamic linker. When programs use cgo on a system using dynamically linked C libraries, the resulting binaries contain the path to the system’s dynamic linker, something like /lib64/ld-linux-x86-64.so.2. If the path is wrong, the binaries don’t run. Typically each operating system/architecture combination has a single correct answer for this path. Unfortunately, musl-based Linuxes like Alpine Linux use a different dynamic linker than glibc-based Linuxes like Ubuntu. To make Go run at all on Alpine Linux, in Go bootstrap process looked like this:\n\n\\\nThe bootstrap program cmd/dist inspected the local system’s dynamic linker and wrote that value into a new source file compiled along with the rest of the linker sources, effectively hard-coding that default into the linker itself. Then when the linker built a program from a set of compiled packages, it used that default. The result is that a Go toolchain built on Alpine is different from a toolchain built on Ubuntu: the host configuration is a relevant input to the toolchain build. This is a reproducibility problem but also a portability problem: a Go toolchain built on Alpine doesn’t build working binaries or even run on Ubuntu, and vice versa.\n\\\nFor Go 1.20, we took a step toward fixing the reproducibility problem by changing the linker to consult the host configuration when it is running, instead of having a default hard-coded at toolchain build time:\n\n\\\nThis fixed the portability of the linker binary on Alpine Linux, although not the overall toolchain, since the go command still used package net and therefore cgo and therefore had a dynamic linker reference in its own binary. Just as in the previous section, compiling the go command without cgo enabled would fix this, but we left that change for Go 1.21. (We didn’t feel there was enough time left in the Go 1.20 cycle to test such that change properly.)\nReproducibility in Go 1.21\nFor Go 1.21, the goal of perfect reproducibility was in sight, and we took care of the remaining, mostly small, relevant inputs that remained.\n\\\nHost C toolchain and dynamic linker. As discussed above, Go 1.20 took important steps toward removing the host C toolchain and dynamic linker as relevant inputs. Go 1.21 completed the removal of these relevant inputs by building the toolchain with cgo disabled. This improved portability of the toolchain too: Go 1.21 is the first Go release where the standard Go toolchain runs unmodified on Alpine Linux systems.\n\\\nRemoving these relevant inputs made it possible to cross-compile a Go toolchain from a different system without any loss in functionality. That in turn improved the supply chain security of the Go toolchain: we can now build Go toolchains for all target systems using a trusted Linux/x86-64 system, instead of needing to arrange a separate trusted system for each target. As a result, Go 1.21 is the first release to include posted binaries for all systems at go.dev/dl/.\n\\\nSource directory. Go programs include full paths in the runtime and debugging metadata, so that when a program crashes or is run in a debugger, stack traces include the full path to the source file, not just the name of the file in an unspecified directory. Unfortunately, including the full path makes the directory where the source code is stored a relevant input to the build. To fix this, Go 1.21 changed the release toolchain builds to install commands like the compiler using go install -trimpath, which replaces the source directory with the module path of the code. If a released compiler crashes, the stack trace will print paths like cmd/compile/main.go instead of /home/user/go/src/cmd/compile/main.go. \n\\\nSince the full paths would refer to a directory on a different machine anyway, this rewrite is no loss. On the other hand, for non-release builds, we keep the full path, so that when developers working on the compiler itself cause it to crash, IDEs and other tools reading those crashes can easily find the correct source file.\n\\\nHost operating system. Paths on Windows systems are backslash-separated, like cmd\\compile\\main.go. Other systems use forward slashes, like cmd/compile/main.go. Although earlier versions of Go had normalized most of these paths to use forward slashes, one inconsistency had crept back in, causing slightly different toolchain builds on Windows. We found and fixed the bug.\n\\\nHost architecture. Go runs on a variety of ARM systems and can emit code using a software library for floating-point math (SWFP) or using hardware floating-point instructions (HWFP). Toolchains defaulting to one mode or the other will necessarily differ. Like we saw with the dynamic linker earlier, the Go bootstrap process inspected the build system to make sure that the resulting toolchain worked on that system. For historical reasons, the rule was “assume SWFP unless the build is running on an ARM system with floating-point hardware”, with cross-compiled toolchains assuming SWFP. \n\\\nThe vast majority of ARM systems today do have floating-point hardware, so this introduced an unnecessary difference between natively compiled and cross-compiled toolchains, and as a further wrinkle, Windows ARM builds always assumed HWFP, making the decision operating system-dependent. We changed the rule to be “assume HWFP unless the build is running on an ARM system without floating-point hardware”. This way, cross-compilation and builds on modern ARM systems produce identical toolchains.\n\\\nPackaging logic. All the code to create the actual toolchain archives we post for download lived in a separate Git repository, golang.org/x/build, and the exact details of how archives get packaged does change over time. If you wanted to reproduce those archives, you needed to have the right version of that repository. We removed this relevant input by moving the code to package the archives into the main Go source tree, as cmd/distpack. As of Go 1.21, if you have the sources for a given version of Go, you also have the sources for packaging the archives. The golang.org/x/build repository is no longer a relevant input.\n\\\nUser IDs. The tar archives we posted for download were built from a distribution written to the file system, and using tar.FileInfoHeader copies the user and group IDs from the file system into the tar file, making the user running the build a relevant input. We changed the archiving code to clear these.\n\\\nCurrent time. Like with user IDs, the tar and zip archives we posted for download had been built by copying the file system modification times into the archives, making the current time a relevant input. We could have cleared the time, but we thought it would look surprising and possibly even break some tools to use the Unix or MS-DOS zero time. Instead, we changed the go/VERSION file stored in the repository to add the time associated with that version:\n$ cat go1.21.0/VERSION\ngo1.21.0\ntime 2023-08-04T20:14:06Z\n$\n\nThe packagers now copy the time from the VERSION file when writing files to archives, instead of copying the local file’s modification times.\n\\\nCryptographic signing keys. The Go toolchain for macOS won’t run on end-user systems unless we sign the binaries with an Apple-approved signing key. We use an internal system to get them signed with Google’s signing key, and obviously we cannot share that secret key in order to allow others to reproduce the signed binaries. Instead, we wrote a verifier that can check whether two binaries are identical except for their signatures.\n\\\nOS-specific packagers. We use the Xcode tools pkgbuild and productbuild to create the downloadable macOS PKG installer, and we use WiX to create the downloadable Windows MSI installer. We don’t want verifiers to need the same exact versions of those tools, so we took the same approach as for the cryptographic signing keys, writing a verifier that can look inside the packages and check that the toolchain files are exactly as expected.\nVerifying the Go Toolchains\nIt’s not enough to make Go toolchains reproducible once. We want to make sure they stay reproducible, and we want to make sure others can reproduce them easily.\n\\\nTo keep ourselves honest, we now build all Go distributions on both a trusted Linux/x86-64 system and a Windows/x86-64 system. Except for the architecture, the two systems have almost nothing in common. The two systems must produce bit-for-bit identical archives or else we do not proceed with the release.\n\\\nTo allow others to verify that we’re honest, we’ve written and published a verifier, golang.org/x/build/cmd/gorebuild. That program will start with the source code in our Git repository and rebuild the current Go versions, checking that they match the archives posted on go.dev/dl. Most archives are required to match bit-for-bit. As mentioned above, there are three exceptions where a more relaxed check is used:\n\\\n\nThe macOS tar.gz file is expected to differ, but then the verifier compares the contents inside. The rebuilt and posted copies must contain the same files, and all the files must match exactly, except for executable binaries. Executable binaries must match exactly after stripping code signatures.\n\\\n\nThe macOS PKG installer is not rebuilt. Instead, the verifier reads the files inside the PKG installer and checks that they match the macOS tar.gz exactly, again after code signature stripping. In the long term, the PKG creation is trivial enough that it could potentially be added to cmd/distpack, but the verifier would still have to parse the PKG file to run the signature-ignoring code executable comparison.\n\\\n\nThe Windows MSI installer is not rebuilt. Instead, the verifier invokes the Linux program msiextract to extract the files inside and check that they match the rebuilt Windows zip file exactly. In the long term, perhaps the MSI creation could be added to cmd/distpack, and then the verifier could use a bit-for-bit MSI comparison.\n\\\nWe run gorebuild nightly, posting the results at go.dev/rebuild, and of course anyone else can run it too.\nVerifying Ubuntu’s Go Toolchain\nThe Go toolchain’s easily reproducible builds should mean that the binaries in the toolchains posted on go.dev match the binaries included in other packaging systems, even when those packagers build from source. Even if the packagers have compiled with different configurations or other changes, the easily reproducible builds should still make it easy to reproduce their binaries. To demonstrate this, let’s reproduce the Ubuntu golang-1.21 package version 1.21.0-1 for Linux/x86-64.\n\\\nTo start, we need to download and extract the Ubuntu packages, which are ar(1) archives containing zstd-compressed tar archives:\n$ mkdir deb\n$ cd deb\n$ curl -LO http://mirrors.kernel.org/ubuntu/pool/main/g/golang-1.21/golang-1.21-src_1.21.0-1_all.deb\n$ ar xv golang-1.21-src_1.21.0-1_all.deb\nx - debian-binary\nx - control.tar.zst\nx - data.tar.zst\n$ unzstd < data.tar.zst | tar xv\n...\nx ./usr/share/go-1.21/src/archive/tar/common.go\nx ./usr/share/go-1.21/src/archive/tar/example_test.go\nx ./usr/share/go-1.21/src/archive/tar/format.go\nx ./usr/share/go-1.21/src/archive/tar/fuzz_test.go\n...\n$\n\n\\\nThat was the source archive. Now the amd64 binary archive:\n$ rm -f debian-binary *.zst\n$ curl -LO http://mirrors.kernel.org/ubuntu/pool/main/g/golang-1.21/golang-1.21-go_1.21.0-1_amd64.deb\n$ ar xv golang-1.21-src_1.21.0-1_all.deb\nx - debian-binary\nx - control.tar.zst\nx - data.tar.zst\n$ unzstd < data.tar.zst | tar xv | grep -v '/$'\n...\nx ./usr/lib/go-1.21/bin/go\nx ./usr/lib/go-1.21/bin/gofmt\nx ./usr/lib/go-1.21/go.env\nx ./usr/lib/go-1.21/pkg/tool/linux_amd64/addr2line\nx ./usr/lib/go-1.21/pkg/tool/linux_amd64/asm\nx ./usr/lib/go-1.21/pkg/tool/linux_amd64/buildid\n...\n$\n\n\\\nUbuntu splits the normal Go tree into two halves, in /usr/share/go-1.21 and /usr/lib/go-1.21. Let’s put them back together:\n$ mkdir go-ubuntu\n$ cp -R usr/share/go-1.21/* usr/lib/go-1.21/* go-ubuntu\ncp: cannot overwrite directory go-ubuntu/api with non-directory usr/lib/go-1.21/api\ncp: cannot overwrite directory go-ubuntu/misc with non-directory usr/lib/go-1.21/misc\ncp: cannot overwrite directory go-ubuntu/pkg/include with non-directory usr/lib/go-1.21/pkg/include\ncp: cannot overwrite directory go-ubuntu/src with non-directory usr/lib/go-1.21/src\ncp: cannot overwrite directory go-ubuntu/test with non-directory usr/lib/go-1.21/test\n$\n\n\\\nThe errors are complaining about copying symlinks, which we can ignore.\n\\\nNow we need to download and extract the upstream Go sources:\n$ curl -LO https://go.googlesource.com/go/+archive/refs/tags/go1.21.0.tar.gz\n$ mkdir go-clean\n$ cd go-clean\n$ curl -L https://go.googlesource.com/go/+archive/refs/tags/go1.21.0.tar.gz | tar xzv\n...\nx src/archive/tar/common.go\nx src/archive/tar/example_test.go\nx src/archive/tar/format.go\nx src/archive/tar/fuzz_test.go\n...\n$\n\n\\\nTo skip some trial and error, it turns out that Ubuntu builds Go with GO386=softfloat, which forces the use of software floating point when compiling for 32-bit x86, and strips (removes symbol tables from) the resulting ELF binaries. Let’s start with a GO386=softfloat build:\n$ cd src\n$ GOOS=linux GO386=softfloat ./make.bash -distpack\nBuilding Go cmd/dist using /Users/rsc/sdk/go1.17.13. (go1.17.13 darwin/amd64)\nBuilding Go toolchain1 using /Users/rsc/sdk/go1.17.13.\nBuilding Go bootstrap cmd/go (go_bootstrap) using Go toolchain1.\nBuilding Go toolchain2 using go_bootstrap and Go toolchain1.\nBuilding Go toolchain3 using go_bootstrap and Go toolchain2.\nBuilding commands for host, darwin/amd64.\nBuilding packages and commands for target, linux/amd64.\nPackaging archives for linux/amd64.\ndistpack: 818d46ede85682dd go1.21.0.src.tar.gz\ndistpack: 4fcd8651d084a03d go1.21.0.linux-amd64.tar.gz\ndistpack: eab8ed80024f444f v0.0.1-go1.21.0.linux-amd64.zip\ndistpack: 58528cce1848ddf4 v0.0.1-go1.21.0.linux-amd64.mod\ndistpack: d8da1f27296edea4 v0.0.1-go1.21.0.linux-amd64.info\n---\nInstalled Go for linux/amd64 in /Users/rsc/deb/go-clean\nInstalled commands in /Users/rsc/deb/go-clean/bin\n*** You need to add /Users/rsc/deb/go-clean/bin to your PATH.\n$\n\n\\\nThat left the standard package in pkg/distpack/go1.21.0.linux-amd64.tar.gz. Let’s unpack it and strip the binaries to match Ubuntu:\n$ cd ../..\n$ tar xzvf go-clean/pkg/distpack/go1.21.0.linux-amd64.tar.gz\nx go/CONTRIBUTING.md\nx go/LICENSE\nx go/PATENTS\nx go/README.md\nx go/SECURITY.md\nx go/VERSION\n...\n$ elfstrip go/bin/* go/pkg/tool/linux_amd64/*\n$\n\n\\\nNow we can diff the Go toolchain we’ve created on our Mac with the Go toolchain that Ubuntu ships:\n$ diff -r go go-ubuntu\nOnly in go: CONTRIBUTING.md\nOnly in go: LICENSE\nOnly in go: PATENTS\nOnly in go: README.md\nOnly in go: SECURITY.md\nOnly in go: codereview.cfg\nOnly in go: doc\nOnly in go: lib\nBinary files go/misc/chrome/gophertool/gopher.png and go-ubuntu/misc/chrome/gophertool/gopher.png differ\nOnly in go-ubuntu/pkg/tool/linux_amd64: dist\nOnly in go-ubuntu/pkg/tool/linux_amd64: distpack\nOnly in go/src: all.rc\nOnly in go/src: clean.rc\nOnly in go/src: make.rc\nOnly in go/src: run.rc\ndiff -r go/src/syscall/mksyscall.pl go-ubuntu/src/syscall/mksyscall.pl\n1c1\n< #!/usr/bin/env perl\n---\n> #! /usr/bin/perl\n...\n$\n\nWe’ve successfully reproduced the Ubuntu package’s executables and identified the complete set of changes that remain:\nVarious metadata and supporting files have been deleted.\n\\\n\nThe gopher.png file has been modified. On closer inspection the two are identical except for an embedded timestamp that Ubuntu has updated. Perhaps Ubuntu’s packaging scripts recompressed the png with a tool that rewrites the timestamp even when it cannot improve on the existing compression.\n\\\n\nThe binaries dist and distpack, which are built during bootstrap but not included in standard archives, have been included in the Ubuntu package.\n\\\n\nThe Plan 9 build scripts (*.rc) have been deleted, although the Windows build scripts (*.bat) remain.\n\\\n\nmksyscall.pl and seven other Perl scripts not shown have had their headers changed.\n\\\nNote in particular that we’ve reconstructed the toolchain binaries bit-for-bit: they do not show up in the diff at all. That is, we proved that the Ubuntu Go binaries correspond exactly to the upstream Go sources.\n\\\nEven better, we proved this without using any Ubuntu software at all: these commands were run on a Mac, and unzstd and elfstrip are short Go programs. A sophisticated attacker might insert malicious code into an Ubuntu package by changing the package-creation tools. If they did, reproducing the Go Ubuntu package from clean sources using those malicious tools would still produce bit-for-bit identical copies of the malicious packages. \n\\\nThis attack would be invisible to that kind of rebuild, much like Ken Thompson’s compiler attack. Verifying the Ubuntu packages using no Ubuntu software at all is a much stronger check. Go’s perfectly reproducible builds, which don’t depend on unindented details like the host operating system, host architecture, and host C toolchain, are what make this stronger check possible.\n\\\n(As an aside for the historical record, Ken Thompson told me once that his attack was in fact detected, because the compiler build stopped being reproducible. It had a bug: a string constant in the backdoor added to the compiler was imperfectly handled and grew by a single NUL byte each time the compiler compiled itself. Eventually someone noticed the non-reproducible build and tried to find the cause by compiling to assembly. The compiler’s backdoor did not reproduce itself into assembly output at all, so assembling that output removed the backdoor.)\nConclusion\nReproducible builds are an important tool for strengthening the open-source supply chain. Frameworks like SLSA focus on provenance and a software chain of custody that can be used to inform decisions about trust. Reproducible builds complement that approach by providing a way to verify that the trust is well-placed.\n\\\nPerfect reproducibility (when the source files are the build’s only relevant input) is only possible for programs that build themselves, like compiler toolchains. It is a lofty but worthwhile goal precisely because self-hosting compiler toolchains are otherwise quite difficult to verify. Go’s perfect reproducibility means that, assuming packagers don’t modify the source code, every repackaging of Go 1.21.0 for Linux/x86-64 (substitute your favorite system) in any form should be distributing exactly the same binaries, even when they all build from source. We’ve seen that this is not quite true for Ubuntu Linux, but perfect reproducibility still lets us reproduce the Ubuntu packaging using a very different, non-Ubuntu system.\n\\\nIdeally all open source software distributed in binary form would have easy-to-reproduce builds. In practice, as we’ve seen in this post, it is very easy for unintended inputs to leak into builds. For Go programs that don’t need cgo, a reproducible build is as simple as compiling with CGO_ENABLED=0 go build -trimpath. Disabling cgo removes the host C toolchain as a relevant input, and -trimpath removes the current directory. If your program does need cgo, you need to arrange for a specific host C toolchain version before running go build, such as by running the build in a specific virtual machine or container image.\n\\\nMoving beyond Go, the Reproducible Builds project aims to improve reproducibility of all open source and is a good starting point for more information about making your own software builds reproducible.\nRuss Cox\n\\\nPhoto by Alex Pudov on Unsplash\n\\\nThis article is available on The Go Blog under a CC BY 4.0 DEED license.",
          "date": "2025-08-03T12:00:07.000Z",
          "link": "https://hackernoon.com/reproducible-go-toolchains-what-you-need-to-know?source=rss",
          "categories": "[\"go\",\"golang\",\"go-toolchains\",\"what-are-go-tool-chains\",\"reproducible-builds\",\"reproducibility-in-go\",\"hackernoon-top-story\",\"host-dynamic-linker\"]"
        }
      }
    ],
    "Aggregate": [
      {
        "json": {
          "title": [
            "The Nintendo Switch 2’s Biggest Problem Is Already Storage",
            "19 Best Barefoot Shoes for Running or Walking (2025), Tested and Reviewed",
            "What Happens to Your Data If You Stop Paying for Cloud Storage?",
            "Efforts to Ground Physics in Math Are Opening the Secrets of Time",
            "12 Best Outdoor Security Cameras (2025): Battery-Powered, LTE, No Subscription",
            "How to Clean Your Mattress (2025)",
            "Apple might be building its own AI ‘answer engine’",
            "Mastercard denies pressuring game platforms, Valve tells a different story",
            "SAP is acquiring SmartRecruiters",
            "Inside OpenAI’s quest to make AI do anything for you",
            "The uproar over Vogue’s AI-generated ad isn’t just about fashion",
            "7 Essential Layers for Building Real-World AI Agents in 2025: A Comprehensive Framework",
            "ByteDance Introduces Seed-Prover: An Advanced Formal Reasoning System for Automated Mathematical Theorem Proving",
            "Tutorial: Exploring SHAP-IQ Visualizations",
            "A Technical Roadmap to Context Engineering in LLMs: Mechanisms, Benchmarks, and Open Challenges",
            "The Ultimate Guide to CPUs, GPUs, NPUs, and TPUs for AI/ML: Performance, Use Cases, and Key Differences",
            "Building an End-to-End Object Tracking and Analytics System with Roboflow Supervision",
            "The Impossibility Theorem Behind Truthful Blockchain Bidding Mechanisms",
            "No Blockchain Auction Can Satisfy UIC, MIC, and Global SCP at Once",
            "What Is a Transaction Fee Mechanism? Definitions, Incentives, and Strategies",
            "Why No Transaction Fee Mechanism Can Truly Be Collusion-Proof",
            "Why Truthful Blockchain Mechanisms Fail Under Finite Block Sizes",
            "Why the Perfect Blockchain Fee Mechanism May Be Impossible",
            "Designing for Intelligence, Efficiency, and Accessibility",
            "SDG LAB Venture Fund Backs Virtual Intimacy with $20 Million — But Will It Work?",
            "The HackerNoon Newsletter: 9 Things Hollywood Gets Wrong About Hacking (8/3/2025)",
            "Mobile AI with ONNX Runtime: How to Build Real-Time Noise Suppression That Works",
            "The Real Reason Most Indie Games Flop (It Has Nothing To Do With Gameplay)",
            "10 Ways AI Is Shaping the Future of Mobile App Development",
            "Solving Coding Puzzles: The Evolution of Programmer Assistance Tools",
            "The Hidden Cost of Performance: How High-Load Specialization Warps Engineering Intuition",
            "Can Anyone Code Now? Exploring AI Help for Non-Programmers",
            "Europe’s Data Vision: Dataspaces for Zero-Trust AI Infrastructure",
            "Reproducible Go Toolchains: What You Need to Know"
          ],
          "content": [
            "In 2025, 256 gigabytes just isn’t enough, and tacking on more storage isn’t as easy as it sounds.",
            "Our favorite zero-drop, minimalist footwear will let you feel the ground beneath your feet.",
            "Hit by subscription fatigue? Here’s what happens to your files and photos if you cancel your paid storage plan.",
            "By proving how individual molecules create the complex motion of fluids, three mathematicians have illuminated why time can’t flow in reverse.",
            "These weatherproof outdoor security cams keep a watchful eye on your property while you get on with life. Our list includes battery-powered and LTE devices and cameras that need no subscription.",
            "From barf to blood, your stained mattress isn’t necessarily beyond repair. Here’s how to salvage your investment from every worst-case scenario.",
            "Apple is reportedly working to create a lightweight competitor to ChatGPT.",
            "Mastercard seemingly denied playing a role in a recent marketplace crackdown on games with adult content, while Valve says the pressure was indirect.",
            "SAP has reached an agreement to acquire SmartRecruiters, with SmartRecruiters' software complementing SAP's existing HR tools.",
            "OpenAI developed the first AI reasoning model less than a year ago, but the technology has shifted Silicon Valley's focus to agents.",
            "“Modeling as a profession is already challenging enough without having to compete with now new digital standards of perfection that can be achieved with AI,” Sarah Murray told TechCrunch.",
            "Building an intelligent agent goes far beyond clever prompt engineering for language models. To create real-world, autonomous AI systems that can think, reason, act, and learn, you need to engineer a full-stack solution that orchestrates multiple tightly–integrated components. The following seven-layer framework is a battle-tested mental model for anyone serious about AI agent development—whether you’re a founder, AI engineer, or product leader.\n1. Experience Layer — The Human Interface\nThe Experience Layer acts as the touchpoint between humans and the agent. It defines how users interact with the system: conversation (chat/web/app), voice, image, or even multimodal engagement. This layer must be intuitive, accessible, and capable of capturing user intent precisely, while providing clear feedback.\nCore design challenge: Translate ambiguous human goals into machine-understandable objectives.\nExample: A customer support chatbot interface, or a voice assistant in a smart home.\n2. Discovery Layer — Information Gathering & Context\nAgents need to orient themselves: knowing what to ask, where to look, and how to gather relevant information. The Discovery Layer encompasses techniques like web search, document retrieval, data mining, context collection, sensor integration, and interaction history analysis.\nCore design challenge: Efficient, reliable, and context-aware information retrieval that surfaces only what matters.\nExample: Fetching product manuals, extracting knowledge bases, or summarizing recent emails.\n3. Agent Composition Layer — Structure, Goals, and Behaviors\nThis layer defines what the agent is and how it should behave. It includes defining the agent’s goals, its modular architecture (sub-agents, policies, roles), possible actions, ethical boundaries, and configurable behaviors.\nCore design challenge: Enabling customization and extensibility while ensuring coherence and alignment with user and business objectives.\nExample: Setting up a sales assistant agent with negotiation tactics, brand voice, and escalation protocols.\n4. Reasoning & Planning Layer — The Agent’s Brain\nAt the heart of autonomy, the Reasoning & Planning Layer handles logic, decision-making, inference, and action sequencing. Here, the agent evaluates information, weighs alternatives, plans steps, and adapts strategies. This layer can leverage symbolic reasoning engines, LLMs, classical AI planners, or hybrids.\nCore design challenge: Moving beyond pattern-matching to true adaptive intelligence.\nExample: Prioritizing customer queries, scheduling multi-step workflows, or generating argument chains.\n5. Tool & API Layer — Acting in the World\nThis layer enables the agent to perform real actions: executing code, triggering APIs, controlling IoT devices, managing files, or running external workflows. The agent must safely interface with digital and (sometimes) physical systems, often requiring robust error handling, authentication, and permissions management.\nCore design challenge: Safe, reliable, and flexible action-taking with external systems.\nExample: Booking a meeting on your calendar, placing an e-commerce order, or running data analysis scripts.\n6. Memory & Feedback Layer — Contextual Recall & Learning\nAgents that learn and improve over time must maintain memory: tracking prior interactions, storing context, and incorporating user feedback. This layer supports both short-term contextual recall (for conversation) and long-term learning (improving models, policies, or knowledge bases).\nCore design challenge: Scalable memory representation and effective feedback integration.\nExample: Remembering user preferences, learning common support issues, or iteratively refining suggestions.\n7. Infrastructure Layer — Scaling, Orchestration, & Security\nBeneath the application stack, robust infrastructure ensures the agent is available, responsive, scalable, and secure. This layer includes orchestration platforms, distributed compute, monitoring, failover, and compliance safeguards.\nCore design challenge: Reliability and robustness at scale.\nExample: Managing thousands of concurrent agent instances with uptime guarantees and secure API gateways.\nKey Takeaways\nTrue autonomy requires more than language understanding.\nIntegrate all 7 layers for agents that can safely sense, plan, act, learn, and scale.\nAdopt this framework to assess, design, and build next-generation AI systems that solve meaningful problems.\nFeel free to check out our GitHub Page for Tutorials, Codes and Notebooks. Also, feel free to follow us on Twitter and don’t forget to join our 100k+ ML SubReddit and Subscribe to our Newsletter.\nThe post 7 Essential Layers for Building Real-World AI Agents in 2025: A Comprehensive Framework appeared first on MarkTechPost.",
            "LLMs have shown notable improvements in mathematical reasoning by extending through natural language, resulting in performance gains on benchmarks such as MATH and AIME. However, reinforcement learning (RL) for training these models encounters a challenge: verifying the correctness of natural language proofs is very difficult, requiring careful manual checking of each reasoning step. This limits the application of RL for training mathematical theorem-proving models. While formal languages like Lean offer automatic correctness verification, current LLM formal provers face their limitations. Step-level provers generate code incrementally but require special scaffolding and lack high-level reasoning capabilities.\nByteDance Seed Team introduces Seed-Prover, a lemma-style whole-proof reasoning model. It refines proofs iteratively using Lean feedback, previously established lemmas, and self-summarization. Seed-Prover employs three specialized test-time inference strategies that allow deep and broad reasoning methods to solve IMO-level contest problems. Its primary innovation is in adopting lemma-style proving as its core method, placing lemmas at the center of the reasoning process rather than relying on traditional step-by-step or whole-proof generation methods. Moreover, this paper introduces Seed-Geometry,  a complementary geometry reasoning engine that overcomes Lean’s limitations in handling geometric support.\n\nFor interaction between Seed-Prover and Lean, multi-stage, multi-task RL based on VAPO is utilized. The training dataset combines open-source datasets with in-house formal problems, using a proposer to create simpler variants of difficult tasks. It excludes overly simple problems with proof rates above 25%. Seed-Geometry’s backend supports large-scale problem generation, identifying over 230 million unique problems across seven days with an eightfold improvement in search efficiency. A separate policy and value model is trained, though extensive testing shows that value models may reduce performance due to estimation errors. As a result, step-by-step generation with beam search is adopted in distributed setups.\nSeed-Prover achieves state-of-the-art results across multiple mathematical benchmarks. For IMO 2025, Seed-Prover fully solves 5 out of 6 problems, with Seed-Geometry instantly solving Problem 2 and Seed-Prover deriving proofs for the remaining problem using various inference settings. On past IMO problems, it proved 121 out of 155 tasks, achieving a 78.1% success rate across all difficulty levels. The performance breakdown shows strong results across problem categories: solving 47 out of 55 easy problems, 47 out of 56 medium problems, and 27 out of 44 hard problems, with subject-specific success rates including 72 out of 85 in algebra, 42 out of 55 in number theory, and 7 out of 14 in combinatorics.\nOn MiniF2F, researchers achieve a 99.6% proof rate for both validation and test sets under medium settings, solving difficult problems such as IMO 1990 P3. PutnamBench results show improvement from 201 to 331 solved problems out of 657 when upgrading from light to medium inference settings, showing a significant performance jump over previous undergraduate-level mathematical reasoning systems. On CombiBench, Seed-Prover solves 30 out of 100 combinatorics problems, outperforming existing methods but revealing continued challenges in combinatorial reasoning. Researchers achieve 81.8% success on MiniCTX-v2, showing strong generalization beyond competition problems and outperforming the o4-mini baseline’s 44.3% at Pass@8.\n\nIn conclusion, ByteDance Seed presents Seed-Geometry and Seed-Prover, two formal reasoning methods that integrate the capabilities of LLMs. Seed-Geometry provides accelerated verification and enhanced search mechanisms while Seed-Prover utilizes iterative refinement and complex test-time inference strategies. The achievement of solving 5 out of 6 problems in the IMO 2025 shows the practical efficacy of these methods in tackling elite mathematical competitions. The adoption of formal languages like Lean provides rapid proof verification that is more cost-effective than human experts and more reliable than LLM-based judges. Future research will focus on combining formal systems with LLMs to address open conjectures.\nCheck out the Paper and GitHub Page. Feel free to check out our GitHub Page for Tutorials, Codes and Notebooks. Also, feel free to follow us on Twitter and don’t forget to join our 100k+ ML SubReddit and Subscribe to our Newsletter.\nThe post ByteDance Introduces Seed-Prover: An Advanced Formal Reasoning System for Automated Mathematical Theorem Proving appeared first on MarkTechPost.",
            "In this tutorial, we’ll explore a range of SHAP-IQ visualizations that provide insights into how a machine learning model arrives at its predictions. These visuals help break down complex model behavior into interpretable components—revealing both the individual and interactive contributions of features to a specific prediction. Check out the Full Codes here.\nInstalling the dependencies\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\n!pip install shapiq overrides scikit-learn pandas numpy seaborn\n\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.model_selection import train_test_split\nfrom tqdm.asyncio import tqdm\n\nimport shapiq\n\nprint(f\"shapiq version: {shapiq.__version__}\")\n\nImporting the dataset\nIn this tutorial, we’ll use the MPG (Miles Per Gallon) dataset, which we’ll load directly from the Seaborn library. This dataset contains information about various car models, including features like horsepower, weight, and origin. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\nimport seaborn as sns\ndf = sns.load_dataset(\"mpg\")\ndf\n\nProcessing the dataset\nWe use Label Encoding to convert the categorical column(s) into numeric format, making them suitable for model training.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\n# Drop rows with missing values\ndf = df.dropna()\n\n# Encoding the origin column\nle = LabelEncoder()\ndf.loc[:, \"origin\"] = le.fit_transform(df[\"origin\"])\ndf['origin'].unique()\n\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\nfor i, label in enumerate(le.classes_):\n    print(f\"{label} → {i}\")\n\nSplitting the data into training & test subsets\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\n# Select features and target\nX = df.drop(columns=[\"mpg\", \"name\"])\ny = df[\"mpg\"]\n\nfeature_names = X.columns.tolist()\nx_data, y_data = X.values, y.values\n\n# Train-test split\nx_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)\n\nModel Training\nWe train a Random Forest Regressor with a maximum depth of 10 and 10 decision trees (n_estimators=10). A fixed random_state ensures reproducibility.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\n# Train model\nmodel = RandomForestRegressor(random_state=42, max_depth=10, n_estimators=10)\nmodel.fit(x_train, y_train)\n\nModel Evaluation\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\n# Evaluate\nmse = mean_squared_error(y_test, model.predict(x_test))\nr2 = r2_score(y_test, model.predict(x_test))\nprint(f\"Mean Squared Error: {mse:.2f}\")\nprint(f\"R2 Score: {r2:.2f}\")\n\nExplaining a Local Instance\nWe choose a specific test instance (with instance_id = 7) to explore how the model arrived at its prediction. We’ll print the true value, predicted value, and the feature values for this instance. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\n# select a local instance to be explained\ninstance_id = 7\nx_explain = x_test[instance_id]\ny_true = y_test[instance_id]\ny_pred = model.predict(x_explain.reshape(1, -1))[0]\nprint(f\"Instance {instance_id}, True Value: {y_true}, Predicted Value: {y_pred}\")\nfor i, feature in enumerate(feature_names):\n    print(f\"{feature}: {x_explain[i]}\")\n\nGenerating Explanations for Multiple Interaction Orders\nWe generate Shapley-based explanations for different interaction orders using the shapiq package. Specifically, we compute:\nOrder 1 (Standard Shapley Values): Individual feature contributions\nOrder 2 (Pairwise Interactions): Combined effects of feature pairs\nOrder N (Full Interaction): All interactions up to the total number of features\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\n# create explanations for different orders\nfeature_names = list(X.columns)  # get the feature names\nn_features = len(feature_names)\n\nsi_order: dict[int, shapiq.InteractionValues] = {}\nfor order in tqdm([1, 2, n_features]):\n    index = \"k-SII\" if order > 1 else \"SV\"  # will also be set automatically by the explainer\n    explainer = shapiq.TreeExplainer(model=model, max_order=order, index=index)\n    si_order[order] = explainer.explain(x=x_explain)\nsi_order\n\n1. Force Chart\nThe force plot is a powerful visualization tool that helps us understand how a machine learning model arrived at a specific prediction. It displays the baseline prediction (i.e., the expected value of the model before seeing any features), and then shows how each feature “pushes” the prediction higher or lower.\nIn this plot:\nRed bars represent features or interactions that increase the prediction.\nBlue bars represent those that decrease it.\nThe length of each bar corresponds to the magnitude of its effect.\nWhen using Shapley interaction values, the force plot can visualize not just individual contributions but also interactions between features. This makes it especially insightful when interpreting complex models, as it visually decomposes how combinations of features work together to influence the outcome. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\nsv = si_order[1]  # get the SV\nsi = si_order[2]  # get the 2-SII\nmi = si_order[n_features]  # get the Moebius transform\n\nsv.plot_force(feature_names=feature_names, show=True)\nsi.plot_force(feature_names=feature_names, show=True)\nmi.plot_force(feature_names=feature_names, show=True)\n\n\n\n\n\nFrom the first plot, we can see that the base value is 23.5. Features like Weight, Cylinders, Horsepower, and Displacement have a positive influence on the prediction, pushing it above the baseline. On the other hand, Model Year and Acceleration have a negative impact, pulling the prediction downward.\n2. Waterfall Chart\nSimilar to the force plot, the waterfall plot is another popular way to visualize Shapley values, originally introduced with the shap library. It shows how different features push the prediction higher or lower compared to the baseline. One key advantage of the waterfall plot is that it automatically groups features with very small impacts into an “other” category, making the chart cleaner and easier to understand. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\nsv.plot_waterfall(feature_names=feature_names, show=True)\nsi.plot_waterfall(feature_names=feature_names, show=True)\nmi.plot_waterfall(feature_names=feature_names, show=True)\n\n\n\n\n\n\n\n\n\n\n\n\n\n3. Network Plot\nThe network plot shows how features interact with each other using first- and second-order Shapley interactions. Node size reflects individual feature impact, while edge width and color show interaction strength and direction. It’s especially helpful when dealing with many features, revealing complex interactions that simpler plots might miss. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\nsi.plot_network(feature_names=feature_names, show=True)\nmi.plot_network(feature_names=feature_names, show=True)\n\n\n\n\n\n4. SI Graph Plot\nThe SI graph plot extends the network plot by visualizing all higher-order interactions as hyper-edges connecting multiple features. Node size shows individual feature impact, while edge width, color, and transparency reflect the strength and direction of interactions. It provides a comprehensive view of how features jointly influence the model’s prediction. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\n# we abbreviate the feature names since, they are plotted inside the nodes\nabbrev_feature_names = shapiq.plot.utils.abbreviate_feature_names(feature_names)\nsv.plot_si_graph(\n    feature_names=abbrev_feature_names,\n    show=True,\n    size_factor=2.5,\n    node_size_scaling=1.5,\n    plot_original_nodes=True,\n)\nsi.plot_si_graph(\n    feature_names=abbrev_feature_names,\n    show=True,\n    size_factor=2.5,\n    node_size_scaling=1.5,\n    plot_original_nodes=True,\n)\nmi.plot_si_graph(\n    feature_names=abbrev_feature_names,\n    show=True,\n    size_factor=2.5,\n    node_size_scaling=1.5,\n    plot_original_nodes=True,\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n5. Bar Plot\nThe bar plot is tailored for global explanations. While other plots can be used both locally and globally, the bar plot summarizes the overall importance of features (or feature interactions) by showing the mean absolute Shapley (or interaction) values across all instances. In shapiq, it highlights which feature interactions contribute most on average. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\nexplanations = []\nexplainer = shapiq.TreeExplainer(model=model, max_order=2, index=\"k-SII\")\nfor instance_id in tqdm(range(20)):\n    x_explain = x_test[instance_id]\n    si = explainer.explain(x=x_explain)\n    explanations.append(si)\nshapiq.plot.bar_plot(explanations, feature_names=feature_names, show=True)\n\n\n\n\n\n“Distance” and “Horsepower” are the most influential features overall, meaning they have the strongest individual impact on the model’s predictions. This is evident from their high mean absolute Shapley interaction values in the bar plot.\nAdditionally, when looking at second-order interactions (i.e., how two features interact together), the combinations “Horsepower × Weight” and “Distance × Horsepower” show significant joint influence. Their combined attribution is around 1.4, indicating that these interactions play an important role in shaping the model’s predictions beyond what each feature contributes individually. This highlights the presence of non-linear relationships between features in the model.\nCheck out the Full Codes here. Feel free to check out our GitHub Page for Tutorials, Codes and Notebooks. Also, feel free to follow us on Twitter and don’t forget to join our 100k+ ML SubReddit and Subscribe to our Newsletter.\nThe post Tutorial: Exploring SHAP-IQ Visualizations appeared first on MarkTechPost.",
            "Estimated reading time: 4 minutes\nTable of contents\n\nWhat Is Context Engineering?\nTaxonomy of Context Engineering\nKey Insights and Research Gaps\nApplications and Impact\nFuture Directions\n\nThe paper “A Survey of Context Engineering for Large Language Models” establishes Context Engineering as a formal discipline that goes far beyond prompt engineering, providing a unified, systematic framework for designing, optimizing, and managing the information that guides Large Language Models (LLMs). Here’s an overview of its main contributions and framework:\nWhat Is Context Engineering?\nContext Engineering is defined as the science and engineering of organizing, assembling, and optimizing all forms of context fed into LLMs to maximize performance across comprehension, reasoning, adaptability, and real-world application. Rather than viewing context as a static string (the premise of prompt engineering), context engineering treats it as a dynamic, structured assembly of components—each sourced, selected, and organized through explicit functions, often under tight resource and architectural constraints.\n\n\n\n\nTaxonomy of Context Engineering\nThe paper breaks down context engineering into:\n1. Foundational Components\na. Context Retrieval and Generation\nEncompasses prompt engineering, in-context learning (zero/few-shot, chain-of-thought, tree-of-thought, graph-of-thought), external knowledge retrieval (e.g., Retrieval-Augmented Generation, knowledge graphs), and dynamic assembly of context elements1.\nTechniques like CLEAR Framework, dynamic template assembly, and modular retrieval architectures are highlighted.\nb. Context Processing\nAddresses long-sequence processing (with architectures like Mamba, LongNet, FlashAttention), context self-refinement (iterative feedback, self-evaluation), and integration of multimodal and structured information (vision, audio, graphs, tables).\nStrategies include attention sparsity, memory compression, and in-context learning meta-optimization.\nc. Context Management\nInvolves memory hierarchies and storage architectures (short-term context windows, long-term memory, external databases), memory paging, context compression (autoencoders, recurrent compression), and scalable management over multi-turn or multi-agent settings.\n2. System Implementations\na. Retrieval-Augmented Generation (RAG)\nModular, agentic, and graph-enhanced RAG architectures integrate external knowledge and support dynamic, sometimes multi-agent retrieval pipelines.\nEnables both real-time knowledge updates and complex reasoning over structured databases/graphs.\nb. Memory Systems\nImplement persistent and hierarchical storage, enabling longitudinal learning and knowledge recall for agents (e.g., MemGPT, MemoryBank, external vector databases).\nKey for extended, multi-turn dialogs, personalized assistants, and simulation agents.\nc. Tool-Integrated Reasoning\nLLMs use external tools (APIs, search engines, code execution) via function calling or environment interaction, combining language reasoning with world-acting abilities.\nEnables new domains (math, programming, web interaction, scientific research).\nd. Multi-Agent Systems\nCoordination among multiple LLMs (agents) via standardized protocols, orchestrators, and context sharing—essential for complex, collaborative problem-solving and distributed AI applications.\nKey Insights and Research Gaps\nComprehension–Generation Asymmetry: LLMs, with advanced context engineering, can comprehend very sophisticated, multi-faceted contexts but still struggle to generate outputs matching that complexity or length.\nIntegration and Modularity: Best performance comes from modular architectures combining multiple techniques (retrieval, memory, tool use).\nEvaluation Limitations: Current evaluation metrics/benchmarks (like BLEU, ROUGE) often fail to capture the compositional, multi-step, and collaborative behaviors enabled by advanced context engineering. New benchmarks and dynamic, holistic evaluation paradigms are needed.\nOpen Research Questions: Theoretical foundations, efficient scaling (especially computationally), cross-modal and structured context integration, real-world deployment, safety, alignment, and ethical concerns remain open research challenges.\nApplications and Impact\nContext engineering supports robust, domain-adaptive AI across:\nLong-document/question answering\nPersonalized digital assistants and memory-augmented agents\nScientific, medical, and technical problem-solving\nMulti-agent collaboration in business, education, and research\nFuture Directions\nUnified Theory: Developing mathematical and information-theoretic frameworks.\nScaling & Efficiency: Innovations in attention mechanisms and memory management.\nMulti-Modal Integration: Seamless coordination of text, vision, audio, and structured data.\nRobust, Safe, and Ethical Deployment: Ensuring reliability, transparency, and fairness in real-world systems.\nIn summary: Context Engineering is emerging as the pivotal discipline for guiding the next generation of LLM-based intelligent systems, shifting the focus from creative prompt writing to the rigorous science of information optimization, system design, and context-driven AI.\nCheck out the Paper. Feel free to check out our GitHub Page for Tutorials, Codes and Notebooks. Also, feel free to follow us on Twitter and don’t forget to join our 100k+ ML SubReddit and Subscribe to our Newsletter.\nThe post A Technical Roadmap to Context Engineering in LLMs: Mechanisms, Benchmarks, and Open Challenges appeared first on MarkTechPost.",
            "Artificial intelligence and machine learning workloads have fueled the evolution of specialized hardware to accelerate computation far beyond what traditional CPUs can offer. Each processing unit—CPU, GPU, NPU, TPU—plays a distinct role in the AI ecosystem, optimized for certain models, applications, or environments. Here’s a technical, data-driven breakdown of their core differences and best use cases.\nCPU (Central Processing Unit): The Versatile Workhorse\nDesign & Strengths: CPUs are general-purpose processors with a few powerful cores—ideal for single-threaded tasks and running diverse software, including operating systems, databases, and light AI/ML inference.\nAI/ML Role: CPUs can execute any kind of AI model, but lack the massive parallelism needed for efficient deep learning training or inference at scale.\nBest for:\n\nClassical ML algorithms (e.g., scikit-learn, XGBoost)\nPrototyping and model development\nInference for small models or low-throughput requirements\nTechnical Note: For neural network operations, CPU throughput (typically measured in GFLOPS—billion floating point operations per second) lags far behind specialized accelerators.\nGPU (Graphics Processing Unit): The Deep Learning Backbone\nDesign & Strengths: Originally for graphics, modern GPUs feature thousands of parallel cores designed for matrix/multiple vector operations, making them highly efficient for training and inference of deep neural networks.\nPerformance Examples:\n\nNVIDIA RTX 3090: 10,496 CUDA cores, up to 35.6 TFLOPS (teraFLOPS) FP32 compute.\nRecent NVIDIA GPUs include “Tensor Cores” for mixed precision, accelerating deep learning operations.\nBest for:\n\nTraining and inferencing large-scale deep learning models (CNNs, RNNs, Transformers)\nBatch processing typical in datacenter and research environments\nSupported by all major AI frameworks (TensorFlow, PyTorch)\nBenchmarks: A 4x RTX A5000 setup can surpass a single, far more expensive NVIDIA H100 in certain workloads, balancing acquisition cost and performance.\nNPU (Neural Processing Unit): The On-device AI Specialist\nDesign & Strengths: NPUs are ASICs (application-specific chips) crafted exclusively for neural network operations. They optimize parallel, low-precision computation for deep learning inference, often running at low power for edge and embedded devices.\nUse Cases & Applications:\n\nMobile & Consumer: Powering features like face unlock, real-time image processing, language translation on devices like the Apple A-series, Samsung Exynos, Google Tensor chips.\nEdge & IoT: Low-latency vision and speech recognition, smart city cameras, AR/VR, and manufacturing sensors.\nAutomotive: Real-time data from sensors for autonomous driving and advanced driver assistance.\nPerformance Example: The Exynos 9820’s NPU is ~7x faster than its predecessor for AI tasks.\nEfficiency: NPUs prioritize energy efficiency over raw throughput, extending battery life while supporting advanced AI features locally.\nTPU (Tensor Processing Unit): Google’s AI Powerhouse\nDesign & Strengths: TPUs are custom chips developed by Google specifically for large tensor computations, tuning hardware around the needs of frameworks like TensorFlow.\nKey Specifications:\n\nTPU v2: Up to 180 TFLOPS for neural network training and inference.\nTPU v4: Available in Google Cloud, up to 275 TFLOPS per chip, scalable to “pods” exceeding 100 petaFLOPS.\nSpecialized matrix multiplication units (“MXU”) for enormous batch computations.\nUp to 30–80x better energy efficiency (TOPS/Watt) for inference compared to contemporary GPUs and CPUs.\nBest for:\n\nTraining and serving massive models (BERT, GPT-2, EfficientNet) in cloud at scale\nHigh-throughput, low-latency AI for research and production pipelines\nTight integration with TensorFlow and JAX; increasingly interfacing with PyTorch\nNote: TPU architecture is less flexible than GPU—optimized for AI, not graphics or general-purpose tasks.\nWhich Models Run Where?\n\nHardwareBest Supported ModelsTypical Workloads\n\nCPUClassical ML, all deep learning models*General software, prototyping, small AI\nGPUCNNs, RNNs, TransformersTraining and inference (cloud/workstation)\nNPUMobileNet, TinyBERT, custom edge modelsOn-device AI, real-time vision/speech\nTPUBERT/GPT-2/ResNet/EfficientNet, etc.Large-scale model training/inference\n\n\n\n\n\n*CPUs support any model, but are not efficient for large-scale DNNs.\nData Processing Units (DPUs): The Data Movers\nRole: DPUs accelerate networking, storage, and data movement, offloading these tasks from CPUs/GPUs. They enable higher infrastructure efficiency in AI datacenters by ensuring compute resources focus on model execution, not I/O or data orchestration.\nSummary Table: Technical Comparison\n\nFeatureCPUGPUNPUTPU\n\nUse CaseGeneral ComputeDeep LearningEdge/On-device AIGoogle Cloud AI\nParallelismLow–ModerateVery High (~10,000+)Moderate–HighExtremely High (Matrix Mult.)\nEfficiencyModeratePower-hungryUltra-efficientHigh for large models\nFlexibilityMaximumVery high (all FW)SpecializedSpecialized (TensorFlow/JAX)\nHardwarex86, ARM, etc.NVIDIA, AMDApple, Samsung, ARMGoogle (Cloud only)\nExampleIntel XeonRTX 3090, A100, H100Apple Neural EngineTPU v4, Edge TPU\n\n\n\n\n\nKey Takeaways\nCPUs are unmatched for general-purpose, flexible workloads.\nGPUs remain the workhorse for training and running neural networks across all frameworks and environments, especially outside Google Cloud.\nNPUs dominate real-time, privacy-preserving, and power-efficient AI for mobile and edge, unlocking local intelligence everywhere from your phone to self-driving cars.\nTPUs offer unmatched scale and speed for massive models—especially in Google’s ecosystem—pushing the frontiers of AI research and industrial deployment.\nChoosing the right hardware depends on model size, compute demands, development environment, and desired deployment (cloud vs. edge/mobile). A robust AI stack often leverages a mix of these processors, each where it excels.\nThe post The Ultimate Guide to CPUs, GPUs, NPUs, and TPUs for AI/ML: Performance, Use Cases, and Key Differences appeared first on MarkTechPost.",
            "In this advanced Roboflow Supervision tutorial, we build a complete object detection pipeline with the Supervision library. We begin by setting up real-time object tracking using ByteTracker, adding detection smoothing, and defining polygon zones to monitor specific regions in a video stream. As we process the frames, we annotate them with bounding boxes, object IDs, and speed data, enabling us to track and analyze object behavior over time. Our goal is to showcase how we can combine detection, tracking, zone-based analytics, and visual annotation into a seamless and intelligent video analysis workflow. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\n!pip install supervision ultralytics opencv-python\n!pip install --upgrade supervision \n\n\nimport cv2\nimport numpy as np\nimport supervision as sv\nfrom ultralytics import YOLO\nimport matplotlib.pyplot as plt\nfrom collections import defaultdict\n\n\nmodel = YOLO('yolov8n.pt')\n\nWe start by installing the necessary packages, including Supervision, Ultralytics, and OpenCV. After ensuring we have the latest version of Supervision, we import all required libraries. We then initialize the YOLOv8n model, which serves as the core detector in our pipeline. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\ntry:\n   tracker = sv.ByteTrack()\nexcept AttributeError:\n   try:\n       tracker = sv.ByteTracker()\n   except AttributeError:\n       print(\"Using basic tracking - install latest supervision for advanced tracking\")\n       tracker = None\n\n\ntry:\n   smoother = sv.DetectionsSmoother(length=5)\nexcept AttributeError:\n   smoother = None\n   print(\"DetectionsSmoother not available in this version\")\n\n\ntry:\n   box_annotator = sv.BoundingBoxAnnotator(thickness=2)\n   label_annotator = sv.LabelAnnotator()\n   if hasattr(sv, 'TraceAnnotator'):\n       trace_annotator = sv.TraceAnnotator(thickness=2, trace_length=30)\n   else:\n       trace_annotator = None\nexcept AttributeError:\n   try:\n       box_annotator = sv.BoxAnnotator(thickness=2)\n       label_annotator = sv.LabelAnnotator()\n       trace_annotator = None\n   except AttributeError:\n       print(\"Using basic annotators - some features may be limited\")\n       box_annotator = None\n       label_annotator = None \n       trace_annotator = None\n\n\ndef create_zones(frame_shape):\n   h, w = frame_shape[:2]\n  \n   try:\n       entry_zone = sv.PolygonZone(\n           polygon=np.array([[0, h//3], [w//3, h//3], [w//3, 2*h//3], [0, 2*h//3]]),\n           frame_resolution_wh=(w, h)\n       )\n      \n       exit_zone = sv.PolygonZone(\n           polygon=np.array([[2*w//3, h//3], [w, h//3], [w, 2*h//3], [2*w//3, 2*h//3]]),\n           frame_resolution_wh=(w, h)\n       )\n   except TypeError:\n       entry_zone = sv.PolygonZone(\n           polygon=np.array([[0, h//3], [w//3, h//3], [w//3, 2*h//3], [0, 2*h//3]])\n       )\n       exit_zone = sv.PolygonZone(\n           polygon=np.array([[2*w//3, h//3], [w, h//3], [w, 2*h//3], [2*w//3, 2*h//3]])\n       )\n  \n   return entry_zone, exit_zone\n\nWe set up essential components from the Supervision library, including object tracking with ByteTrack, optional smoothing using DetectionsSmoother, and flexible annotators for bounding boxes, labels, and traces. To ensure compatibility across versions, we use try-except blocks to fall back to alternative classes or basic functionality when needed. Additionally, we define dynamic polygon zones within the frame to monitor specific regions like entry and exit areas, enabling advanced spatial analytics. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\nclass AdvancedAnalytics:\n   def __init__(self):\n       self.track_history = defaultdict(list)\n       self.zone_crossings = {\"entry\": 0, \"exit\": 0}\n       self.speed_data = defaultdict(list)\n      \n   def update_tracking(self, detections):\n       if hasattr(detections, 'tracker_id') and detections.tracker_id is not None:\n           for i in range(len(detections)):\n               track_id = detections.tracker_id[i]\n               if track_id is not None:\n                   bbox = detections.xyxy[i]\n                   center = np.array([(bbox[0] + bbox[2]) / 2, (bbox[1] + bbox[3]) / 2])\n                   self.track_history[track_id].append(center)\n                  \n                   if len(self.track_history[track_id]) >= 2:\n                       prev_pos = self.track_history[track_id][-2]\n                       curr_pos = self.track_history[track_id][-1]\n                       speed = np.linalg.norm(curr_pos - prev_pos)\n                       self.speed_data[track_id].append(speed)\n  \n   def get_statistics(self):\n       total_tracks = len(self.track_history)\n       avg_speed = np.mean([np.mean(speeds) for speeds in self.speed_data.values() if speeds])\n       return {\n           \"total_objects\": total_tracks,\n           \"zone_entries\": self.zone_crossings[\"entry\"],\n           \"zone_exits\": self.zone_crossings[\"exit\"],\n           \"avg_speed\": avg_speed if not np.isnan(avg_speed) else 0\n       }\n\n\ndef process_video(source=0, max_frames=300):\n   \"\"\"\n   Process video source with advanced supervision features\n   source: video path or 0 for webcam\n   max_frames: limit processing for demo\n   \"\"\"\n   cap = cv2.VideoCapture(source)\n   analytics = AdvancedAnalytics()\n  \n   ret, frame = cap.read()\n   if not ret:\n       print(\"Failed to read video source\")\n       return\n  \n   entry_zone, exit_zone = create_zones(frame.shape)\n  \n   try:\n       entry_zone_annotator = sv.PolygonZoneAnnotator(\n           zone=entry_zone,\n           color=sv.Color.GREEN,\n           thickness=2\n       )\n       exit_zone_annotator = sv.PolygonZoneAnnotator(\n           zone=exit_zone,\n           color=sv.Color.RED,\n           thickness=2\n       )\n   except (AttributeError, TypeError):\n       entry_zone_annotator = sv.PolygonZoneAnnotator(zone=entry_zone)\n       exit_zone_annotator = sv.PolygonZoneAnnotator(zone=exit_zone)\n  \n   frame_count = 0\n   results_frames = []\n  \n   cap.set(cv2.CAP_PROP_POS_FRAMES, 0) \n  \n   while ret and frame_count < max_frames:\n       ret, frame = cap.read()\n       if not ret:\n           break\n          \n       results = model(frame, verbose=False)[0]\n       detections = sv.Detections.from_ultralytics(results)\n      \n       detections = detections[detections.class_id == 0]\n      \n       if tracker is not None:\n           detections = tracker.update_with_detections(detections)\n      \n       if smoother is not None:\n           detections = smoother.update_with_detections(detections)\n      \n       analytics.update_tracking(detections)\n      \n       entry_zone.trigger(detections)\n       exit_zone.trigger(detections)\n      \n       labels = []\n       for i in range(len(detections)):\n           confidence = detections.confidence[i] if detections.confidence is not None else 0.0\n          \n           if hasattr(detections, 'tracker_id') and detections.tracker_id is not None:\n               track_id = detections.tracker_id[i]\n               if track_id is not None:\n                   speed = analytics.speed_data[track_id][-1] if analytics.speed_data[track_id] else 0\n                   label = f\"ID:{track_id} | Conf:{confidence:.2f} | Speed:{speed:.1f}\"\n               else:\n                   label = f\"Conf:{confidence:.2f}\"\n           else:\n               label = f\"Conf:{confidence:.2f}\"\n           labels.append(label)\n      \n       annotated_frame = frame.copy()\n      \n       annotated_frame = entry_zone_annotator.annotate(annotated_frame)\n       annotated_frame = exit_zone_annotator.annotate(annotated_frame)\n      \n       if trace_annotator is not None:\n           annotated_frame = trace_annotator.annotate(annotated_frame, detections)\n      \n       if box_annotator is not None:\n           annotated_frame = box_annotator.annotate(annotated_frame, detections)\n       else:\n           for i in range(len(detections)):\n               bbox = detections.xyxy[i].astype(int)\n               cv2.rectangle(annotated_frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 2)\n      \n       if label_annotator is not None:\n           annotated_frame = label_annotator.annotate(annotated_frame, detections, labels)\n       else:\n           for i, label in enumerate(labels):\n               if i < len(detections):\n                   bbox = detections.xyxy[i].astype(int)\n                   cv2.putText(annotated_frame, label, (bbox[0], bbox[1]-10),\n                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n      \n       stats = analytics.get_statistics()\n       y_offset = 30\n       for key, value in stats.items():\n           text = f\"{key.replace('_', ' ').title()}: {value:.1f}\"\n           cv2.putText(annotated_frame, text, (10, y_offset),\n                      cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n           y_offset += 30\n      \n       if frame_count % 30 == 0:\n           results_frames.append(cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB))\n      \n       frame_count += 1\n      \n       if frame_count % 50 == 0:\n           print(f\"Processed {frame_count} frames...\")\n  \n   cap.release()\n  \n   if results_frames:\n       fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n       axes = axes.flatten()\n      \n       for i, (ax, frame) in enumerate(zip(axes, results_frames[:4])):\n           ax.imshow(frame)\n           ax.set_title(f\"Frame {i*30}\")\n           ax.axis('off')\n      \n       plt.tight_layout()\n       plt.show()\n  \n   final_stats = analytics.get_statistics()\n   print(\"\\n=== FINAL ANALYTICS ===\")\n   for key, value in final_stats.items():\n       print(f\"{key.replace('_', ' ').title()}: {value:.2f}\")\n  \n   return analytics\n\n\nprint(\"Starting advanced supervision demo...\")\nprint(\"Features: Object detection, tracking, zones, speed analysis, smoothing\")\n\n\nWe define the AdvancedAnalytics class to track object movement, calculate speed, and count zone crossings, enabling rich real-time video insights. Inside the process_video function, we read each frame from the video source and run it through our detection, tracking, and smoothing pipeline. We annotate frames with bounding boxes, labels, zone overlays, and live statistics, giving us a powerful, flexible system for object monitoring and spatial analytics. Throughout the loop, we also collect data for visualization and print final statistics, showcasing the effectiveness of Roboflow Supervision’s end-to-end capabilities. Check out the Full Codes here.\n\n\n\n\n\nCopy CodeCopiedUse a different Browser\n\ndef create_demo_video():\n   \"\"\"Create a simple demo video with moving objects\"\"\"\n   fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n   out = cv2.VideoWriter('demo.mp4', fourcc, 20.0, (640, 480))\n  \n   for i in range(100):\n       frame = np.zeros((480, 640, 3), dtype=np.uint8)\n      \n       x1 = int(50 + i * 2)\n       y1 = 200\n       x2 = int(100 + i * 1.5)\n       y2 = 250\n      \n       cv2.rectangle(frame, (x1, y1), (x1+50, y1+50), (0, 255, 0), -1)\n       cv2.rectangle(frame, (x2, y2), (x2+50, y2+50), (255, 0, 0), -1)\n      \n       out.write(frame)\n  \n   out.release()\n   return 'demo.mp4'\n\n\ndemo_video = create_demo_video()\nanalytics = process_video(demo_video, max_frames=100)\n\n\nprint(\"\\nTutorial completed! Key features demonstrated:\")\nprint(\"✓ YOLO integration with Supervision\")\nprint(\"✓ Multi-object tracking with ByteTracker\")\nprint(\"✓ Detection smoothing\")\nprint(\"✓ Polygon zones for area monitoring\")\nprint(\"✓ Advanced annotations (boxes, labels, traces)\")\nprint(\"✓ Real-time analytics and statistics\")\nprint(\"✓ Speed calculation and tracking history\")\n\n\nTo test our full pipeline, we generate a synthetic demo video with two moving rectangles simulating tracked objects. This allows us to validate detection, tracking, zone monitoring, and speed analysis without needing a real-world input. We then run the process_video function on the generated clip. At the end, we print out a summary of all key features we’ve implemented, showcasing the power of Roboflow Supervision for real-time visual analytics.\nIn conclusion, we have successfully implemented a full pipeline that brings together object detection, tracking, zone monitoring, and real-time analytics. We demonstrate how to visualize key insights like object speed, zone crossings, and tracking history with annotated video frames. This setup empowers us to go beyond basic detection and build a smart surveillance or analytics system using open-source tools. Whether for research or production use, we now have a powerful foundation to expand upon with even more advanced capabilities.\nCheck out the Full Codes here. Feel free to check out our GitHub Page for Tutorials, Codes and Notebooks. Also, feel free to follow us on Twitter and don’t forget to join our 100k+ ML SubReddit and Subscribe to our Newsletter.\nThe post Building an End-to-End Object Tracking and Analytics System with Roboflow Supervision appeared first on MarkTechPost.",
            "Table of Links\nAbstract and 1. Introduction\n1.1 Our Contributions\n1.2 TFM Incentive-Compatibility Notions: A Cheat Sheet\nDefinitions\n2.1 Transaction Fee Mechanism\n2.2 Incentive Compatibility Notions\n\n\nPreliminary: Myerson’s Lemma\n\n\nWarmup: Impossibility of UIC + MIC + Global SCP for Deterministic Mechanisms\n\n\nImpossibility of UIC + MIC + Global SCP for Randomized Mechanisms and 5.1 Proof Roadmap\n5.2 Formal Proofs\n\n\nFeasibility and Impossibility of UIC + MIC + OCA-Proof\n6.1 A Non-Truthful Mechanism with UIC + MIC + OCA-Proof\n6.2 Impossibility of UIC + MIC + OCA-Proof for Truthful Mechanisms\n\n\nHow to Circumvent the Impossibilities and 7.1 Allowing the Globally Optimal Strategy to Coordinate\n7.2 Allowing the Globally Optimal Strategy to Output Multiple Bids\n7.3 Inclusion-Rule-Respecting and 7.4 Discussions and Open Questions Regarding the Use of Cryptography\n\n\nStatic Revelation Principle for Transaction Fee Mechanisms\n8.1 Static Revelation Principle: Bidding Rules That Output Single Bid\n8.2 Static Revelation Principle: Allowing Bidding Rules that Output Multiple Bids\n\n\nA. Comparison of Collusion-Resilience Notions\nReferences\n\\\n6 Feasibility and Impossibility of UIC + MIC + OCA-Proof\nWe can generalize the proof in Section 5, and rule out UIC, MIC, and OCA-proof (rather than global SCP) for truthful mechanisms. Recall that for a truthful mechanism, the difference between OCA-proof and global SCP is that global SCP insists that the optimal strategy of the global coalition is the truthful strategy, whereas OCA-proofness allows it to be some other strategy in which each user acts independently and bids the outcome of some function σ(·).\n\\\nInterestingly, if we allow the bidding rule to be not truth-telling, i.e. considering non-truthful mechanisms, we can have a mechanism that satisfies UIC, MIC, and OCA-proof. We present the feasibility for non-truthful mechanisms in Section 6.1, and we prove the impossibility of UIC + MIC + OCA-proof for truthful mechanisms in Section 6.2. Notice that because of the feasibility in Section 6.1, we must require the bidding rule to be truth-telling to reach an impossibility in Section 6.2.\n6.1 A Non-Truthful Mechanism with UIC + MIC + OCA-Proof\nThe rationale of the design is to signal to the mechanism when everyone is adopting the globally optimal strategy σ (as opposed to the bidding rule used to establish UIC). When the mechanism detects that everyone is behaving according to σ, it adopts a different behavior to optimize social welfare. We use the range [0, 1) to encode the actual bid, and use the range [1,∞) for signalling. While the resulting mechanism is somewhat contrived and not necessarily meaningful from a practical point of view, it clarifies which notions of collusion-resilience most accurately capture the intended modeling goals and illustrates some technical challenges involved in the proof in Section 6.2. Consider the following TFM:\n\\\n• Globally optimal strategy σ(v): Given a true value v, output a bid v + 1.\n\\\n• Bidding rule: Given a true value v, output a bid 1/(v + 2).\n\\\n• Inclusion rule: Let S be the set of all pending bids that are in [0, 1). If |S| > k, then randomly select k bids from S to include. If 1 ≤ |S| ≤ k, then include all bids in S. If |S| = 0, choose the top up to k bids to include.\n\\\n• Confirmation, payment, and miner revenue rules: All included bids are confirmed. Each confirmed bid pays nothing, and the miner gets nothing.\n\\\nObviously, this mechanism is non-trivial.\n\\\nClaim 6.1. The above mechanism satisfies UIC, MIC, and OCA-proofness.\n\\\nProof. For UIC, notice that if a user follows the bidding rule, its bid is always in [0, 1). If there is no bid in [0, 1) before a user submits its bid, then bidding 1/(v + 2) always guarantees user’s bid to be included and confirmed, where v denote the true value. If there is already some bids in [0, 1) before a user submits its bid, then bidding 1/(v + 2) is a dominant strategy since it guarantees the user’s bid is added to S, the set of all bids in [0, 1), which is the best a user can do. Next, MIC holds since the miner revenue is always zero. Finally, if all users follow the globally optimal strategy σ, everyone’s bid is at least 1. The honest inclusion rule will include the top up to k bids, which maximizes the social welfare. Thus, OCA-proofness holds.\n\\\nRemark 1. We can try to apply revelation principle, and bake the bidding rule into the mechanism so that the resulting mechanism is truthful. For example, whenever seeing a bid b, the miner and the mechanism view it as 1/(b + 2). The modified mechanism, however, does not satisfy OCAproofness anymore when the number of users is larger than the block size, since the miner should choose k users with the highest true values instead of the random selection as indicated by the inclusion rule. This is not a coincidence: in the next section, we show that it is impossible to have a non-trivial truthful mechanism satisfying UIC, MIC, and OCA-proofness.\n\\\n:::info\nAuthors:\n(1) Hao Chung∗, Carnegie Mellon University (haochung@andrew.cmu.edu);\n(2) Tim Roughgarden†, Columbia University and a16z (crypto tim.roughgarden@gmail.com);\n(3) Elaine Shi∗, Carnegie Mellon University (runting@cs.cmu.edu).\n:::\n:::info\nThis paper is available on arxiv under CC BY 4.0 DEED license.\n:::\n\\",
            "Table of Links\nAbstract and 1. Introduction\n1.1 Our Contributions\n1.2 TFM Incentive-Compatibility Notions: A Cheat Sheet\nDefinitions\n2.1 Transaction Fee Mechanism\n2.2 Incentive Compatibility Notions\n\n\nPreliminary: Myerson’s Lemma\n\n\nWarmup: Impossibility of UIC + MIC + Global SCP for Deterministic Mechanisms\n\n\nImpossibility of UIC + MIC + Global SCP for Randomized Mechanisms and 5.1 Proof Roadmap\n5.2 Formal Proofs\n\n\nFeasibility and Impossibility of UIC + MIC + OCA-Proof\n6.1 A Non-Truthful Mechanism with UIC + MIC + OCA-Proof\n6.2 Impossibility of UIC + MIC + OCA-Proof for Truthful Mechanisms\n\n\nHow to Circumvent the Impossibilities and 7.1 Allowing the Globally Optimal Strategy to Coordinate\n7.2 Allowing the Globally Optimal Strategy to Output Multiple Bids\n7.3 Inclusion-Rule-Respecting and 7.4 Discussions and Open Questions Regarding the Use of Cryptography\n\n\nStatic Revelation Principle for Transaction Fee Mechanisms\n8.1 Static Revelation Principle: Bidding Rules That Output Single Bid\n8.2 Static Revelation Principle: Allowing Bidding Rules that Output Multiple Bids\n\n\nA. Comparison of Collusion-Resilience Notions\nReferences\n3 Preliminary: Myerson’s Lemma\n\n\\\nConceptually, user i must pay the minimal price which makes its bid confirmed.\n4 Warmup: Impossibility of UIC + MIC + Global SCP for Deterministic Mechanisms\nAs a warmup, we first show a finite-block impossibility for UIC + MIC + global SCP for deterministic mechanisms. Recall that a TFM is said to be trivial if everyone’s confirmation probability is zero for any bid vector assuming the miner follows the inclusion rule. In this case, everyone’s utility is always zero in an honest execution. We will show that no non-trivial mechanism can satisfy all three properties simultaneously. Later in Section 5, we extend the impossibility to randomized mechanisms. Due to the revelation principle that we prove in Section 8, if we can prove the impossibility for truthful mechanisms, the impossibility immediately extends to non-truthful mechanisms as well. Therefore, in this section, we shall assume truthful mechanisms.\n\\\nLemma 4.1. For any global SCP mechanism, the confirmed bids must correspond to the highest bids.\n\\\nProof. Suppose in some scenario, Alice bids her true value b and Bob bids his true value b ′ < b; however, Bob’s bid is confirmed, and Alice’s is not. Now, we can have Alice and Bob swap their bids. The miner creates the same block as before in which the position originally corresponding to Bob now has Alice’s bid of b′. Since the mechanism is weakly symmetric (Definition 1), Alice’s bid is confirmed. This way, the social welfare increases by b − b′ in comparison with the honest case, and this violates global SCP.\n\\\nLemma 4.2. For any global SCP mechanism, the amount of burnt coins depends only on the number of confirmed bids.\n\\\nProof. Suppose in two different scenarios, when everyone acts honestly, the blocks made are B and B′ respectively, the confirmed bids are b ⊆ B and b′ ⊆ B′ respectively where b and b′ are of the same length, and the burnt amount in the two scenarios are q and q′ respectively, where q < q′. Now, suppose we are actually in the second scenario. A global coalition can adopt the following strategy: create a block identical to B in which the confirmed bids correspond to the users with the highest true values and the rest can be fake bids. Observe that the social welfare is the sum of the true values of all confirmed bids (where fake bids have a true value of 0) minus the total coins burnt. Therefore, the above strategy achieves strictly higher social welfare than the honest case.\n\\\nTheorem 4.3. No non-trivial deterministic TFM can simultaneously satisfy UIC, MIC, and global SCP when the block size is finite.\n\\\n\\\n \n5 Impossibility of UIC + MIC + Global SCP for Randomized Mechanisms\nIn this section, we extend the finite-block impossibility of UIC + MIC + global SCP to even randomized mechanisms. Recall that a TFM consists of five rules as defined in Section 2.1, and a randomized TFM may use randomness in any of the five rules. Since the confirmation, the payment, and the miner revenue rules are executed by the blockchain, the strategic players can only bias the randomness in and deviate from the bidding rule and the inclusion rule. Again, due to the revelation principle proven in Section 8, it suffices to consider truthful mechanisms.\n5.1 Proof Roadmap\n\\\n \n5.2 Formal Proofs\nIn the rest of this section, we present the formal proofs.\n\\\n\\\n \n\\\n\\\n\\\n \n\\\n\\\n\\\n \n\\\n\\\nProof. We first prove that expected miner utility is the same in both scenarios. Suppose this is not true, and without loss of generality, suppose expected miner utility is higher in scenario 1. Then, the miner can ignore the bids b, inject the fake bids b′, pretend that the bid vector is (a, b′), and run the honest mechanism. Since the confirmation probability of b′ is 0, the miner need not pay any cost for the fake bids. Therefore, the miner gets higher expected utility by taking the above strategy which violates MIC.\n\\\nThe proof of total social welfare is similar. Suppose without loss of generality, that the expected total social welfare in scenario 1 is higher. Then, the global coalition can inject fake bids b′ and pretend that the bid vector is (a, b′), thus allowing it to increase its expected social welfare. This violates global SCP.\n\\\nThe equivalence in total user utility follows directly from the above, since total user utility is the difference between the social welfare and the miner utility.\n\\\n\\\n \n\\\n\\\n\\\n \n\\\n\\\nLemma 5.5. Suppose the mechanism satisfies UIC, MIC, and global SCP, and the block size is k. Let a be any positive real number. Consider a scenario with only one bid a. Then, the only user’s utility is zero assuming it bids its true value.\n\\\n\\\n \n\\\n\\\nTheorem 5.6. No non-trivial, possibly randomized TFM can simultaneously satisfy UIC, MIC, and global SCP when the block size is finite.\n\\\nProof. We will show that under any sufficiently large a, the confirmation probability under a single bid a is non-zero. If we can show this, then we can show a contradiction to UIC. Specifically, consider b > a and both sufficiently large. By Lemma 5.5, if there is only one user with true value b, its utility is zero when it bids truthfully. However, the user can underbid a. Since the confirmation probability is non-zero and the payment is at most a, the user enjoys positive utility, which violates UIC.\n\\\n\\\n \n\\\n\\\n:::info\nAuthors:\n(1) Hao Chung∗, Carnegie Mellon University (haochung@andrew.cmu.edu);\n(2) Tim Roughgarden†, Columbia University and a16z (crypto tim.roughgarden@gmail.com);\n(3) Elaine Shi∗, Carnegie Mellon University (runting@cs.cmu.edu).\n:::\n:::info\nThis paper is available on arxiv under CC BY 4.0 DEED license.\n:::\n\\",
            "Table of Links\nAbstract and 1. Introduction\n1.1 Our Contributions\n1.2 TFM Incentive-Compatibility Notions: A Cheat Sheet\nDefinitions\n2.1 Transaction Fee Mechanism\n2.2 Incentive Compatibility Notions\n\n\nPreliminary: Myerson’s Lemma\n\n\nWarmup: Impossibility of UIC + MIC + Global SCP for Deterministic Mechanisms\n\n\nImpossibility of UIC + MIC + Global SCP for Randomized Mechanisms and 5.1 Proof Roadmap\n5.2 Formal Proofs\n\n\nFeasibility and Impossibility of UIC + MIC + OCA-Proof\n6.1 A Non-Truthful Mechanism with UIC + MIC + OCA-Proof\n6.2 Impossibility of UIC + MIC + OCA-Proof for Truthful Mechanisms\n\n\nHow to Circumvent the Impossibilities and 7.1 Allowing the Globally Optimal Strategy to Coordinate\n7.2 Allowing the Globally Optimal Strategy to Output Multiple Bids\n7.3 Inclusion-Rule-Respecting and 7.4 Discussions and Open Questions Regarding the Use of Cryptography\n\n\nStatic Revelation Principle for Transaction Fee Mechanisms\n8.1 Static Revelation Principle: Bidding Rules That Output Single Bid\n8.2 Static Revelation Principle: Allowing Bidding Rules that Output Multiple Bids\n\n\nA. Comparison of Collusion-Resilience Notions\nReferences\n2 Definitions\n2.1 Transaction Fee Mechanism\n\n\\\nA transaction fee mechanism (TFM) consists of the following possibly randomized algorithms:\n\\\n \n\\\nWe say a TFM is trivial if the confirmation probability of all transactions is zero for any bid vector assuming the miner honestly follows the inclusion rule; otherwise, it is called non-trivial.\n\\\nA strategic miner or miner-user coalition may deviate from the honest inclusion rule. On the other hand, since the confirmation, payment, and miner revenue rules are executed by the blockchain, they are always implemented honestly.\n\\\nWe focus on mechanisms that are weakly symmetric, i.e., mechanisms that do not make use of the bidders’ identities or other auxiliary information (e.g., timestamp, transaction metadata), except for tie-breaking among equal bids. More formally, we define weak symmetry as below.\n\\\nDefinition 1 (Weak symmetry). A mechanism is called weakly symmetric if the mechanism can always be equivalently described in the following manner: given a bid vector b where each bid may carry some extra information such as identity or timestamp, the honest mechanism always sorts the vector b by the bid amount first. During the sorting step, if multiple bids have the same amount, then arbitrary tie-breaking rules may be applied, and the tie-breaking can depend on extra information such as timestamp, identity, or random coins. After this sorting step, the inclusion rule and the confirmation rules should depend only on the amount of the bids and their relative position in the sorted bid vector.\n\\\n \n\\\nStrategy space. A strategic user can deviate from the honest bidding rule and post an arbitrary bid vector with zero to multiple bids. Without loss of generality, we may assume that in the strategic bid vector, at most one bid can correspond to the user’s actual transaction which has a non-zero true value; all other bids must be fake bids with zero true value. A strategic miner can deviate from the honest inclusion rule, and instead create an arbitrary block (subject to the block size limit) that includes any subset of the bid vector as well as any number of fake bids that it chooses to inject. A strategic miner-user coalition can adopt a combination of the above strategies.\n\\\nUtility and social welfare. For a user with true value v, let x ∈ {0, 1} be the indicator of whether its primary bid is confirmed or not, let p denote its total payment, then the user’s utility is x · v − p. The miner’s utility is simply its revenue. The social welfare is defined to be the sum of the utilities of all users and the miner (i.e., the total value of the confirmed transactions, less any burned payments).\n\\\nNotice that we allow the miner revenue to be smaller than the sum of users’ payment, since the coins can be burnt. When calculating the social welfare, the payments among the users and the miner are canceled out, so the social welfare is independent of the payment; however, the amount of burnt coins decreases the social welfare. For example, suppose there is only one user, and let p be the user’s payment and q be the amount of burnt coins. In this case, the user’s utility is x·v −p, the miner revenue is p − q, and the social welfare is (x · v − p) + (p − q) = x · v − q.\n2.2 Incentive Compatibility Notions\n\\\n \n\\\n\\\nDefinition 3 (Miner incentive compatible (MIC)). A TFM is said to be miner incentive compatible (MIC), iff given any bid vector b, the miner’s expected utility is maximized when the miner does not inject any fake bid and creates a block indicated by the honest inclusion rule.\n\\\n\\\n \n\\\n\\\nDefinition 5 (Global side-contract-proof (global SCP)). A TFM is said to be global side-contract-proof (global SCP), iff given any vector of true values v, the expected social welfare is maximized when all the users bid according to the honest bidding rule, and the miner follows the honest inclusion rule, where the maximization is taken over all the coordinated strategies that the coalition consisting of the miner and all users can adopt.\n\\\n\\\n \n\\\n\\\nIn the definitions above, the expectation is taken over the randomness of the TFM. More explicitly, in Definition 2, the expectation is taken over the randomness of the inclusion/confirmation/payment rules; in Definitions 3 to 6, the expectation is taken over the randomness of the inclusion/confirmation/ payment/miner revenue rules.\n\\\nNote that in the OCA-proofness definition, σ is required to output a single real-valued bid. A canonical example of σ is scaling; that is, σ(v) = γv for some γ ∈ [0, 1] (cf., Corollary 5.12 and 5.14 in [Rou21]).\n\\\nA detailed comparison between c-SCP, global SCP, and OCA-proofness is given in Appendix A.\n\\\n:::info\nAuthors:\n(1) Hao Chung∗, Carnegie Mellon University (haochung@andrew.cmu.edu);\n(2) Tim Roughgarden†, Columbia University and a16z (crypto tim.roughgarden@gmail.com);\n(3) Elaine Shi∗, Carnegie Mellon University (runting@cs.cmu.edu).\n:::\n:::info\nThis paper is available on arxiv under CC BY 4.0 DEED license.\n:::\n[5] The finite block size regime in this work and [CS23] corresponds to the case in [Rou21] where the base fee in the EIP-1559 or tipless mechanisms is excessively low, i.e. the number of transactions willing to pay the base fee exceeds the maximum block size (cf., Definition 5.6 in [Rou21]).\n\\\n[6] The blockchain protocol can always suppress conflicting or double-spending transactions.\n\\\n[7] Throughout the paper except Section 8, we only focus on bidding rules that output a single bid. In Section 8, we consider general bidding rules that may output multiple bids.\n\\\n[8] Roughgarden [Rou21] assumes that all included transactions are confirmed. However, Chung and Shi [CS23] show that allowing unconfirmed transactions in a block enlarges the design space. For example, some mechanisms require a block to contain some unconfirmed transactions (see Section 7 in [CS23]).\n\\\n[9] We can also relax the requirement such that individual rationality holds in expectation. Both the impossibility results (Sections 4, 5 and 6.2) and the revelation principle result (Section 8) continue to hold.",
            "Table of Links\nAbstract and 1. Introduction\n1.1 Our Contributions\n1.2 TFM Incentive-Compatibility Notions: A Cheat Sheet\nDefinitions\n2.1 Transaction Fee Mechanism\n2.2 Incentive Compatibility Notions\n\n\nPreliminary: Myerson’s Lemma\n\n\nWarmup: Impossibility of UIC + MIC + Global SCP for Deterministic Mechanisms\n\n\nImpossibility of UIC + MIC + Global SCP for Randomized Mechanisms and 5.1 Proof Roadmap\n5.2 Formal Proofs\n\n\nFeasibility and Impossibility of UIC + MIC + OCA-Proof\n6.1 A Non-Truthful Mechanism with UIC + MIC + OCA-Proof\n6.2 Impossibility of UIC + MIC + OCA-Proof for Truthful Mechanisms\n\n\nHow to Circumvent the Impossibilities and 7.1 Allowing the Globally Optimal Strategy to Coordinate\n7.2 Allowing the Globally Optimal Strategy to Output Multiple Bids\n7.3 Inclusion-Rule-Respecting and 7.4 Discussions and Open Questions Regarding the Use of Cryptography\n\n\nStatic Revelation Principle for Transaction Fee Mechanisms\n8.1 Static Revelation Principle: Bidding Rules That Output Single Bid\n8.2 Static Revelation Principle: Allowing Bidding Rules that Output Multiple Bids\n\n\nA. Comparison of Collusion-Resilience Notions\nReferences\n1.2 TFM Incentive-Compatibility Notions: A Cheat Sheet\nWe gather here informal definitions and comparisons of the key incentive-compatibility notions used in this paper. First, a transaction fee mechanism specifies how a user is supposed to bid (as a function of its private valuation), which transactions a miner is supposed to include (as a function of the transactions it knows about and their bids), and the resulting outcome (the subset of included transactions that get confirmed, and the payments made by the users and received by the miner). If the bidding strategy suggested by the TFM is the identity, then we additionally call the TFM truthful. In this paper, as in the rest of the TFM literature, we consider only static mechanisms.\n\\\n• UIC. (Definition 2) Provided that the miner follows the suggested inclusion rule, the bidding strategy suggested by the TFM is a dominant strategy for users.\n\\\n• MIC. (Definition 3) The inclusion rule suggested by the TFM is always revenue-maximizing for the miner regardless of users’ bids; moreover, the miner cannot increase its revenue through the injection of fake transactions.\n\\\n• Global SCP. (Definition 5) If the miner follows the inclusion rule suggested by the TFM and all users follow the bidding rule suggested by the TFM, then their joint surplus is at least as large as it would be from any coordinated deviation.\n\\\n• c-SCP. (Definition 4) For every coalition of the miner and at most c users, if the miner follows the inclusion rule suggested by the TFM and the users in the coalition follow the bidding rule suggested by the TFM, then the joint surplus of the coalition is at least as large as it would be from any coordinated deviation (holding fixed the bids of users outside the coalition).\n\\\n• OCA-proof. (Definition 6) If the miner follows the inclusion rule suggested by the TFM and all users follow a suitably chosen individually rational bidding rule σ (possibly different from the one suggested in the TFM description), then their joint surplus is as large as it would be from any coordinated deviation.\n\\\nFor example, in [Rou21] it was shown that Ethereum’s EIP-1559 TFM and a variant called the “tipless mechanism” satisfy UIC, MIC, and OCA-proofness when there is no contention between transactions; in fact, in this case, these TFMs satisfy the c-SCP condition for every c ≥ 1. When there is contention between transactions for inclusion in a block, the EIP-1559 TFM loses its UIC property and the tipless mechanism loses (all three notions of) collusion-resilience.\n\\\nAs mentioned above:\n\\\n• (Theorem 8.1) A relevation principle holds for the global SCP and c-SCP notions: any UIC and MIC TFM that satisfies one of these properties can be simulated by a truthful UIC and MIC TFM that satisfies the same property.\n\\\n• A relevation principle does not in general hold for the OCA-proof notion: while there are non-truthful TFMs that satisfy UIC, MIC, and OCA-proofness (Section 6.1), there are no truthful TFMs that satisfy UIC, MIC, and OCA-proofness (Theorem 6.9).\n\\\nThe main result in Chung and Shi [CS23] states that, even among randomized TFMs, no TFM satisfies UIC and c-SCP for any c ≥ 1. Our Theorem 5.6 proves that, even among randomized TFMs, no TFM satisfies UIC, MIC, and global SCP. (Due to the revelation principle mentioned above, these impossibility results apply to both truthful and non-truthful TFMs.) Our Theorem 6.9 proves the stronger statement that, even among randomized TFMs, no truthful TFM satisfies UIC, MIC, and OCA-proofness.\n\\\nReflecting on the competing notions of collusion-resilience, we can observe the following. The cSCP condition may be particularly appropriate in scenarios where the primary concern is deviations by small coalitions, or in scenarios where users may wish to deviate in ways that exploit other users. The c-SCP condition is also notable in that, together with the UIC condition, it already triggers the impossibility result in [CS23] (without any appeal to MIC). The OCA-proofness condition is distinguished by being the weakest of the three notions (thus leading to the strongest impossibility results) and by allowing the discussion of non-UIC mechanisms.[4] For TFMs that are UIC and MIC, like those studied in this paper, global SCP is arguably the “right” definition—capturing the spirit of OCA-proofness, without any additional technical complications arising from users using different bidding strategies to satisfy UIC and collusion-resilience. Put differently, the UIC and MIC conditions imply that the miner and the users following their intended strategies constitutes a Nash equilibrium; the global SCP condition asserts that this Nash equilibrium is also robust to deviations by the grand coalition, while OCA-proofness only asserts such robustness for a possibly different strategy profile (defined by the intended inclusion rule and some individually rational bidding strategy). From this vantage point, one might view Theorem 5.6 as the main impossibility result in this paper, with Theorem 6.9 serving as a technically challenging extension of the result under still weaker incentive-compatibility conditions.\n\\\n:::info\nAuthors:\n(1) Hao Chung∗, Carnegie Mellon University (haochung@andrew.cmu.edu);\n(2) Tim Roughgarden†, Columbia University and a16z (crypto tim.roughgarden@gmail.com);\n(3) Elaine Shi∗, Carnegie Mellon University (runting@cs.cmu.edu).\n:::\n:::info\nThis paper is available on arxiv under CC BY 4.0 DEED license.\n:::\n[4] For example, in a first-price auction, the “reference outcome” might be defined by a (non-truthful) bidding strategy that would constitute a Bayes-Nash equilibrium with respect to some prior over user valuations (cf., Corollary 5.12 in [Rou21]).",
            "Table of Links\nAbstract and 1. Introduction\n1.1 Our Contributions\n1.2 TFM Incentive-Compatibility Notions: A Cheat Sheet\nDefinitions\n2.1 Transaction Fee Mechanism\n2.2 Incentive Compatibility Notions\n\n\nPreliminary: Myerson’s Lemma\n\n\nWarmup: Impossibility of UIC + MIC + Global SCP for Deterministic Mechanisms\n\n\nImpossibility of UIC + MIC + Global SCP for Randomized Mechanisms and 5.1 Proof Roadmap\n5.2 Formal Proofs\n\n\nFeasibility and Impossibility of UIC + MIC + OCA-Proof\n6.1 A Non-Truthful Mechanism with UIC + MIC + OCA-Proof\n6.2 Impossibility of UIC + MIC + OCA-Proof for Truthful Mechanisms\n\n\nHow to Circumvent the Impossibilities and 7.1 Allowing the Globally Optimal Strategy to Coordinate\n7.2 Allowing the Globally Optimal Strategy to Output Multiple Bids\n7.3 Inclusion-Rule-Respecting and 7.4 Discussions and Open Questions Regarding the Use of Cryptography\n\n\nStatic Revelation Principle for Transaction Fee Mechanisms\n8.1 Static Revelation Principle: Bidding Rules That Output Single Bid\n8.2 Static Revelation Principle: Allowing Bidding Rules that Output Multiple Bids\n\n\nA. Comparison of Collusion-Resilience Notions\nReferences\n1.1 Our Contributions\nAs explained above, both Roughgarden’s and Chung and Shi’s collusion-resilience notions capture meaningful incentive compatibility considerations. Recognizing their differences, one natural question is: does Chung and Shi’s finite-block impossibility result still hold if we adopt the original OCA-proofness notion of Roughgarden in lieu of c-SCP? Notably, no existing TFM construction [LSZ19, Yao, BEOS19, BCD+, Rou20, Rou21, FMPS21, CS23, SCW23, WSC24, GY22, ZCZ22, BGR23, TY23, KKLP23, XFP23, CMW23, LRMP23, Ndi23] simultaneously satisfies user incentive compatibility, miner incentive compatibility, and OCA-proofness under finite block size.\n\\\nMain impossibility result. In our work, we give an affirmative answer to the above question. We show that, indeed, an analog of Chung and Shi’s finite-block impossibility result still holds when we replace the c-SCP requirement with OCA-proofness. Specifically, we prove the following theorem.\n\\\nTheorem 1.1. Suppose the block size is finite. Then, no possibly randomized, truthful TFM can simultaneously satisfy user incentive compatibility (UIC), miner incentive compatibility (MIC), and OCA-proofness. Further, this impossibility holds even when the globally optimal strategy σ need not be individually rational.\n\\\nIn a truthful TFM, a user is expected to bid truthfully, so if the mechanism satisfies UIC, a user’s utility is maximized when it just reports its true value. However, OCA-proofness allows the global coalition to adopt a non-truthful bidding strategy σ even for truthful mechanisms.\n\\\nOur Theorem 1.1 is intuitively stronger but technically incomparable in comparison with Chung and Shi’s impossibility, which shows that no TFM can simultaneously satisfy UIC and 1-SCP for finite block sizes. The reason is that Chung and Shi’s impossibility does not rely on MIC; however, MIC is necessary for our Theorem 1.1 to hold. Specifically, a simple second-price auction with no burning (see Remark 2) satisfies both UIC and OCA-proofness, but does not satisfy MIC since the miner may benefit by injecting a fake (t + 1)-th bid where t is the number of confirmed bids, since the (t + 1)-th bid sets the price for confirmed bids.\n\\\nGlobal SCP. We suggest a simpler version of OCA-proofness that we call global SCP, which also intuitively captures the requirement that strategic users and miners cannot steal from the protocol, and is perhaps more appropriate when focusing on UIC TFMs (as we do in this paper). In our work, global SCP is not only a technical stepping stone towards proving Theorem 1.1, but also of independent interest as we explain below. Specifically, global SCP is almost the same as OCAproofness, except for requiring σ to be the honest bidding strategy indicated by the mechanism (i.e., the same bidding strategy used to establish UIC). In other words, a mechanism satisfies global SCP if and only if the honest strategy is surplus-maximizing for the global coalition. It is easy to see that for a truthful mechanism, c-SCP for any c implies global SCP, which in turn implies OCA-proofness. To prove Theorem 1.1, we first prove the following theorem:\n\\\nTheorem 1.2. Suppose that the block size is finite. Then no possibly randomized TFM can simultaneously satisfy user incentive compatibility (UIC), miner incentive compatibility (MIC), and global SCP. Further, the impossibility holds even for non-truthful mechanisms.\n\\\nWe now explain why the global SCP notion is of independent interest. One advantage of global SCP is that the revelation principle holds for any TFM that satisfies UIC, MIC, and global SCP, which we formally prove in Section 8. In other words, given any TFM that is UIC, MIC, and global SCP, there is an equivalent truthful mechanism that simulates it. For this reason, Theorem 1.2 rules out even non-truthful TFMs that simultaneously satisfy UIC, MIC, and global SCP.[3]\n\\\nBy contrast, Theorem 1.1 holds only for truthful mechanisms. In particular, in Section 6.1, we show a non-truthful mechanism that simultaneously satisfies UIC, MIC, and OCA-proof. The mechanism is contrived, but it demonstrates the subtlety and the technical challenges when modeling the notion of collusion-resilience. This also suggests that the revelation principle does not hold for mechanisms that satisfy UIC, MIC, and OCA-proofness, partly because in such a mechanism, the bidding strategies used to establish UIC and OCA-proofness may be different.\n\\\nWays to circumvent the impossibilities. We show in Section 7 that the impossibility of Theorem 1.1 can be circumvented by allowing non-truthful mechanisms or by allowing users to coordinate in bidding in the globally optimal strategy σ. In the same section, we raise an open question regarding whether it is possible to use cryptography (e.g., the MPC-assisted model of Shi et al. [SCW23]) and Bayesian notions of incentive compatibility to circumvent the impossibilities.\n\\\n:::info\nAuthors:\n(1) Hao Chung∗, Carnegie Mellon University (haochung@andrew.cmu.edu);\n(2) Tim Roughgarden†, Columbia University and a16z (crypto tim.roughgarden@gmail.com);\n(3) Elaine Shi∗, Carnegie Mellon University (runting@cs.cmu.edu).\n:::\n:::info\nThis paper is available on arxiv under CC BY 4.0 DEED license.\n:::\n[3] Simultaneously with and independently of this paper, Gafni and Yaish [GY24] proved, among other results, a version of Theorem 1.2 for the special case of deterministic mechanisms and a block size of 1.",
            ":::info\nAuthors:\n(1) Hao Chung∗, Carnegie Mellon University (haochung@andrew.cmu.edu);\n(2) Tim Roughgarden†, Columbia University and a16z (crypto tim.roughgarden@gmail.com);\n(3) Elaine Shi∗, Carnegie Mellon University (runting@cs.cmu.edu).\n:::\nTable of Links\nAbstract and 1. Introduction\n1.1 Our Contributions\n1.2 TFM Incentive-Compatibility Notions: A Cheat Sheet\nDefinitions\n2.1 Transaction Fee Mechanism\n2.2 Incentive Compatibility Notions\n\n\nPreliminary: Myerson’s Lemma\n\n\nWarmup: Impossibility of UIC + MIC + Global SCP for Deterministic Mechanisms\n\n\nImpossibility of UIC + MIC + Global SCP for Randomized Mechanisms and 5.1 Proof Roadmap\n5.2 Formal Proofs\n\n\nFeasibility and Impossibility of UIC + MIC + OCA-Proof\n6.1 A Non-Truthful Mechanism with UIC + MIC + OCA-Proof\n6.2 Impossibility of UIC + MIC + OCA-Proof for Truthful Mechanisms\n\n\nHow to Circumvent the Impossibilities and 7.1 Allowing the Globally Optimal Strategy to Coordinate\n7.2 Allowing the Globally Optimal Strategy to Output Multiple Bids\n7.3 Inclusion-Rule-Respecting and 7.4 Discussions and Open Questions Regarding the Use of Cryptography\n\n\nStatic Revelation Principle for Transaction Fee Mechanisms\n8.1 Static Revelation Principle: Bidding Rules That Output Single Bid\n8.2 Static Revelation Principle: Allowing Bidding Rules that Output Multiple Bids\n\n\nA. Comparison of Collusion-Resilience Notions\nReferences\nAbstract\nUsers bid in a transaction fee mechanism (TFM) to get their transactions included and confirmed by a blockchain protocol. Roughgarden (EC’21) initiated the formal treatment of TFMs and proposed three requirements: user incentive compatibility (UIC), miner incentive compatibility (MIC), and a form of collusion-resilience called OCA-proofness. Ethereum’s EIP1559 mechanism satisfies all three properties simultaneously when there is no contention between transactions, but loses the UIC property when there are too many eligible transactions to fit in a single block. Chung and Shi (SODA’23) considered an alternative notion of collusion-resilience, called c-side-contract-proofness (c-SCP), and showed that, when there is contention between transactions, no TFM can satisfy UIC, MIC, and c-SCP for any c ≥ 1. OCA-proofness asserts that the users and a miner should not be able to “steal from the protocol.” On the other hand, the c-SCP condition requires that a coalition of a miner and a subset of users should not be able to profit through strategic deviations (whether at the expense of the protocol or of the users outside the coalition).\n\\\nOur main result is the first proof that, when there is contention between transactions, no (possibly randomized) TFM in which users are expected to bid truthfully satisfies UIC, MIC, and OCA-proofness. This result resolves the main open question in Roughgarden (EC’21). We also suggest several relaxations of the basic model that allow our impossibility result to be circumvented.\n1 Introduction\nReal estate on the blockchain is scarce, and blockchain users bid in an auction called the transaction fee mechanism (TFM) to have their transactions included and confirmed on the blockchain. The original Bitcoin protocol adopted a simple first-price auction, where the top k bids win and they each pay their bid. However, such first-price auctions are known to incentivize untruthful bidding. Therefore, a line of subsequent works [LSZ19, Yao, BEOS19, BCD+, Rou20, Rou21, FMPS21, CS23, SCW23, WSC24, GY22, ZCZ22, BGR23, TY23, KKLP23, XFP23, CMW23, LRMP23, Ndi23] explored what is the “dream TFM” for blockchains. Most works [Rou20, Rou21, CS23, SCW23, WSC24, GY22, GY22, ZCZ22, BGR23, TY23] agree on roughly the same set of desiderata, that is, a dream TFM should provide incentive compatibility not just for an individual user, but also for the miner of the block. Further, a dream TFM should provide resilience against miner-user collusion.\n\\\nRoughgarden [Rou21] was the first to formally define the aforementioned requirements for a TFM, which he referred to as user incentive compatibility[1], (myopic) miner incentive compatibility, and OCA-proofness, where OCA stands for “off-chain agreement” and refers to colluding strategies between the miner and a set of users that allow off-chain transfers. Roughgarden [Rou21] also showed that the simple “posted price auction with all fees burnt” mechanism, which corresponds to the behavior of Ethereum’s EIP-1559 TFM [BCD+] when there is no congestion, satisfies all three properties. However, the posted price auction with all fees burnt does not satisfy all three properties when there is congestion. In practice, congestion does occur when there are major events such as an NFT mint or price fluctuations — for example, in Ethereum, roughly 2.3% of the blocks experience congestion.[2] When congestion arises, approximately speaking, Ethereum’s EIP-1559 mechanism falls back to the first-price auction, violating user incentive compatibility. Therefore, an interesting question is whether we can design a dream TFM satisfying all three properties for finite block sizes.\n\\\nChung and Shi [CS23] considered an alternative notion of collusion-resilience, called sidecontract-proofness. Unfortunately, they proved that no (even randomized) TFM can simultaneously satisfy user incentive compatibility and side-contract-proofness. Because side-contract-proofness is a more demanding property than OCA-proofness, the question raised by Roughgarden [Rou21], of whether there is a dream TFM satisfying all three properties under his collusion-resilience notion, had remained open.\n\\\nTwo notions of miner-user collusion-resilience. Multiple natural notions of collusion-resilience can and have been studied in the context of TFM design. Here we clarify informally the key differences between the notions proposed by Roughgarden [Rou21] and Chung and Shi [CS23]. These notions are defined formally in Definitions 4–6 (see Section 2) and compared further via examples in Appendix A.\n\\\n• OCA-proofness: Roughgarden’s notion, henceforth referred to as OCA-proofness, asserts that there should exist a “reference strategy” for a miner and all users that is guaranteed to maximize their joint surplus. In this reference strategy, the miner is expected to follow the inclusion rule intended by the TFM. For users, the definition requires only that users follow some fixed bidding trategy σ (i.e., a mapping from a private user valuation to a user bid) that is individually rational (i.e., σ(v) ≤ v for all v ≥ 0). In particular, in the reference strategy, users are expected to bid independently (with a user’s bid independent of other users’ valuations and bids), and expected to submit a single bid (with no additional fake bids injected). One example of such a bidding strategy is the truth-telling strategy (with σ(v) = v). Because Roughgarden [Rou21] wished to discuss the OCA-proofness properties of non-UIC TFMs like first-price auctions, the definition also allows the reference strategy to be defined by a non-truthful bidding strategy (e.g., σ(v) = v/2). As a consequence, to prove that a TFM is both UIC and OCA-proof, it is sufficient to prove that it is UIC under one bidding strategy and OCA-proof under a possibly different bidding strategy (as in the example in Section 6.1).\n\\\n• c-SCP: Chung and Shi’s notion [CS23], henceforth called c-SCP (where SCP stands for sidecontract-proofness), requires that the honest strategy (i.e., all users follow the honest bidding rule and the miner honestly implements the inclusion rule) is the profit-maximizing strategy for any coalition consisting of the miner of the present block and at most c users. For truthful mechanisms, the honest bidding rule is the truthful one, while for non-truthful mechanisms, the bidding rule can be more general (see Section 2.1 for the formal definition). Chung and Shi’s notion aligns with standard notions used in a line of work at the intersection of game theory and cryptography [HT04, KN08, ADGH06, OPRV09, AL11, ACH11, GKM+13, GKTZ15, GTZ15, Kat08, DR07, GLR10, CGL+18, WAS22, CCWS21, PS17, KMSW22, FW20, EFW22].\n\\\nDiscussion. The two notions of collusion-resilience address different issues. OCA-proofness captures the intuitive requirement that the users and miners should not be able to steal from the protocol through strategic deviations — for this reason, it considers only the global coalition consisting of the miner and all users. By contrast, the c-SCP notion captures the intuitive idea that a miner-user coalition’s best response is to act honestly, and that no strategic deviations can allow the coalition to steal from other users or steal from the protocol. For further discussion, see the end of this section and Appendix A.\n\\\n:::info\nThis paper is available on arxiv under CC BY 4.0 DEED license.\n:::\n∗Supported by NSF awards 2212746, 2044679, 1704788, a Packard Fellowship, a generous gift from the late Nikolai Mushegian, a gift from Google, and an ACE center grant from Algorand Foundation.\n\\\n†Author’s research at Columbia University supported in part by NSF awards CCF-2006737 and CNS-2212745, and research awards from the Briger Family Digital Finance Lab and the Center for Digital Finance and Technologies.\n\\\n[1] User incentive compatibility (UIC) is usually called dominant-strategy incentive compatible (DSIC) in the mechanism design literature. In general, we allow UIC TFMs to make use of non-truthful (but dominant) bidding strategies (see Definition 2).\n\\\n[2] From Jan 1, 2024 to Feb 5, 2024, 256595 blocks have been produced on Ethereum, and 5840 blocks among them were full (meaning more than 99.9% of the gas limit (30M) was used).",
            "A few years ago, if someone mentioned Artificial Intelligence in a product design meeting, they’d likely be met with skeptical glances or a cautious “let’s not overcomplicate things.” Today? AI isn’t just welcome at the UX table; it’s practically running the show.\nWe’re in a new era where the user experience is no longer just about beautifully designed buttons and seamless navigation; it's about intelligence. It’s about designing systems that think a little, predict a lot, and adapt even more. And most importantly, it’s about making those experiences accessible to everyone, not just the tech-savvy.\nIn this article, I will unpack how AI is reshaping UX through three powerful lenses: intelligence, efficiency, and accessibility.\n1. Designing for Intelligence\nThis means designing a user experience (UX) that learns and adapts to users' needs and preferences. Imagine opening your favorite streaming app and seeing a lineup so in tune with your mood, it’s like it read your mind. That’s AI quietly doing its thing: tracking behavior, learning preferences, and curating experiences.\nBut it goes deeper than Netflix suggestions. In UX, AI is helping designers build systems that understand user intent. Think about voice assistants that interpret vague commands or smart email apps that finish your sentences. These aren’t just cool features; they represent a paradigm shift from static interfaces to intelligent, evolving ones.\n\nGmail auto reply options\nAs designers, our role is evolving too. We’re not just sketching wireframes, we’re mapping out decision trees, training datasets, and predicting edge cases. We’re asking, \"What should the system do if the user does X, but also what if they do Y, or nothing at all?\"\nThe design process becomes less about dictating user journeys and more about enabling dynamic, adaptive experiences.\n2. Designing for Efficiency\nLet’s face it, users are busy, distracted, and often overwhelmed. The best UX anticipates this. AI is turning reactive design into proactive design, streamlining interactions before users even realize they need help.\nTake auto-generated replies in Gmail. What once took 30 seconds now takes two clicks. Or smart forms that auto-fill based on past behavior. These aren’t just nice-to-haves; they redefine what “fast” and “frictionless” mean in today’s digital age.\n\nDesigners are now integrating features like:\nPredictive search that learns as you type.\nConversational UIs that simulate human-like dialogue.\nMicro-personalizations that fine-tune experiences per individual.\nWe’re shifting from “How can we make this easier?” to “How can we make this invisible?” AI enables us to reduce the cognitive load, streamline the number of steps, and allow users to navigate digital spaces with near-effortless precision.\n3. Designing for Accessibility\nOne of the most inspiring aspects of AI in UX is its potential to make products more accessible than ever.\nThink about screen readers enhanced with natural language processing, turning robotic monotones into human-like guidance. Or image recognition tools that generate detailed alt text, giving blind users richer context. Or even real-time captioning powered by AI, helping deaf users fully participate in digital experiences, such as virtual calls.\nAI is becoming an equalizer, helping bridge the gap for users with disabilities, language barriers, or limited digital literacy.\nBut here’s the catch: AI can only be inclusive if it’s designed that way. Biased training data and one-size-fits-all algorithms can easily undo the progress made. As UX professionals, we must approach AI with empathy and ethical foresight. Who are we designing for? Who might we be excluding? How do we test, iterate, and refine AI so that it helps rather than hinders?\nSo, after all I have shared, where do we go from here?\nThe future of UX is not about choosing between human-centered and machine-assisted design; it's about combining them. AI doesn’t replace the empathy, intuition, and creativity of designers; it amplifies them.\nOur job now is to become translators. To understand both the language of people and the language of machines, and to create experiences where the two meet in harmony.\nSo the next time you open a product and it just gets you, don’t chalk it up to luck. That’s AI in UX, quietly evolving behind the scenes, making every tap, scroll, and swipe a little more magical.\nAI is no longer a “feature.” It’s a UX game-changer. It helps us design smarter (intelligence), faster (efficiency), and better for everyone (accessibility) products. But it’s up to us to ensure it’s used ethically, creatively, and inclusively.\nRecommended Resources for Deeper Insight:\n→ The Future of UX - Embracing AI in Design\n→ The Future of UX Design: How AI and Machine Learning Are Changing the Way We Design\n→ The future of AI in user experience (UX) design\n\\",
            "In an age of hyperconnectivity, Europe faces an unexpected crisis: loneliness. The EU Loneliness Survey 2022 reveals that 13% of Europeans feel lonely most or all the time, while 35% experience it regularly. Despite the digital revolution, authentic human connection seems to be unraveling—replaced by surface-level engagements that lack emotional resonance.\nThis paradox lies at the heart of Social Discovery Group (SDG)’s $20 million venture studio, SDG Lab Venture Studio. The studio is betting big on a controversial but potentially transformative concept: Virtual Intimacy — a technological attempt to restore emotional closeness in an increasingly isolated society.\nUnderstanding Loneliness: More Than Just Being Alone\nLoneliness is not simply a matter of physical solitude. It’s a mental and emotional state where individuals feel unseen, disconnected, and emotionally deprived — even in crowds. It’s a perceived disconnection, not merely the absence of company.\nHealth Consequences of Loneliness\nA 2015 meta-analysis by Holt-Lunstad found that:\nSocial isolation increases mortality risk by 29%\nLoneliness increases it by 26%\nThese numbers are comparable to the health risks of smoking 15 cigarettes a day, as outlined in the 2023 U.S. Surgeon General’s guidelines.\nMoreover, loneliness is linked to:\nSleep disturbances\nHigh cortisol levels\nHypertension\nHeart disease\n==It’s no longer just a social issue; it’s a public health crisis.== \\n \n\nTech Meets Emotional Need: SDG Lab’s $20 Million Response\nEnter SDG Lab, the corporate venture arm of Social Discovery Group, which backs early-stage startups that focus on:\nAI-powered communication\nVirtual and extended reality\nSocial discovery platforms\nThese startups are designed to build what SDG calls “virtual intimacy”: emotional connections that transcend physical interaction through digital mediums.\nAlex Kudos, CEO of SDG Lab Venture Studio, puts it simply:\n“Technology doesn’t just help us build relationships — it becomes part of them.”\nThis shift challenges traditional notions of closeness. Can digital interactions really replace the emotional depth of face-to-face contact?\n\n\\\nThe Geography of Loneliness\nNot all regions are affected equally. According to EU data:\nEastern and Southern Europe (e.g., Bulgaria, Romania, Greece) suffer higher loneliness rates\nNorthern and Western countries (e.g., Austria, the Netherlands) show lower levels\nFor example, Cyprus mirrors this southern trend. Kudos notes that older populations in Cyprus are particularly affected. SDG’s solution? Use technology to build connections tailored to older users. Products like DateMyAge show that virtual platforms can appeal to users beyond Gen Z — if designed inclusively.\nA New Era of Digital Connection\nStudies show that 57% of Gen Z believe online relationships are as meaningful as in-person ones. During the COVID-19 pandemic, virtual worlds offered emotional refuge:\nAltspaceVR users reported lower loneliness\nEvents and interactions in VR felt more immersive than real life for some\nHowever, this comes with a caveat: telepresence fatigue. Some users found screens emotionally exhausting, emphasizing the fragility of digital intimacy.\n\nEconomic and Societal Costs\nLoneliness doesn’t just hurt individuals — it strains entire economies. Increased loneliness leads to:\nRising healthcare costs\nWorkforce productivity loss\nGreater pressure on social services\nIn regions like Cyprus, where aging populations and shrinking community structures prevail, digital intimacy becomes not just an innovation — but a necessity.\nBeyond Online Dating Apps: The SDG and SDG Labs Portfolios\nSocial Discovery Group operates over 60 global brands, including:\nDating.com\nDateMyAge\nDilMil (for South Asians)\nKiseki (for Japanese audiences)\nThis diversification reflects the global loneliness crisis -as people migrate and lose touch with their cultural roots. SDG’s platforms aim to rebuild those connections in new contexts.\nWith SDG Lab Investments , the approach shifts from quantity to quality:\nFocuses on 5–10 projects/year\nOffers operational and strategic support\nInvests in startups building AI relationships, virtual influencers, and platforms for older demographics.\nFor entrepreneurs navigating the complex funding landscape, Alex Kudos, CEO of SDG Lab, offers crucial insights in the Founder`s Guide about choosing between traditional venture capital and venture studio models. Understanding these funding paths becomes essential when building the next generation of connection technologies.\nKey Concerns: Can Tech Really Cure Loneliness?\nBefore we accept virtual intimacy as the cure for our loneliness, or shall I say, disconnection crisis, we need to confront some uncomfortable truths. The research paints a complicated picture, one that challenges a somewhat simplistic, surface narrative around technology engineering its way out of a crisis.\nThe Accessibility Trap\nThe most vulnerable -older, poorer, and less educated users -are also least likely to access digital tools. A 2024 study found that nursing home residents without tech access were more isolated than ever, underlining the danger of digital exclusion.\nQuality Over Quantity\nTech helps maintain existing relationships better than it builds new ones. A 2022 meta-review found only moderate evidence that technology reduces loneliness, particularly for forming close new bonds.\nThe Presence Paradox\nEven the best-designed platforms may fail to offer a true sense of emotional co-presence. According to the European Commission’s 2024 brief,\n“Technology is seen as both enhancing and suppressing connections.”\nThis reflects the paradox of virtual presence: the appearance of intimacy without the psychological reality.\nMore about the Critical Questions ↘\nhttps://thefuturemedia.eu/the-loneliness-economy-how-social-discovery-groups-20m-bet-is-logging-us-into-a-new-kind-of-intimacy/?embedable=true\n\nSDG Lab’s Response: Technology as an Extension, Not a Replacement\nSDG Lab confronts virtual intimacy criticisms directly, viewing ethical concerns as opportunities rather than roadblocks.\nAlex Kudos, CEO of SDG Lab Venture Studio, believes that exclusion is more about poor design than user capability. For example, 90% of DateMyAge users regularly engage in video dating, disproving the stereotype that older people aren’t tech-savvy.\n\\\n\n  \n“Our goal is not to generate maximum engagement, but to promote genuine connection.” — he explains.\n\\\nThat includes resisting the urge to gamify relationships or promote constant stimulation.\nPerhaps most telling is Kudos’s reframing of the “bandage versus cure” debate. The real issue, he argues, may be that traditional relationships are already failing to meet modern emotional needs.\n\\\n\n  \n“Despite the idea that romantic partnerships are the foundation of emotional well-being, many of us are struggling even within those close connections,” Alex says.\nVirtual intimacy, in his view, isn’t a replacement but an expansion: one that amplifies access to connection across geography, identity, and life stage.\n\\\nThese questions aren’t meant to dismiss Lab’s vision. The company may very well be the revolution that our society needs, even if we don’t fully understand it yet. **For Kudos and his team, AI companionship isn’t ‘less than’ human. This type of connection allows people to be more vulnerable, authentic, and introspective in a safe space.**And in our current climate, don’t we all deserve the safety to be ourselves, fully? \\n ✓ Conclusion: Rethinking What It Means to Be Together\n==So, can virtual intimacy solve the loneliness epidemic?==\nMaybe. Research shows promise -but also flags risks. The real challenge is ensuring these tools don’t redefine connection in a way that erodes emotional depth.\nAs Kudos sees it, virtual intimacy isn’t about escaping reality. It’s about creating new spaces for vulnerability, connection, and self-expression. In a world where loneliness is both a personal pain and a public crisis, perhaps the most radical act is simply helping people feel seen — wherever they are.\nSDG Lab is Actively Seeking New Ventures!\nSDG LAB Venture Studio is actively seeking for founders and companies working on the future of human connection.\nIf you’re working on AI, video tech, or social innovation — contact us! \\n",
            "How are you, hacker?\n🪐 What’s happening in tech today, August 3, 2025?\n HackerNoon Newsletter\n          brings the HackerNoon \n          homepage\n          straight to your inbox.\n          On this day,\n          \n            Radio Shack Announced TRS-80 Computer in 1977,  Mozilla Corporation was founded in 2005,  Christopher Columbus set sail in 1492, \n          \n          and  we present you with these top quality stories. \n          \n            From \n        AI Agents Are Growing Up - And They Need Zero-Trust Parenting\n       to \n        Turn a Regular Wallet into a Smart Account with EIP 7702 ,\n       let’s dive right in.\n          \n        \nImmutable Backups: Everything You Need To Know To Protect Your Cloud\n \nBy @n2w [ 6 Min read ] Learn how immutable backups prevent ransomware, ensure data integrity, and meet compliance needs with secure, tamper-proof cloud data protection. Read More.\nAI Agents Are Growing Up - And They Need Zero-Trust Parenting\n \nBy @arjun-subedi [ 8 Min read ] AI is evolving fast, but security isn’t keeping up. Discover why zero-trust architecture is critical for safe, scalable AI agent deployment. Read More.\nA Human-centred Framework for Designing Complex AI Solutions for Strategic Decision-making\n \nBy @v3d [ 7 Min read ] The practical framework helps designers, data scientists, and engineers find common ground, aligning the voice and needs of users with the design of AI systems Read More.\nTurn a Regular Wallet into a Smart Account with EIP 7702 \n \nBy @hacker39947670 [ 13 Min read ] Learn how EIP-7702 enables smart wallet features for existing Ethereum accounts. Complete developer guide with code examples. Read More.\n9 Things Hollywood Gets Wrong About Hacking\n \nBy @moonlock [ 11 Min read ] Movie hacking ≠ reality: Real cyberattacks rely on phishing, not fast code. Moonlock, MacPaw’s cybersecurity division, reveals how films get it wrong. Read More.\nA Simple Way to Build a Progress Bar for Your Website’s Image Uploader Using Filestack\n \nBy @filestack [ 7 Min read ] Let’s walk through how to build one manually, and then I’ll show you why we ensured you would never have to. Read More.\nHow an NYC-Based University Boosted Backup Reliability While Slashing Costs​\n \nBy @n2w [ 4 Min read ] Learn how N2W supports St. Johns University, which educates more than 20,000 students and employs over 1,400 staff, using a hybrid environment. Read More.\nFrom Chatbots to Guardians of Data: How BChat Harnesses AI for Secure Messaging\n \nBy @beldexcoin [ 5 Min read ] AI is often associated with collecting personal data but what if AI helped protect user data? Read to know how BeldexAI protects your data on BChat.  Read More.\n🧑‍💻 What happened in your world this week?\nwriting can help consolidate technical knowledge,\n          establish credibility,\n           and contribute to emerging community standards.\n          Feeling stuck? We got you covered ⬇️⬇️⬇️\n        \nANSWER THESE GREATEST INTERVIEW QUESTIONS OF ALL TIME\n        \nWe hope you enjoy this worth of free reading material. Feel free to forward this email to a nerdy friend who'll love you for it.See you on Planet Internet! With love, \n The HackerNoon Team ✌️",
            "Your phone is more powerful than a desktop computer from five years ago. The latest flagship Android devices pack neural processing units, multi-core CPUs that would make 2019 laptops jealous, and RAM configurations that seemed impossible just a few years back. So why does it feel like we're barely scratching the surface of what's possible with AI on mobile?\nSure, you can now even run quantized versions of Llama and DeepSeek models locally on your device. But let's be honest - those conversations still feel clunky, slow, and nowhere near the seamless experience users expect from their apps. The hype around on-device conversational AI is real, but the practical reality? We're not quite there yet.\nHere's where most developers miss the opportunity: conversational AI isn't the only game in town. While everyone's chasing the next ChatGPT clone, there's a massive untapped potential in specialized AI applications that actually work brilliantly on mobile hardware right now.\nTake noise suppression. Your users are constantly battling background noise during calls, recordings, and voice messages. Wind, traffic, crying babies, barking dogs - it's an endless war against audio chaos. But what if your app could eliminate that noise in real-time, locally, without sending a single byte to the cloud?\nThis isn't science fiction. It's happening today, and any Android developer can implement it. The tools are mature, the performance is there, and your users will immediately notice the difference.\nONNX Runtime: Your Gateway to Mobile AI\nThe mobile AI landscape is fragmented. PyTorch dominates research, TensorFlow rules production, and countless specialized frameworks emerge for specific use cases. For Android developers, this creates a painful choice: commit to one ecosystem or maintain separate pipelines for different models.\nAfter evaluating mobile AI frameworks, we chose ONNX Runtime for several compelling reasons that directly impact Android development.\nWider Compatibility Across Android Versions\nUnlike Google's LiteRT (formerly TensorFlow Lite), which mandates a minimum SDK level of 31 (Android 12), ONNX Runtime comfortably supports Android API levels as low as 24 (or even 21, if you are a magician). Our project’s minimum supported version was API 28, making ONNX Runtime the clear choice to reach a broader audience without excluding millions of active users on Android 10 and earlier devices.\nSeamless Cross-Framework Integration\nONNX Runtime’s greatest strength lies in its framework-agnostic nature. Whether your AI models originate from PyTorch, TensorFlow, or even traditional ML libraries like scikit-learn, exporting models to ONNX allows uniform deployment across Android, iOS, desktops, and cloud environments. This flexibility significantly simplifies maintenance, enabling a unified pipeline rather than juggling multiple framework-specific tools.\nLightweight and Modular Deployment\nIntegration with ONNX Runtime is straightforward. With a compact Maven AAR (around 5–7 MB for CPU builds), the library integrates cleanly into your existing Android app without introducing unnecessary dependencies like Google Play Services or requesting additional user permissions. This streamlined deployment keeps your app lean, performant, and secure.\nProven Real-Time Performance\nONNX Runtime is battle-tested in demanding real-time scenarios. Audio-processing models, such as noise suppression or speech enhancement, consistently deliver inference speeds under 4 ms per audio frame on standard mobile hardware - comfortably within real-time performance requirements. Our team leveraged this exact capability for reliable, low-latency noise suppression.\nUltimately, ONNX Runtime provided our team not just convenience, but strategic advantage - allowing us to maintain compatibility, performance, and simplicity without compromises. If your project demands accessible, performant, and scalable mobile AI, ONNX Runtime could very well be your optimal choice.\nIntegration Plan: Setting Up ONNX Runtime\nThe default ONNX Runtime package weighs in at a hefty 27MB. For a mobile app, that's not just bloat - it's a user acquisition killer. Research shows that for every 6MB increase in APK size, install conversion rates drop by 1% (I should note that the study is not the newest one, and concerns mainly not the most developed countries, but still, it is worth considering)\nThe solution? A custom minimal build that strips your deployment down to exactly what you need. Our DTLN noise suppression implementation clocks in at just 7.1MB - a 70% size reduction that keeps your app lean and your users happy.\nONNX Runtime's architecture is modular by design. The full package includes execution providers for GPU acceleration (NNAPI, Vulkan), dozens of operators you'll never use, and compatibility layers for edge cases that don't apply to your specific model. By building only what you need, you eliminate this overhead entirely.\nStep 1: Convert Your Models to ORT Format\nBefore building, convert your ONNX models to ORT format. This optimized format removes unused graph nodes and operator definitions, further reducing your final binary size.\n\\\npython -m onnxruntime.tools.convert_onnx_models_to_ort <onnx model file or dir> &nbsp;&nbsp;&nbsp;--target_platform {arm,amd64}\n\nStep 2: Create Operator Configuration\nAfter converting all the necessary models, configuration files with the necessary operators that will be required for the minimal build of ONNX will also be generated.\nWhen using several models, combine all the configuration files into one.\nThe final file will look something like this:\n\\\n# Generated from model/s:\nai.onnx;1;Transpose\nai.onnx;6;Sigmoid\nai.onnx;7;Add,LSTM\nai.onnx;9;MatMul\nai.onnx;11;Concat,Slice,Squeeze,Unsqueeze\nai.onnx;1;Transpose\nai.onnx;5;Reshape\n//other operators\n\nStep 3: Execute Custom Build\nWith your operator configuration ready, build ONNX Runtime from source with minimal dependencies:\n\\\n./build.sh --android \\\n  --android_sdk_path ~/Library/Android/sdk \\\n  --android_ndk_path ~/Library/Android/sdk/ndk/28.0.12674087 \\\n  --android_abi arm64-v8a \\\n  --android_api 24 \\\n  --minimal_build \\\n  --include_ops_by_config path/to/required_operators.config \\\n  --build_java \\\n  --config=Rel\n\n--minimal_build: Excludes unnecessary execution providers and operators\n--includeopsby_config: Includes only operators specified in your config file\n--android_abi armeabi-v7a: Targets ARM32 for maximum device compatibility\n--android_api 24: Maintains compatibility with Android 7.0+\nIf you also want to support old devices, repeat step 3 with –android_abi armeabi-v7a and them merge both resulting aar files with following script:\n\\\n#!/usr/bin/env sh\n\n# Clean up from previous runs, if any\nrm -rf merge-tmp\nmkdir -p merge-tmp\ncd merge-tmp\n\necho \"Unzipping each ABI-specific AAR...\"\nmkdir a64\nunzip ../onnxruntime-arm64-v8a.aar -d a64\n\nmkdir a32\nunzip ../onnxruntime-armeabi-v7a.aar -d a32\n\necho \"Preparing universal base from arm64 AAR...\"\nmkdir universal\ncp -r a64/* universal\n\nrm -rf universal/jni\nmkdir -p universal/jni\n\n\necho \"Merging native libs from each architecture...\"\nmkdir -p universal/jni/arm64-v8a\ncp a64/jni/arm64-v8a/*.so universal/jni/arm64-v8a\n\nmkdir -p universal/jni/armeabi-v7a\ncp a32/jni/armeabi-v7a/*.so universal/jni/armeabi-v7a\n\n\n# Re-zip contents of 'universal' to create a new AAR\necho \"Creating universal AAR...\"\ncd universal\nzip -r onnxruntime-universal.aar ./*\n\necho \"Done! The merged AAR is at:\"\necho \"$(pwd)/onnxruntime-universal.aar\"\n\nThe minimal build approach transforms ONNX Runtime from a deployment liability into a strategic advantage. Your users get the full AI capability without the bloat, and your app maintains the lean profile that modern mobile development demands.\nNext, let's see this optimized runtime in action with real-time DTLN noise suppression.\nWhy Audio Processing Showcases AI Value\nAudio processing is the perfect introduction to mobile AI - delivering immediate, tangible value while your competitors wrestle with bloated language models that drain batteries and require constant internet connections.\nThe Daily Audio War Your Users Are Fighting\nSarah records voice messages while walking through a busy street. Between honking taxis, construction noise, and subway rumbles, she re-records messages three times before giving up and typing instead.\nMarcus joins client calls from his home office, which doubles as his toddler's playroom. Every presentation becomes a cycle of \"mute, unmute, apologize for the crying.\"\nElena creates YouTube content in her apartment but spends hours in post-production cleaning up neighbor noise, traffic, and air conditioning hum.\nThese aren't edge cases - they're the reality of modern mobile computing where everyone expects professional results from consumer hardware in chaotic environments.\nWhy Noise Suppression Creates Instant \"Wow\" Moments\nAudio quality improvements trigger immediate emotional responses. Unlike other AI applications requiring explanation, noise suppression provides instant gratification users can perceive within seconds. Play someone their own voice - crystal clear - after removing background noise, and watch their reaction. They don't need to understand LSTM networks; they just know their audio sounds professional.\nThe beauty of audio processing as an AI showcase lies in universality. Everyone understands good audio, everyone has experienced bad audio, and everyone immediately recognizes improvement when noise disappears. You're not asking users to trust your AI - you're proving its value in the most direct way possible.\nBuilding a Production-Ready Demo: Real-Time Noise Suppression\nNow, let's build a sample project that demonstrates the practical power of ONNX Runtime on Android. Rather than a basic \"hello world\" example, we'll create something close to production quality - a real-time noise suppression demonstration where users can record audio in noisy environments and experience the striking difference between their original recording and the AI-cleaned version.\nYou can find a complete sample here, on my Github: https://github.com/linreal/android-onnx-showcase.\nModels, used in sample are from https://github.com/breizhn/DTLN\nQuick Implementation Overview\nBefore diving into DTLN's dual-path architecture, let's establish how the pieces fit together. The beauty of this implementation lies in its clean separation of concerns - each component has a single responsibility, making the system both testable and maintainable.\nThe Core Components\nAt the heart of our noise suppression pipeline sit three key interfaces that work together:\n\\\ninterface NoiseSuppressor {\n    suspend fun initialize()\n    fun processChunk(audioChunk: FloatArray): FloatArray\n    fun release()\n}\n\ninterface AudioRecorder {\n    suspend fun startRecording(): Flow<ShortArray>\n    suspend fun stopRecording()\n}\n\ninterface ConcurrentAudioProcessor {\n    suspend fun startProcessing(\n        suppressor: NoiseSuppressor,\n        rawOutputFile: File,\n        processedOutputFile: File\n    )\n    suspend fun stopProcessing(): ProcessingResult\n}\n\nThe NoiseSuppressor encapsulates all ONNX Runtime complexity behind a simple interface. Feed it audio chunks, get back denoised audio. The stateful nature of DTLN is completely hidden - the implementation maintains LSTM states internally between calls.\nData Flow Architecture\n\\\nAudioRecorder → Flow<ShortArray> → ConcurrentAudioProcessor → NoiseSuppressor → Processed Audio Files\n\n\\\nThe ConcurrentAudioProcessor orchestrates the entire pipeline. It subscribes to the audio recorder's Flow, converts audio formats, processes chunks through the noise suppressor, and writes both original and processed audio to files simultaneously.\n\\\nrawAudioRecorder.startRecording().collect { audioChunk ->\n    // Convert format for processing\n    val floatChunk = AudioConversionUtils.shortArrayToFloatArray(audioChunk)\n\n    // Process through DTLN\n    val processedChunk = suppressor.processChunk(floatChunk)\n\n    // Save both versions concurrently\n    launch { rawFileWriter.writeAudioData(floatChunk) }\n    launch { processedFileWriter.writeAudioData(processedChunk) }\n}\n\nWhy This Architecture Works\nReactive Processing: The Flow-based design ensures your UI remains responsive. Audio processing happens on background threads while the main thread handles user interactions.\nFormat Isolation: Each component works with its preferred audio format. AudioRecorder produces ShortArray (16-bit PCM), while NoiseSuppressor expects FloatArray (normalized samples). Conversion happens at the boundary.\nError Boundaries: If ONNX initialization fails, only the NoiseSuppressor component is affected. The audio recorder and file writers continue functioning, ensuring graceful degradation.\nResource Management: Each component manages its own resources. The ConcurrentAudioProcessor coordinates lifecycle events but doesn't own the underlying implementations.\nThis modular approach means you can swap out the DTLN implementation for any other ONNX model, replace the audio recorder with a file-based source, or modify the output format without touching other components. The architecture scales from proof-of-concept to production deployment.\nNext, we'll explore the DTLN architecture that makes this magic happen.\nUnderstanding DTLN Architecture\nTraditional noise suppression approaches face a fundamental tradeoff. Frequency-domain methods excel at removing stationary noise (air conditioning, fan hum) but struggle with dynamic sounds like speech or music bleeding through. Time-domain approaches handle complex, changing signals well but often introduce artifacts or fail with consistent background noise.\nDTLN sidesteps this limitation entirely through its dual-path architecture:\nStage 1: Frequency Domain Processing The first model operates in the frequency domain, analyzing the spectral characteristics of your audio. It generates a suppression mask that identifies which frequency components contain noise versus speech. This stage excels at removing stationary background noise - the steady hum of air conditioning, traffic, or office chatter.\n\\\n// Stage 1: Frequency domain mask estimation\n\nval (magnitude, phase) = fftProcessor.forward(inBuffer)\nval outMask = model1.run(mapOf(\"input_2\" to magnitudeTensor, \"input_3\" to lstmState))\nfor (i in magnitude.indices) {\n    magnitude[i] *= outMask[i] // Apply suppression mask\n}\n\nStage 2: Time Domain Refinement The masked frequency-domain signal gets converted back to the time domain, then fed into a second model that operates directly on the audio waveform. This stage catches what the frequency analysis missed - handling dynamic noise patterns, preserving speech naturalness, and cleaning up any artifacts from the first stage.\n\\\n// Stage 2: Time domain refinement\n\nval estimatedBlock = fftProcessor.inverse(magnitude, phase)\nval finalBlock = model2.run(mapOf(\"input_4\" to estimatedTensor, \"input_5\" to lstmState))\n\nThe Mobile-First Design Philosophy\nDTLN's architecture reflects years of practical mobile AI deployment experience. Every design decision prioritizes real-world constraints over academic benchmarks.\nChunk-Based Processing The model processes audio in 512-sample chunks (32ms at 16kHz), striking the optimal balance between latency and context. This chunk size is small enough for real-time processing but large enough to provide meaningful temporal context for the LSTM networks.\n\\\ncompanion object {\n    private const val BLOCK_LEN = 512  // 32ms chunks\n    private const val BLOCK_SHIFT = 128  // 75% overlap for smooth processing\n}\n\nStateful LSTM Networks Both models use LSTM (Long Short-Term Memory) networks that maintain internal state between chunks. This temporal memory allows the model to distinguish between speech and noise based on context, not just instantaneous audio characteristics.\n\\\nclass NoiseSuppressorImpl {\n    // These tensors maintain LSTM state between processing calls\n    private var input3Tensor: OnnxTensor? = null  // Model 1 LSTM state\n    private var input5Tensor: OnnxTensor? = null  // Model 2 LSTM state\n\n    fun processChunk(audioChunk: FloatArray): FloatArray {\n        // State automatically carries forward to next chunk\n        val result1 = model1.run(mapOf(\"input_3\" to input3Tensor))\n        input3Tensor?.close()\n        input3Tensor = result1[1] as OnnxTensor  // Update state\n\n        // State continuity ensures smooth, artifact-free processing\n    }\n}\n\nPerformance Characteristics That Matter\nUnderstanding DTLN's architecture helps predict its behavior in your application. These performance characteristics directly impact user experience:\nLatency Profile\nAlgorithmic Delay: 32ms (one chunk processing time)\nInference Time: 3-4ms per chunk on mid-range Android hardware\nTotal Latency: ~35ms end-to-end (imperceptible for most use cases)\nResource Usage\nMemory Footprint: ~28MB during active processing\nCPU Usage: 12-18% on typical mid-range device\nBattery Impact: Negligible for typical recording sessions\nThese characteristics make DTLN particularly well-suited for mobile applications where users expect immediate results without sacrificing device performance or battery life.\nONNX Runtime Integration Strategy\nGetting ONNX Runtime working on Android isn't just about adding a dependency to your build.gradle. The difference between a proof-of-concept that crashes under load and a production-ready implementation lies in the session configuration, memory management, and resource allocation strategy.\nAs we already prepared a minimal runtime build, it’s time to look into what lies next.\nSession Configuration for Mobile Reality\nThe default ONNX Runtime session configuration assumes you're running on a server with abundant resources. Mobile devices operate under entirely different constraints: limited memory, thermal throttling, and users who expect apps to remain responsive during AI processing.\n\\\nprivate val sessionOptions = OrtSession.SessionOptions().apply {\n    setIntraOpNumThreads(numThreads.coerceIn(1, 4))\n    setInterOpNumThreads(numThreads)\n    setMemoryPatternOptimization(true)\n    setOptimizationLevel(OrtSession.SessionOptions.OptLevel.ALL_OPT)\n    setExecutionMode(OrtSession.SessionOptions.ExecutionMode.SEQUENTIAL)\n}\n\nYour first instinct might be to use all available CPU cores for maximum performance. Resist this urge. Mobile devices prioritize battery life over raw computational speed, and Android's thermal management will throttle aggressive CPU usage within seconds.\nThe sweet spot for real-time audio processing sits between 2-4 threads, determined by your device's core count:\n\\\nprivate val numThreads = Runtime.getRuntime().availableProcessors().coerceIn(1, 4)\n\nThis configuration delivers 95% of maximum performance while consuming 60% less battery than an unrestricted thread pool. Your users notice the efficiency gains more than the minor latency difference.\nsetMemoryPatternOptimization(true) activates ONNX Runtime's most impactful mobile optimization. This setting analyzes your model's memory access patterns during the first few inference calls, then pre-allocates memory pools to minimize garbage collection pressure during real-time processing.\n\\\nsetExecutionMode(OrtSession.SessionOptions.ExecutionMode.SEQUENTIAL)\n\nSequential execution might seem counterintuitive when parallel processing offers higher throughput. However, real-time audio processing demands predictable latency over peak performance. Parallel execution creates latency spikes when thread synchronization occurs - precisely what you want to avoid during live audio processing.\nSequential execution delivers consistent 3-4ms inference times, while parallel mode ranges from 2-8ms with unpredictable spikes. Users perceive consistency as quality.\nMemory Pre-allocation: The Performance Multiplier\nThe most critical optimization for mobile ONNX Runtime applications involves pre-allocating tensors that get reused across inference calls. Creating tensors during inference triggers memory allocations that accumulate into significant performance bottlenecks.\n\\\n// Pre-allocate tensors during initialization\ninput3Tensor = createZeroTensor(INP_SHAPE_2)  // Model 1 LSTM state\ninput5Tensor = createZeroTensor(INP_SHAPE_2)  // Model 2 LSTM state\n\nprivate fun createZeroTensor(shape: LongArray): OnnxTensor {\n    val env = requireNotNull(env) { \"ONNX Environment not initialized\" }\n    val size = shape.reduce { acc, i -> acc * i }.toInt()\n    return OnnxTensor.createTensor(env, FloatBuffer.allocate(size), shape)\n}\n\nGarbage Collection Pressure Reduction - Creating tensors during inference generates objects that must be garbage collected. Pre-allocation moves this cost to initialization time, keeping inference paths allocation-free.\nMemory Fragmentation Prevention - Repeated tensor creation fragments heap memory, leading to unexpected allocation failures. Pre-allocated tensors maintain consistent memory layout.\nLatency Consistency - Allocation costs are unpredictable and can introduce latency spikes during real-time processing. Pre-allocation ensures consistent inference timing.\nThese integration strategies transform ONNX Runtime from a research tool into a production-ready component. The configuration choices, memory management patterns, and error handling approaches directly impact user experience in ways that become apparent only under real-world usage conditions.\nYou can look into https://github.com/linreal/android-onnx-showcase/blob/main/app/src/main/java/gos/denver/onnxshowcase/audio/impl/NoiseSuppressorImpl.kt for a full source code.\nConclusion: AI as Competitive Advantage\nThe mobile AI landscape is experiencing a fundamental shift. While competitors chase resource-hungry language models and cloud-dependent solutions, there's a massive opportunity in specialized, on-device AI that delivers immediate value to users.\nKey Takeaways for Android Developers\nOn-device AI is production-ready today. The combination of ONNX Runtime's optimization capabilities and purpose-built models like DTLN delivers performance that matches or exceeds cloud solutions while eliminating latency and connectivity requirements. Your users get instant results, and you get a feature that works everywhere - from subway tunnels to airplane mode.\nAPK size optimization transforms deployment strategy. Our minimal ONNX Runtime build reduced library size by 70% without sacrificing functionality. This isn't just about storage - it directly impacts user acquisition. When AI features add 7MB instead of 27MB to your app, the cost-benefit equation shifts dramatically in your favor.\nUser experience trumps algorithmic sophistication. DTLN isn't the most advanced noise suppression model available, but it strikes the perfect balance between quality, performance, and resource consumption for mobile deployment. Users don't care about model architecture - they care about crystal-clear audio in noisy environments.\nApps implementing on-device AI gain three competitive advantages: Privacy by Design (no sensitive data leaves the device), Offline Reliability (consistent experience regardless of network conditions), and Cost Structure Benefits (no cloud inference costs or operational expenses that scale with usage).\nNext Steps and Exploration\nThe techniques demonstrated here extend far beyond noise suppression. ONNX Runtime enables practical deployment of models for audio processing, computer vision, natural language tasks, and sensor fusion applications.\nThe complete implementation is available on GitHub: android-onnx-showcase. Use it as a foundation for your own AI-powered features.\nYour Android app deserves AI that enhances user experience without compromising performance, privacy, or reliability. ONNX Runtime makes this vision achievable today. The tools are ready, the performance is proven - time to build something amazing.\nFound this implementation useful? Star the GitHub repository and share your results. The mobile AI community grows stronger when we share practical knowledge.\nFollow me for more deep-dives into production-ready mobile AI implementations that your users will actually notice and appreciate. \\n",
            "High-Quality Games Are Getting Lost\nIn the past few years, the gaming industry has seen a tidal wave of investment. Tens of billions of dollars have flowed into studios and publishers—more than ten times the historical average. The result is exactly what you’d expect: an explosion of high-quality content.\nFrom 2019 to 2023, the number of games released on Steam nearly doubled, reaching over 14,500 new games per year. Meanwhile, the App Store and Google Play are flooded with over a thousand apps published every day, offering players more choice than ever. Those distribution channels have become saturated.\nDespite the surge in funding and quality, most games are quietly slipping through the cracks. I meet founders all the time whose launch strategy is no deeper than: “We’re making a great game and putting it up on Steam Early Access.”That’s not a go-to-market strategy—that’s wishful thinking. \\n \nWe’ve Seen This Story Before\nIn the early 2000s and throughout the 2010s, Hollywood studios kept doubling down on blockbuster content—fund content, release in theaters, repeat. The assumption was that the better the content, the better the outcome. Then Netflix changed the game. They didn’t just create shows. They changed how audiences discovered and consumed content. It was a new distribution model: personalized, frictionless, on-demand access to content, delivered over the internet, bypassing movie theaters entirely. Today, nearly every major player from Disney to HBO follows that same model. Content still matters, but distribution is what changed the industry.\nThe same happened in music. Record labels used to control everything through their artist rosters. But Spotify, YouTube, and later TikTok shifted the power. They didn’t make music—they just made it easier to access and share. Today, artists break through because of those platforms. Labels that once owned the pipeline now find themselves negotiating with it.\nGaming is following the same arc. Incredible content, saturated channels, and a growing realization that discovery—not quality—is the real bottleneck. \\n \nDistribution Is the Bottleneck\nWe’re not short on great games. We’re short on new ways to make people care.\nSteam saw more than 40 games launched a day in 2023. Mobile app stores are even more saturated, with over 1,000 apps published daily. Discovery hasn’t kept up with the flood of content. It’s been overwhelmed by it.\nSteam has added curators, tags, and algorithmic feeds, but most releases still sink within days. Mobile stores are worse—prime real estate is dominated by paid ads, and organic discovery is nearly nonexistent. There’s simply too much content, not enough visibility, and no efficient way to rise above the noise unless you pay your way to the front.\nThis saturation is not just a discovery problem—it’s an economic one.\nApple’s ATT rollout in 2021 disrupted mobile user acquisition overnight. Over 80% of iPhone users became invisible to targeted ads, breaking the model that many mobile studios relied on to find and convert high-value players. CPI costs jumped nearly 90%. ROAS dropped. What once worked no longer does.\nAt the same time, most games don’t make money. But it’s not always because the games are bad—it’s because they’re invisible. On Steam, 67% of games have earned less than $5,000 in lifetime revenue—and more than half never crossed $1,000. The average player sticks to four games a year. On mobile, the top 1% of games account for over 90% of downloads. Nearly 60% of apps on the App Store don’t even have a single review.\nThere’s no middle class. Big-budget games and breakout hits get all the attention. Everyone else fights for scraps. The end result is the “rich get richer.”\nIndies can’t afford to brute-force their way into visibility. They can’t outspend or outmarket incumbents. And yet most studios still rely on the same tired playbook: launch on Steam, pay the platform tax, hope the algorithm works. That’s not a strategy. It’s a gamble (tho, once in a blue moon, the algorithm favors an indie and it breaks out).\nDistribution is not a side task—it’s the real product challenge. And it’s the one thing this industry hasn’t meaningfully rethought.\n\\\nThe Shift Has Already Started\nSome companies aren’t waiting for better distribution. They’re building it.\nEpic didn’t just launch a hit game—they turned Fortnite into a platform. With UEFN (Unreal Editor for Fortnite), developers can now build games inside Fortnite using AAA tools, publish instantly, and tap into a built-in audience of millions. Discovery and monetization are integrated. The friction is gone.\nRoblox took it even further. It’s a closed-loop system where content and distribution live in the same place. Creators build games, users discover them, and both sides benefit. What makes Roblox especially interesting right now is this: distribution is ahead of content. The platform has reach. It just doesn’t have enough standout experiences. For developers, that’s an opportunity to succeed not by out-marketing the competition, but simply by building something better.\nOther players are entering the space from the edges. YouTube is embedding games directly into its platform. Discord lets users play inside servers. Netflix now offers games alongside its shows. Even Telegram supports native games through mini-apps. All of these are experiments in rethinking where and how games are discovered.\nAnd then there’s the web.\nThe open web is becoming viable again—not just for casual games, but for real, session-based experiences. There’s no platform tax. No gatekeepers. No approval queues. A single build can reach anyone with a browser. For developers, that’s freedom. For players, it’s one click away.\nWe’re starting to see early signs of this shift. BAPBAP built an early fanbase in 2023 through a web version before launching on Steam, fueling thousands of installs on day one. Hero Wars took the same path years earlier—starting on the web, then expanding to mobile, where it surpassed 150 million installs and $1.5 billion in revenue.\nBut most developers are still funneling their games into the same overcrowded storefronts—fighting over the same algorithms, the same paid installs, and the same limited real estate. It’s time to shift that energy. Instead of competing in the same narrow lanes, the opportunity is to explore new ones. Go where users already are. Build for the platforms that actually enable discovery. Let distribution shape your strategy—not follow it.\nThe future won’t be defined by who builds the best-looking game. It will be defined by who rethinks the path to finding it.",
            "Artificial Intelligence (AI) in mobile apps was synonymous with chatbots for an extended period. Ask a question and get an answer to the extent of that on many users. This perception would have been long outdated by 2025. Today, AI is not a mere feature; it is fast becoming the invisible force that shapes how an app is built, how it unfolds upon its release, and the way it interacts with users at a very intimate level. \nWalking this path, mobile app development is getting changed, and AI is leading it. Even though conversational AI still holds important roles, developers and businesses have begun utilizing machine learning, predictive analytics, computer vision, natural language processing, and generative AI to their fullest capacity to produce intelligent and adaptive experiences, many of which latter thought to be from the far future.\nWhat does this mean for the current mobile app development scenario? Transitioning from static apps to those learning, adapting, and anticipating is the forecasted step. Let's further know how well AI is reshaping mobile app development services way beyond the virtual assistant zone.\nTop 10 Ways AI Is Transforming Mobile App Development in 2025\nAI is driving a massive shift in mobile app development changing how apps interact, adapt, and perform. From personalization to predictive design, here are the top ten ways AI is revolutionizing the mobile experience:\nPersonalized Experiences at Scale\nSome of the most visible changes in the AI field are the enhancement of user-oriented experiences. Earlier, the apps had the very same layout, content, and function for all users. Now, AI helps apps observe user behaviour, learn from these observations, and adapt their content and interface accordingly. Behind the scenes, AI goes on to analyze it all to provide every user with a very special session just for them.\nThis level of personalization has become a core expectation, prompting every mobile app development company to incorporate such features. Whether it's a cross platform mobile app development project or a native solution, the need to create contextual user experiences is paramount.\nIntelligent Search and Discovery\nAnother major shift has been the interaction facet of search within apps. Conventional search functions depended significantly on exact keywords, often discouraging users from locating what they wanted. AI radically enhanced this experience to make search more intelligent and conversational. Natural Language Processing (NLP) enables users with the ability to ask questions or make search queries using off-the-cuff language, and AI looks at the underlying intention of the words.\nIn modern applications, the integration of an intelligent layer is standard practice among companies specializing in custom mobile app development services.\nPredictive Capabilities and Anticipatory Design\nOne compelling ability of AI is prediction. AI can analyze patterns in user behavior and come up with what a user may want to see next, and offer it before the user asks for it. The anticipatory design, as people today commonly know it, makes the app truly clever by putting up suggestions, reminders, or shortcuts that really resonate with the user's habits.\nAI in Design and Development \nAI is influencing not only how apps work but also how they are created. Mobile app development, which embodies long design cycles and manual testing, is now aided and accelerated by AI in each step. There are now AI-aided tools that help designers create wireframes or mockups based on simple sketches or text prompts.\nHence, repetitive tasks will require very little time and thus allow teams to invest more in creativity and strategy. This transformation is reshaping enterprise mobile app development, helping larger organizations deploy sophisticated solutions faster and with higher quality assurance.\nSmarter App Testing and Maintenance\nAI finds another key use case in quality assurance. Traditional methods are unable to keep pace with short deployment cycles and constant upgrades. AI-based test frameworks simulate user behavior or find edge cases and even predict where the bugs are most likely to appear based on prior data. Besides that, AI is doing wonders post-launch by monitoring app performance. It records crashes, wanders into behavioral analysis, detects anomalies, and blows the whistle when it stumbles upon deviations from the normal.\nMultimodal Interaction with AI\nFurthermore, this has been extended and pushed towards sensory interaction, particularly in voice, image, and gesture recognition. Making apps more inclusive and user-friendly, especially for those who use experimental hands-free or visual inputs. AI in voice recognition enables users to interact with apps to initiate commands and have them respond through speech, giving ways of interface new fluid and human feeling. \nComputer vision aids in the identification of faces by the app, scanning QR codes, or physically identifying objects via the smartphone camera. Today, users don't just want to know what is meant by mobile application development; they demand smarter, intuitive apps that understand them deeply.\nSecurity and Fraud Detection\nSecurity is another area where AI technologies have taken a giant leap. Older computer security models deal with threats of the past, whereas the cyber-threats of today are an altogether different animal. Using AI-based models, these computers now analyze millions of interactions occurring among interconnected devices to detect suspicious activity, irregular login patterns, or even data theft. \nSuch apps now use AI to watch transactions for fraudulent behavior before any harm is done to users. The biometric security system, whether it be facial recognition or fingerprint scanning, is an AI-enabled gateway to an easy and secure authentication method.\nRise of Generative AI in Mobile Apps\nIn the last year, generative AI has emerged as one of the most thrilling areas in the app development world. Tools such as GPT-4 and DALL·E of OpenAI have opened a new avenue for users to generate text, images, music, and videos, with a mere handful of commands. Mobile applications are using this technology to create generative spaces for creators to work in. \nFrom AI photo editing, avatar generation, to story ideation, to productivity apps, users have become accustomed to AI either assisting or potentially co-creating content with them.\nFrom Reactive to Adaptive Apps\nOne of the most revolutionary and disruptive changes is from reactive to adaptive app experiences. Traditional apps respond to user input. This is where AI-enabled apps excel they can learn behaviors from their human users, changing the interface, suggesting actions, and even dynamically reprogramming their workflows. For instance, depending on whether a user's mood is detected from voice tone or facial expression, a mental wellness app may choose to deliver a particular set of suggestive activities.\nAccessibility and Inclusivity Through AI\nAI has emerged as an enabler to infuse accessibility into mobile app creation, thereby catering to a variety of user needs. These days, apps offer a wide range of capabilities, including real-time conversion between text and speech, and vice versa. AI translations and UI variations that meet the needs of visually impaired users. Thus, by breaking down the barriers of language, cognition, and physicality it necessitates that technology assist everyone, irrespective of ability or creed.\nThe Challenges Ahead\nIntegrating AI into mobile app development services is challenging when it comes to ensuring data privacy, model accuracy, algorithmic bias, and development budgets. Trust is key from the user's perspective. They have to be transparent about the collection and use of data, conform to global privacy laws, continuously monitor, and update the model to avoid unintended consequences. \nDespite all these problems, the benefits of AI are significant enough to overpower any challenge. If applied properly, AI can help developers build smarter, faster, and safer mobile apps.\nClosing Thoughts: Future-Ready with AI\nMobile app development would become intelligent even in the manner of their behavior, way of their imagination, and way of their construction. It means we are during those moments when AI chips on the device will make processing real-time but safer and efficient; emotion recognition and zero-UI interfaces will set new limits; and then AI will be analyzed as a collaborator instead of a tool. \nFor developers, the latest technologies must be mastered with data-first thinking. Businesses must do the innovation, invest in more innovative experiences, and keep the user as a priority.\nWhether it’s for startups or enterprises, those looking for the best mobile app development company need to focus on long-term value, where AI meets user-centric design. As AI becomes the backbone of digital evolution, the future of cross platform mobile app development and beyond is undeniably innovative, intuitive, and transformational.\n\\n",
            "Table of Links\nAbstract and 1 Introduction\n2. Prior conceptualisations of intelligent assistance for programmers \n3. A brief overview of large language models for code generation \n4. Commercial programming tools that use large language models \n5. Reliability, safety, and security implications of code-generating AI models \n6. Usability and design studies of AI-assisted programming \n7. Experience reports and 7.1. Writing effective prompts is hard\n7.2. The activity of programming shifts towards checking and unfamiliar debugging\n7.3. These tools are useful for boilerplate and code reuse\n8. The inadequacy of existing metaphors for AI-assisted programming \n8.1. AI assistance as search \n8.2. AI assistance as compilation \n8.3. AI assistance as pair programming \n8.4. A distinct way of programming \n9. Issues with application to end-user programming \n9.1. Issue 1: Intent specification, problem decomposition and computational thinking\n9.2. Issue 2: Code correctness, quality and (over)confidence \n9.3. Issue 3: Code comprehension and maintenance \n9.4. Issue 4: Consequences of automation in end-user programming \n9.5. Issue 5: No code, and the dilemma of the direct answer \n10. Conclusion \nA. Experience report sources \nReferences\n2. Prior conceptualisations of intelligent assistance for programmers\nWhat counts as ‘intelligent assistance’ can be the subject of some debate. Do we select only features that are driven by technologies that the artificial intelligence research community (itself undefined) would recognise as artificial intelligence? Do we include those that use expert-coded heuristics? Systems that make inferences a human might disagree with, or those with the potential for error? Mixed-initiative systems (Horvitz, 1999)? Or those that make the user feel intelligent, assisted, or empowered? While this debate is beyond the scope of this paper, we feel that to properly contextualise the qualitative difference made by large language models, a broad and inclusive approach to the term ‘intelligence’ is required.\n\\\nEnd-user programming has long been home to inferential, or intelligent assistance. The strategy of direct manipulation (Shneiderman & Norwood, 1993) is highly successful for certain types of limited, albeit useful, computational tasks, where the interface being used (“what you see”, e.g., a text editor or an image editor) to develop an information artefact can represent closely the artefact being developed (“what you get”, e.g., a text document or an image). However, this strategy cannot be straightforwardly applied to programs. Programs notate multiple possible paths of execution simultaneously, and they define “behaviour to occur at some future time” (Blackwell, 2002b). Rendering multiple futures in the present is a core problem of live programming research (Tanimoto, 2013), which aims to externalise programs as they are edited (Basman et al., 2016).\n\\\nThe need to bridge the abstraction gap between direct manipulation and multiple paths of execution led to the invention of programming by demonstration (PBD) (Kurlander et al., 1993; Lieberman, 2001; Myers, 1992). A form of inferential assistance, PBD allows end-user programmers to make concrete demonstrations of desired behaviour that are generalised into executable programs. Despite their promise, PBD systems have not achieved widespread success as end-user programming tools, although their idea survives in vestigial form as various “macro recording” tools, and the approach is seeing a resurgence with the growing commercialisation of “robotic process automation”.\n\\\nProgramming language design has long been concerned with shifting the burden of intelligence between programmer, program, compiler, and user. Programming language compilers, in translating between high-level languages and machine code, are a kind of intelligent assistance for programmers. The declarative language Prolog aspired to bring a kind of intelligence, where the programmer would only be responsible for specifying (“declaring”) what to compute, but not how to compute it; that responsibility was left to the interpreter. At the same time, the language was designed with intelligent applications in mind. Indeed, it found widespread use within artificial intelligence and computational linguistics research (Colmerauer & Roussel, 1996; Rouchy, 2006).\n\\\nFormal verification tools use a specification language, such as Hoare triples (Hoare, 1969), and writing such specifications can be considered programming at a ‘higher’ level of abstraction. Program synthesis, in particular synthesis through refinement, aims at intelligently transforming these rules into executable and correct code. However, the term “program synthesis” is also used more broadly, and programs can be synthesised from other sources than higher-level specifications. Concretely, program synthesis by example, or simply programming by example (PBE), facilitates the generation of executable code from input-output examples. An example of successfully commercialised PBE is Excel’s Flash Fill (Gulwani, 2011), which synthesises string transformations in spreadsheets from a small number of examples.\n\\\nThe Cognitive Dimensions framework (T. R. Green, 1989; T. Green & Blackwell, 1998) identifies three categories of programming activity: authoring, transcription, and modification. Modern programmer assistance encompasses each of these. For example, program synthesis tools transform the direct authoring of code into the (arguably easier) authoring of examples. Intelligent code completions (Marasoiu et al., 2015) support the direct authoring of code. Intelligent support for reuse, such as smart code copy/paste (Allamanis & Brockschmidt, 2017) support transcription, and refactoring tools (Hermans et al., 2015) support modification. Researchers have investigated inferential support for navigating source code (Henley & Fleming, 2014), debugging (J. Williams et al., 2020), and selectively undoing code changes (Yoon & Myers, 2015). Additionally, intelligent tools can also support learning (Cao et al., 2015).\n\\\nAllamanis et al. (2018) review work at the intersection of machine learning, programming languages, and software engineering. They seek to adapt methods first developed for natural language, such as language models, to source code. The emergence of large bodies of open source code, sometimes called “big code”, enabled this research area. Language models are sensitive to lexical features like names, code formatting, and order of methods, while traditional tools like compilers or code verifiers are not. Through the “naturalness hypothesis”, which claims that “software is a form of human communication; software corpora have similar statistical properties to natural language corpora; the authors claim that these properties can be exploited to build better software engineering tools.” Some support for this hypothesis comes from research that used n-gram models to build a code completion engine for Java that outperformed Eclipse’s completion feature (Hindle et al., 2012, 2016). This approach can underpin recommender systems (such as code autocompletion), debuggers, code analysers (such as type checkers (Raychev et al., 2015)), and code synthesizers. We can expect the recent expansion in capability of language models, discussed next, to magnify the effectiveness of these applications.\n\\\n:::info\nAuthors:\n(1) Advait Sarkar, Microsoft Research, University of Cambridge (advait@microsoft.com);\n(2) Andrew D. Gordon, Microsoft Research, University of Edinburgh (adg@microsoft.com);\n(3) Carina Negreanu, Microsoft Research (cnegreanu@microsoft.com);\n(4) Christian Poelitz, Microsoft Research (cpoelitz@microsoft.com);\n(5) Sruti Srinivasa Ragavan, Microsoft Research (a-srutis@microsoft.com);\n(6) Ben Zorn, Microsoft Research (ben.zorn@microsoft.com).\n:::\n:::info\nThis paper is available on arxiv under CC BY-NC-ND 4.0 DEED license.\n:::\n\\",
            "In high-performance software engineering, it’s easy to become so focused on optimization that you lose sight of broader business needs. This article shares lessons from my 20+ years building real-time, high-load systems across finance, telecom, and advertising. I explain how engineering intuition—shaped by edge-case systems—can become a liability when applied blindly. The goal: help engineering teams, managers, and even non-technical leaders understand when performance matters, and when it doesn’t.\nThe world of high-load, low-latency systems is a crucible of engineering disciplines. It distills software down to its most brutal essence: cycles, bytes, wire time. It teaches you to think like a CPU, to treat L1 cache behavior as gospel, and to view allocations with suspicion. It sharpens your instincts for system limits and exposes any architectural indecision under fire at 200,000 RPS. Like all specializations, it also distorts your lens.\nIn this piece, I want to reflect on the cost of repeatedly optimizing for edge cases. Specifically, how the deeply internalized mindset from building ultra-performant, latency-sensitive systems can become a limiting factor when engineers work in more elastic, less deterministic business domains.\nWhere Intuition Begins\nI started my journey in real-time systems, where timing guarantees are absolute. Like brakes in a car, the system simply cannot be late. Over time, I transitioned into web systems where elasticity and geo-distribution took precedence over millisecond determinism. In banking, consistency and security overtook performance. Then, in adtech, I encountered the most complex compromise yet: soft real-time expectations (under 100ms), low cost per request, and architectural elasticity, all under high traffic conditions.\nThis varied experience taught me that an engineer must think vertically, understanding the entire system from business goals to infrastructure. However, it also exposed the trap many fall into: carrying over instincts honed in one domain into another, without adapting them.\nLatency as Reflex\nIn high-load systems with latency constraints, your thinking changes. You focus not on modularity or reusability, but on minimizing processing. The logic is data-centric: don’t transform the data. Shape your logic to fit the data. Don’t pass structures between microservices. Instead, keep them where they are and compute directly. Don’t copy—compute in place.\nThese habits are powerful. But the engineer must also understand the variability of input data, the business flow that justifies it, and the degree of correctness required. And they must know when such reflexes start working against the business.\nPathological Optimization in General Systems\nAn engineer who grew up working on high-load systems often assumes the bottleneck is always latency. But most systems are not bound by that constraint. Over the years, I’ve seen engineers apply data-centric programming, sharded databases and even custom databases, to CRUD backends. The performance gain was marginal; the complexity cost was vast.\nOne example: while working at MTS and AdNow, we optimized the DSP backend to hit 200k RPS. The temptation was to optimize everything. We learned to isolate the high-performance core and treat admin panels, user dashboards, and analytics with simpler tools like Postgres and standard libraries. Not every component needed to live at the edge.\nWhen Experience Becomes Bias\nEngineers carry the weight of their successes. For example, I avoided sharding if it was possible to do the processing on a single server, albeit with a significantly expanded RAM volume (for example, up to 4TB), and this often gave excellent results both in the cost of maintenance and in development - it is much easier to write code when all the data is in your memory than to work with sharded data. In such cases, we scaled vertically, adding RAM.\nHowever, this same intuition can become counterproductive in systems where horizontal scale is natural and cheap. Intuition must be regularly retrained. A 10-core server may outperform a 40-core box unless NUMA topology and mutex contention are addressed. You must consider switches (Cut-Through vs. Store-and-Forward), storage behavior (95th percentile latency), and data access patterns.\nThe mature engineer’s mindset is not \"What is the best possible system?\" but \"What does the business need, and how can we get there with minimum future pain?\"\nDebuggability vs. Efficiency\nAnother anti-pattern from high-performance thinking: sacrificing observability for CPU savings. In one system, we replaced JSON logging with binary formats to reduce overhead. It worked—3% CPU saved. But the trade-off? Incident response slowed, human debugging suffered, and onboarding became a challenge.\nIn ultra-constrained systems like SCADA (which I worked on early in my career), this trade-off is acceptable. But in most cloud-native systems, human time trumps compute time. Engineers should always ask: “Who’s going to debug this at 3 a.m.?”\nCultural Drift in Engineering Teams\nI’ve seen high-performance specialists bring over habits that don’t scale organizationally: rewriting libraries, resisting abstractions, and insisting on building from scratch. I’ve been guilty of it too, creating \"hot\" functions in x86-64 assembler and using directly the processor's SIMD commands (AVX-512), even when using the Go language. These systems work brilliantly, but only in the hands of their authors. By the way, assembler is very conveniently integrated into Go, but, as practice has shown, few people know it.\nToday, as a manager, I emphasize that business tasks must come first. If business requires creating a system with extreme performance characteristics, then we must remember that this will require a stellar team and vice versa, if a standard system is required, then it is not worth using solutions that are difficult to support and develop, but should focus on schemes and architecture that are understandable to the mass developer, which can be mastered by a mid-level developer in two weeks.\nI also caution against microservices sprawl. Teams eager to optimize development workflows may inadvertently turn a tight data-centric pipeline into a network of chatty, latency-laden services. Even Amazon Prime Video teams have returned from microservices to monoliths in such contexts.\nUnlearning the Habit of Optimization\nThe hardest thing for performance-oriented engineers to learn is when not to optimize. When building the MTS platform, we had parts of the system that were hot paths and others that were barely used. Initially, the urge was to use the same tooling across all components. But it’s a trap. CRUD services don’t need to scale like your bidding engine. Choose the right tool, even if that means sacrificing uniformity.\nSimilarly, early in my career, when developing code to perform a fast inverse Fourier transform, I wrote a highly optimized assembler code that outperformed GCC by 30%. But six months later, the processors changed, and my code optimized for prefetch pipelines began to perform worse than the compiler-generated one. That’s the real cost of low-level perfection: it rarely lasts. Performance tuning should be reserved for business-critical paths.\nLifecycle Cost of Optimization\nWhat often gets overlooked is the total lifecycle cost of early optimization. An efficient algorithm or exotic data layout may save compute time today, but if it slows down onboarding, complicates testability, or becomes a barrier to architectural evolution, then the system is effectively accruing technical debt disguised as technical brilliance. I’ve seen projects where an engineer’s initial low-level perfection became a tax the team paid for years—refactoring was too risky, and new hires avoided touching critical modules. Mature systems require performance that evolves with the business, not just code that’s clever in the moment. The question we should always ask is: “Can this optimization survive team growth and domain shifts over 3–5 years?”\nLearning to Let Go\nIn our CTR/VTR predictor, we send updates in real time. But for the segment coverage calculator in the UI, we switched to batch processing. The latency of updating the data in the UI has increased, but the complexity of support and development has decreased significantly without any impact on the business goal.\nThe wisdom is not in knowing how to optimize, but in knowing when the business doesn’t need it. Premature optimization is only “evil” when it’s misaligned with business maturity. If you're targeting 200k RPS on a core, yes—start sharp. But if it's 200k RPS on a cluster, and you can shard data processing (e.g. distribute requests across nodes), then act iteratively, start with inefficient but working code, and plan refactoring to achieve lower server load. And how to use the \"extra\" hardware freed up after optimization has never been a problem.\nMature Engineers Understand Trade-offs\nThe most balanced engineers I’ve worked with understand the entire vertical, from business requirements to infrastructure tuning. They know when to use Apache Ignite and when Postgres is enough. They make performance decisions only where bottlenecks align with business outcomes.\nSuch engineers avoid optimization addiction. They favor maintainability. They are patient with temporary solutions and confident that the roadmap allows for future improvements. That confidence, along with technical range, is what I consider “technical maturity.”\nLeading Self-Organizing Teams Without Overengineering\nLeft unchecked, high-performance teams often over-abstract. To prevent that, I encourage cross-functional ownership—engineers who think like analysts, testers, and product managers. I advocate for teams that talk openly, document and justify the architectural decisions (ADR), and include domain experts in the loop. You cannot succeed with brilliant engineers alone. You need people from the market.\nAlso, I’ve seen over-specialization derail early-stage teams. For new systems, buy experienced teams or foundational platforms. Don’t reinvent everything. Starting from scratch without market-ready expertise often leads to failure, unless backed by large investments.\nFinal Thoughts\nI don’t regret specializing in high-load systems. It shaped how I think. But I’ve also seen how these instincts, left unchecked, can limit engineers in broader domains. We must relearn general software engineering just as athletes must relearn walking after years of sprinting.\nYour best skill can become your biggest bias. And your greatest strength, when balanced, is what makes you a truly versatile engineer.\nIf you’re a product leader, founder, or manager: don’t ask your engineers to over-optimize from the start. Let them build clear, maintainable systems that can scale later if needed. High performance has its place—but business alignment always comes first.",
            "Table of Links\nAbstract and 1 Introduction\n2. Prior conceptualisations of intelligent assistance for programmers\n3. A brief overview of large language models for code generation\n4. Commercial programming tools that use large language models\n5. Reliability, safety, and security implications of code-generating AI models\n6. Usability and design studies of AI-assisted programming\n7. Experience reports and 7.1. Writing effective prompts is hard\n7.2. The activity of programming shifts towards checking and unfamiliar debugging\n7.3. These tools are useful for boilerplate and code reuse\n8. The inadequacy of existing metaphors for AI-assisted programming\n8.1. AI assistance as search\n8.2. AI assistance as compilation\n8.3. AI assistance as pair programming\n8.4. A distinct way of programming\n9. Issues with application to end-user programming\n9.1. Issue 1: Intent specification, problem decomposition and computational thinking\n9.2. Issue 2: Code correctness, quality and (over)confidence\n9.3. Issue 3: Code comprehension and maintenance\n9.4. Issue 4: Consequences of automation in end-user programming\n9.5. Issue 5: No code, and the dilemma of the direct answer\n10. Conclusion\nA. Experience report sources\nReferences\n\\\n \nAbstract\nLarge language models, such as OpenAI’s codex and Deepmind’s AlphaCode, can generate code to solve a variety of problems expressed in natural language. This technology has already been commercialised in at least one widely-used programming editor extension: GitHub Copilot.\n\\\nIn this paper, we explore how programming with large language models (LLM-assisted programming) is similar to, and differs from, prior conceptualisations of programmer assistance. We draw upon publicly available experience reports of LLM-assisted programming, as well as prior usability and design studies. We find that while LLM-assisted programming shares some properties of compilation, pair programming, and programming via search and reuse, there are fundamental differences both in the technical possibilities as well as the practical experience. Thus, LLM-assisted programming ought to be viewed as a new way of programming with its own distinct properties and challenges.\n\\\nFinally, we draw upon observations from a user study in which non-expert end user programmers use LLM-assisted tools for solving data tasks in spreadsheets. We discuss the issues that might arise, and open research challenges, in applying large language models to end-user programming, particularly with users who have little or no programming expertise.\n1. Introduction\nInferential assistance for programmers has manifested in various forms, such as programming by demonstration, declarative programming languages, and program synthesis (Section 2). Large language models such as GPT mark a quantitative and qualitative step-change in the automatic generation of code and natural language text. This can be attributed to cumulative innovations of vector-space word embeddings, the transformer architecture, large text corpora, and pre-trained language models (Section 3).\n\\\nThese models have been commercialised in the form of APIs such as OpenAI Codex, or as programmerfacing tools such as GitHub Copilot and Tabnine. These tools function as a sort of advanced autocomplete, able to synthesize multiple lines of code based on a prompt within the code editor, which may be natural language (e.g., a comment), code (e.g., a function signature) or an ad-hoc mixture. The capabilities of such tools go well beyond traditional syntax-directed autocomplete, and include the ability to synthesize entire function bodies, write test cases, and complete repetitive patterns (Section 4). These tools have reliability, safety, and security implications (Section 5).\n\\\nPrior lab-based and telemetric research on the usability of such tools finds that developers generally appreciate the capabilities of these tools and find them to be a positive asset to the development experience, despite no strong effects on task completion times or correctness. Core usability issues include the challenge of correctly framing prompts as well as the effort required to check and debug generated code (Section 6).\n\\\nLongitudinal experience reports of developers support some of the lab-based findings, while contradicting others. The challenges of correctly framing prompts and the efforts of debugging also appear here. However, there are many reports that these tools do in fact strongly reduce task time (i.e., speed up the development process) (Section 7).\n\\\nProgramming with large language models invites comparison to related ways of programming, such as search, compilation, and pair programming. While there are indeed similarities with each of these, the empirical reports of the experience of such tools also show crucial differences. Search, compilation, and pair programming are thus found to be inadequate metaphors for the nature of LLM-assisted programming; it is a distinct way of programming with its own unique blend of properties (Section 8).\n\\\nWhile LLM-assisted programming is currently geared towards expert programmers, arguably the greatest beneficiaries of their abilities will be non-expert end-user programmers. Nonetheless, there are issues with their direct application in end-user programming scenarios. Through a study of LLM-assisted end-user programming in spreadsheets, we uncover issues in intent specification, code correctness, comprehension, LLM tuning, and end-user behaviour, and motivate the need for further study in this area (Section 9).\n\\\n:::info\nThis paper is available on arxiv under CC BY-NC-ND 4.0 DEED license.\n:::\n:::info\nAuthors:\n(1) Advait Sarkar, Microsoft Research, University of Cambridge (advait@microsoft.com);\n(2) Andrew D. Gordon, Microsoft Research, University of Edinburgh (adg@microsoft.com);\n(3) Carina Negreanu, Microsoft Research (cnegreanu@microsoft.com);\n(4) Christian Poelitz, Microsoft Research (cpoelitz@microsoft.com);\n(5) Sruti Srinivasa Ragavan, Microsoft Research (a-srutis@microsoft.com);\n(6) Ben Zorn, Microsoft Research (ben.zorn@microsoft.com).\n:::\n\\",
            "As AI systems scale across sectors like healthcare, manufacturing, and finance, Europe faces a critical challenge: how to orchestrate AI securely across privacy, regulatory, and organizational boundaries.\n\\\nThis case study explores a pioneering Huberta project that embraces zero-trust architecture, metadata-first orchestration, and mathematical compliance via PDEs.\n\\\nAt the heart of this initiative lies a breakthrough: policy-aware orchestration through partial differential equations, allowing AI to run only when privacy, intent, and law align.\n\\\nUpstaff provided specialized AI engineers who tackled the core challenges of federated orchestration, zero-trust metadata, and explainable infrastructure at scale.\n\\\nThis article provides insights into a European data infrastructure project focused on creating a policy-aware, zero-trust system for federated AI.\n\\\nThe initiative aims to revolutionize data infrastructure by replacing centralized data systems with a decentralized, privacy-preserving framework.\n\\\nIt uses partial differential equations (PDEs) to enforce compliance (e.g., GDPR, EU AI Act) and manage data access for secure multi-party collaboration without raw data exchange.\n\\\nWhat we will cover:\n\\\n\nZero-Trust Metadata and Dataspaces\nZero-Trust AI Orchestration Across Privacy and Policy Boundaries\nSystem Architecture Overview\nEngineering Stack & Capabilities\nCloud Infrastructure Capability Matrix (AWS-focused)\nEngineering the Backbone of Federated AI\nResults So Far\nLessons Learned & Engineering Insights\nWhy This Matters: The Next Wave of AI Infrastructure\nConclusion: Engineering Trustworthy AI at Scale\nDataspace\nA dataspace is a federated network designed for secure, decentralized data exchange. It allows organizations to maintain control over their data while enabling interoperability across different platforms and industries.\n\\\n \n\\\nDataspace enables trusted data sharing in a way that preserves the data sovereignty of participants based on a standard governance framework.\n\\\n\nDataspaces are pivotal in sectors like mobility, healthcare, logistics, and smart cities, where data integration is essential for innovation and efficiency.\nDataspaces can be purpose- or sector-specific, or cross-sectoral.\nZero-Trust Metadata and Dataspaces\nAs Europe advances toward a digitally sovereign future, the way we handle data is undergoing a fundamental shift.\n\\\n \n\\\n\\\nTraditional architectures such as centralized data lakes, post-hoc compliance checks, and monolithic workflows are no longer sufficient. Emerging standards, like the EU AI Act and GDPR, demand real-time governance, privacy-preserving design, and explainability by default.\n\\\nAt the frontier of this transformation is a groundbreaking project. Its mission is to reimagine data infrastructure as a policy-aware, zero-trust system built not from pipelines, but from mathematics.\n\\\nAt the core of this system are partial differential equations (PDEs) that regulate resource access, data movement, and AI behavior through boundary conditions.\n\\\nThis paradigm allows multi-party collaboration without raw data exchange, high-performance computing (HPC) on demand, with minimal energy footprint, and compliance encoded directly into the infrastructure.\nHow PDE-Orchestrated Infrastructure Differs From Conventional Systems\n| Feauture | Conventional Cloud AI | PDE-Orchestrated Zero-Trust AI |\n|----|----|----|\n| Data Movement | Centralized | Local-only |\n| Policy Compliance | Post-hoc | By-construction |\n| Resource Usage | Persistent | Ephemeral |\n| Governance | Manual | Embedded in PDEs |\n| Traceability | Limited | DAG + Policy-bound |\nZero-Trust AI Orchestration Across Privacy and Policy Boundaries\nThe project's vision is radical: create a framework where data never moves, but value does.\n\\\nRather than collecting data into central repositories, each participant in the system, whether in healthcare, manufacturing, or public services, retains full control of their data.\n\\\nA dynamic knowledge graph holds metadata, ontologies, and processing “recipes.” Computation is triggered by PDEs that enforce policy gates (GDPR, ISO, GAMP) as mathematical constraints.\n\\\nWhen certain boundary conditions are met, e.g., a spike in demand or anomaly detection, a short-lived HPC cluster spins up, computes locally, and vanishes.\n\\\nBut to make this vision real, the team needed engineers with a rare mix of skills:\n\\\n\nPrivacy-preserving machine learning\nFederated AI\nKnowledge graph integration\nExplainable DAG orchestration\nSemantic modeling and metadata processing\n\\\nAt the heart of the system lies a governance PDE, where each term in the equation maps to a constraint:\n\\\n\n∂u/∂t + ∇·(α(u)∇u) = f(x, t)- represents AI execution across time and space.\n∂u/∂t — latency or response time\nα(u) — policy gating/access weights\nf(x, t) — triggers like demand spike or anomaly\nBoundary terms = regulatory or domain-specific constraints, GDPR compliance, semantic gates, and user intent.\n\\\nIf the PDE has no solution, computation is halted. This turns policy from a rule to a hard condition of execution. “If you can’t solve the PDE, you can’t run the task.” This is proactive compliance by construction.\nSystem Architecture Overview\nLocal Data Silos: Hospitals, factories, and labs retain full control of raw data. Nothing is centralized.\n\\\nPolicy Gate: Applies GDPR, AI Act, and internal policies at the metadata boundary. Invalid flows are filtered before orchestration.\n\\\nPDE Engine: The core of the system. It solves boundary-condition equations where each constraint represents a legal, semantic, or resource constraint.\n\\\nExamples:\n\\\n\nA GDPR clause becomes an unsolvable boundary if data leaves its origin.\nA compute budget becomes a conditional activation.\n\\\n\n\nKnowledge Graph: Stores semantic mappings, policy clauses, domain taxonomies, and orchestration “recipes.” This separates logic from data — enabling fast, ontology-driven decisions.\n\\\nEphemeral HPC Clusters: Resources are spun up only when a PDE solution exists — when policy, readiness, and workload match.\n\\\nThese may include:\n\\\nClassification models\nAnomaly detectors\nSimulation workloads\nFederated training\n\\\n\nDAG Traceability: Each operation logs its origin: which policy triggered it, which resource was allocated, and which boundary condition was met.\nEngineering Stack & Capabilities\n| Domain | Contribution | Tools and Methods |\n|----|----|----|\n| Federated AI | Built vertical & horizontal pipelines | PySyft, Flower, OpenMined, custom secure aggregation protocols |\n| Semantic Modeling | Ontology→PDE mapping | RDF/OWL, Protégé, SPARQL, Neo4j, GraphQL |\n| Metadata-First Design | Graph-driven orchestration | GraphQL, custom DAG wrappers, Apache Airflow, Argo Workflows, Prefect, Temporal |\n| Explainability & Auditing | Traceable execution lineage | DAG visualizers, metadata provenance tracing, JSON-LD, OpenPolicyAgent logs |\n| PDE Compliance Runtime | Mathematical constraint solver | SciPy, JAX, TensorFlow PDE, PyTorch autograd, custom symbolic solvers |\n| Infrastructure Engineering | Deployed resilient, policy-aware federated systems across cloud-native and hybrid environments | Amazon Web Services |\n\\\nCloud Infrastructure Capability Matrix (AWS-Focused)\n\\\n| Category | AWS Services Listed | Notes |\n|----|----|----|\n| Compute & Containerization | ECS, EKS, EC2, Fargate, Lambda | All AWS-native |\n| Networking & Security | VPC, PrivateLink, IAM, Security Groups, KMS, Secrets Manager | AWS-specific |\n| Storage | S3, EFS, FSx | AWS storage services |\n| Serverless Pipelines | Step Functions, EventBridge, DynamoDB Streams | AWS-native serverless tools |\n| Data Layer | Neptune, RDS, Aurora, Glue, Athena | All are AWS-managed data services |\n| Monitoring & Observability | CloudWatch, X-Ray, OpenTelemetry | FirOpenTelemetry is a cross-cloud; two are AWS |\n| Compliance Enforcement | Macie, GuardDuty, Config | All AWS-native compliance/security tools |\nEngineering the Backbone of Federated AI\nAmong others, Federated AI also allows them to significantly reduce the amount of data they transfer. In fact, some projects managed to reduce their data transfer burden by more than 99% compared to a centralized training model.\n\\\nThis is important because moving very large datasets contributes to higher costs, lower performance, and decreased energy efficiency.\n\\\nThere are two main approaches to federated AI:\n\\\n\n\nHorizontal federated AI: pulls model weights from the same types of data in every site\n\\\nVertical federated AI: pulls model weights from different types of data in different sites\n\\\nAI engineers contributed to several mission-critical domains:\n\\\n\n\nMulti-head AI pipelines\nAsynchronous pipelines for classification, anomaly detection, and schema interpretation, all integrated into a dynamic metadata fabric.\n\\\nSemantic-aware orchestration\nKnowledge graph outputs to PDE boundary inputs, ensuring compute only runs when policies, semantics, and capacity align.\n\\\nZero-trust federation logic\nAI workflows to operate without ever touching raw data—only abstracted metadata fragments.\n\\\nAudit-ready explainability\nDirected acyclic graphs (DAGs) trace each decision back to a semantic label or policy clause, aligning with upcoming EU AI Act requirements.\n\n\n\\\nBehind some of the engineering challenges in this initiative is a team of specialized AI engineers from Upstaff, who could contribute to policy-aware AI infrastructure across domains as sensitive as healthcare and industrial manufacturing.\nResults So Far\nThough still in active development, the project has made several breakthroughs:\n\\\n\nA working alpha prototype of the PDE aggregator with sub-second concurrency response.\nReal-time metadata ingestion and anomaly classification through AI modules.\nFederated learning simulations operating under policy constraints.\nTraceable, explainable orchestration flows through self-documenting DAGs.\nLessons Learned & Engineering Insights\nMath over policies wins: Executable PDEs > static rules\nMetadata is infrastructure: Ontologies replaced scripts\nCompliance must be first-class: Not a feature—an execution condition\nNo-code ≠ Low-trust: Engineers must deeply understand the domain and legal semantics\nWhy This Matters: The Next Wave of AI Infrastructure\n \n\n\\\nThe technical architecture being developed in this project isn’t niche. It’s a preview of where AI and data engineering are headed:\n\\\n\nFederated AI in finance and healthcare\nSemantic interoperability across ESG supply chains\nEphemeral HPC for energy-efficient computing\nMathematical governance over data flows\nConclusion: Engineering Trustworthy AI at Scale\nReal-world AI lives at the intersection of regulation, infrastructure, ethics, and performance. This initiative is a bold attempt to build a system where all those concerns are solved mathematically, structurally, and scalably.\n\\\nCompliance isn’t a document; it’s a boundary condition. And orchestration isn’t a workflow; it’s an equation.",
            "One of the key benefits of open-source software is that anyone can read the source code and inspect what it does. And yet most software, even open-source software, is downloaded in the form of compiled binaries, which are much more difficult to inspect. If an attacker wanted to run a supply chain attack on an open-source project, the least visible way would be to replace the binaries being served while leaving the source code unmodified.\n\\\nThe best way to address this kind of attack is to make open-source software builds reproducible, meaning that a build that starts with the same sources produces the same outputs every time it runs. That way, anyone can verify that posted binaries are free of hidden changes by building from authentic sources and checking that the rebuilt binaries are bit-for-bit identical to the posted binaries. That approach proves the binaries have no backdoors or other changes not present in the source code, without having to disassemble or look inside them at all. Since anyone can verify the binaries, independent groups can easily detect and report supply chain attacks.\n\\\nAs supply chain security becomes more important, so do reproducible builds, because they provide a simple way to verify the posted binaries for open-source projects.\n\\\nGo 1.21.0 is the first Go toolchain with perfectly reproducible builds. Earlier toolchains were possible to reproduce, but only with significant effort, and probably no one did: they just trusted that the binaries posted on go.dev/dl were the correct ones. Now it’s easy to “trust but verify.”\n\\\nThis post explains what goes into making builds reproducible, examines the many changes we had to make to Go to make Go toolchains reproducible, and then demonstrates one of the benefits of reproducibility by verifying the Ubuntu package for Go 1.21.0.\nMaking a Build Reproducible\nComputers are generally deterministic, so you might think all builds would be equally reproducible. That’s only true from a certain point of view. Let’s call a piece of information a relevant input when the output of a build can change depending on that input. A build is reproducible if it can be repeated with all the same relevant inputs. Unfortunately, lots of build tools turn out to incorporate inputs that we would usually not realize are relevant and that might be difficult to recreate or provide as input. Let’s call an input an unintentional input when it turns out to be relevant but we didn’t mean it to be.\n\\\nThe most common unintentional input in build systems is the current time. If a build writes an executable to disk, the file system records the current time as the executable’s modification time. If the build then packages that file using a tool like “tar” or “zip”, the modification time is written into the archive. We certainly didn’t want our build to change based on the current time, but it does. So the current time turns out to be an unintentional input to the build. Worse, most programs don’t let you provide the current time as an input, so there is no way to repeat this build. To fix this, we might set the time stamps on created files to Unix time 0 or to a specific time read from one of the build’s source files. That way, the current time is no longer a relevant input to the build.\n\\\nCommon relevant inputs to a build include:\nthe specific version of the source code to build;\nthe specific versions of dependencies that will be included in the build;\nthe operating system running the build, which may affect path names in the resulting binaries;\nthe architecture of the CPU on the build system, which may affect which optimizations the compiler uses or the layout of certain data structures;\nthe compiler version being used, as well as compiler options passed to it, which affect how the code is compiled;\nthe name of the directory containing the source code, which may appear in debug information;\nthe user name, group name, uid, and gid of the account running the build, which may appear in file metadata in an archive;\nand many more.\n\\\nTo have a reproducible build, every relevant input must be configurable in the build, and then the binaries must be posted alongside an explicit configuration listing every relevant input. If you’ve done that, you have a reproducible build. Congratulations!\n\\\nWe’re not done, though. If the binaries can only be reproduced if you first find a computer with the right architecture, install a specific operating system version, compiler version, put the source code in the right directory, set your user identity correctly, and so on, that may be too much work in practice for anyone to bother.\n\\\nWe want builds to be not just reproducible but easy to reproduce. To do that, we need to identify relevant inputs and then, instead of documenting them, eliminate them. The build obviously has to depend on the source code being built, but everything else can be eliminated. When a build’s only relevant input is its source code, let’s call that perfectly reproducible.\nPerfectly Reproducible Builds for Go\nAs of Go 1.21, the Go toolchain is perfectly reproducible: its only relevant input is the source code for that build. We can build a specific toolchain (say, Go for Linux/x86-64) on a Linux/x86-64 host, or a Windows/ARM64 host, or a FreeBSD/386 host, or any other host that supports Go, and we can use any Go bootstrap compiler, including bootstrapping all the way back to Go 1.4’s C implementation, and we can vary any other details. None of that changes the toolchains that are built. If we start with the same toolchain source code, we will get the exact same toolchain binaries out.\n\\\nThis perfect reproducibility is the culmination of efforts dating back originally to Go 1.10, although most of the effort was concentrated in Go 1.20 and Go 1.21. This section highlights some of the most interesting relevant inputs that we eliminated.\nReproducibility in Go 1.10\nGo 1.10 introduced a content-aware build cache that decides whether targets are up-to-date based on a fingerprint of the build inputs instead of file modification times. Because the toolchain itself is one of those build inputs, and because Go is written in Go, the bootstrap process would only converge if the toolchain build on a single machine was reproducible. The overall toolchain build looks like this:\n\n\\\nWe start by building the sources for the current Go toolchain using an earlier Go version, the bootstrap toolchain (Go 1.10 used Go 1.4, written in C; Go 1.21 uses Go 1.17). That produces “toolchain1”, which we use to build everything again, producing “toolchain2”, which we use to build everything again, producing “toolchain3”.\n\\\nToolchain1 and toolchain2 have been built from the same sources but with different Go implementations (compilers and libraries), so their binaries are certain to be different. However, if both Go implementations are non-buggy, correct implementations, toolchain1 and toolchain2 should behave exactly the same. In particular, when presented with the Go 1.X sources, toolchain1’s output (toolchain2) and toolchain2’s output (toolchain3) should be identical, meaning toolchain2 and toolchain3 should be identical.\n\\\nAt least, that’s the idea. Making that true in practice required removing a couple unintentional inputs:\nRandomness. Map iteration and running work in multiple goroutines serialized with locks both introduce randomness in the order that results may be generated. This randomness can make the toolchain produce one of several different possible outputs each time it runs. To make the build reproducible, we had to find each of these and sort the relevant list of items before using it to generate output.\n\\\nBootstrap Libraries. Any library used by the compiler that can choose from multiple different correct outputs might change its output from one Go version to the next. If that library output change causes a compiler output change, then toolchain1 and toolchain2 will not be semantically identical, and toolchain2 and toolchain3 will not be bit-for-bit identical.\n\\\nThe canonical example is the sort package, which can place elements that compare equal in any order it likes. A register allocator might sort to prioritize commonly used variables, and the linker sorts symbols in the data section by size. To completely eliminate any effect from the sorting algorithm, the comparison function used must never report two distinct elements as equal. In practice, this invariant turned out to be too onerous to impose on every use of sort in the toolchain, so instead we arranged to copy the Go 1.X sort package into the source tree that is presented to the bootstrap compiler. That way, the compiler uses the same sort algorithm when using the bootstrap toolchain as it does when built with itself.\n\\\nAnother package we had to copy was compress/zlib, because the linker writes compressed debug information, and optimizations to compression libraries can change the exact output. Over time, we’ve added other packages to that list too. This approach has the added benefit of allowing the Go 1.X compiler to use new APIs added to those packages immediately, at the cost that those packages must be written to compile with older versions of Go.\nReproducibility in Go 1.20\nWork on Go 1.20 prepared for both easy reproducible builds and toolchain management by removing two more relevant inputs from the toolchain build.\n\\\nHost C toolchain. Some Go packages, most notably net, default to using cgo on most operating systems. In some cases, such as macOS and Windows, invoking system DLLs using cgo is the only reliable way to resolve host names. When we use cgo, though, we invoke the host C toolchain (meaning a specific C compiler and C library), and different toolchains have different compilation algorithms and library code, producing different outputs. The build graph for a cgo package looks like:\n\n\\\nThe host C toolchain is therefore a relevant input to the pre-compiled net.a that ships with the toolchain. For Go 1.20, we decided to fix this by removing net.a from the toolchain. That is, Go 1.20 stopped shipping pre-compiled packages to seed the build cache with. Now, the first time a program uses package net, the Go toolchain compiles it using the local system’s C toolchain and caches that result. \n\\\nIn addition to removing a relevant input from toolchain builds and making toolchain downloads smaller, not shipping pre-compiled packages also makes toolchain downloads more portable. If we build package net on one system with one C toolchain and then compile other parts of the program on a different system with a different C toolchain, in general there is no guarantee that the two parts can be linked together.\n\\\nOne reason we shipped the pre-compiled net package in the first place was to allow building programs that used package net even on systems without a C toolchain installed. If there’s no pre-compiled package, what happens on those systems? The answer varies by operating system, but in all cases we arranged for the Go toolchain to continue to work well for building pure Go programs without a host C toolchain.\n\\\n\nOn macOS, we rewrote package net using the underlying mechanisms that cgo would use, without any actual C code. This avoids invoking the host C toolchain but still emits a binary that refers to the required system DLLs. This approach is only possible because every Mac has the same dynamic libraries installed. Making the non-cgo macOS package net use the system DLLs also meant that cross-compiled macOS executables now use the system DLLs for network access, resolving a long-standing feature request.\n\\\n\nOn Windows, package net already made direct use of DLLs without C code, so nothing needed to be changed.\n\\\n\nOn Unix systems, we cannot assume a specific DLL interface to network code, but the pure Go version works fine for systems that use typical IP and DNS setups. Also, it is much easier to install a C toolchain on Unix systems than it is on macOS and especially Windows. We changed the go command to enable or disable cgo automatically based on whether the system has a C toolchain installed. Unix systems without a C toolchain fall back to the pure Go version of package net, and in the rare cases where that’s not good enough, they can install a C toolchain.\n\\\nHaving dropped the pre-compiled packages, the only part of the Go toolchain that still depended on the host C toolchain was binaries built using package net, specifically the go command. With the macOS improvements, it was now viable to build those commands with cgo disabled, completely removing the host C toolchain as an input, but we left that final step for Go 1.21.\n\\\nHost dynamic linker. When programs use cgo on a system using dynamically linked C libraries, the resulting binaries contain the path to the system’s dynamic linker, something like /lib64/ld-linux-x86-64.so.2. If the path is wrong, the binaries don’t run. Typically each operating system/architecture combination has a single correct answer for this path. Unfortunately, musl-based Linuxes like Alpine Linux use a different dynamic linker than glibc-based Linuxes like Ubuntu. To make Go run at all on Alpine Linux, in Go bootstrap process looked like this:\n\n\\\nThe bootstrap program cmd/dist inspected the local system’s dynamic linker and wrote that value into a new source file compiled along with the rest of the linker sources, effectively hard-coding that default into the linker itself. Then when the linker built a program from a set of compiled packages, it used that default. The result is that a Go toolchain built on Alpine is different from a toolchain built on Ubuntu: the host configuration is a relevant input to the toolchain build. This is a reproducibility problem but also a portability problem: a Go toolchain built on Alpine doesn’t build working binaries or even run on Ubuntu, and vice versa.\n\\\nFor Go 1.20, we took a step toward fixing the reproducibility problem by changing the linker to consult the host configuration when it is running, instead of having a default hard-coded at toolchain build time:\n\n\\\nThis fixed the portability of the linker binary on Alpine Linux, although not the overall toolchain, since the go command still used package net and therefore cgo and therefore had a dynamic linker reference in its own binary. Just as in the previous section, compiling the go command without cgo enabled would fix this, but we left that change for Go 1.21. (We didn’t feel there was enough time left in the Go 1.20 cycle to test such that change properly.)\nReproducibility in Go 1.21\nFor Go 1.21, the goal of perfect reproducibility was in sight, and we took care of the remaining, mostly small, relevant inputs that remained.\n\\\nHost C toolchain and dynamic linker. As discussed above, Go 1.20 took important steps toward removing the host C toolchain and dynamic linker as relevant inputs. Go 1.21 completed the removal of these relevant inputs by building the toolchain with cgo disabled. This improved portability of the toolchain too: Go 1.21 is the first Go release where the standard Go toolchain runs unmodified on Alpine Linux systems.\n\\\nRemoving these relevant inputs made it possible to cross-compile a Go toolchain from a different system without any loss in functionality. That in turn improved the supply chain security of the Go toolchain: we can now build Go toolchains for all target systems using a trusted Linux/x86-64 system, instead of needing to arrange a separate trusted system for each target. As a result, Go 1.21 is the first release to include posted binaries for all systems at go.dev/dl/.\n\\\nSource directory. Go programs include full paths in the runtime and debugging metadata, so that when a program crashes or is run in a debugger, stack traces include the full path to the source file, not just the name of the file in an unspecified directory. Unfortunately, including the full path makes the directory where the source code is stored a relevant input to the build. To fix this, Go 1.21 changed the release toolchain builds to install commands like the compiler using go install -trimpath, which replaces the source directory with the module path of the code. If a released compiler crashes, the stack trace will print paths like cmd/compile/main.go instead of /home/user/go/src/cmd/compile/main.go. \n\\\nSince the full paths would refer to a directory on a different machine anyway, this rewrite is no loss. On the other hand, for non-release builds, we keep the full path, so that when developers working on the compiler itself cause it to crash, IDEs and other tools reading those crashes can easily find the correct source file.\n\\\nHost operating system. Paths on Windows systems are backslash-separated, like cmd\\compile\\main.go. Other systems use forward slashes, like cmd/compile/main.go. Although earlier versions of Go had normalized most of these paths to use forward slashes, one inconsistency had crept back in, causing slightly different toolchain builds on Windows. We found and fixed the bug.\n\\\nHost architecture. Go runs on a variety of ARM systems and can emit code using a software library for floating-point math (SWFP) or using hardware floating-point instructions (HWFP). Toolchains defaulting to one mode or the other will necessarily differ. Like we saw with the dynamic linker earlier, the Go bootstrap process inspected the build system to make sure that the resulting toolchain worked on that system. For historical reasons, the rule was “assume SWFP unless the build is running on an ARM system with floating-point hardware”, with cross-compiled toolchains assuming SWFP. \n\\\nThe vast majority of ARM systems today do have floating-point hardware, so this introduced an unnecessary difference between natively compiled and cross-compiled toolchains, and as a further wrinkle, Windows ARM builds always assumed HWFP, making the decision operating system-dependent. We changed the rule to be “assume HWFP unless the build is running on an ARM system without floating-point hardware”. This way, cross-compilation and builds on modern ARM systems produce identical toolchains.\n\\\nPackaging logic. All the code to create the actual toolchain archives we post for download lived in a separate Git repository, golang.org/x/build, and the exact details of how archives get packaged does change over time. If you wanted to reproduce those archives, you needed to have the right version of that repository. We removed this relevant input by moving the code to package the archives into the main Go source tree, as cmd/distpack. As of Go 1.21, if you have the sources for a given version of Go, you also have the sources for packaging the archives. The golang.org/x/build repository is no longer a relevant input.\n\\\nUser IDs. The tar archives we posted for download were built from a distribution written to the file system, and using tar.FileInfoHeader copies the user and group IDs from the file system into the tar file, making the user running the build a relevant input. We changed the archiving code to clear these.\n\\\nCurrent time. Like with user IDs, the tar and zip archives we posted for download had been built by copying the file system modification times into the archives, making the current time a relevant input. We could have cleared the time, but we thought it would look surprising and possibly even break some tools to use the Unix or MS-DOS zero time. Instead, we changed the go/VERSION file stored in the repository to add the time associated with that version:\n$ cat go1.21.0/VERSION\ngo1.21.0\ntime 2023-08-04T20:14:06Z\n$\n\nThe packagers now copy the time from the VERSION file when writing files to archives, instead of copying the local file’s modification times.\n\\\nCryptographic signing keys. The Go toolchain for macOS won’t run on end-user systems unless we sign the binaries with an Apple-approved signing key. We use an internal system to get them signed with Google’s signing key, and obviously we cannot share that secret key in order to allow others to reproduce the signed binaries. Instead, we wrote a verifier that can check whether two binaries are identical except for their signatures.\n\\\nOS-specific packagers. We use the Xcode tools pkgbuild and productbuild to create the downloadable macOS PKG installer, and we use WiX to create the downloadable Windows MSI installer. We don’t want verifiers to need the same exact versions of those tools, so we took the same approach as for the cryptographic signing keys, writing a verifier that can look inside the packages and check that the toolchain files are exactly as expected.\nVerifying the Go Toolchains\nIt’s not enough to make Go toolchains reproducible once. We want to make sure they stay reproducible, and we want to make sure others can reproduce them easily.\n\\\nTo keep ourselves honest, we now build all Go distributions on both a trusted Linux/x86-64 system and a Windows/x86-64 system. Except for the architecture, the two systems have almost nothing in common. The two systems must produce bit-for-bit identical archives or else we do not proceed with the release.\n\\\nTo allow others to verify that we’re honest, we’ve written and published a verifier, golang.org/x/build/cmd/gorebuild. That program will start with the source code in our Git repository and rebuild the current Go versions, checking that they match the archives posted on go.dev/dl. Most archives are required to match bit-for-bit. As mentioned above, there are three exceptions where a more relaxed check is used:\n\\\n\nThe macOS tar.gz file is expected to differ, but then the verifier compares the contents inside. The rebuilt and posted copies must contain the same files, and all the files must match exactly, except for executable binaries. Executable binaries must match exactly after stripping code signatures.\n\\\n\nThe macOS PKG installer is not rebuilt. Instead, the verifier reads the files inside the PKG installer and checks that they match the macOS tar.gz exactly, again after code signature stripping. In the long term, the PKG creation is trivial enough that it could potentially be added to cmd/distpack, but the verifier would still have to parse the PKG file to run the signature-ignoring code executable comparison.\n\\\n\nThe Windows MSI installer is not rebuilt. Instead, the verifier invokes the Linux program msiextract to extract the files inside and check that they match the rebuilt Windows zip file exactly. In the long term, perhaps the MSI creation could be added to cmd/distpack, and then the verifier could use a bit-for-bit MSI comparison.\n\\\nWe run gorebuild nightly, posting the results at go.dev/rebuild, and of course anyone else can run it too.\nVerifying Ubuntu’s Go Toolchain\nThe Go toolchain’s easily reproducible builds should mean that the binaries in the toolchains posted on go.dev match the binaries included in other packaging systems, even when those packagers build from source. Even if the packagers have compiled with different configurations or other changes, the easily reproducible builds should still make it easy to reproduce their binaries. To demonstrate this, let’s reproduce the Ubuntu golang-1.21 package version 1.21.0-1 for Linux/x86-64.\n\\\nTo start, we need to download and extract the Ubuntu packages, which are ar(1) archives containing zstd-compressed tar archives:\n$ mkdir deb\n$ cd deb\n$ curl -LO http://mirrors.kernel.org/ubuntu/pool/main/g/golang-1.21/golang-1.21-src_1.21.0-1_all.deb\n$ ar xv golang-1.21-src_1.21.0-1_all.deb\nx - debian-binary\nx - control.tar.zst\nx - data.tar.zst\n$ unzstd < data.tar.zst | tar xv\n...\nx ./usr/share/go-1.21/src/archive/tar/common.go\nx ./usr/share/go-1.21/src/archive/tar/example_test.go\nx ./usr/share/go-1.21/src/archive/tar/format.go\nx ./usr/share/go-1.21/src/archive/tar/fuzz_test.go\n...\n$\n\n\\\nThat was the source archive. Now the amd64 binary archive:\n$ rm -f debian-binary *.zst\n$ curl -LO http://mirrors.kernel.org/ubuntu/pool/main/g/golang-1.21/golang-1.21-go_1.21.0-1_amd64.deb\n$ ar xv golang-1.21-src_1.21.0-1_all.deb\nx - debian-binary\nx - control.tar.zst\nx - data.tar.zst\n$ unzstd < data.tar.zst | tar xv | grep -v '/$'\n...\nx ./usr/lib/go-1.21/bin/go\nx ./usr/lib/go-1.21/bin/gofmt\nx ./usr/lib/go-1.21/go.env\nx ./usr/lib/go-1.21/pkg/tool/linux_amd64/addr2line\nx ./usr/lib/go-1.21/pkg/tool/linux_amd64/asm\nx ./usr/lib/go-1.21/pkg/tool/linux_amd64/buildid\n...\n$\n\n\\\nUbuntu splits the normal Go tree into two halves, in /usr/share/go-1.21 and /usr/lib/go-1.21. Let’s put them back together:\n$ mkdir go-ubuntu\n$ cp -R usr/share/go-1.21/* usr/lib/go-1.21/* go-ubuntu\ncp: cannot overwrite directory go-ubuntu/api with non-directory usr/lib/go-1.21/api\ncp: cannot overwrite directory go-ubuntu/misc with non-directory usr/lib/go-1.21/misc\ncp: cannot overwrite directory go-ubuntu/pkg/include with non-directory usr/lib/go-1.21/pkg/include\ncp: cannot overwrite directory go-ubuntu/src with non-directory usr/lib/go-1.21/src\ncp: cannot overwrite directory go-ubuntu/test with non-directory usr/lib/go-1.21/test\n$\n\n\\\nThe errors are complaining about copying symlinks, which we can ignore.\n\\\nNow we need to download and extract the upstream Go sources:\n$ curl -LO https://go.googlesource.com/go/+archive/refs/tags/go1.21.0.tar.gz\n$ mkdir go-clean\n$ cd go-clean\n$ curl -L https://go.googlesource.com/go/+archive/refs/tags/go1.21.0.tar.gz | tar xzv\n...\nx src/archive/tar/common.go\nx src/archive/tar/example_test.go\nx src/archive/tar/format.go\nx src/archive/tar/fuzz_test.go\n...\n$\n\n\\\nTo skip some trial and error, it turns out that Ubuntu builds Go with GO386=softfloat, which forces the use of software floating point when compiling for 32-bit x86, and strips (removes symbol tables from) the resulting ELF binaries. Let’s start with a GO386=softfloat build:\n$ cd src\n$ GOOS=linux GO386=softfloat ./make.bash -distpack\nBuilding Go cmd/dist using /Users/rsc/sdk/go1.17.13. (go1.17.13 darwin/amd64)\nBuilding Go toolchain1 using /Users/rsc/sdk/go1.17.13.\nBuilding Go bootstrap cmd/go (go_bootstrap) using Go toolchain1.\nBuilding Go toolchain2 using go_bootstrap and Go toolchain1.\nBuilding Go toolchain3 using go_bootstrap and Go toolchain2.\nBuilding commands for host, darwin/amd64.\nBuilding packages and commands for target, linux/amd64.\nPackaging archives for linux/amd64.\ndistpack: 818d46ede85682dd go1.21.0.src.tar.gz\ndistpack: 4fcd8651d084a03d go1.21.0.linux-amd64.tar.gz\ndistpack: eab8ed80024f444f v0.0.1-go1.21.0.linux-amd64.zip\ndistpack: 58528cce1848ddf4 v0.0.1-go1.21.0.linux-amd64.mod\ndistpack: d8da1f27296edea4 v0.0.1-go1.21.0.linux-amd64.info\n---\nInstalled Go for linux/amd64 in /Users/rsc/deb/go-clean\nInstalled commands in /Users/rsc/deb/go-clean/bin\n*** You need to add /Users/rsc/deb/go-clean/bin to your PATH.\n$\n\n\\\nThat left the standard package in pkg/distpack/go1.21.0.linux-amd64.tar.gz. Let’s unpack it and strip the binaries to match Ubuntu:\n$ cd ../..\n$ tar xzvf go-clean/pkg/distpack/go1.21.0.linux-amd64.tar.gz\nx go/CONTRIBUTING.md\nx go/LICENSE\nx go/PATENTS\nx go/README.md\nx go/SECURITY.md\nx go/VERSION\n...\n$ elfstrip go/bin/* go/pkg/tool/linux_amd64/*\n$\n\n\\\nNow we can diff the Go toolchain we’ve created on our Mac with the Go toolchain that Ubuntu ships:\n$ diff -r go go-ubuntu\nOnly in go: CONTRIBUTING.md\nOnly in go: LICENSE\nOnly in go: PATENTS\nOnly in go: README.md\nOnly in go: SECURITY.md\nOnly in go: codereview.cfg\nOnly in go: doc\nOnly in go: lib\nBinary files go/misc/chrome/gophertool/gopher.png and go-ubuntu/misc/chrome/gophertool/gopher.png differ\nOnly in go-ubuntu/pkg/tool/linux_amd64: dist\nOnly in go-ubuntu/pkg/tool/linux_amd64: distpack\nOnly in go/src: all.rc\nOnly in go/src: clean.rc\nOnly in go/src: make.rc\nOnly in go/src: run.rc\ndiff -r go/src/syscall/mksyscall.pl go-ubuntu/src/syscall/mksyscall.pl\n1c1\n< #!/usr/bin/env perl\n---\n> #! /usr/bin/perl\n...\n$\n\nWe’ve successfully reproduced the Ubuntu package’s executables and identified the complete set of changes that remain:\nVarious metadata and supporting files have been deleted.\n\\\n\nThe gopher.png file has been modified. On closer inspection the two are identical except for an embedded timestamp that Ubuntu has updated. Perhaps Ubuntu’s packaging scripts recompressed the png with a tool that rewrites the timestamp even when it cannot improve on the existing compression.\n\\\n\nThe binaries dist and distpack, which are built during bootstrap but not included in standard archives, have been included in the Ubuntu package.\n\\\n\nThe Plan 9 build scripts (*.rc) have been deleted, although the Windows build scripts (*.bat) remain.\n\\\n\nmksyscall.pl and seven other Perl scripts not shown have had their headers changed.\n\\\nNote in particular that we’ve reconstructed the toolchain binaries bit-for-bit: they do not show up in the diff at all. That is, we proved that the Ubuntu Go binaries correspond exactly to the upstream Go sources.\n\\\nEven better, we proved this without using any Ubuntu software at all: these commands were run on a Mac, and unzstd and elfstrip are short Go programs. A sophisticated attacker might insert malicious code into an Ubuntu package by changing the package-creation tools. If they did, reproducing the Go Ubuntu package from clean sources using those malicious tools would still produce bit-for-bit identical copies of the malicious packages. \n\\\nThis attack would be invisible to that kind of rebuild, much like Ken Thompson’s compiler attack. Verifying the Ubuntu packages using no Ubuntu software at all is a much stronger check. Go’s perfectly reproducible builds, which don’t depend on unindented details like the host operating system, host architecture, and host C toolchain, are what make this stronger check possible.\n\\\n(As an aside for the historical record, Ken Thompson told me once that his attack was in fact detected, because the compiler build stopped being reproducible. It had a bug: a string constant in the backdoor added to the compiler was imperfectly handled and grew by a single NUL byte each time the compiler compiled itself. Eventually someone noticed the non-reproducible build and tried to find the cause by compiling to assembly. The compiler’s backdoor did not reproduce itself into assembly output at all, so assembling that output removed the backdoor.)\nConclusion\nReproducible builds are an important tool for strengthening the open-source supply chain. Frameworks like SLSA focus on provenance and a software chain of custody that can be used to inform decisions about trust. Reproducible builds complement that approach by providing a way to verify that the trust is well-placed.\n\\\nPerfect reproducibility (when the source files are the build’s only relevant input) is only possible for programs that build themselves, like compiler toolchains. It is a lofty but worthwhile goal precisely because self-hosting compiler toolchains are otherwise quite difficult to verify. Go’s perfect reproducibility means that, assuming packagers don’t modify the source code, every repackaging of Go 1.21.0 for Linux/x86-64 (substitute your favorite system) in any form should be distributing exactly the same binaries, even when they all build from source. We’ve seen that this is not quite true for Ubuntu Linux, but perfect reproducibility still lets us reproduce the Ubuntu packaging using a very different, non-Ubuntu system.\n\\\nIdeally all open source software distributed in binary form would have easy-to-reproduce builds. In practice, as we’ve seen in this post, it is very easy for unintended inputs to leak into builds. For Go programs that don’t need cgo, a reproducible build is as simple as compiling with CGO_ENABLED=0 go build -trimpath. Disabling cgo removes the host C toolchain as a relevant input, and -trimpath removes the current directory. If your program does need cgo, you need to arrange for a specific host C toolchain version before running go build, such as by running the build in a specific virtual machine or container image.\n\\\nMoving beyond Go, the Reproducible Builds project aims to improve reproducibility of all open source and is a good starting point for more information about making your own software builds reproducible.\nRuss Cox\n\\\nPhoto by Alex Pudov on Unsplash\n\\\nThis article is available on The Go Blog under a CC BY 4.0 DEED license."
          ],
          "link": [
            "https://www.wired.com/story/nintendo-switch-2-biggest-problem-is-already-storage/",
            "https://www.wired.com/gallery/best-barefoot-shoes/",
            "https://www.wired.com/story/what-happens-to-your-data-if-you-stop-paying-for-cloud-storage/",
            "https://www.wired.com/story/efforts-to-ground-physics-in-math-are-opening-the-secrets-of-time/",
            "https://www.wired.com/gallery/best-outdoor-security-cameras/",
            "https://www.wired.com/story/how-to-clean-your-mattress/",
            "https://techcrunch.com/2025/08/03/apple-might-be-building-its-own-ai-answer-engine/",
            "https://techcrunch.com/2025/08/03/mastercard-denies-pressuring-game-platforms-valve-tells-a-different-story/",
            "https://techcrunch.com/2025/08/03/sap-is-acquiring-smartrecruiters/",
            "https://techcrunch.com/2025/08/03/inside-openais-quest-to-make-ai-do-anything-for-you/",
            "https://techcrunch.com/2025/08/03/the-uproar-over-vogues-ai-generated-ad-isnt-just-about-fashion/",
            "https://www.marktechpost.com/2025/08/04/7-essential-layers-for-building-real-world-ai-agents-in-2025-a-comprehensive-framework/",
            "https://www.marktechpost.com/2025/08/03/bytedance-introduces-seed-prover-an-advanced-formal-reasoning-system-for-automated-mathematical-theorem-proving/",
            "https://www.marktechpost.com/2025/08/03/tutorial-exploring-shap-iq-visualizations/",
            "https://www.marktechpost.com/2025/08/03/a-technical-roadmap-to-context-engineering-in-llms-mechanisms-benchmarks-and-open-challenges/",
            "https://www.marktechpost.com/2025/08/03/the-ultimate-guide-to-cpus-gpus-npus-and-tpus-for-ai-ml-performance-use-cases-and-key-differences/",
            "https://www.marktechpost.com/2025/08/03/building-an-end-to-end-object-tracking-and-analytics-system-with-roboflow-supervision/",
            "https://hackernoon.com/the-impossibility-theorem-behind-truthful-blockchain-bidding-mechanisms?source=rss",
            "https://hackernoon.com/no-blockchain-auction-can-satisfy-uic-mic-and-global-scp-at-once?source=rss",
            "https://hackernoon.com/what-is-a-transaction-fee-mechanism-definitions-incentives-and-strategies?source=rss",
            "https://hackernoon.com/why-no-transaction-fee-mechanism-can-truly-be-collusion-proof?source=rss",
            "https://hackernoon.com/why-truthful-blockchain-mechanisms-fail-under-finite-block-sizes?source=rss",
            "https://hackernoon.com/why-the-perfect-blockchain-fee-mechanism-may-be-impossible?source=rss",
            "https://hackernoon.com/designing-for-intelligence-efficiency-and-accessibility?source=rss",
            "https://hackernoon.com/sdg-lab-venture-fund-backs-virtual-intimacy-with-$20-million-but-will-it-work?source=rss",
            "https://hackernoon.com/8-3-2025-newsletter?source=rss",
            "https://hackernoon.com/mobile-ai-with-onnx-runtime-how-to-build-real-time-noise-suppression-that-works?source=rss",
            "https://hackernoon.com/the-real-reason-most-indie-games-flop-it-has-nothing-to-do-with-gameplay?source=rss",
            "https://hackernoon.com/10-ways-ai-is-shaping-the-future-of-mobile-app-development?source=rss",
            "https://hackernoon.com/solving-coding-puzzles-the-evolution-of-programmer-assistance-tools?source=rss",
            "https://hackernoon.com/the-hidden-cost-of-performance-how-high-load-specialization-warps-engineering-intuition?source=rss",
            "https://hackernoon.com/can-anyone-code-now-exploring-ai-help-for-non-programmers?source=rss",
            "https://hackernoon.com/europes-data-vision-dataspaces-for-zero-trust-ai-infrastructure?source=rss",
            "https://hackernoon.com/reproducible-go-toolchains-what-you-need-to-know?source=rss"
          ],
          "categories": [
            "[\"Gear\",\"Gear / Gear News and Events\",\"Gear / Products / Gaming\",\"Gear / Trends\"]",
            "[\"Gear\",\"Gear / Buying Guides\",\"Gear / Products / Health and Fitness\",\"Gear / Products / Outdoor\"]",
            "[\"Gear\",\"Gear / Gear News and Events\"]",
            "[\"Science\",\"Science / Physics and Math\"]",
            "[\"Gear\",\"Gear / Buying Guides\",\"Gear / Products / Smart Home\",\"Gear / Products / Home\"]",
            "[\"Gear\",\"Gear / How To and Advice\",\"Gear / Products / Sleep\"]",
            "[\"AI\",\"Apple\",\"siri\"]",
            "[\"Gaming\",\"Government & Policy\",\"Media & Entertainment\",\"itch.io\",\"mastercard\",\"Steam\"]",
            "[\"Enterprise\",\"sap\",\"smartrecruiters\"]",
            "[\"AI\",\"Exclusive\",\"OpenAI\",\"ChatGPT\",\"agents\"]",
            "[\"Media & Entertainment\",\"AI\",\"Fashion\",\"vogue\",\"guess\",\"digital fashion models\"]",
            "[\"Agentic AI\",\"AI Agents\",\"Editors Pick\",\"Staff\",\"Tech News\"]",
            "[\"AI Paper Summary\",\"AI Shorts\",\"Applications\",\"Artificial Intelligence\",\"Editors Pick\",\"Staff\",\"Tech News\",\"Technology\"]",
            "[\"Artificial Intelligence\",\"Editors Pick\",\"Machine Learning\",\"Staff\",\"Technology\",\"Tutorials\"]",
            "[\"Context Engineering\",\"Editors Pick\",\"Staff\",\"Uncategorized\"]",
            "[\"AI Infrastructure\",\"Artificial Intelligence\",\"Editors Pick\",\"Staff\",\"Technology\"]",
            "[\"Artificial Intelligence\",\"Editors Pick\",\"Machine Learning\",\"Staff\",\"Tech News\",\"Technology\",\"Tutorials\"]",
            "[\"blockchain-scalability\",\"transaction-fee-mechanisms\",\"ethereum-eip-1559\",\"user-incentive-compatibility\",\"miner-incentive-compatibility\",\"oca-proofness\",\"side-contract-proofness\",\"auction-mechanisms\"]",
            "[\"blockchain-scalability\",\"transaction-fee-mechanisms\",\"ethereum-eip-1559\",\"user-incentive-compatibility\",\"miner-incentive-compatibility\",\"oca-proofness\",\"side-contract-proofness\",\"auction-mechanisms\"]",
            "[\"blockchain-scalability\",\"transaction-fee-mechanisms\",\"ethereum-eip-1559\",\"user-incentive-compatibility\",\"miner-incentive-compatibility\",\"oca-proofness\",\"side-contract-proofness\",\"auction-mechanisms\"]",
            "[\"blockchain-scalability\",\"transaction-fee-mechanisms\",\"ethereum-eip-1559\",\"user-incentive-compatibility\",\"miner-incentive-compatibility\",\"oca-proofness\",\"side-contract-proofness\",\"auction-mechanisms\"]",
            "[\"blockchain-scalability\",\"transaction-fee-mechanisms\",\"ethereum-eip-1559\",\"user-incentive-compatibility\",\"miner-incentive-compatibility\",\"oca-proofness\",\"side-contract-proofness\",\"auction-mechanisms\"]",
            "[\"blockchain-scalability\",\"transaction-fee-mechanisms\",\"ethereum-eip-1559\",\"user-incentive-compatibility\",\"collusion-resilience\",\"oca-proofness\",\"auction-mechanisms\",\"hackernoon-top-story\"]",
            "[\"ux-design\",\"ai-in-ux-design\",\"intelligent-ux-systems\",\"accessible-design-with-ai\",\"adaptive-user-interfaces\",\"predictive-ux-design\",\"frictionless-user-experiences\",\"ux-design-trends-2025\"]",
            "[\"virtual-intimacy\",\"ai-dating\",\"sdg-lab-venture-fund\",\"the-loneliness-epidemic\",\"ai-and-human-connection\",\"emotional-ai\",\"tech-and-loneliness\",\"good-company\"]",
            "[\"hackernoon-newsletter\",\"noonification\",\"latest-tect-stories\",\"immutable-backups\",\"ai-agent\",\"ai-design\",\"web3-ux\",\"cybersecurity\",\"filestack\",\"st.-john's-university-backup\",\"ai\"]",
            "[\"mobile-ai\",\"onnx-runtime\",\"on-device-ai\",\"mobile-ai-performance\",\"android-ai-sdk\",\"dtln-noise-reduction\",\"lightweight-ai-deployment\",\"onnx-runtime-android\"]",
            "[\"gaming\",\"game-discovery\",\"indie-game-marketing\",\"mobile-game-visibility\",\"game-development\",\"game-distribution-strategy\",\"app-store-visibility-hacks\",\"game-launch-strategy-2025\"]",
            "[\"ai-mobile-app-development\",\"mobile-app-development\",\"ai-trends\",\"predictive-mobile-ux\",\"generative-ai-apps\",\"cross-platform-ai-apps\",\"custom-app-development\",\"good-company\"]",
            "[\"large-language-models\",\"ai-assisted-programming\",\"github-copilot\",\"code-generation\",\"programmer-assistance\",\"end-user-programming\",\"usability-studies\",\"inferential-assistance\"]",
            "[\"engineering-teams\",\"system-design\",\"performance-optimization\",\"tech-leadership\",\"high-load-systems\",\"crud-backend-scaling\",\"software-architecture\",\"software-engineering\"]",
            "[\"large-language-models\",\"ai-assisted-programming\",\"github-copilot\",\"code-generation\",\"programmer-assistance\",\"end-user-programming\",\"usability-studies\",\"inferential-assistance\"]",
            "[\"ai-infrastructure\",\"zero-trust-ai\",\"pde\",\"zero-trust\",\"federated-ai\",\"zero-trust-metadata\",\"what-is-federated-ai\",\"europe-data-vision\"]",
            "[\"go\",\"golang\",\"go-toolchains\",\"what-are-go-tool-chains\",\"reproducible-builds\",\"reproducibility-in-go\",\"hackernoon-top-story\",\"host-dynamic-linker\"]"
          ]
        }
      }
    ],
    "Create Comprehensive Prompt": [
      {
        "json": {
          "topic": "Can Anyone Code Now? Exploring AI Help for Non-Programmers",
          "prompt": "Write a comprehensive, well-researched blog post about Can Anyone Code Now? Exploring AI Help for Non-Programmers in markdown format.\n\nPlease create a detailed blog post with the following structure:\n1. An engaging introduction that hooks the reader\n2. Main content sections with clear subheadings (use ## for main sections, ### for subsections)\n3. Include relevant examples, case studies, or practical applications\n4. If it's a technical topic, include code examples with proper syntax highlighting\n5. Add tips, best practices, or actionable advice where appropriate\n6. A strong conclusion that summarizes key points\n\nWriting Guidelines:\n- Write 1000-1500 words minimum\n- Use a professional yet accessible tone\n- Include bullet points or numbered lists where helpful\n- Add relevant external linking suggestions (use placeholder links)\n- Make it SEO-friendly with natural keyword usage\n- Ensure content is original and valuable to readers\n- Use Bahasa Indonesia\n\nIMPORTANT: \n- Do NOT include frontmatter (title, date, etc.) - this will be added separately\n- Start directly with the introduction\n- Use proper markdown formatting\n- Make the content engaging and informative"
        }
      }
    ],
    "input query": [
      {
        "json": {
          "ContextFinal": "Can Anyone Code Now? Exploring AI Help for Non-Programmers",
          "index": 31
        }
      }
    ],
    "Title": [
      {
        "json": {
          "id": "gen-1754293212-Uo2LRYuJagYLXbtnZrAt",
          "provider": "Targon",
          "model": "deepseek/deepseek-chat-v3-0324:free",
          "object": "chat.completion",
          "created": 1754293212,
          "choices": [
            {
              "logprobs": null,
              "finish_reason": "stop",
              "native_finish_reason": "stop",
              "index": 0,
              "message": {
                "role": "assistant",
                "content": "```json\n{\"judul\":\"AI untuk Coding: Bisakah Semua Orang Sekarang Koding?\"}\n```",
                "refusal": null,
                "reasoning": null
              }
            }
          ],
          "usage": {
            "prompt_tokens": 149,
            "completion_tokens": 24,
            "total_tokens": 173,
            "prompt_tokens_details": null
          }
        }
      }
    ],
    "Open Router Chat": [
      {
        "json": {
          "id": "gen-1754293296-heRYjiPYQqAE1wSRHBtq",
          "provider": "Chutes",
          "model": "deepseek/deepseek-r1-0528:free",
          "object": "chat.completion",
          "created": 1754293296,
          "choices": [
            {
              "logprobs": null,
              "finish_reason": "stop",
              "native_finish_reason": "stop",
              "index": 0,
              "message": {
                "role": "assistant",
                "content": "## Tembok Koding Ambruk! Benarkah Sekarang Siapa Pun Bisa Menjadi Programmer Berkat AI?\n\nBayangkan Anda bisa membuat aplikasi hanya dengan berbicara, menyusun script otomatisasi lewat perintah santai, atau membangun website tanpa pernah mengetikkan satu baris sintaks. Dulu, ini terdengar seperti fiksi ilmiah. Tapi era AI generative telah mengubahnya menjadi kenyataan—membuka dunia pemrograman bagi jutaan non-teknis. Lantas, benarkah kini siapa pun bisa \"coding\"? Mari selami revolusi ini!\n\nAI coding assistant—seperti ChatGPT, GitHub Copilot, dan Google Bard—tidak sekadar alat baru, tapi juru terjemah yang menghubungkan bahasa manusia dengan bahasa mesin. Mereka memahami perintah alami (seperti \"Buatkan kode untuk mengekstrak semua email dari dokumen Word dan simpan ke spreadsheet\") lalu menghasilkan sintaks yang relevan. Kini, batas antara \"programmer\" dan \"non-programmer\" semakin kabur.\n\n## Bagaimana AI Mengubah Permainan untuk Pemula?\n\n### From Zero to \"Hello World\": Menghancurkan Rintangan Pertama\nBagi pemula, mencoba koding sering kali seperti belajar menyelam di lautan sintaks. Tools berbasis AI mematahkan penghalang ini dengan:\n- **Translator bahasa manusia → kode**: Ketikkan logika bisnis atau deskripsi fitur dalam bahasa sehari-hari, AI meramu kodenya.\n- **Tutor interaktif 24/7**: Meminta penjelasan konsep seperti *loops* atau *APIs* dengan contoh kontekstual.\n- *Contoh Praktis*:  \n  Permintaan ke ChatGPT: *\"Buat function JavaScript untuk validasi email*\"  \n  Output:  \n  ```javascript\n  function validateEmail(email) {\n    const regex = /^[^\\s@]+@[^\\s@]+\\.[^\\s@]+$/;\n    return regex.test(email);\n  }\n  ```\n\n### Katalis Produktivitas: Dari Tugas Repetitif ke Solusi Kompleks\nAI mempercepat pengembangan bahkan bagi non-programmer:\n- **Generasi boilerplate code**: Membuat struktur dasar proyek via perintah sederhana.\n- **Debugging bahasa manusia**: Jelaskan error (*\"Program gagal ketika inpu kosong\"*), AI sarankan perbaikan.\n- **Otomatisasi sehari-hari**: Script untuk backup data, scraping web, atau olah spreadsheet.\n\n## Konteks Nyata: Kisah Sukses Non-Programmer\nBukti nyata revolusi ini sudah bersemi:\n\n- **Kasus Wharton School**: Mahasiswa MBA menggunakan ChatGPT membangun aplikasi startup dalam hitungan jam—tanpa latar belakang teknis. Hasil? Prototipe layak untuk demo investor.  \n- **Story of Sarah (Pemilik UKM)**: Membuat website katalog produk dengan ChatGPT + tools *no-code* seperti Bubble. Hanya perlu mendeskripsikan layout dan fungsionalitas.  \n- **Riset Gartner**: Memproyeksikan >50% pengguna tools *low-code/no-code* adalah \"citizen developer\" (non-IT) pada 2026.\n\n## Tantangan: Keterbatasan yang Perlu Diakui\nAI coding bukan solusi ajaib. Sadari limitasi:\n- **Sintaks ≠ Pemahaman Logika**: Kode bisa *running* tapi tidak optimal atau mengandung bias logis.\n- **Quality Variance**: Output 89% akurat pada skenario umum, namun berpeluang error pada kasus niche.\n- **Jebakan Ketergantungan**: Tanpa fondasi pemahaman dasar, koreksi bug oleh AI menjadi sulit diikuti.\n\n## Strategi Sukses untuk Non-Programmer yang Memanfaatkan AI\n### Prinsip Penting\n- **Be Hyper-Spesifik**:  \n  Contoh buruk: *\"Buat kode Python\"*  \n  Contoh baik: *\"Buat kode Python untuk compare dua file CSV, tampilkan baris berbeda beserta nama kolomnya\"*\n- **Iterate Don’t Hype**: Kode AI adalah draft pertama, uji coba dan minta revisi (*\"Tambahkan fitur ekspor output ke Google Sheets\"*).\n- **Learn Core Concepts**: Kuasai dasar seperti variabel, conditional (if-else), loops. Sumber: [freeCodeCamp](https://freecodecamp.org) | [Dicoding](https://dicoding.com).\n\n### Toolbox Penting untuk Pemula\n- **AI Coding Assistants**:  \n  - GitHub Copilot [https://copilot.github.com/](https://copilot.github.com/) (*integrasi IDE*)  \n  - ChatGPT [https://chat.openai.com/](https://chat.openai.com/) (*versi gratis sudah cukup untuk eksplorasi*)  \n- **No-Code Suplementer**:  \n  - Bubble: Permak kode ke antarmukamenarik  \n  - Zapier: Otomasi dukungan bagian backend  \n- **Debugging Helper**:  \n  - Replit AI: Jelaskan error dengan natural language [https://replit.com/site/ai](https://replit.com/site/ai)\n\n## Masa Depan: Dalam Tangan \"Citizen Developer\"\nEvolusi akan mendekatkan pemrograman ke khalayak luas:\n- **Bahasa Natural sebagai Antarmuka Utama**: Berdialog dengan AI untuk pengembangan kompleks.\n- **AI Terfokus Domain**: Asisten khusus bidang (kesehatan, finansial) yang pahami konteks jargon.\n- **Edukasi Berbasis Simulasi**: Startup seperti Mimo [https://mimo.org](https://mimo.org) menggunakan AI buat kurikulum responsif.\n\n## Penutup: Ya, Anda Bisa Mulai Koding—Asal Ada \"AI Copilot\"\nJawabannya jelas: Ya, siapa pun dapat menghasilkan kode hari ini berkat AI. Tapi drumben revolusi ini bukan penghapusan belajar, melainkan demokratisasi akses. Fondasi logika tetap krusial, namun rintangan teknis tak lagi jadi penghadang.  \n\n**Kuncinya? Pendekatan hybrid**:  \n- Gunakan AI sebagai pelecut konsep hingga generasi draf kode.  \n- Kuasai prinsip dasar untuk menganalisis dan mengadaptasi output.  \n- Fokus pada **problem-solving** ketimbang hafalan sintaks.  \n\nDunia membutuhkan lebih banyak pemecah masalah—bukan hanya programmer. Mulailah dengan tantangan kecil hari ini: otomasi pembuatan laporan, landing page toko online, atau pemrosesan data. Teknologi sudah siap mendampingi Anda. *Code* adalah bahasa baru literasi. Dan sekarang, kamusnya ada di genggaman Anda.  \n\n> \"Di era AI, yang vital bukanlah *menulis setiap baris kode*, tapi **mempersembahkan nilai** di belakangnya.\"",
                "refusal": null,
                "reasoning": "We are writing in Bahasa Indonesia, so the entire content will be in Indonesian.\n The structure:\n 1. Introduction\n 2. Main sections with subheadings (use ## and ###)\n 3. Examples, case studies, practical applications\n 4. If technical, code examples with syntax highlighting (even for non-programmers, we'll show how AI tools generate code)\n 5. Tips, best practices\n 6. Conclusion\n\n The topic: \"Can Anyone Code Now? Exploring AI Help for Non-Programmers\"\n\n Word count: 1000-1500 words\n\n Let's outline the sections:\n\n ## Pendahuluan: Dunia Pemrograman yang Terbuka untuk Semua\n   - Hook: Pernahkah Anda merasa ingin membuat aplikasi, situs web, atau mengotomatiskan tugas tapi terhalang karena tidak bisa coding?\n   - Perkembangan AI telah membuka pintu bagi non-programmer untuk dapat menciptakan solusi digital.\n\n ## Bagaimana AI Membantu Non-Programmer dalam Coding?\n   - AI sebagai penerjemah: mengubah bahasa alami menjadi kode\n   - Tools populer: GitHub Copilot, ChatGPT, Google Gemini, dll.\n   - Contoh: Meminta AI untuk membuatkan kode dalam bahasa tertentu\n\n ## Contoh Praktis: Dari Permintaan ke Kode\n   ### Contoh 1: Membuat script sederhana untuk otomatisasi\n     - Permintaan: \"Buatkan script Python yang membaca file Excel dan mengirim email dengan lampiran\"\n     - Potongan kode hasil AI (dengan penjelasan sederhana)\n\n   ### Contoh 2: Membuat website tanpa coding\n     - Permintaan: \"Buatkan kode HTML, CSS, JavaScript untuk halaman landing page sederhana\"\n     - AI memberikan kode, dan non-programmer hanya perlu menyalin dan menjalankan\n\n ## Case Study: Kisah Sukses Non-Programmer yang Menggunakan AI untuk Coding\n   - Narasi tentang seseorang tanpa latar belakang pemrograman berhasil membuat aplikasi atau alat bantu dengan bantuan AI.\n   - Contoh: Seorang guru yang membuat aplikasi kuis untuk muridnya dengan bantuan ChatGPT.\n\n ## Menavigasi Tantangan dan Keterbatasan\n   - AI tidak sempurna: kode mungkin mengandung bug atau tidak sesuai harapan\n   - Perlunya pemahaman dasar untuk debugging dan penyesuaian\n   - Isu etika: plagiarisme kode, hak cipta, dan keamanan\n\n ## Tips untuk Non-Programmer yang Ingin Mulai Coding dengan AI\n   - Mulai dengan tujuan kecil dan spesifik\n   - Jelaskan dengan jelas dan rinci permintaan ke AI\n   - Pelajari dasar-dasar pemrograman (variabel, kondisi, loop) untuk memahami output AI\n   - Gunakan tools dengan fitur debugging dan penjelasan kode\n   - Bergabung dengan komunitas untuk bertanya\n\n ## Masa Depan: Coding dengan AI - Ke Mana Arahnya?\n   - Prediksi tren: AI semakin cerdas, interaksi semakin natural\n   - Peran non-programmer dalam pengembangan perangkat lunak\n   - Transformasi pendidikan pemrograman\n\n ## Kesimpulan\n   - AI membuat coding dapat diakses oleh siapapun, tetapi pemahaman dasar tetap penting\n   - Ajakan untuk mencoba: Siapa tahu Anda adalah programmer berikutnya?\n\n We'll use Indonesian language throughout. Let's write with a professional yet friendly tone.\n\n Note: We are to use placeholder links, like [link-to-github-copilot] for external links.\n\n Let's write.\n"
              }
            }
          ],
          "usage": {
            "prompt_tokens": 247,
            "completion_tokens": 2321,
            "total_tokens": 2568
          }
        }
      }
    ],
    "parsed json": [
      {
        "json": {
          "judul": "AI untuk Coding: Bisakah Semua Orang Sekarang Koding?"
        }
      }
    ],
    "Send a text message1": [
      {
        "json": {
          "ok": true,
          "result": {
            "message_id": 316,
            "from": {
              "id": 7695897574,
              "is_bot": true,
              "first_name": "Yumana",
              "username": "YumanaBot"
            },
            "chat": {
              "id": 1282266650,
              "first_name": "Yuma",
              "last_name": "Nur Alfath",
              "username": "yumana20",
              "type": "private"
            },
            "date": 1754293295,
            "text": "꧁𓊈𒆜AI untuk Coding: Bisakah Semua Orang Sekarang Koding?𒆜𓊉꧂\n──── ୨୧ ────\nCan Anyone Code Now? Exploring AI Help for Non-Programmers\n────୨ৎ────\n\nThis message was sent automatically with n8n",
            "entities": [
              {
                "offset": 148,
                "length": 41,
                "type": "italic"
              },
              {
                "offset": 189,
                "length": 3,
                "type": "text_link",
                "url": "https://n8n.io/?utm_source=n8n-internal&utm_medium=powered_by&utm_campaign=n8n-nodes-base.telegram_5ce5c7bb69689bb5026a039f71db56efa2d930850a7172513b11beb1d0cdb7c3"
              }
            ],
            "link_preview_options": {
              "is_disabled": true
            }
          }
        }
      }
    ]
  },
  "connections": {
    "Schedule Trigger": {
      "main": [
        [
          {
            "node": "Set Tech News RSS Feeds",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Google_trends search": {
      "main": [
        []
      ]
    },
    "Telegram Trigger": {
      "main": [
        [
          {
            "node": "If",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "If": {
      "main": [
        [
          {
            "node": "Set Tech News RSS Feeds",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Send a text message",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Random Related Query": {
      "main": [
        [
          {
            "node": "Send valid query gacha",
            "type": "main",
            "index": 0
          },
          {
            "node": "Create Comprehensive Prompt",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Save Related Query": {
      "main": [
        []
      ]
    },
    "Create Comprehensive Prompt": {
      "main": [
        [
          {
            "node": "Open Router Chat",
            "type": "main",
            "index": 0
          },
          {
            "node": "Title",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Open Router Chat": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Select Topic": {
      "main": [
        [
          {
            "node": "Google search",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Markdown Output": {
      "main": [
        [
          {
            "node": "Send message and wait for response1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Github Trigger": {
      "main": [
        [
          {
            "node": "Send a text message2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Create a blog post": {
      "main": [
        [
          {
            "node": "check github",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "check github": {
      "main": [
        [
          {
            "node": "Send a text message3",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Send a text message4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Title Search": {
      "main": [
        []
      ]
    },
    "parsed json": {
      "main": [
        [
          {
            "node": "Send a text message1",
            "type": "main",
            "index": 0
          },
          {
            "node": "Merge",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge": {
      "main": [
        [
          {
            "node": "Random Category",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "HTTP Request": {
      "main": [
        [
          {
            "node": "Markdown Output",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Select Menu": {
      "main": [
        [
          {
            "node": "If1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "If1": {
      "main": [
        [
          {
            "node": "input query",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Random Related Query",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "input query": {
      "main": [
        [
          {
            "node": "Create Comprehensive Prompt",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Google search": {
      "main": [
        [
          {
            "node": "Save Related Query",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Send a text message1": {
      "main": [
        []
      ]
    },
    "Send valid query gacha": {
      "main": [
        []
      ]
    },
    "Title": {
      "main": [
        [
          {
            "node": "parsed json",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Send message and wait for response1": {
      "main": [
        [
          {
            "node": "If4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "If4": {
      "main": [
        [
          {
            "node": "Send a text message5",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Create a blog post",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Github Trigger1": {
      "main": [
        [
          {
            "node": "Send a text message7",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Filter": {
      "main": [
        [
          {
            "node": "Set and Normalize Fields",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Split Out": {
      "main": [
        [
          {
            "node": "Read RSS News Feeds",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Read RSS News Feeds": {
      "main": [
        [
          {
            "node": "Filter",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Set Tech News RSS Feeds": {
      "main": [
        [
          {
            "node": "Split Out",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Set and Normalize Fields": {
      "main": [
        [
          {
            "node": "Aggregate",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Aggregate": {
      "main": [
        [
          {
            "node": "Select Menu",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Random Category": {
      "main": [
        [
          {
            "node": "HTTP Request",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": true,
  "settings": {
    "executionOrder": "v1",
    "timezone": "Asia/Jakarta",
    "saveDataErrorExecution": "none",
    "saveManualExecutions": false,
    "callerPolicy": "workflowsFromSameOwner",
    "timeSavedPerExecution": 60
  },
  "versionId": "565836d2-8cb7-4cd7-a2f4-74b6e6c848af",
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "5ce5c7bb69689bb5026a039f71db56efa2d930850a7172513b11beb1d0cdb7c3"
  },
  "id": "KdU2iI9yqxmpmlTM",
  "tags": []
}